<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE ep-patent-document PUBLIC "-//EPO//EP PATENT DOCUMENT 1.5.1//EN" "ep-patent-document-v1-5-1.dtd">
<!-- This XML data has been generated under the supervision of the European Patent Office -->
<ep-patent-document id="EP20167885A1" file="EP20167885NWA1.xml" lang="en" country="EP" doc-number="3890299" kind="A1" date-publ="20211006" status="n" dtd-version="ep-patent-document-v1-5-1">
<SDOBI lang="en"><B000><eptags><B001EP>ATBECHDEDKESFRGBGRITLILUNLSEMCPTIESILTLVFIROMKCYALTRBGCZEEHUPLSKBAHRIS..MTNORSMESMMAKHTNMD..........</B001EP><B005EP>J</B005EP><B007EP>BDM Ver 2.0.12 (4th of August) -  1100000/0</B007EP></eptags></B000><B100><B110>3890299</B110><B120><B121>EUROPEAN PATENT APPLICATION</B121></B120><B130>A1</B130><B140><date>20211006</date></B140><B190>EP</B190></B100><B200><B210>20167885.1</B210><B220><date>20200403</date></B220><B250>en</B250><B251EP>en</B251EP><B260>en</B260></B200><B400><B405><date>20211006</date><bnum>202140</bnum></B405><B430><date>20211006</date><bnum>202140</bnum></B430></B400><B500><B510EP><classification-ipcr sequence="1"><text>H04N   5/225       20060101AFI20200805BHEP        </text></classification-ipcr><classification-ipcr sequence="2"><text>G01B  11/25        20060101ALI20200805BHEP        </text></classification-ipcr><classification-ipcr sequence="3"><text>F21V   8/00        20060101ALI20200805BHEP        </text></classification-ipcr></B510EP><B520EP><classifications-cpc><classification-cpc sequence="1"><text>G01B  11/2513      20130101 LI20210301BHEP        </text></classification-cpc><classification-cpc sequence="2"><text>H04N   5/2256      20130101 FI20200729BHEP        </text></classification-cpc><classification-cpc sequence="3"><text>G02B   6/004       20130101 LA20200915BHEP        </text></classification-cpc></classifications-cpc></B520EP><B540><B541>de</B541><B542>KAMERAEINHEIT MIT EINER LICHTLEITERPLATTE</B542><B541>en</B541><B542>CAMERA UNIT HAVING A LIGHT GUIDE PLATE</B542><B541>fr</B541><B542>UNITÉ DE CAMÉRA DOTÉE D'UNE PLAQUE DE GUIDAGE DE LUMIÈRE</B542></B540><B590><B598>1a</B598></B590></B500><B700><B710><B711><snm>Vestel Elektronik Sanayi ve Ticaret A.S.</snm><iid>100249217</iid><irf>5022-426-EP</irf><adr><str>Organize Sanayi Bölgesi</str><city>45030 Manisa</city><ctry>TR</ctry></adr></B711></B710><B720><B721><snm>KIRISKEN, Barbaros</snm><adr><str>c/o Vestel Elektronik Sanayi ve Ticaret A.S.
Organize Sanayi Bölgesi</str><city>45030 Manisa</city><ctry>TR</ctry></adr></B721></B720><B740><B741><snm>Kehl, Ascherl, Liebhoff &amp; Ettmayr 
Patentanwälte Partnerschaft mbB</snm><iid>101770160</iid><adr><str>Emil-Riedel-Straße 18</str><city>80538 München</city><ctry>DE</ctry></adr></B741></B740></B700><B800><B840><ctry>AL</ctry><ctry>AT</ctry><ctry>BE</ctry><ctry>BG</ctry><ctry>CH</ctry><ctry>CY</ctry><ctry>CZ</ctry><ctry>DE</ctry><ctry>DK</ctry><ctry>EE</ctry><ctry>ES</ctry><ctry>FI</ctry><ctry>FR</ctry><ctry>GB</ctry><ctry>GR</ctry><ctry>HR</ctry><ctry>HU</ctry><ctry>IE</ctry><ctry>IS</ctry><ctry>IT</ctry><ctry>LI</ctry><ctry>LT</ctry><ctry>LU</ctry><ctry>LV</ctry><ctry>MC</ctry><ctry>MK</ctry><ctry>MT</ctry><ctry>NL</ctry><ctry>NO</ctry><ctry>PL</ctry><ctry>PT</ctry><ctry>RO</ctry><ctry>RS</ctry><ctry>SE</ctry><ctry>SI</ctry><ctry>SK</ctry><ctry>SM</ctry><ctry>TR</ctry></B840><B844EP><B845EP><ctry>BA</ctry></B845EP><B845EP><ctry>ME</ctry></B845EP></B844EP><B848EP><B849EP><ctry>KH</ctry></B849EP><B849EP><ctry>MA</ctry></B849EP><B849EP><ctry>MD</ctry></B849EP><B849EP><ctry>TN</ctry></B849EP></B848EP></B800></SDOBI>
<abstract id="abst" lang="en">
<p id="pa01" num="0001">The present invention refers to a camera unit (1). The camera unit according to the present invention comprises at least:<br/>
An optical sensor device (2) for capturing image data,<br/>
a lens device (4) for guiding light to the optical sensor device (2),<br/>
wherein the lens device (4) is arranged in front of the optical sensor device (2),<br/>
characterized in that<br/>
a light guide plate (6) is provided<br/>
wherein the light guide plate (6) comprises multiple light emitting sections (8) for emitting light,<br/>
wherein the light guide plate (6) is oriented in such a manner that light emitted by means of the light emitting sections (8) passes through at least one lens (10) of the lens device (4).
<img id="iaf01" file="imgaf001.tif" wi="86" he="104" img-content="drawing" img-format="tif"/></p>
</abstract>
<description id="desc" lang="en"><!-- EPO <DP n="1"> -->
<p id="p0001" num="0001">The present invention refers to a camera unit respectively camera device according to claim 1, a multimedia device according to claim 11, according to claim 12 to a method for operating a camera unit, according to claim 14 to a method for producing a camera unit and according to claim 15 to a computer program product.</p>
<heading id="h0001"><b>Background of the invention</b></heading>
<p id="p0002" num="0002"><patcit id="pcit0001" dnum="US2018343403A1"><text>US2018343403A1</text></patcit> discloses a video camera assembly, wherein the video camera assembly includes: one or more processors configured to operate the video camera assembly in a day mode and in a night mode; an image sensor having a field of view of a scene and configured to capture video of a first portion of the scene while in the day mode of operation and in the night mode of operation, the first portion corresponding to the field of view of the image sensor; one or more infrared (IR) illuminators configured to provide illumination during the night mode of operation while the image sensor captures video; and an IR reflector component configured to: substantially restrict the illumination onto the first portion of the scene, and illuminate the first portion in a substantially uniform manner across the field of view of the image sensor.</p>
<p id="p0003" num="0003"><patcit id="pcit0002" dnum="US4657393A"><text>US4657393A</text></patcit> discloses that a pattern of light is projected upon a surface to be measured which may be devoid of surface detail. A sharply focused image of the surface provides distance discrimination. Although the projected pattern a separate from the imaging optics, a common optics path removes distortion, provides maximum sensitivity and eliminates processing for misalignment between projector and imager. Sequential cross-correlation, synchronous detection or percent modulation processing methods may be readily implemented to develop three-dimensional coordinates relative to the sensor for all in-focus regions of the image. Refocusing the lens provides depth coverage. The amount of data can be increased by adapting the projected pattern to produce a maximum of detail in the direction of minimum rate of change of depth of the surface being measured.</p>
<p id="p0004" num="0004"><patcit id="pcit0003" dnum="US10066933B2"><text>US10066933B2</text></patcit> discloses systems for depth mapping. A method of depth mapping is performed at an apparatus including a projector, a camera, one or more processors, and memory storing one or more programs for execution by the one or more processors. The method includes<!-- EPO <DP n="2"> --> identifying one or more areas of interest in a scene in accordance with variation of depth in the scene as detected at a first resolution. The method also includes, for each area of interest: applying, via the projector, a respective structured-light pattern to the area of interest; capturing, via the camera, an image of the area of interest with the respective structured-light pattern applied to it; and creating a respective depth map of the area of interest using the captured image, the respective depth map having a higher resolution than the first resolution</p>
<p id="p0005" num="0005"><patcit id="pcit0004" dnum="US20180270474A1"><text>US20180270474A1</text></patcit> discloses an optical imaging system utilizes a three-dimensional (3D) light scanner to capture topography information, color reflectance information, and fluorescence information of a target object being imaged, such as a surgical patient. The system also utilizes the topography information of the target object to perform an image mapping process to project the captured fluorescence or other intraoperative images back onto the target object with enhanced definition or sharpness. Additionally, the system utilizes the topography information of the target object to co-register two or more images, such as a color image of the target object with a fluorescence image for presentation on a display or for projection back onto the target object.</p>
<p id="p0006" num="0006"><patcit id="pcit0005" dnum="WO2012057088A1"><text>WO2012057088A1</text></patcit> discloses a manufacturing method for a light-guide plate. According to <patcit id="pcit0006" dnum="WO2012057088A1"><text>WO2012057088A1</text></patcit> a first surface from which light is emitted and a dot pattern are divided by the same mesh, and diffusion dots are formed on a second surface by the designed dot pattern to create a light-guide plate.</p>
<p id="p0007" num="0007">Prior art systems especially have separated camera and projector assemblies. Those systems require an additional camera and decreasing detection performance because of separation between camera and projector.</p>
<heading id="h0002"><b>Object of the invention</b></heading>
<p id="p0008" num="0008">Thus, it is the object of the present invention to provide an advanced solution that enables better performance and/or lower costs.</p>
<heading id="h0003"><b>Description of the invention</b></heading>
<p id="p0009" num="0009">The before mentioned object is solved by a camera unit according to claim 1. Said camera unit preferably comprises at least an optical sensor device for capturing image data. The camera unit preferably also comprises a lens device for guiding light to the optical sensor device, wherein the<!-- EPO <DP n="3"> --> lens device is arranged in front of the optical sensor device. The lens device preferably comprises one or more than one, in particularly multiple or two or more than two or up to 20 or up to 10 or up to 5 lens elements. According to the invention a light guide plate is provided, wherein the light guide plate comprises multiple light emitting sections for emitting light, wherein the light guide plate is oriented in such a manner that light emitted by means of the light emitting sections passes through at least one lens of the lens device. The light guide plate can be a light guide plate e.g. produced according to the method described in <patcit id="pcit0007" dnum="WO2012057088A1"><text>WO2012057088A1</text></patcit>.</p>
<p id="p0010" num="0010">This solution is beneficial since all necessary components are arranges in one device. Thus, production costs can be reduced to less and/or smaller parts and overall performance can be increased since all images and/or frames can be captured by means of one optical sensor device (and therefore the main optical sensor).</p>
<p id="p0011" num="0011">Thus, the present invention preferably has a light guide and IR light inside a camera assembly. The light guide is preferably arranged the between lenses and camera sensor. Light guide has dots which is seen under IR and power IR light for projection. Normally the camera makes its function by taking the photo and/or video. When it is converted to 3D sensor mode for depth detection, electronic shutter turned off the camera sensor and IR light powered on, then the sensor is turned on sequentially. At that time camera saw very near structured dots and larger and separated dots further away. When the system compares two, the difference vector is taken and larger and separated dots and dots directly in front of the camera are separated.</p>
<p id="p0012" num="0012">Thus, the camera respectively optical sensor and projector are preferably combined, and the camera can be used its native function. Additionally, the original dot-matrix respectively the light guide plate) is near to the optical sensor and projected dots are on same picture and system respectively an analyser unit separating them by differentiating on the same picture. Preferably non-visible dots are used on the visible spectrum. Thus, highly preferably a combined structure of camera and light guide plate is provided.</p>
<p id="p0013" num="0013">Further preferred embodiments are subject matter of the dependent claims and of the following specification parts.</p>
<p id="p0014" num="0014">The light guide plate comprises according to a further preferred embodiment of the present invention more than three, in particularly more than 10 or more than 20 or more than 50 or more than 100, light emitting sections. It is possible that some of the light emitting sections have the same shape and/or size (mm<sup>2</sup>) or a majority of light emitting sections has the same shape and/or size (mm<sup>2</sup>) or all of the light emitting sections have the same shape and/or size (mm<sup>2</sup>). Thus, it is also possible that some of the light emitting sections have a first shape and/or first size (mm<sup>2</sup>) and some of the light emitting sections have a second shape and/or second size (mm<sup>2</sup>). Additionally, it is possible that some of the light emitting sections have a third shape and/or a third size<!-- EPO <DP n="4"> --> (mm<sup>2</sup>). A preferred shape is hereby a circular shape. However further or alternative shapes are e.g. a rectangular shape or a polygonal shape or a triangular shape. Further shapes are also possible.</p>
<p id="p0015" num="0015">The light guide plate comprises according to a further preferred embodiment of the present invention at least one light source and/or at least one port for receiving light emitted by a light source, wherein the light guide plate distributes the light of the light source to all light emitting sections. In case the light guide plate receives light via the port, in particularly the light port, the light source can be arranged as separate light source, that means that the light source is e.g. physically not directly coupled to the light guide plate or materialized as part of the light guide plate. The separate light source is preferably physically coupled via a light guide element to the light guide plate. However, it is possible that the separate light source is functionally directly coupled with the light guide plate, that means that light emitted by the light source preferably directly enter the light guide plate.</p>
<p id="p0016" num="0016">Each light emitting section receives according to a further preferred embodiment of the present invention a predefined amount of light of the at least one light source. Preferably each light emitting section receives the same amount of light or an amount of light that differs up to 80% or up to 50% or up to 30% from the amount of light which is the highest amount emitted to one of the light emitting sections. This embodiment is beneficial since a predefined pattern can be generated by the light emitted through the light emitting sections respectively by the light emitted through the light emitting sections and projected onto one or multiple object. Light emitted through each light emitting section forms a marking projected in the one or multiple object/s. At least one property of one or multiple or all markings or of the light emitted through the respective light emitting section is provided to an analyzer unit and/or stored as property data in a data storage means.</p>
<p id="p0017" num="0017">At least two light emitting sections and preferably the majority of light emitting sections and highly preferably all light emitting sections form according to a further preferred embodiment of the present invention an opening in a housing, in particularly in one preferably plane wall, of the light guide plate, or in a wall member or sheet member or mask member attached to the housing.</p>
<p id="p0018" num="0018">Each of the openings has according to a further preferred embodiment of the present invention a predefined shape, wherein all openings have the same shape. Each of the openings has according to a further preferred embodiment of the present invention a predefined shape, wherein at least a first group of openings has a first shape and wherein a second group of openings has a second shape, wherein the first shape differs from the second shape by the contour and/or opening size (respective size of area delimited by contour of opening)</p>
<p id="p0019" num="0019">The light guide plate is according to a further preferred embodiment of the present invention arranged between the optical sensor device and the lens device, in particularly closer to a surface<!-- EPO <DP n="5"> --> of a lens (closest lens) of the lens device compared to a surface of an optical sensor of the optical sensor device. Alternatively, the light guide plate can be arranged closer to optical sensor compared to a lens (closest lens) of the lens device. Alternatively, the light guide plate can be arranged between the optical sensor and a lens (closest lens) of the lens device.</p>
<p id="p0020" num="0020">The light source is according to a further preferred embodiment of the present invention an IR light source. The IR light source preferably emits light in the IR-B range, which is preferably in the range of 1,4-3 µm. Additionally, or alternatively the IR light source emits light in the IR-C range which is preferably in the range of 3-1000 µm. The IR-C range can be divided into a MIR range and a FIR, wherein the MIR range is preferably a range of 3-50 µm and wherein the FIR range is preferably a range of 50-1000 µm.</p>
<p id="p0021" num="0021">According to a further preferred embodiment of the present invention a control device respectively an analyzer unit for controlling the light source device and the optical sensor device is provided. The control device respectively the analyzer unit operates the optical sensor device in dependency of an operation of the light source device. The analyzer unit preferably accesses data, in particularly property data, stored in a data storage.</p>
<p id="p0022" num="0022">The above-mentioned object is also solved by a multimedia device, in particularly smartphone, tablet PC or smartwatch, according to claim 11. The multimedia device according to the present invention preferably comprises at least a camera unit according to any of the preceding claims and at least one display device for displaying images captured by means of the camera unit, wherein the camera unit and the display device are arranged in the same housing. This solution is beneficial since multimedia devices like smartphones, tablet PCs or smartwatches are used by a high number of people. Due to the present invention said devices are able to gather depth information respectively depth data with respect to the analyzed object. Said depth data can be stored together with the further data captured by the optical sensor in a data storage means.</p>
<p id="p0023" num="0023">The above-mentioned object is also solved by a method for operating a camera unit according to claims 1 to 10, in particularly a multimedia device, according to claim 11. The method according to the present invention preferably comprises at least the steps: Emitting light by means of a light source, wherein the light is emitted into a first direction, deflecting the light by means of a light guide plate, wherein the light guide plate comprises multiple openings for emitting said deflected light, wherein the deflected light is emitted into a direction of a lens device, capturing light by means of an optical sensor device, wherein the captured light comprises reflected light, wherein said reflected light is a fraction of the light emitted through the multiple openings, wherein the light source, the light guide plate, the lens device and the optical sensor device are arranged inside the same housing.<!-- EPO <DP n="6"> --></p>
<p id="p0024" num="0024">This solution is beneficial since depth information can be gathered by operating a camera unit or a multimedia device according to the present invention.</p>
<p id="p0025" num="0025">The emitted light is according to a further preferred embodiment of the present invention light in the visible spectrum and wherein the light source and the optical sensor device are operated in a predefined sequences, wherein the optical sensor device captures with respect to one photo or one video one or multiple images and/or one or multiple frames in a row, wherein a first set of images and/or frames is captured while the light source is operated and wherein a second set of images and/or frames is captured while the light source is not operated. It is possible that the first set comprises one photo or consists of one photo or the first set comprises one frame or consist of one frame and/or the second set comprises one photo or consist of one photo or the second set comprises one frame or consists of one frame. An analyzer unit preferably processes the first set of images and/or frames and the second set of images and/or frames differently, wherein the analyzer unit generates one file representing the photo or video and preferably also depth data representing depth information of the object. This embodiment is beneficial since the generated file can be forwarded to further recipients and/or analyzed and/or utilized in further processes.</p>
<p id="p0026" num="0026">In one possible feature timing is done by taking series photos, so the first instance system takes a photo by not projecting the light and takes the second photo with light projected, under millisecond level. Another possible feature is taking video and sequentially turn on/off the projection.</p>
<p id="p0027" num="0027">The emitted light is according to a further preferred embodiment of the present invention light in the invisible spectrum and wherein the light source and the optical sensor device are operated in a predefined sequences, wherein the optical sensor device captures with respect to one photo or one video multiple images and/or frames in a row, wherein an analyzer unit analyzes a light pattern caused by the emitted light and reflected by the object, wherein the analyzer unit assigns depth data to multiple image and/or frame sections in dependency of the analyzed light pattern. Preferably the amount of light passing through each single light emitting section is registered by an analyzer unit. Additionally, or alternatively the position and/or size and/or shape of multiple light emitting sections and/or of each single light emitting section is registered by the analyzer unit. Additionally, or alternatively data representing the amount of light passing through each single light emitting section and/or the position and/or size and/or shape of multiple light emitting sections and/or of each single light emitting section is stored in a data storage means. The analyzer unit preferably has access to the data storage means for accessing said data.</p>
<p id="p0028" num="0028">According to a further preferred embodiment of the present invention difference vectors are created with markings projected onto the object and by means of light emitted through the openings of the light guide plate, wherein the markings are captured and processed, in particularly<!-- EPO <DP n="7"> --> compared to each other and/or compared with comparison data or compared with a look-up table, to determine a depth information respectively depth data. This embodiment is beneficial since depth information about the present scene or object can be determined by means of an optical 2D sensor, in particularly a CCD-chip or CMOS-chip.</p>
<p id="p0029" num="0029">The above-mentioned object is also solved by a method for producing a camera unit according to claims 1 to 10. The method for producing a camera unit preferably comprises at least the steps: Providing a lens device; Providing an optical sensor device; Providing an IR light source; Providing a light guide plate; Arranging the light guide plate in such a manner, that light emitted through multiple openings of the light guide plate directly passes at least one lens element of the lens device; Arranging the camera unit on the same side of the lens device on which the light guide plate is arranged. This solution is beneficial since the produced camera device can be small and it is possible to capture image data in high quality.</p>
<p id="p0030" num="0030">The above-mentioned object is also solved by a computer program product comprising instructions that cause the device according to the present invention, in particularly according to claim 11, to perform the method steps of the present invention, in particularly according to claim 12.</p>
<p id="p0031" num="0031">Further benefits, goals and features of the present invention will be described by the following specification of the attached figures, in which components of the invention are exemplarily illustrated. Components of the devices and methods according to the inventions, which match at least essentially with respect to their function, can be marked with the same reference sign, wherein such components do not have to be marked or described in all figures.</p>
<p id="p0032" num="0032">The invention is just exemplarily described with respect to the attached figure in the following.</p>
<heading id="h0004"><b>Brief Description of the Drawings</b></heading>
<p id="p0033" num="0033">
<dl id="dl0001">
<dt>Fig. 1a</dt><dd>shows schematically a side view of a camera device according to the present invention,</dd>
<dt>Fig. 1b</dt><dd>shows schematically an object, wherein markings are projected onto the object,</dd>
<dt>Fig. 2</dt><dd>a multimedia device according to the present invention, and</dd>
<dt>Fig. 3a</dt><dd>steps of a method for operating a camera device according to the present invention,<!-- EPO <DP n="8"> --></dd>
<dt>Fig. 3b</dt><dd>steps of a production method for producing a camera device according to the present invention.</dd>
</dl></p>
<p id="p0034" num="0034"><figref idref="f0001">Fig. 1a</figref> shows a camera unit 1 respectively a camera assembly, where the camera device has structured light dots on a lens assembly respectively lens device and applying light, in particularly IR light, to an object 14. In other words, <figref idref="f0001">Fig. 1a</figref> shows a camera assembly with a light guide and special dots under IR.</p>
<p id="p0035" num="0035">An optical sensor 3, in particularly a CCD-chip or CMOS-chip, captures image data of a scene respectively an object 14. The image data (cf. <figref idref="f0001">fig. 1b</figref>) at least partially represents markings, in particularly dots, projected on the scene and/or object 14. Thus, difference vectors are created with structured lights. The structured light respectively the markings are captured and processed, in particularly compared to each other and/or compared with comparison data or compared with a look-up table, to determine a depth information respectively depth data. The present solution is specific for 3D depth sensors and can be used in any place that depth sensor needed, especially multimedia devices, like mobile phones.</p>
<p id="p0036" num="0036">Thus, the camera unit 1 preferably comprises an optical sensor device 2 for capturing image data. As mentioned above the optical sensor can be a 2D sensor. The camera unit 1 preferably also comprises a lens device 4 for guiding light to the optical sensor device 2. The lens device preferably comprises one or more than one lens 10, in particularly two or more than two lenses 10, 11. Preferably up to 5 or 10 or 15 lenses. The lens device 3 preferably comprises at least or exactly one convex lens or one bi-convex lens or one planar-convex lens. Additionally, or alternatively the lens device 4 comprises at least or exactly one concave lens or one bi-concave or one planar-concave lens. The lens device 4 is preferably arranged in front of the optical sensor device 2.</p>
<p id="p0037" num="0037">A light guide means, in particularly a light guide plate 6, is provided, in particularly in the optical path between the optical sensor 3 and the lens device 4. Additionally, or alternatively the light guide means, in particularly light guide plate 6 partially or fully surrounds the optical sensor 3 or the light path from the lens device 4 to the optical sensor 3.</p>
<p id="p0038" num="0038">The light guide means, in particularly the light guide plate, 6 comprises multiple light emitting sections 8 for emitting light, in particularly for projecting markings, in particularly dots, onto a scene or object (cf. <figref idref="f0001">fig. 1b</figref>). The light guide plate 6 is oriented in such a manner that light emitted by means of the light emitting sections 8 passes through at least one lens 10 of the lens device 4.<!-- EPO <DP n="9"> --></p>
<p id="p0039" num="0039">Alternative it is also possible that the light guide means, in particularly light guide plate 6, is arranged on one side of the lens device and the optical sensor 3 is arranged on another side respectively opposing side (in the light path) of the lens device 4.</p>
<p id="p0040" num="0040">Reference DL indicates a light path of light generated by a light source 12 and entering the light guide plate 6 in a direction aligned to direction DES of a light path of light emitted through the lens device 4.</p>
<p id="p0041" num="0041">The emitting sections 8, 9 can be described as dots, in particularly light dots through which light, in particularly IR-light, can be emitted. The emitting sections 8, 9 are arranged in a large number, in particularly 3 x 3 matrix or 5 x 5 matrix or 10 x 10 matrix or 50 x 50 matrix or 100 x 100 matrix or X x X matrix or X x Y matrix, wherein X is preferably more than 5 or equal to 5 and/or wherein Y is preferably more than 5 or equal to 5. The individual emitting section 8, 9 are preferably spaced apart from the next emitting section 8, 9 more than 2µm or more than 5 µm or more than 10 µm or more than 20 µm or more than 50 µm or more than 100 µm, in particularly up to 200 µm or 500 µm or 1000 µm or 2000 µm. Preferably all emitting sections 8, 9 are having the same size and/or shape and/or distance to the next emitting section 8, 9. However, it is also possible that some emitting sections 8, 9 have a larger distance to the next respectively closest emitting section 8, 9 compared to other emitting sections. It is alternatively or additionally possible that some emitting sections have a first shape and/or shape and some emitting sections have a second form and/or shape and some emitting sections have a third form and/or shape. Thus, the dots on light guide plate 6 are preferably very small and very near. The light guide plate 6 is preferably arranged very close to the camera respectively optical sensor device 2, so that it is out of focus of the optical sensor device 2 respectively camera. The light projected via said emitting sections 8, 9 can be eliminated from captured image data, in particularly by using preferably real-time image editing algorithms. It is possible to recover original photo respectively original image data from the taken photo respectively generated image data with dots, very similar with "fence removal" algorithms.</p>
<p id="p0042" num="0042">This camera unit 1 can be used, in particularly together with an additional camera, very likely in all recent devices, in particularly mobile phones or tablet PCs or smart watches, so that the image data captured and/or generated by of one camera, in particularly of the camera unit 1 of the present invention, is used to recover image data captured and/or generated by a further camera of said device.</p>
<p id="p0043" num="0043">Thus, it is possible that the optical sensor 2 of the camera unit 1 captures one photo or a series of photos and/or generates image data representing said photo or the series of photos. After a first defined number of photos, in particularly after the first photo or after a plurality of photos, in particularly a second photo, a second defined number of photos can be taken, wherein the second defined number of photos comprises one photo or exactly one photo or multiple photos, in<!-- EPO <DP n="10"> --> particularly more than two or exactly two photos. The first defined number of photos or the second defined number of photos is preferably captured while light is emitted through light emitting plate 6 and therefore by optical sensor 2. The other defined number of photos is preferably captured while no light, in particularly no IR-light, is emitted through the light guide plate 6. Said number of photos is preferably also captured by the optical sensor 2 or by another optical sensor respectively another camera. Said other optical sensor respectively other camera is preferably also part of the device, in particularly of the mobile phone or tablet PC or smart watch. In case multiple the optical sensors 2 captures and/or generates image data and in case another camera respectively optical sensor captures and/or generates image data, the image data generated by said optical sensors is processed by one processor unit.</p>
<p id="p0044" num="0044">Light guide plate 6 is preferably a transparent (in particularly visible light) object, which is preferably manufactured of a polymer material, in particularly plastic or Plexiglas, or glass or similar hardened glass/plastics. Wherein the light guide plate 6 preferably has a very high optical permeability. Alternatively, the light guide plate can be a thin light guide film (LGF), in particularly a light guide film thinner than 2mm, or thinner than 1mm or thinner than 0,8mm or thinner than 0,5mm or thinner than 0,1mm.</p>
<p id="p0045" num="0045"><figref idref="f0002">Fig. 2</figref> shows a multimedia device 20, in particularly a smartphone or Tablet PC or smartwatch. The multimedia device 20 preferably comprises a housing 22 and a display 24. The multimedia device preferably comprises a communication unit for communicating via the internet.</p>
<p id="p0046" num="0046"><figref idref="f0003">Fig. 3a</figref> shows steps of a method for operating a camera unit 1 according to the present invention. The method preferably comprises the steps:
<ul id="ul0001" list-style="none">
<li>S1: emitting light by means of a light source 12. The light is preferably emitted into a first direction DL.</li>
<li>S2: deflecting the light by means of a light guide plate 6. The light guide plate 6 preferably comprises multiple openings for emitting said deflected light, wherein the deflected light is preferably emitted into a direction (DES) of a lens device 4.</li>
<li>S3: capturing light by means of an optical sensor device 2. The captured light preferably comprises reflected light, wherein said reflected light is preferably a fraction of the light emitted through the multiple openings. The light source 12, the light guide plate 6, the lens device 4 and the optical sensor device 3 are preferably arranged inside the same housing 22.</li>
</ul></p>
<p id="p0047" num="0047"><figref idref="f0003">Fig. 3b</figref> shows steps for producing a camera unit 1 according to the present invention. The method comprises at least the steps:
<ul id="ul0002" list-style="none">
<li>S100: Providing a lens device 4.<!-- EPO <DP n="11"> --></li>
<li>S101: Providing an optical sensor device 2.</li>
<li>S102: Providing an IR light source 12.</li>
<li>S103: Providing a light guide plate 6.</li>
<li>S104: Arranging the light guide plate 6 in such a manner, that light emitted through multiple openings of the light guide plate 6 directly passes at least one lens element of the lens device 4.</li>
<li>S105: Arranging the camera unit 1 on the same side of the lens device (4) on which the light guide plate 6 is arranged.</li>
</ul></p>
<p id="p0048" num="0048">Alternatively to steps S104 and S105 the light guide means, in particularly light guide plate 6, can be arranged on one side of the lens device 4, in particularly surrounding the lens device 4 or light entering the lens device 4, and the optical sensor 3 can be arranged on another side of the lens device 4, in particularly in a light path of light entering the camera behind the lens device 4. Thus, the light guide means, in particularly light guide plate 6, can be arranged in the light path of light entering the camera unit 1 before the lens device.<!-- EPO <DP n="12"> --></p>
<heading id="h0005">List of reference numbers</heading>
<p id="p0049" num="0049">
<dl id="dl0002" compact="compact">
<dt>1</dt><dd>camera unit</dd>
<dt>2</dt><dd>optical sensor device</dd>
<dt>3</dt><dd>optical sensor</dd>
<dt>4</dt><dd>lens device</dd>
<dt>6</dt><dd>light guide plate</dd>
<dt>8</dt><dd>light emitting section</dd>
<dt>9</dt><dd>further light emitting section</dd>
<dt>10</dt><dd>lens of lens device</dd>
<dt>11</dt><dd>further lens of lens device</dd>
<dt>12</dt><dd>light source</dd>
<dt>14</dt><dd>object</dd>
<dt>20</dt><dd>multimedia device</dd>
<dt>22</dt><dd>frame or housing</dd>
<dt>24</dt><dd>display</dd>
</dl>
<dl id="dl0003" compact="compact">
<dt>DL</dt><dd>Direction of light emitted by light source</dd>
<dt>DES</dt><dd>Direction of light emitted through light emitting section of light guide plate</dd>
</dl></p>
</description>
<claims id="claims01" lang="en"><!-- EPO <DP n="13"> -->
<claim id="c-en-0001" num="0001">
<claim-text>Camera unit (1)
<claim-text>at least comprising</claim-text>
<claim-text>an optical sensor device (2) for capturing image data,</claim-text>
<claim-text>a lens device (4) for guiding light to the optical sensor device (2),</claim-text>
<claim-text>wherein the lens device (4) is arranged in front of the optical sensor device (2),</claim-text>
<claim-text><b>characterized in that</b></claim-text>
<claim-text>a light guide plate (6) is provided</claim-text>
<claim-text>wherein the light guide plate (6) comprises multiple light emitting sections (8) for emitting light, wherein the light guide plate (6) is oriented in such a manner that light emitted by means of the light emitting sections (8) passes through at least one lens (10) of the lens device (4).</claim-text></claim-text></claim>
<claim id="c-en-0002" num="0002">
<claim-text>Camera unit according to claim 1,
<claim-text><b>characterized in that</b></claim-text>
<claim-text>the light guide plate (6) comprises more than three, in particularly more than 10 or more than 20 or more than 50 or more than 100, light emitting sections.</claim-text></claim-text></claim>
<claim id="c-en-0003" num="0003">
<claim-text>Camera unit according to claim 2,
<claim-text><b>characterized in that</b></claim-text>
<claim-text>the light guide plate (6) comprises at least one light source (12), in particularly an IR light source, and/or at least one port (14) for receiving light emitted by a light source (12), in particularly an IR light source, wherein the light guide plate (6) distributes the light of the light source (12) to all light emitting sections (8, 9).</claim-text></claim-text></claim>
<claim id="c-en-0004" num="0004">
<claim-text>Camera unit according to claim 3,
<claim-text><b>characterized in that</b><!-- EPO <DP n="14"> --></claim-text>
<claim-text>each light emitting section (8, 9) receives a predefined amount of light of the at least one light source (12).</claim-text></claim-text></claim>
<claim id="c-en-0005" num="0005">
<claim-text>Camera unit according to claim 4,
<claim-text><b>characterized in that</b></claim-text>
<claim-text>at least two light emitting sections (8, 9) and preferably the majority of the light emitting sections and highly preferably all light emitting sections form an opening in a housing, in particularly in one preferably plane wall, of the light guide plate (6).</claim-text></claim-text></claim>
<claim id="c-en-0006" num="0006">
<claim-text>Camera unit according to claims 2 to 5,
<claim-text><b>characterized in that</b></claim-text>
<claim-text>each of the openings has a predefined shape, wherein all openings have the same shape.</claim-text></claim-text></claim>
<claim id="c-en-0007" num="0007">
<claim-text>Camera unit according to claims 2 to 5,
<claim-text><b>characterized in that</b></claim-text>
<claim-text>each of the openings has a predefined shape,</claim-text>
<claim-text>wherein at least a first group of openings has a first shape and wherein a second group of openings has a second shape, wherein the first shape differs from the second shape by the contour and/or opening size.</claim-text></claim-text></claim>
<claim id="c-en-0008" num="0008">
<claim-text>Camera unit according to any of the preceding claims,
<claim-text><b>characterized in that</b></claim-text>
<claim-text>the light guide plate (6) is arranged between the optical sensor device (12) and the lens device (4), in particularly closer to a surface of a lens (10) of the lens device (4) compared to a surface of an optical sensor (3) of the optical sensor device (2).</claim-text></claim-text></claim>
<claim id="c-en-0009" num="0009">
<claim-text>Camera unit according to any of the preceding claims,
<claim-text><b>characterized in that</b><!-- EPO <DP n="15"> --></claim-text>
<claim-text>a control device for controlling the light source (12) and the optical sensor device (2) is provided, wherein the control device operates the optical sensor device (2) in dependency of an operation of the light source device (12).</claim-text></claim-text></claim>
<claim id="c-en-0010" num="0010">
<claim-text>Multimedia device (20), in particularly smartphone, tablet PC or smartwatch, at least comprising
<claim-text>a camera unit (1) according to any of the preceding claims and</claim-text>
<claim-text>at least one display device (24) for displaying images captured by means of the camera unit (20), wherein the camera unit (1) and the display device (24) are arranged in the same housing (22).</claim-text></claim-text></claim>
<claim id="c-en-0011" num="0011">
<claim-text>Method for operating a camera unit according to claims 1 to 10, at least comprising the steps:
<claim-text>emitting light by means of a light source (12), wherein the light is emitted into a first direction,</claim-text>
<claim-text>deflecting the light by means of a light guide plate (6), wherein the light guide plate (6) comprises multiple openings for emitting said deflected light, wherein the deflected light is emitted into a direction of a lens device (4),</claim-text>
<claim-text>capturing light by means of an optical sensor device (2), wherein the captured light comprises reflected light, wherein said reflected light is a fraction of the light emitted through the multiple openings,</claim-text>
<claim-text>wherein the light source (12), the light guide plate (6), the lens device (4) and the optical sensor device (3) are arranged inside the same housing (22).</claim-text></claim-text></claim>
<claim id="c-en-0012" num="0012">
<claim-text>Method according to claim 11,
<claim-text><b>characterized in that</b></claim-text>
<claim-text>the emitted light is light in the visible spectrum and wherein the light source (12) and the optical sensor device (2) are operated in a predefined sequences, wherein the optical sensor device (2) captures with respect to one photo or one video multiple images and/or frames in a row, wherein a first set of images and/or frames is captured while the light source (12) is operated and wherein a second set of images and/or frames is captured while the light source (12) is not operated, wherein an analyzer unit processes the first set of images and/or frames and the second set of<!-- EPO <DP n="16"> --> images and/or frames differently, wherein the analyzer unit generates one file representing the photo or video</claim-text>
<claim-text>or</claim-text>
<claim-text>wherein the emitted light is light in the invisible spectrum and wherein the light source (12) and the optical sensor device (2) are operated in a predefined sequences, wherein the optical sensor device (2) captures with respect to one photo or one video multiple images and/or frames in a row, wherein an analyzer unit analyzes a light pattern caused by the emitted light and reflected by the object, wherein the analyzer unit assigns depth data to multiple image and/or frame sections in dependency of the analyzed light pattern.</claim-text></claim-text></claim>
<claim id="c-en-0013" num="0013">
<claim-text>Method according to claim 11 or 12,
<claim-text><b>characterized in that</b></claim-text>
<claim-text>difference vectors are created with markings projected onto the object and by means of light emitted through the openings of the light guide plate, wherein the markings are captured and processed, in particularly compared to each other and/or compared with comparison data or compared with a look-up table, to determine a depth information respectively depth data.</claim-text></claim-text></claim>
<claim id="c-en-0014" num="0014">
<claim-text>Method for producing a camera unit according to claims 1 to 10,
<claim-text>at least comprising the steps:</claim-text>
<claim-text>Providing a lens device (4),</claim-text>
<claim-text>Providing an optical sensor device (2),</claim-text>
<claim-text>Providing an IR light source (12),</claim-text>
<claim-text>Providing a light guide plate (6),</claim-text>
<claim-text>Arranging the light guide plate (6) in such a manner, that light emitted through multiple openings of the light guide plate (6) directly passes at least one lens element of the lens device (4),</claim-text>
<claim-text>Arranging the camera unit (1) on the same side of the lens device (4) on which the light guide plate (6) is arranged.</claim-text></claim-text></claim>
<claim id="c-en-0015" num="0015">
<claim-text>Computer program product comprising instructions that cause the device according to claim 11 to perform the method steps of claim 12.</claim-text></claim>
</claims>
<drawings id="draw" lang="en"><!-- EPO <DP n="17"> -->
<figure id="f0001" num="1a,1b"><img id="if0001" file="imgf0001.tif" wi="161" he="209" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="18"> -->
<figure id="f0002" num="2"><img id="if0002" file="imgf0002.tif" wi="165" he="120" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="19"> -->
<figure id="f0003" num="3a,3b"><img id="if0003" file="imgf0003.tif" wi="163" he="204" img-content="drawing" img-format="tif"/></figure>
</drawings>
<search-report-data id="srep" lang="en" srep-office="EP" date-produced=""><doc-page id="srep0001" file="srep0001.tif" wi="157" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="155" he="233" type="tif"/></search-report-data><search-report-data date-produced="20200731" id="srepxml" lang="en" srep-office="EP" srep-type="ep-sr" status="n"><!--
 The search report data in XML is provided for the users' convenience only. It might differ from the search report of the PDF document, which contains the officially published data. The EPO disclaims any liability for incorrect or incomplete data in the XML for search reports.
 -->

<srep-info><file-reference-id>5022-426-EP</file-reference-id><application-reference><document-id><country>EP</country><doc-number>20167885.1</doc-number></document-id></application-reference><applicant-name><name>Vestel Elektronik Sanayi ve Ticaret A.S.</name></applicant-name><srep-established srep-established="yes"/><srep-invention-title title-approval="yes"/><srep-abstract abs-approval="yes"/><srep-figure-to-publish figinfo="by-applicant"><figure-to-publish><fig-number>1a</fig-number></figure-to-publish></srep-figure-to-publish><srep-info-admin><srep-office><addressbook><text>MN</text></addressbook></srep-office><date-search-report-mailed><date>20200811</date></date-search-report-mailed></srep-info-admin></srep-info><srep-for-pub><srep-fields-searched><minimum-documentation><classifications-ipcr><classification-ipcr><text>H04N</text></classification-ipcr><classification-ipcr><text>G02B</text></classification-ipcr><classification-ipcr><text>G01B</text></classification-ipcr></classifications-ipcr></minimum-documentation></srep-fields-searched><srep-citations><citation id="sr-cit0001"><patcit dnum="US2008088731A1" id="sr-pcit0001" url="http://v3.espacenet.com/textdoc?DB=EPODOC&amp;IDX=US2008088731&amp;CY=ep"><document-id><country>US</country><doc-number>2008088731</doc-number><kind>A1</kind><name>TANAKA YASUHIRO [JP] ET AL</name><date>20080417</date></document-id></patcit><category>X</category><rel-claims>1-4,8-11,14,15</rel-claims><category>Y</category><rel-claims>12,13</rel-claims><rel-passage><passage>* abstract *</passage></rel-passage><rel-passage><passage>* paragraph [0001] - paragraph [0009] *</passage><passage>* paragraph [0054] - paragraph [0056] *</passage><passage>* paragraph [0066] - paragraph [0080] *</passage><passage>* paragraph [0086] *</passage><passage>* paragraph [0094] - paragraph [0097] *</passage><passage>* figures 1-14 *</passage></rel-passage></citation><citation id="sr-cit0002"><patcit dnum="US2016330433A1" id="sr-pcit0002" url="http://v3.espacenet.com/textdoc?DB=EPODOC&amp;IDX=US2016330433&amp;CY=ep"><document-id><country>US</country><doc-number>2016330433</doc-number><kind>A1</kind><name>SHEN SHIZHE [US] ET AL</name><date>20161110</date></document-id></patcit><category>Y,D</category><rel-claims>12,13</rel-claims><category>A</category><rel-claims>1-11,14,15</rel-claims><rel-passage><passage>* abstract *</passage></rel-passage><rel-passage><passage>* paragraph [0047] - paragraph [0059] *</passage><passage>* figures 1-6B *</passage></rel-passage></citation><citation id="sr-cit0003"><patcit dnum="WO2012057088A1" id="sr-pcit0003" url="http://v3.espacenet.com/textdoc?DB=EPODOC&amp;IDX=WO2012057088&amp;CY=ep"><document-id><country>WO</country><doc-number>2012057088</doc-number><kind>A1</kind><name>SUMITOMO CHEMICAL CO [JP]; SEKIGUCHI YASUHIRO [JP] ET AL.</name><date>20120503</date></document-id></patcit><category>A,D</category><rel-claims>1-15</rel-claims><rel-passage><passage>* abstract *</passage><passage>* paragraph [0004] - paragraph [0011] *</passage><passage>* figures 1-3 *</passage></rel-passage></citation></srep-citations><srep-admin><examiners><primary-examiner><name>Schreib, Franz</name></primary-examiner></examiners><srep-office><addressbook><text>Munich</text></addressbook></srep-office><date-search-completed><date>20200731</date></date-search-completed></srep-admin><!--							The annex lists the patent family members relating to the patent documents cited in the above mentioned European search report.							The members are as contained in the European Patent Office EDP file on							The European Patent Office is in no way liable for these particulars which are merely given for the purpose of information.							For more details about this annex : see Official Journal of the European Patent Office, No 12/82						--><srep-patent-family><patent-family><priority-application><document-id><country>US</country><doc-number>2008088731</doc-number><kind>A1</kind><date>20080417</date></document-id></priority-application><family-member><document-id><country>CN</country><doc-number>101103372</doc-number><kind>A</kind><date>20080109</date></document-id></family-member><family-member><document-id><country>JP</country><doc-number>WO2006077718</doc-number><kind>A1</kind><date>20080619</date></document-id></family-member><family-member><document-id><country>US</country><doc-number>2008088731</doc-number><kind>A1</kind><date>20080417</date></document-id></family-member><family-member><document-id><country>WO</country><doc-number>2006077718</doc-number><kind>A1</kind><date>20060727</date></document-id></family-member></patent-family><patent-family><priority-application><document-id><country>US</country><doc-number>2016330433</doc-number><kind>A1</kind><date>20161110</date></document-id></priority-application><family-member><document-id><country>US</country><doc-number>2016330433</doc-number><kind>A1</kind><date>20161110</date></document-id></family-member><family-member><document-id><country>US</country><doc-number>2018335299</doc-number><kind>A1</kind><date>20181122</date></document-id></family-member></patent-family><patent-family><priority-application><document-id><country>WO</country><doc-number>2012057088</doc-number><kind>A1</kind><date>20120503</date></document-id></priority-application><family-member><document-id><country>JP</country><doc-number>2012109235</doc-number><kind>A</kind><date>20120607</date></document-id></family-member><family-member><document-id><country>TW</country><doc-number>201227017</doc-number><kind>A</kind><date>20120701</date></document-id></family-member><family-member><document-id><country>WO</country><doc-number>2012057088</doc-number><kind>A1</kind><date>20120503</date></document-id></family-member></patent-family></srep-patent-family></srep-for-pub></search-report-data>
<ep-reference-list id="ref-list">
<heading id="ref-h0001"><b>REFERENCES CITED IN THE DESCRIPTION</b></heading>
<p id="ref-p0001" num=""><i>This list of references cited by the applicant is for the reader's convenience only. It does not form part of the European patent document. Even though great care has been taken in compiling the references, errors or omissions cannot be excluded and the EPO disclaims all liability in this regard.</i></p>
<heading id="ref-h0002"><b>Patent documents cited in the description</b></heading>
<p id="ref-p0002" num="">
<ul id="ref-ul0001" list-style="bullet">
<li><patcit id="ref-pcit0001" dnum="US2018343403A1"><document-id><country>US</country><doc-number>2018343403</doc-number><kind>A1</kind></document-id></patcit><crossref idref="pcit0001">[0002]</crossref></li>
<li><patcit id="ref-pcit0002" dnum="US4657393A"><document-id><country>US</country><doc-number>4657393</doc-number><kind>A</kind></document-id></patcit><crossref idref="pcit0002">[0003]</crossref></li>
<li><patcit id="ref-pcit0003" dnum="US10066933B2"><document-id><country>US</country><doc-number>10066933</doc-number><kind>B2</kind></document-id></patcit><crossref idref="pcit0003">[0004]</crossref></li>
<li><patcit id="ref-pcit0004" dnum="US20180270474A1"><document-id><country>US</country><doc-number>20180270474</doc-number><kind>A1</kind></document-id></patcit><crossref idref="pcit0004">[0005]</crossref></li>
<li><patcit id="ref-pcit0005" dnum="WO2012057088A1"><document-id><country>WO</country><doc-number>2012057088</doc-number><kind>A1</kind></document-id></patcit><crossref idref="pcit0005">[0006]</crossref><crossref idref="pcit0006">[0006]</crossref><crossref idref="pcit0007">[0009]</crossref></li>
</ul></p>
</ep-reference-list>
</ep-patent-document>
