<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE ep-patent-document PUBLIC "-//EPO//EP PATENT DOCUMENT 1.5.1//EN" "ep-patent-document-v1-5-1.dtd">
<!-- This XML data has been generated under the supervision of the European Patent Office -->
<ep-patent-document id="EP20166559A1" file="EP20166559NWA1.xml" lang="en" country="EP" doc-number="3889933" kind="A1" date-publ="20211006" status="n" dtd-version="ep-patent-document-v1-5-1">
<SDOBI lang="en"><B000><eptags><B001EP>ATBECHDEDKESFRGBGRITLILUNLSEMCPTIESILTLVFIROMKCYALTRBGCZEEHUPLSKBAHRIS..MTNORSMESMMAKHTNMD..........</B001EP><B005EP>J</B005EP><B007EP>BDM Ver 2.0.12 (4th of August) -  1100000/0</B007EP></eptags></B000><B100><B110>3889933</B110><B120><B121>EUROPEAN PATENT APPLICATION</B121></B120><B130>A1</B130><B140><date>20211006</date></B140><B190>EP</B190></B100><B200><B210>20166559.3</B210><B220><date>20200330</date></B220><B250>en</B250><B251EP>en</B251EP><B260>en</B260></B200><B400><B405><date>20211006</date><bnum>202140</bnum></B405><B430><date>20211006</date><bnum>202140</bnum></B430></B400><B500><B510EP><classification-ipcr sequence="1"><text>G08B  21/04        20060101AFI20200907BHEP        </text></classification-ipcr><classification-ipcr sequence="2"><text>G08B  13/00        20060101ALN20200907BHEP        </text></classification-ipcr></B510EP><B520EP><classifications-cpc><classification-cpc sequence="1"><text>F21V  23/0442      20130101 LA20200506BHEP        </text></classification-cpc><classification-cpc sequence="2"><text>G08B  13/00        20130101 LA20200827BHEP        </text></classification-cpc><classification-cpc sequence="3"><text>G08B  21/0492      20130101 FI20200827BHEP        </text></classification-cpc></classifications-cpc></B520EP><B540><B541>de</B541><B542>SYSTEM ZUR ÜBERWACHUNG EINES RAUMES DURCH EINE TRAGBARE SENSORVORRICHTUNG UND VERFAHREN DAFÜR</B542><B541>en</B541><B542>A SYSTEM FOR MONITORING A SPACE BY A PORTABLE SENSOR DEVICE AND A METHOD THEREOF</B542><B541>fr</B541><B542>SYSTÈME DE SURVEILLANCE D'UN ESPACE À L'AIDE D'UN DISPOSITIF DE CAPTEUR PORTABLE ET PROCÉDÉ ASSOCIÉ</B542></B540><B590><B598>1a</B598></B590></B500><B700><B710><B711><snm>Signify Holding B.V.</snm><iid>101800886</iid><irf>2020P80031EP</irf><adr><str>High Tech Campus 48</str><city>5656 AE Eindhoven</city><ctry>NL</ctry></adr></B711></B710><B720><B721><snm>The designation of the inventor has not yet been filed</snm></B721></B720><B740><B741><snm>Verweij, Petronella Daniëlle</snm><sfx>et al</sfx><iid>101576853</iid><adr><str>Signify Netherlands B.V. 
Intellectual Property 
High Tech Campus 7</str><city>5656 AE Eindhoven</city><ctry>NL</ctry></adr></B741></B740></B700><B800><B840><ctry>AL</ctry><ctry>AT</ctry><ctry>BE</ctry><ctry>BG</ctry><ctry>CH</ctry><ctry>CY</ctry><ctry>CZ</ctry><ctry>DE</ctry><ctry>DK</ctry><ctry>EE</ctry><ctry>ES</ctry><ctry>FI</ctry><ctry>FR</ctry><ctry>GB</ctry><ctry>GR</ctry><ctry>HR</ctry><ctry>HU</ctry><ctry>IE</ctry><ctry>IS</ctry><ctry>IT</ctry><ctry>LI</ctry><ctry>LT</ctry><ctry>LU</ctry><ctry>LV</ctry><ctry>MC</ctry><ctry>MK</ctry><ctry>MT</ctry><ctry>NL</ctry><ctry>NO</ctry><ctry>PL</ctry><ctry>PT</ctry><ctry>RO</ctry><ctry>RS</ctry><ctry>SE</ctry><ctry>SI</ctry><ctry>SK</ctry><ctry>SM</ctry><ctry>TR</ctry></B840><B844EP><B845EP><ctry>BA</ctry></B845EP><B845EP><ctry>ME</ctry></B845EP></B844EP><B848EP><B849EP><ctry>KH</ctry></B849EP><B849EP><ctry>MA</ctry></B849EP><B849EP><ctry>MD</ctry></B849EP><B849EP><ctry>TN</ctry></B849EP></B848EP></B800></SDOBI>
<abstract id="abst" lang="en">
<p id="pa01" num="0001">A method and a system for monitoring a space by a portable sensor device 102 are disclosed. The portable sensor device 102 comprising a first sensor 120 of a first sensor type for providing first sensor data indicative of first environmental information in the space, and a second sensor 122 of a second sensor type for providing second sensor data indicative of second environmental information in the space. The method comprises determining a location of the portable sensor device 102 in the space, transmitting, if the portable sensor device 102 is located at the first location, the first sensor data indicative of the first environmental information via the communication unit to a first device or application 110 of a plurality of devices or applications 110, 112, and transmitting, if the portable sensor device 102 is located at the second location, the second sensor data indicative of the second environmental information via the communication unit to a second device or application 112 of the plurality of devices or applications 110, 112.
<img id="iaf01" file="imgaf001.tif" wi="107" he="89" img-content="drawing" img-format="tif"/></p>
</abstract>
<description id="desc" lang="en"><!-- EPO <DP n="1"> -->
<heading id="h0001">FIELD OF THE INVENTION</heading>
<p id="p0001" num="0001">The invention relates to a method for monitoring a space and a computer program product for executing the method. The invention further relates to a system for monitoring the space.</p>
<heading id="h0002">BACKGROUND</heading>
<p id="p0002" num="0002">More and more sensor devices are being used as part of smart home systems, as they enable automatic control of devices, such as for example lighting devices, to a desired setting based on a detected sensor input. Sensor devices are getting more advanced, often combining multiple sensor modalities. For example, the Philips Hue Motion Sensor comprises an integrated light sensor, a temperature sensor and a PIR sensor.</p>
<p id="p0003" num="0003">A sensor device that combines multiple modalities is also disclosed in <patcit id="pcit0001" dnum="US20160345406A1"><text>US 2016/0345406 A1</text></patcit>. The path light control device disclosed in the patent application can include a processor, light source and any combination of ambient light sensors, passive infrared sensors, accelerometers and compass sensors. In one embodiment, the orientation of the sensor is determined, a degree of sensor function in such orientation is determined and sensor operation is disabled when the detected orientation indicates the data of the sensor is not applicable for proper device control.</p>
<p id="p0004" num="0004">Sensor devices are not only used as part of lighting systems, but also for other applications, e.g. security. Each application typically uses its own sensor devices. This results in many sensor devices being installed in homes and offices, which increases power consumption and decreases the buildings' aesthetics.</p>
<heading id="h0003">SUMMARY OF THE INVENTION</heading>
<p id="p0005" num="0005">It is an object of the invention to provide a portable sensor device which can be used to reduce the number of portable sensor devices that is needed for a certain set of applications.</p>
<p id="p0006" num="0006">According to a first aspect of the present invention, the object is achieved by a method of monitoring a space by a portable sensor device, the portable sensor device<!-- EPO <DP n="2"> --> comprising a first sensor of a first sensor type for providing first sensor data indicative of first environmental information in the space, and a second sensor of a second sensor type for providing second sensor data indicative of second environmental information in the space, the method comprising:
<ul id="ul0001" list-style="dash" compact="compact">
<li>determining a location of the portable sensor device in the space,</li>
<li>transmitting, if the portable sensor device is located at the first location, the first sensor data indicative of the first environmental information via the communication unit to a first device or application of a plurality of devices or applications, and</li>
<li>transmitting, if the portable sensor device is located at the second location, the second sensor data indicative of the second environmental information via the communication unit to a second device or application of the plurality of devices or applications.</li>
</ul></p>
<p id="p0007" num="0007">The inventors have recognized that it is beneficial to allow a single portable sensor device comprising multiple types of sensors to be used for multiple applications and that repositioning the portable sensor device is a very intuitive way of switching between applications. The different applications may run on a single device or on a plurality of devices. The sensor data is transmitted to one of the plurality of devices or applications in dependence on the location of the portable sensor device. The location of the portable sensor device may be determined by an (indoor) positioning system, or the location may be predefined or defined by a user.</p>
<p id="p0008" num="0008">The method may comprise: if the first sensor data has been transmitted to the first device or application, controlling the first device or application based on the first sensor data, or if the second sensor data has been transmitted to the second device or application, rendering information indicative of the second sensor data on an information rendering device. In other words, if the portable sensor device is located at the first location, the first sensor data is transmitted to the first device or application, whereupon the first device or application is controlled based on the first sensor data. If the portable sensor device is located at the second location, the second sensor data is transmitted to the second device or application, whereupon the second device or application provides information about the second sensor data. This enables a user to place the portable sensor device at the first location whereupon the first device is controlled, or place the portable sensor device at the second location, whereupon information about the sensor data is provided (e.g. rendered on an electronic display). By repositioning the portable sensor device, the user can switch between different applications.<!-- EPO <DP n="3"> --></p>
<p id="p0009" num="0009">The first device or application is a lighting device or application and the second device or application may be a device or application different from a lighting device or application. This enables a user to place the portable sensor device at the first location whereupon a lighting device or application may be controlled, or place the portable sensor device at the second location, whereupon non-lighting device or non-lighting application may be controlled. For example, the first device or application may be configured to control a light, e.g. turn on and/or off the light, in dependence on the first sensor data. The second device or application may be configured to perform, for example, sleep monitoring, baby monitoring, security monitoring, people counting, pet monitoring and/or health monitoring.</p>
<p id="p0010" num="0010">If the portable sensor device is located at the first location, the first sensor may be activated and the second sensor may be deactivated. Additionally or alternatively, if the portable sensor device is located at the second location, the second sensor is activated and the first sensor is deactivated. The activation/deactivation of a respective sensor may be executed when it has been determined that the portable sensor device is located at a certain location. The sensors may be deactivated by default and a certain sensor may only be activated when the portable sensor device is located at a respective location. Alternatively, the sensors may be activated by default and a certain sensor may only be deactivated when the portable sensor device is located at a respective location. In the context of the present invention, deactivation of a sensor may, for example, mean to switch the sensor off (e.g. to power it off), to not use, store, process, analyze or communicate sensor data of the respective sensor, etc. In the context of the present invention, activation of a sensor may, for example, mean to switch the sensor on (e.g. to power it on), to use, store, process, analyze or communicate sensor data of the respective sensor, etc. Deactivation of a sensor is beneficial because it may reduce battery/power usage, the network resources and/or processing resources.</p>
<p id="p0011" num="0011">The portable sensor device may comprise a battery. The method may further comprise: determining a charge level of the battery, and, if the portable sensor device is located at the first location, deactivating the second sensor if the charge level exceeds a first threshold, and if the portable sensor device is located at the second location, deactivating the first sensor if the charge level exceeds a second threshold. The thresholds may be the same, or different. The thresholds may be determined or predefined based on the respective types of the respective sensors.</p>
<p id="p0012" num="0012">The method may further comprise: determining a sampling rate and/or granularity of the sensor data based on the location of the portable sensor device. If, for example, the portable sensor device is located at the first location, a first sampling rate and/or<!-- EPO <DP n="4"> --> granularity for the first sensor data may be used, and if the the portable sensor device is located at the second location, a second sampling rate and/or granularity for the second sensor data may be used. If a sensor has been associated with multiple locations, the sampling rate and/or the granularity may be different for different locations. If, for example, the second sensor has been associated with the second location and a third location, a third sampling rate and/or granularity for the second sensor data may be used when the portable sensor device is located at the third location.</p>
<p id="p0013" num="0013">The first device or application may be a central control device or application configured to control the second device or application, and the second device or application may be configured to receive control signals from the central control device or application. The first device or application may, for example, be a central (home) control device such as a bridge, and the second device or application may be a (smart) (home) device or application such as a lighting device or application configured to receive control signals from the central (home) control device. This enables the user to position the portable sensor device at a location at which the central control device or application receives the first sensor data. The central control device or application may be configured to control the second device or application based on the first sensor data. Alternatively, the user may position the portable sensor device at a location at which the second device or application receives the second sensor data (directly) from the portable sensor device.</p>
<p id="p0014" num="0014">The method may further comprise determining if the portable sensor device has been located at a (first or second) location for a predetermined period of time. The first or second sensor data may be transmitted and/or the first or second sensor may be activated only if the portable sensor device has been located at the location for a predetermined period of time. The determination whether the portable sensor device has been located at a (first or second) location for a predetermined period of time may be performed by monitoring the location of the portable sensor device. Additionally or alternatively, determining whether the portable sensor device has been located at a (first or second) location for a predetermined period of time may be based on sensor data of a motion sensor comprised in the portable sensor device. It may be beneficial to (first) determine that the portable sensor device has been at the same location/has not moved for a predetermined period of time (e.g. 3 seconds, 5 seconds, 1 minute, etc.) and only transmit sensor data or activate a sensor if it has been at the same location, because environmental data may be irrelevant when the sensor device is being moved from a first location to a second location. Additionally or alternatively, the first or<!-- EPO <DP n="5"> --> second sensor may be activated for a predetermined period of time after the portable sensor device has been positioned at a (first or second) location.</p>
<p id="p0015" num="0015">The method may further comprise determining an orientation of the portable sensor device. The first sensor data may be transmitted to the first device or application if the portable sensor device is located at the first location and if the portable sensor device is oriented in a first predefined orientation. The second sensor data may be transmitted to the second device or application if the portable sensor device is located at the second location and if the portable sensor device is oriented in a second predefined orientation.</p>
<p id="p0016" num="0016">The location of the portable sensor device may be determined based on a detection of a beacon by a detector comprised in the portable sensor device. This may enable the portable sensor device to determine its location without being dependent on an external positioning system. Alternatively, the position of the portable sensor device may be determined by an external positioning system.</p>
<p id="p0017" num="0017">The location of the portable sensor device may be determined based on signal characteristics of radio frequency signals transmitted or received by the portable sensor device. The location of the portable sensor device may be determined by the portable sensor device based on received signals. Alternatively, an external positioning system may determine the location of the portable sensor device based on the transmitted or received signals.</p>
<p id="p0018" num="0018">The method may further comprise:
<ul id="ul0002" list-style="dash" compact="compact">
<li>associating the first sensor or the first sensor data with the first location and the first device or application,</li>
<li>associating the second sensor or the second sensor data with the second location and the second device or application, and</li>
<li>store the associations in a memory. The associations comprise a first association between the first sensor or the first sensor data and the first location and the first device or application, and a second association between the second sensor or the second sensor data with the second location and the second device or application.</li>
</ul></p>
<p id="p0019" num="0019">The (first and second) associations may be based on user input received via a user interface. The user input is indicative of associating the respective sensor or sensor data with the respective location and device or application. The user input may, for example, be received via a touch screen, a voice interface, etc. This is beneficial, because it enables users to define which sensors are activated at which location.<!-- EPO <DP n="6"> --></p>
<p id="p0020" num="0020">The first sensor data may be transmitted to the first device and the second sensor data may be transmitted to the second device, The method may further comprise: obtaining information indicative of a first location of the first device and a second location of the second device, determining the associations based on the first location of the first device and the second location of the second device. Associations between the sensors, the sensors' locations and the respective devices or applications may be determined based on the locations of the respective devices. If, for example, a first device is in proximity or closest to the first location, the first location may be associated with that first device, and a second device in proximity or closest to the second location may be associated with that second location, such that when the sensor device is located at the first location, the first sensor data is transmitted to the first device, and such that when the sensor device is located at the second location, the second sensor data is transmitted to the second device.</p>
<p id="p0021" num="0021">The method may further comprise: identifying a user present in the space, and determining the associations based on an identity of the identified user. Advantageously, the correct devices or applications are associated with the correct locations for an identified user.</p>
<p id="p0022" num="0022">According to a second aspect of the present invention, the object is achieved by a computer program product for a computing device, the computer program product comprising computer program code to perform any of the above-mentioned methods when the computer program product is run on a processing unit of the computing device.</p>
<p id="p0023" num="0023">According to a third aspect of the present invention, the object is achieved by a system for monitoring a space, the system comprising:
<ul id="ul0003" list-style="dash" compact="compact">
<li>a portable sensor device for monitoring the space, comprising<br/>
a first sensor of a first sensor type for providing first sensor data indicative of first environmental information in the space,<br/>
a second sensor of a second sensor type for providing second sensor data indicative of second environmental information in the space,</li>
<li>a communication unit configured to communicate with a plurality of devices or applications,</li>
<li>a processor configured to:
<ul id="ul0004" list-style="none" compact="compact">
<li>obtain information indicative of a location of the portable sensor device in the space, and</li>
<li>transmit, if the portable sensor device is located at the first location, the first sensor data indicative of the first environmental information via the communication unit to a first device or application of the plurality of devices or applications, and<!-- EPO <DP n="7"> --></li>
<li>transmit, if the portable sensor device is located at the second location, the second sensor data indicative of the second environmental information via the communication unit to a second device.</li>
</ul></li>
</ul>
It should be understood that the computer program product and the system may have similar and/or identical embodiments and advantages as the above-mentioned methods.</p>
<p id="p0024" num="0024">In the context of the present invention the wording "environmental information in the space" may relate to any type of environmental parameter that can be detected by a respective sensor of a respective type. Examples of environmental information may, for example, be temperature information, environmental illumination information, humidity information, presence/occupancy information, information related to a property or physiological state of a person, animal or plant, information related to a motion or activity of a person or animal, etc. A processor may analyze sensor data to determine the environmental information.</p>
<heading id="h0004">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p0025" num="0025">The above, as well as additional objects, features and advantages of the disclosed systems, devices and methods will be better understood through the following illustrative and non-limiting detailed description of embodiments of devices and methods, with reference to the appended drawings, in which:
<ul id="ul0005" list-style="none" compact="compact">
<li><figref idref="f0001">Figs. 1a and 1b</figref> show schematically different configurations of a system for monitoring a space and for communicating sensor data to devices and/or applications;</li>
<li><figref idref="f0002">Figs. 2a and 2b</figref> show schematically embodiments of spaces comprising devices and a portable sensor device; and</li>
<li><figref idref="f0003">Fig. 3</figref> shows schematically a user interface for associating locations with sensors and devices or applications.</li>
</ul></p>
<p id="p0026" num="0026">All the figures are schematic, not necessarily to scale, and generally only show parts which are necessary in order to elucidate the invention, wherein other parts may be omitted or merely suggested.</p>
<heading id="h0005">DETAILED DESCRIPTION OF EMBODIMENTS</heading>
<p id="p0027" num="0027"><figref idref="f0001">Figs. 1a and 1b</figref> each show a system for monitoring a space 100. The system comprises a portable sensor device 102 for monitoring the space 100. The portable sensor device 102 comprises a first sensor 120 of a first sensor type for providing first sensor data indicative of first environmental information in the space 100. The portable sensor device<!-- EPO <DP n="8"> --> 102 further comprises a second sensor 122 of a second sensor type for providing second sensor data indicative of second environmental information in the space 100.</p>
<p id="p0028" num="0028">The system further comprises a communication unit 108 configured to communicate with a plurality of devices or applications 110, 112 and a processor 106. In the example of <figref idref="f0001">Fig. 1a</figref>, the first sensor 120, the second sensor 122, the processor 106 and the communication unit 108 are comprised in the portable sensor device 102. In the example of <figref idref="f0001">Fig. 1b</figref>, the first sensor 120 and the second sensor 122 are comprised in the portable sensor device 102, and the processor 106 and the communication unit 108 are comprised in another device 130 (e.g. in an intermediary device such as a bridge, a smartphone, a central (home) control system, etc.). In this example, the sensor device 102 may comprise a further communication unit (not shown) configured to communicate sensor data from the sensor device 102 to the other device 130 comprising the processor 106 and the communication unit 108.</p>
<p id="p0029" num="0029">The processor 106 (e.g. circuitry, a microchip, a microcontroller) is configured to obtain information indicative of a location of the portable sensor device 102 in the space 100, and transmit, if the portable sensor device 102 is located at the first location, the first sensor data indicative of the first environmental information via the communication unit 108 to a first device or application 110 of the plurality of devices or applications 110, 112, and transmit, if the portable sensor device 102 is located at the second location, the second sensor data indicative of the second environmental information via the communication unit 108 to a second device or application 112 of the plurality of devices or applications 110, 112.</p>
<p id="p0030" num="0030">The portable sensor device 102 is repositionable by a user. Since the functionality of the portable sensor device 102 (i.e. to which device or application 110 or 112 the sensor data is communicated) is dependent on the sensor device's location, the user may determine the functionality of the portable sensor device 102 by repositioning the portable sensor device 102. The portable sensor device 102 may be attachable to the device 110, 112 (e.g. via a connector such as a plug/socket), and the device 110, 112 may be a lighting device. The location of the portable sensor device 102 may be received from the device 110, 112 to which it has been attached. This enables 'upgrading' a lighting device by attaching the portable sensor device to the lighting device. The portable sensor device 102 may be connected to a central (home/office) control system and communicate sensor data to the central (home/office) control system, or directly to controllable devices or applications.</p>
<p id="p0031" num="0031">The portable sensor device 102 is configured to monitor environmental conditions of the space 100. The portable sensor device 102 comprises the first sensor 120 of<!-- EPO <DP n="9"> --> the first sensor type for providing first sensor data indicative of first environmental information in the space 100 and the second sensor 122 of a second sensor type for providing second sensor data indicative of second environmental information in the space. The first sensor 120 may comprise a single sensor (e.g. a single microphone, or a single thermopile sensor) or a plurality of (the same type of) sensors (e.g. an array of microphones, an array of thermopile sensors). Such environmental information/conditions may relate to any type of environmental parameter that can be detected by a respective sensor, which sensor provides sensor data indicative of environmental information. Examples of types of such sensors are temperature sensors (for providing sensor data indicative of temperature information), light sensors (for providing sensor data indicative of environmental illumination information), vision sensors (for providing sensor data indicative of environmental objects and/or events), humidity sensors (for providing sensor data indicative of humidity information), motion/presence sensors such as PIR sensors, RF sensors, thermopile sensors, cameras, etc. (for providing sensor data indicative of presence/occupancy information), etc.</p>
<p id="p0032" num="0032">The communication unit 108 is configured to communicate with the plurality of devices or applications 110, 112. The communication unit 108 may be configured to communicate with the devices 110, 112 (which may be running the applications), either directly or indirectly. The communication unit 108 may be configured to communicate via any wired or wireless communication protocol (e.g. Ethernet, DALI, Bluetooth, Wi-Fi, Li-Fi, Thread, ZigBee, etc.). The communication unit 108 may be configured to communicate via multiple communication protocols, for example via a mesh network protocol such as Zigbee with the first device 110, and via a point-to-point network protocol such as Wi-Fi and/or Bluetooth with the second device 112.</p>
<p id="p0033" num="0033">The processor 106 is configured to determine the location of the portable sensor device 102 in the space 100. The location may for example be defined as a set of coordinates in the space 102 or as an area defined by multiple sets or coordinates. Alternatively, the location may be defined by an area in the space 100 which may have been defined by a user (e.g. "kitchen", "office", "corridor", "garden", etc.). The space 100 may be a room, a building, an outdoor area, etc. The processor 106 may be configured to obtain location information indicative of the location of the portable sensor device 102 in the space 100. The location information may, for example, be obtained from a (local or external) memory configured to store a current location of the portable sensor device. The location information may be obtained from an (indoor) positioning system (e.g. an RF-based positioning system that uses triangulation or trilateration, a VLC based positioning system, a<!-- EPO <DP n="10"> --> VSLAM positioning system, etc.) configured to detect the location of the portable sensor device 102 in the space 100. Such (indoor) positioning systems are known in the art and will therefore not be discussed in detail. Alternatively, the processor 106 may be configured to obtain the location of the portable sensor device 102 by determining the location based on signals received from (networked) devices such as the first device 110 and the second device 112. The processor 106 may determine the location based on one or more characteristics (e.g. based on the time of flight or the signal strength) of received RF (radio frequency) signals communicated between the portable sensor device 102 and other devices (such as the first and second device 110, 122). Determining the position of a device based on one or more characteristics of received RF signals is known in the art and will therefore not be discussed in detail. Alternatively, the location of the portable sensor device 102 may be determined based on a detection of a beacon by a detector comprised in the portable sensor device 102. The detector may be configured to detect the presence (and optionally the distance to) the beacon. The beacon may, for example, be a VLC beacon, a passive RF beacon such as a passive NFC tag, an active RF beacon which emits an RF signal, a QR code, etc.</p>
<p id="p0034" num="0034">The processor 106 is further configured to transmit sensor data to a device or application based on the location of the portable sensor device 102. The space 100 may, for example, be divided in areas and certain areas may be associated with certain sensors of the portable sensor device 102. If the portable sensor device 102 is located at a first location (e.g. in a first area) in the space 100, the first sensor data indicative of the first environmental information from the first sensor 120 may be transmitted to the first device or application 110 via the communication unit 108. If the portable sensor device 102 is located at a second location (e.g. in a second area) in the space 100, the second sensor data indicative of the second environmental information from the second sensor 122 may be transmitted to the second device or application 112 via the communication unit 108.</p>
<p id="p0035" num="0035">The plurality of devices or applications comprise the first device or application 110 and the second device or application 112. In the examples of <figref idref="f0001">Figs. 1</figref>, <figref idref="f0002">2a and 2b</figref> the devices or applications 110, 112 are depicted as devices located at different locations in the space 100. It should be understood that this is an example of a plurality of devices or applications. In another example, a plurality of applications (comprising the first and second application) may be running on one or more devices located in the space 100, or be located remotely and be accessible via a network/the internet. The different applications may run on a single device or on a plurality of devices. The plurality of applications may for example be running on a remote server. Examples of applications include but are not limited to<!-- EPO <DP n="11"> --> security/people monitoring, people counting, temperature monitoring, health monitoring, etc. In dependence on the location of the portable sensor device 102, the sensor data is may be transmitted to a respective application.</p>
<p id="p0036" num="0036">The processor 106 is configured to transmit the first or second sensor data to the first or second device, respectively, based on the location of the portable sensor device 102. The sensor data is indicative of respective environmental information. The sensor data that is transmitted to a respective device may be raw sensor data. Alternatively, the sensor data may have already been analyzed by the processor 106 and the environmental information may have been extracted (e.g. a temperature value, an occupation/presence value, a number of people present, a light level, etc.), and the analyzed sensor data may be transmitted to a respective device.</p>
<p id="p0037" num="0037"><figref idref="f0002">Figs. 2a and 2b</figref> illustrate examples of spaces 200a, 200b comprising devices 110, 112 and a portable sensor device 102. In the example of <figref idref="f0002">Fig. 2a</figref>, the portable sensor device 102 is located at first location/area 202a. The processor 106 (not shown) may transmit the first sensor data of the first sensor to the first device 110 when the portable sensor device 102 is located at first location/area 202a. A user may move 250a the portable sensor device 102, whereupon the processor 106 may determine that the portable device 102 is located at second location 204a. The processor 106 may transmit the second sensor data of the second sensor to the second device 112 when the portable sensor device 102 is located at second location/area 204a. In this example, the locations/areas 202a, 204a may be areas/locations defined by coordinates in the space 200a. In the example of <figref idref="f0002">Fig. 2b</figref>, the locations/areas 202b, 204b in the space 200b are defined as rooms. A memory may store information indicative of the locations and the names of the rooms. First room 202b may, for example, be defined as "kitchen" and second room 204b may, for example, be defined as "living room". In the example of <figref idref="f0002">Fig. 2b</figref>, the portable sensor device 102 is located in the first room 202b. The processor 106 (not shown) may transmit the first sensor data of the first sensor to the first device 110 when the portable sensor device 102 is located in the first room 202b. A user may move 250b the portable sensor device 102, whereupon the processor 106 may determine that the portable device 102 is located in the second room 204b. The processor 106 may transmit the second sensor data of the second sensor to the second device 112 when the portable sensor device 102 is located in the second room 204b.</p>
<p id="p0038" num="0038">In a first example, the portable sensor device 102 may comprise a (first) motion sensor and a (second) light sensor. The first device 110 may be a camera, for instance a security camera, and the second device 110 may be a lighting device which comprises one<!-- EPO <DP n="12"> --> or more light sources. If the user places the portable sensor device 102 at the first location (e.g. 202a, 202b), the processor 106 may determine that the portable sensor device 102 is located at the first location 202a, and transmit the sensor data of the motion sensor (e.g. data indicating that motion has been detected) to the camera (e.g. to switch the camera on). If the user places the portable sensor device 102 at the second location (e.g. 204a, 204b), the processor 106 may determine that the portable sensor device 102 is located at the second location, and transmit the sensor data of the light sensor (e.g. data indicating a current light level) to the lighting device (e.g. to control the light output of the light sources based on the current light level).</p>
<p id="p0039" num="0039">In a second example, the portable sensor device 102 may comprise a (first) vision sensor (e.g. a camera) and a (second) presence sensor (e.g. a PIR sensor). The first application 110 may be a people monitoring application running on a local or remote server, and the second device 110 may be a lighting device which comprises one or more light sources. If the user places the portable sensor device 102 at the first location (e.g. 202a, 202b), the processor 106 may determine that the portable sensor device 102 is located at that location, and transmit the sensor data of the camera (e.g. video captured by the camera) to the first application 110 (e.g. to enable people monitoring). If the user places the portable sensor device 102 at the second location (e.g. 204a, 204b), the processor 106 may determine that the portable sensor device 102 is located at that location, and transmit the sensor data of the PIR sensor (e.g. indicating presence of a user) to the lighting device (e.g. to control the light output of the light sources when presence has been detected).</p>
<p id="p0040" num="0040">In another example, the portable sensor device 102 may comprise a (first) audio sensor (e.g. a microphone) and a (second) presence sensor (e.g. a single-pixel thermopile sensor). The first device 110 may be a voice-controlled intelligent personal assistant, and the second device 110 may be a connected doorbell system. If the user places the portable sensor device 102 at the first location (e.g. 202a, 202b), the processor 106 may determine that the portable sensor device 102 is located at the first location, and transmit/stream the sensor data of the audio sensor (e.g. audio/voice data captured by the microphone) to the voice-controlled intelligent personal assistant (e.g. to provide voice input to the voice-controlled intelligent personal assistant). If the user places the portable sensor device 102 at the second location (e.g. 204a, 204b) (e.g. at the user's front door), the processor 106 may determine that the portable sensor device 102 is located at the second location, and transmit the sensor data of the presence sensor (e.g. indicating presence of a<!-- EPO <DP n="13"> --> person) to the connected doorbell system (e.g. to control the doorbell to inform a user that a person is present).</p>
<p id="p0041" num="0041">The processor 106 may be configured to transmit the sensor data of a respective sensor to control the respective device or application 110. Alternatively, the processor 106 may be configured to transmit sensor data of a respective sensor to render information indicative of the respective sensor data on an information rendering device (e.g. a personal mobile device such as a smartphone, on a monitoring device, on the respective device or application, etc.). The processor 106 may, for example, transmit the first sensor data (e.g. a current ambient light level) of the first sensor 120 (e.g. a light sensor) to control the first device 110 (e.g. a lighting device) based on the first sensor data (e.g. by increasing or decreasing the light output of the lighting device based on the current ambient light level). The processor 106 may, for example, transmit the second sensor data (e.g. video data) of the second sensor 122 (e.g. a camera) to the second device 112 (e.g. a smartphone) to render the second sensor data on the second device (e.g. rendering the video data on the smartphone of the user).</p>
<p id="p0042" num="0042">The processor 106 may be configured to activate and/or deactivate the sensors 120, 122 based on the location of the portable sensor device 102. If, for example, the portable sensor device 102 is located at the first location, the processor 106 may activate the first sensor 120 and deactivate the second sensor, and vice versa. The sensors 120, 122 may be deactivated by default and a certain sensor may only be activated when the portable sensor device 102 is located at a respective location. Alternatively, the sensors 120, 122 may be activated by default and a certain sensor may only be deactivated when the portable sensor device 102 is located at a respective location. The processor 106 may, for example, deactivate a sensor by switching the sensor off (e.g. by powering it off), or by refraining from using, storing or communicating sensor data of the respective sensor, etc. The processor 106 may, for example, activate a sensor by switching the sensor on (e.g. by powering it on), or by using, storing or communicating sensor data of the respective sensor, etc.</p>
<p id="p0043" num="0043">The portable sensor device 102 may comprise a battery. The processor 106 may be configured to activate and/or deactivate sensors based on a charge level of the battery. The processor 106 may be configured to determine the charge level of the battery, and, if the portable sensor device 102 is located at the first location, deactivate the second sensor 122 if the charge level exceeds a first threshold, and if the portable sensor device 102 is located at the second location, deactivate the first sensor 120 if the charge level exceeds a<!-- EPO <DP n="14"> --> second threshold. The thresholds may be the same, or different. The thresholds may be determined or predefined based on the respective types of the respective sensors.</p>
<p id="p0044" num="0044">The processor 106 may be further configured to determine/set a sampling rate and/or granularity of the sensor data based on the location of the portable sensor device 102. If, for example, the portable sensor device 102 is located at the first location, a first sampling rate and/or granularity for the first sensor data may be used, and if the the portable sensor device 102 is located at the second location, a second sampling rate and/or granularity for the second sensor data may be used. If a sensor has been associated with multiple locations, the sampling rate and/or the granularity may be different for different locations. If, for example, the second sensor has been associated with the second location and a third location, a third sampling rate and/or granularity for the second sensor data may be used when the portable sensor device 102 is located at the third location. The sampling rate may be indicative of a number of sensor readings per time period (e.g. images per second of a camera, temperature measurements of a temperature sensor, etc.), and the granularity may be indicative of the size of the sensor data (e.g. image resolution of images captured by a camera).</p>
<p id="p0045" num="0045">The first device or application 110 may be a central control device or application configured to control the second device or application 112, and the second device or application 112 may be configured to receive control signals from the central control device or application. The first device or application 110 may, for example, be a central (home) control device such as a bridge, and the second device or application 112 may be a (smart) (home) device or application such as a lighting device or lighting application configured to receive control signals from the central (home) control device. A user may for example position the portable sensor device 102 at a location at which the central control device or application receives the first sensor data from the portable sensor device 102. The central control device or application may be configured to control the second device or application based on the first sensor data. The user may then position the portable sensor device 102 at a location at which the second device or application receives the second sensor data (directly) from the portable sensor device 102, and the second device may be controlled by the processor 106 based on the second sensor data.</p>
<p id="p0046" num="0046">The processor 106 may be further configured to determine if the portable sensor device 102 has been located at a (first or second) location for a predetermined period of time. The processor 106 may start a timer when the location of the portable sensor device 102 does not change. The processor 106 may transmit the first or second sensor data and/or<!-- EPO <DP n="15"> --> activate the first or second sensor only if the portable sensor device 102 has been located at the location for the predetermined period of time.</p>
<p id="p0047" num="0047">Additionally or alternatively, the processor 102 may be configured to activate the first or second sensor for a predetermined period of time after the portable sensor device 102 has been positioned at a (first or second) location. The processor 106 may, for example, activate a sensor for a number of minutes, hours or days. If, for example, the first sensor 120 (or the second sensor 122) is a camera, the camera may be activated for the predetermined period of time to enable monitoring of the space for that period of time.</p>
<p id="p0048" num="0048">The processor 106 may be further configured to associate the sensors (or their respective sensor data) with locations in the space 100 and with the devices or applications. The processor 106 may, for example, be configured to associate the first sensor 120 or the first sensor data with the first location and the first device or application 110. The processor may be further configured to associate the second sensor 122 or the second sensor data with the second location and the second device or application 120. The processor 106 may be further configured to store the associations in a memory. The memory may be located in the portable sensor device 102, or in an external device. The associations comprise a first association between the first sensor 120 or the first sensor data and the first location and the first device or application 110, and a second association between the second sensor 122 or the second sensor data with the second location and the second device or application 112.</p>
<p id="p0049" num="0049">The associations may be based on various inputs. The associations may, for example, be defined by a user via a user interface, based on the locations of the first and second devices 110, 112, based on the types of the first and second devices 110, 112 and/or based on an identity of a user.</p>
<p id="p0050" num="0050">The associations may be learned over time based on (historical) sensor data of the first and second sensors 120, 122. The processor 102 may for example determine based on historical sensor data of the first sensor that the first sensor 120 (e.g. a motion sensor) senses more motion at a first location compared to another (second) location, an association between that location and the first sensor 120 may be created. The processor 102 may for example determine that a first sensor 120 (e.g. a motion sensor) of the portable sensor device 102 detects more sensor data or more variations in sensor data (e.g. motion data) at a first location compared to another (second) location, and the processor 102 may therefore associate the first location with the first sensor 120. The processor 102 may for example determine that a second sensor 122 (e.g. a light sensor) of the portable sensor device 102 detects more sensor data or more variations in sensor data (e.g. a higher variation in light<!-- EPO <DP n="16"> --> intensity) at a second location compared to another (first) location, and the processor 102 may therefore associate the second location with the second sensor 122. This enables the processor 102 to learn the associations based on historical sensor data.</p>
<p id="p0051" num="0051">The (first and second) associations may be based on user input received via a user interface. The user input is indicative of associating the respective sensor or sensor data with the respective location and device or application. The user input may, for example, be received via a touch screen, a voice interface (a user may provide voice commands to create the associations), etc. <figref idref="f0003">Fig. 3</figref> illustrates an example of a user interface on a touch screen. The user interface shows (top) a space 302 comprising three areas (e.g. room) A, B and C. Three devices are installed in the space: a first lighting device 310, a second lighting device 312 and electric curtains 314. The portable sensor device 102 (not shown in <figref idref="f0003">Fig. 3</figref>) comprises a presence sensor 320 (e.g. a PIR sensor or a camera) and a light sensor 322 (e.g. a photodiode). A user may provide user input on the touch screen to associate the sensors 320, 322 with locations A, B, C in the space 302 and with the devices 310, 312, 314 (for example by selecting devices, areas and sensors from different drop-down menus (not shown), or by dragging different on-screen icons 320, 322 of sensors onto the areas A, B, C). In the example of <figref idref="f0003">Fig. 3</figref>, the user has associated sensor 320 with area A such that sensor data of sensor 320 controls lighting device 310 when the portable sensor device 102 is located in area A. The user has also associated sensor 320 also with area B such that sensor data of sensor 320 controls lighting device 312 when the portable sensor device 102 is located in area B. The user has further associated sensor 322 with area C such that sensor data of sensor 322 controls the electric curtains 314 when the portable sensor device 102 is located in area C.</p>
<p id="p0052" num="0052">The user interface may be further configured to receive user inputs indicative of activating/deactivating respective sensors at respective locations. The user may, for example, indicate via the user interface that a first sensor (e.g. a camera) is to be deactivated when the portable sensor device 102 is located at the second location (e.g. in the bedroom). Additionally, the user interface may be further configured to receive user inputs indicative of activating/deactivating respective sensors at respective locations based on contextual information at a respective location. The user may, for example, indicate via the user interface that a first sensor (e.g. a light sensor) is to be deactivated when the portable sensor device 102 is located at the second location based on contextual information at the second location (e.g. when the ambient light level is below a certain value, when an occupancy value is below a certain value, etc.).<!-- EPO <DP n="17"> --></p>
<p id="p0053" num="0053">The (first and second) associations may be based on the locations of the first and second devices 110, 122. The processor 106, may obtain information indicative of a first location of the first device 110 and a second location of the second device 122, and determine the associations based on the first location of the first device 110 and the second location of the second device 112. If, for example, a first device 110 is in proximity of the first location or closer to the first location compared to the second device 112, the first location may be associated with that first device 110, and a second device 112 in proximity of the second location or closer to the second location compared to the first device 110 may be associated with that second location, such that when the portable sensor device 102 is located at the first location, the first sensor data is transmitted to the first device 110, and such that when the sensor device 112 is located at the second location, the second sensor data is transmitted to the second device 112.</p>
<p id="p0054" num="0054">The (first and second) associations may be based on the identity of a user who is present in the space 100. The user may de detected by a presence sensor (which may be located in the portable sensor device 102). The user may be identified based on face recognition of the user, based on voice recognition of the user, based on the presence of a portable device carried by the user, etc. User presence detection and identification techniques are known in the art and will therefore not be discussed in detail. The user identity may be compared to a plurality of user identities that are stored in a (local or remote) memory. The user identities may be associated with user preferences, indicative of associations between sensors (or their respective sensor data), locations and devices or applications. If an identity matches one of the user identities in the memory, the respective user preference matching that identity may be selected and the respective associations may be used.</p>
<p id="p0055" num="0055">The associations may be determined based on/derived from a location type, for example a room type or an area type. In an example, the first location may be a hallway, the second location may be a front door entrance, the first sensor may be a presence sensor and the second sensor may be a camera. Based on the location type, the processor 106 may associate a respective sensor with a respective location. The processor 106 may, for example, associate the camera with the front door entrance and with a home monitoring system, such that when the portable sensor device 102 is located at the front door entrance a video feed from the camera is transmitted to the home monitoring system. Additionally, the processor may, for example, associate the presence sensor with the hallway and with a lighting control system, such that when the portable sensor device 102 is located in the hallway, sensor data<!-- EPO <DP n="18"> --> from the presence sensor is transmitted to the lighting control system to control the lights based on the presence.</p>
<p id="p0056" num="0056">It should be noted that the above-mentioned embodiments illustrate rather than limit the invention, and that those skilled in the art will be able to design many alternative embodiments without departing from the scope of the appended claims.</p>
<p id="p0057" num="0057">In the claims, any reference signs placed between parentheses shall not be construed as limiting the claim. Use of the verb "comprise" and its conjugations does not exclude the presence of elements or steps other than those stated in a claim. The article "a" or "an" preceding an element does not exclude the presence of a plurality of such elements. The invention may be implemented by means of hardware comprising several distinct elements, and by means of a suitably programmed computer or processing unit. In the device claim enumerating several means, several of these means may be embodied by one and the same item of hardware. The mere fact that certain measures are recited in mutually different dependent claims does not indicate that a combination of these measures cannot be used to advantage.</p>
<p id="p0058" num="0058">Aspects of the invention may be implemented in a computer program product, which may be a collection of computer program instructions stored on a computer readable storage device which may be executed by a computer. The instructions of the present invention may be in any interpretable or executable code mechanism, including but not limited to scripts, interpretable programs, dynamic link libraries (DLLs) or Java classes. The instructions can be provided as complete executable programs, partial executable programs, as modifications to existing programs (e.g. updates) or extensions for existing programs (e.g. plugins). Moreover, parts of the processing of the present invention may be distributed over multiple computers or processors or even the 'cloud'.</p>
<p id="p0059" num="0059">Storage media suitable for storing computer program instructions include all forms of nonvolatile memory, including but not limited to EPROM, EEPROM and flash memory devices, magnetic disks such as the internal and external hard disk drives, removable disks and CD-ROM disks. The computer program product may be distributed on such a storage medium, or may be offered for download through HTTP, FTP, email or through a server connected to a network such as the Internet.</p>
</description>
<claims id="claims01" lang="en"><!-- EPO <DP n="19"> -->
<claim id="c-en-0001" num="0001">
<claim-text>A method of monitoring a space by a portable sensor device (102), the portable sensor device (102) comprising a first sensor (120) of a first sensor type for providing first sensor data indicative of first environmental information in the space, and a second sensor (122) of a second sensor type for providing second sensor data indicative of second environmental information in the space, the method comprising:
<claim-text>- determining a location of the portable sensor device (102) in the space,</claim-text>
<claim-text>- transmitting, if the portable sensor device (102) is located at the first location, the first sensor data indicative of the first environmental information via the communication unit to a first device or application (110) of a plurality of devices or applications (110, 112), and</claim-text>
<claim-text>- transmitting, if the portable sensor device (102) is located at the second location, the second sensor data indicative of the second environmental information via the communication unit to a second device or application (112) of the plurality of devices or applications (110, 112).</claim-text></claim-text></claim>
<claim id="c-en-0002" num="0002">
<claim-text>The method of any preceding claim, wherein the method comprises:
<claim-text>- if the first sensor data has been transmitted to the first device or application (110), controlling the first device or application (110) based on the sensor data, or</claim-text>
<claim-text>- if the second sensor data has been transmitted to the second device or application (112), rendering information indicative of the second sensor data on an information rendering device.</claim-text></claim-text></claim>
<claim id="c-en-0003" num="0003">
<claim-text>The method of any preceding claim, wherein the first device or application (110) is a lighting device or application and the second device or application (112) is a device or application different from a lighting device or application.</claim-text></claim>
<claim id="c-en-0004" num="0004">
<claim-text>The method of any preceding claim, wherein, if the portable sensor device (102) is located at the first location, the first sensor (120) is activated and the second sensor (122) is deactivated, and/or<br/>
<!-- EPO <DP n="20"> -->wherein, if the portable sensor device (102) is located at the second location, the second sensor (122) is activated and the first sensor (120) is deactivated.</claim-text></claim>
<claim id="c-en-0005" num="0005">
<claim-text>The method of any preceding claim, wherein the portable sensor device (102) comprises a battery, and wherein the method further comprises:
<claim-text>- determining a charge level of the battery,</claim-text>
<claim-text>- if the portable sensor device (102) is located at the first location, deactivating the second sensor (122) if the charge level exceeds a first threshold, and</claim-text>
<claim-text>- if the portable sensor device (102) is located at the second location, deactivating the first sensor (120) if the charge level exceeds a second threshold.</claim-text></claim-text></claim>
<claim id="c-en-0006" num="0006">
<claim-text>The method of any preceding claim, wherein the first device or application (110) is a central control device or application configured to control the second device or application (112), and wherein the second device or application (112) is configured to receive control signals from the central control device or application.</claim-text></claim>
<claim id="c-en-0007" num="0007">
<claim-text>The method of any preceding claim, further comprising:
<claim-text>- determining if the portable sensor device (102) has been located at a location for a predetermined period of time, and wherein the first or second sensor data is transmitted and/or the first or second sensor (122) is activated only if the portable sensor device (102) has been located at the location for a predetermined period of time.</claim-text></claim-text></claim>
<claim id="c-en-0008" num="0008">
<claim-text>The method of any preceding claim, wherein the location of the portable sensor device (102) is determined based on a detection of a beacon by a detector comprised in the portable sensor device (102)</claim-text></claim>
<claim id="c-en-0009" num="0009">
<claim-text>The method of any preceding claim, wherein the location of the portable sensor device (102) is determined based on signal characteristics of radio frequency signals transmitted or received by the portable sensor device (102).</claim-text></claim>
<claim id="c-en-0010" num="0010">
<claim-text>The method of any preceding claim, further comprising:
<claim-text>- associating the first sensor (120) or the first sensor data with the first location and the first device or application (110),<!-- EPO <DP n="21"> --></claim-text>
<claim-text>- associating the second sensor (122) or the second sensor data with the second location and the second device or application (112), and</claim-text>
<claim-text>- store the associations in a memory.</claim-text></claim-text></claim>
<claim id="c-en-0011" num="0011">
<claim-text>The method of claim 10, wherein the associations are based on user input received via a user interface.</claim-text></claim>
<claim id="c-en-0012" num="0012">
<claim-text>The method of claim 10 or 11, wherein the first sensor data is transmitted to the first device and wherein the second sensor data is transmitted to the second device, the method further comprising:
<claim-text>- obtaining information indicative of a first location of the first device and a second location of the second device,</claim-text>
<claim-text>- determining the associations based on the first location of the first device and the second location of the second device.</claim-text></claim-text></claim>
<claim id="c-en-0013" num="0013">
<claim-text>The method of claim 10, 11 or 12, further comprising:
<claim-text>- identifying a user present in the space, and</claim-text>
<claim-text>- determining the associations based on an identity of the identified user.</claim-text></claim-text></claim>
<claim id="c-en-0014" num="0014">
<claim-text>A computer program product for a computing device, the computer program product comprising computer program code to perform the method of any preceding claim when the computer program product is run on a processing unit of the computing device.</claim-text></claim>
<claim id="c-en-0015" num="0015">
<claim-text>A system for monitoring a space, the system comprising:
<claim-text>- a portable sensor device (102) for monitoring the space, comprising<br/>
a first sensor (120) of a first sensor type for providing first sensor data indicative of first environmental information in the space,<br/>
a second sensor (122) of a second sensor type for providing second sensor data indicative of second environmental information in the space,</claim-text>
<claim-text>- a communication unit (108) configured to communicate with a plurality of devices or applications (110, 112),</claim-text>
<claim-text>- a processor (106) configured to:
<claim-text>obtain information indicative of a location of the portable sensor device (102) in the space, and<!-- EPO <DP n="22"> --></claim-text>
<claim-text>transmit, if the portable sensor device (102) is located at the first location, the first sensor data indicative of the first environmental information via the communication unit to a first device or application (110) of the plurality of devices or applications (110, 112), and</claim-text>
<claim-text>transmit, if the portable sensor device (102) is located at the second location, the second sensor data indicative of the second environmental information via the communication unit to a second device or application (112) of the plurality of devices or applications (110, 112).</claim-text></claim-text></claim-text></claim>
</claims>
<drawings id="draw" lang="en"><!-- EPO <DP n="23"> -->
<figure id="f0001" num="1a,1b"><img id="if0001" file="imgf0001.tif" wi="125" he="220" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="24"> -->
<figure id="f0002" num="2a,2b"><img id="if0002" file="imgf0002.tif" wi="135" he="213" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="25"> -->
<figure id="f0003" num="3"><img id="if0003" file="imgf0003.tif" wi="123" he="188" img-content="drawing" img-format="tif"/></figure>
</drawings>
<search-report-data id="srep" lang="en" srep-office="EP" date-produced=""><doc-page id="srep0001" file="srep0001.tif" wi="157" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="155" he="233" type="tif"/></search-report-data><search-report-data date-produced="20200831" id="srepxml" lang="en" srep-office="EP" srep-type="ep-sr" status="n"><!--
 The search report data in XML is provided for the users' convenience only. It might differ from the search report of the PDF document, which contains the officially published data. The EPO disclaims any liability for incorrect or incomplete data in the XML for search reports.
 -->

<srep-info><file-reference-id>2020P80031EP</file-reference-id><application-reference><document-id><country>EP</country><doc-number>20166559.3</doc-number></document-id></application-reference><applicant-name><name>Signify Holding B.V.</name></applicant-name><srep-established srep-established="yes"/><srep-invention-title title-approval="yes"/><srep-abstract abs-approval="yes"/><srep-figure-to-publish figinfo="by-applicant"><figure-to-publish><fig-number>1a</fig-number></figure-to-publish></srep-figure-to-publish><srep-info-admin><srep-office><addressbook><text>MN</text></addressbook></srep-office><date-search-report-mailed><date>20200911</date></date-search-report-mailed></srep-info-admin></srep-info><srep-for-pub><srep-fields-searched><minimum-documentation><classifications-ipcr><classification-ipcr><text>G08B</text></classification-ipcr><classification-ipcr><text>F21V</text></classification-ipcr></classifications-ipcr></minimum-documentation></srep-fields-searched><srep-citations><citation id="sr-cit0001"><patcit dnum="WO9956262A1" id="sr-pcit0001" url="http://v3.espacenet.com/textdoc?DB=EPODOC&amp;IDX=WO9956262&amp;CY=ep"><document-id><country>WO</country><doc-number>9956262</doc-number><kind>A1</kind><name>IST OY [FI]; MYLLYMAEKI MATTI [FI]</name><date>19991104</date></document-id></patcit><category>A</category><rel-claims>1-15</rel-claims><rel-passage><passage>* abstract *</passage><passage>* page 5, line 1 - page 8, line 4 *</passage><passage>* page 8, line 30 - page 9, line 23 *</passage><passage>* figures 1,2,4 *</passage></rel-passage></citation><citation id="sr-cit0002"><patcit dnum="WO2018160990A1" id="sr-pcit0002" url="http://v3.espacenet.com/textdoc?DB=EPODOC&amp;IDX=WO2018160990&amp;CY=ep"><document-id><country>WO</country><doc-number>2018160990</doc-number><kind>A1</kind><name>CHOPRIX LLC [US]</name><date>20180907</date></document-id></patcit><category>A</category><rel-claims>1-15</rel-claims><rel-passage><passage>* abstract *</passage><passage>* paragraph [0031] *</passage><passage>* paragraph [0035] - paragraph [0059]; figure 1 *</passage></rel-passage></citation><citation id="sr-cit0003"><patcit dnum="US2019373222A1" id="sr-pcit0003" url="http://v3.espacenet.com/textdoc?DB=EPODOC&amp;IDX=US2019373222&amp;CY=ep"><document-id><country>US</country><doc-number>2019373222</doc-number><kind>A1</kind><name>CHIU FU-SHENG [TW]</name><date>20191205</date></document-id></patcit><category>A</category><rel-claims>1-15</rel-claims><rel-passage><passage>* abstract *</passage><passage>* paragraph [0019] - paragraph [0057]; figures 1,3 *</passage></rel-passage></citation></srep-citations><srep-admin><examiners><primary-examiner><name>La Gioia, Cosimo</name></primary-examiner></examiners><srep-office><addressbook><text>Munich</text></addressbook></srep-office><date-search-completed><date>20200831</date></date-search-completed></srep-admin><!--							The annex lists the patent family members relating to the patent documents cited in the above mentioned European search report.							The members are as contained in the European Patent Office EDP file on							The European Patent Office is in no way liable for these particulars which are merely given for the purpose of information.							For more details about this annex : see Official Journal of the European Patent Office, No 12/82						--><srep-patent-family><patent-family><priority-application><document-id><country>WO</country><doc-number>9956262</doc-number><kind>A1</kind><date>19991104</date></document-id></priority-application><family-member><document-id><country>AT</country><doc-number>281684</doc-number><kind>T</kind><date>20041115</date></document-id></family-member><family-member><document-id><country>AU</country><doc-number>3422699</doc-number><kind>A</kind><date>19991116</date></document-id></family-member><family-member><document-id><country>DE</country><doc-number>69921633</doc-number><kind>T2</kind><date>20051201</date></document-id></family-member><family-member><document-id><country>EP</country><doc-number>1068602</doc-number><kind>A1</kind><date>20010117</date></document-id></family-member><family-member><document-id><country>ES</country><doc-number>2233034</doc-number><kind>T3</kind><date>20050601</date></document-id></family-member><family-member><document-id><country>FI</country><doc-number>980819</doc-number><kind>A</kind><date>19991010</date></document-id></family-member><family-member><document-id><country>JP</country><doc-number>2002513225</doc-number><kind>A</kind><date>20020508</date></document-id></family-member><family-member><document-id><country>NO</country><doc-number>329462</doc-number><kind>B1</kind><date>20101025</date></document-id></family-member><family-member><document-id><country>US</country><doc-number>6348867</doc-number><kind>B1</kind><date>20020219</date></document-id></family-member><family-member><document-id><country>WO</country><doc-number>9956262</doc-number><kind>A1</kind><date>19991104</date></document-id></family-member></patent-family><patent-family><priority-application><document-id><country>WO</country><doc-number>2018160990</doc-number><kind>A1</kind><date>20180907</date></document-id></priority-application><family-member><document-id><country>CA</country><doc-number>3055097</doc-number><kind>A1</kind><date>20180907</date></document-id></family-member><family-member><document-id><country>EP</country><doc-number>3590106</doc-number><kind>A1</kind><date>20200108</date></document-id></family-member><family-member><document-id><country>US</country><doc-number>2019385438</doc-number><kind>A1</kind><date>20191219</date></document-id></family-member><family-member><document-id><country>WO</country><doc-number>2018160990</doc-number><kind>A1</kind><date>20180907</date></document-id></family-member></patent-family><patent-family><priority-application><document-id><country>US</country><doc-number>2019373222</doc-number><kind>A1</kind><date>20191205</date></document-id></priority-application><text>NONE</text></patent-family></srep-patent-family></srep-for-pub></search-report-data>
<ep-reference-list id="ref-list">
<heading id="ref-h0001"><b>REFERENCES CITED IN THE DESCRIPTION</b></heading>
<p id="ref-p0001" num=""><i>This list of references cited by the applicant is for the reader's convenience only. It does not form part of the European patent document. Even though great care has been taken in compiling the references, errors or omissions cannot be excluded and the EPO disclaims all liability in this regard.</i></p>
<heading id="ref-h0002"><b>Patent documents cited in the description</b></heading>
<p id="ref-p0002" num="">
<ul id="ref-ul0001" list-style="bullet">
<li><patcit id="ref-pcit0001" dnum="US20160345406A1"><document-id><country>US</country><doc-number>20160345406</doc-number><kind>A1</kind></document-id></patcit><crossref idref="pcit0001">[0003]</crossref></li>
</ul></p>
</ep-reference-list>
</ep-patent-document>
