<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE ep-patent-document PUBLIC "-//EPO//EP PATENT DOCUMENT 1.5.1//EN" "ep-patent-document-v1-5-1.dtd">
<!-- This XML data has been generated under the supervision of the European Patent Office -->
<ep-patent-document id="EP21158828A1" file="EP21158828NWA1.xml" lang="de" country="EP" doc-number="3890357" kind="A1" date-publ="20211006" status="n" dtd-version="ep-patent-document-v1-5-1">
<SDOBI lang="de"><B000><eptags><B001EP>ATBECHDEDKESFRGBGRITLILUNLSEMCPTIESILTLVFIROMKCYALTRBGCZEEHUPLSKBAHRIS..MTNORSMESMMAKHTNMD..........</B001EP><B005EP>J</B005EP><B007EP>BDM Ver 2.0.12 (4th of August) -  1100000/0</B007EP></eptags></B000><B100><B110>3890357</B110><B120><B121>EUROPÄISCHE PATENTANMELDUNG</B121></B120><B130>A1</B130><B140><date>20211006</date></B140><B190>EP</B190></B100><B200><B210>21158828.0</B210><B220><date>20210223</date></B220><B250>de</B250><B251EP>de</B251EP><B260>de</B260></B200><B300><B310>102020204332</B310><B320><date>20200402</date></B320><B330><ctry>DE</ctry></B330></B300><B400><B405><date>20211006</date><bnum>202140</bnum></B405><B430><date>20211006</date><bnum>202140</bnum></B430></B400><B500><B510EP><classification-ipcr sequence="1"><text>H04R  25/00        20060101AFI20210707BHEP        </text></classification-ipcr></B510EP><B520EP><classifications-cpc><classification-cpc sequence="1"><text>H04R  25/558       20130101 FI20210630BHEP        </text></classification-cpc><classification-cpc sequence="2"><text>H04R2225/55        20130101 LA20210630BHEP        </text></classification-cpc><classification-cpc sequence="3"><text>H04R  25/40        20130101 LI20210630BHEP        </text></classification-cpc></classifications-cpc></B520EP><B540><B541>de</B541><B542>VERFAHREN ZUM BETRIEB EINES HÖRSYSTEMS SOWIE HÖRSYSTEM</B542><B541>en</B541><B542>HEARING SYSTEM AND METHOD FOR OPERATING A HEARING SYSTEM</B542><B541>fr</B541><B542>PROCÉDÉ DE FONCTIONNEMENT D'UN SYSTÈME AUDITIF ET SYSTÈME AUDITIF</B542></B540><B590><B598>2</B598></B590></B500><B700><B710><B711><snm>Sivantos Pte. Ltd.</snm><iid>101717005</iid><irf>P190645E-MD/NM/CS</irf><adr><str>18 Tai Seng Street 
No. 08-08 
18 Tai Seng</str><city>Singapore 539775</city><ctry>SG</ctry></adr></B711></B710><B720><B721><snm>PISCHEL, Judith</snm><adr><str>Lahmannstr. 13</str><city>90419 Nürnberg</city><ctry>DE</ctry></adr></B721></B720><B740><B741><snm>FDST Patentanwälte</snm><iid>101222733</iid><adr><str>Nordostpark 16</str><city>90411 Nürnberg</city><ctry>DE</ctry></adr></B741></B740></B700><B800><B840><ctry>AL</ctry><ctry>AT</ctry><ctry>BE</ctry><ctry>BG</ctry><ctry>CH</ctry><ctry>CY</ctry><ctry>CZ</ctry><ctry>DE</ctry><ctry>DK</ctry><ctry>EE</ctry><ctry>ES</ctry><ctry>FI</ctry><ctry>FR</ctry><ctry>GB</ctry><ctry>GR</ctry><ctry>HR</ctry><ctry>HU</ctry><ctry>IE</ctry><ctry>IS</ctry><ctry>IT</ctry><ctry>LI</ctry><ctry>LT</ctry><ctry>LU</ctry><ctry>LV</ctry><ctry>MC</ctry><ctry>MK</ctry><ctry>MT</ctry><ctry>NL</ctry><ctry>NO</ctry><ctry>PL</ctry><ctry>PT</ctry><ctry>RO</ctry><ctry>RS</ctry><ctry>SE</ctry><ctry>SI</ctry><ctry>SK</ctry><ctry>SM</ctry><ctry>TR</ctry></B840><B844EP><B845EP><ctry>BA</ctry></B845EP><B845EP><ctry>ME</ctry></B845EP></B844EP><B848EP><B849EP><ctry>KH</ctry></B849EP><B849EP><ctry>MA</ctry></B849EP><B849EP><ctry>MD</ctry></B849EP><B849EP><ctry>TN</ctry></B849EP></B848EP></B800></SDOBI>
<abstract id="abst" lang="de">
<p id="pa01" num="0001">Es wird ein Verfahren zum Betrieb eines Hörsystems (2) angegeben, wobei das Hörsystem (2) ein Hörgerät (4) aufweist, welches von einem Nutzer (N) getragen wird, wobei das Hörsystem (2) ein Zusatzgerät (6) aufweist, welches eine Kamera (8) aufweist, mittels welcher von einer aktuellen Umgebung (U) ein Echtzeitbild (E) aufgenommen wird, wobei das Zusatzgerät (6) einen Bildschirm (10) aufweist, auf welchem das Echtzeitbild (E) ausgegeben wird, sodass die Umgebung (U) auf dem Bildschirm (10) dargestellt wird, wobei das Hörgerät (4) an das Zusatzgerät (6) eine Information (I) übermittelt, welche mit einem Teilbereich (T) der Umgebung (U) verknüpft ist und somit eine Information (I) zu diesem Teilbereich (T) ist, wobei die Information (I) ebenfalls auf dem Bildschirm (10) dargestellt wird, indem ein Bildelement (B) erzeugt wird und mit dem Echtzeitbild (E) derart überlagert wird, dass für den Nutzer (N) erkennbar ist, mit welchem Teilbereich (T) der Umgebung (U) die Information (I) verknüpft ist. Außerdem werden ein Hörsystem (2) und ein Computerprogrammprodukt angegeben.
<img id="iaf01" file="imgaf001.tif" wi="96" he="71" img-content="drawing" img-format="tif"/></p>
</abstract>
<description id="desc" lang="de"><!-- EPO <DP n="1"> -->
<p id="p0001" num="0001">Die Erfindung betrifft ein Verfahren zum Betrieb eines Hörsystems sowie ein entsprechendes Hörsystem.</p>
<p id="p0002" num="0002">Ein Hörsystem weist ein Hörgerät auf, welches von einem Nutzer am oder im Ohr getragen wird. Das Hörgerät nimmt Geräusche aus der Umgebung mittels eines oder mehrerer Mikrofone auf und erzeugt dabei elektrische Eingangssignale, welche über einen Hörer des Hörgeräts wieder in Geräusche umgewandelt und an den Nutzer ausgegeben werden. Die elektrischen Eingangssignale werden mittels einer Signalverarbeitung zu elektrischen Ausgangssignalen für den Hörer verarbeitet, um das Hörerlebnis und die Wahrnehmung der Geräusche an die persönlichen Bedürfnisse des Nutzers anzupassen. Typischerweise dient ein Hörgerät zur Versorgung eines hörgeschädigten Nutzers, d.h. zum Ausgleich eines Hördefizits des Nutzers. Die Signalverarbeitung verarbeitet die elektrischen Eingangssignale dann derart, dass das Hördefizit ausgeglichen wird. Weiter weist ein Hörsystem oftmals ein Zusatzgerät auf, welches mit dem Hörgerät verbunden ist, um Daten auszutauschen.</p>
<p id="p0003" num="0003">Beispielsweise ist in der <patcit id="pcit0001" dnum="EP3120578B1"><text>EP 3 120 578 B1</text></patcit> ein System mit einer Empfehlungs-Engine beschrieben, welche über eine mobile Vorrichtung mit einer Hörhilfevorrichtung kommunizieren kann.</p>
<p id="p0004" num="0004">In der <patcit id="pcit0002" dnum="EP2928214A1"><text>EP 2 928 214 A1</text></patcit> ist ein binaurales Hörassistenzsystem beschrieben, mit zwei Hörassistenzgeräten und mit einem Nutzer-Interface, welches mit den Hörassistenzgeräten kommunizieren kann.<!-- EPO <DP n="2"> --></p>
<p id="p0005" num="0005">Die <patcit id="pcit0003" dnum="US9669296B1"><text>US 9,669,296 B1</text></patcit> beschreibt ein Verfahren zur Bereitstellung eines Spiels mit paralleler Realität. Es werden ein System und ein Verfahren beschrieben, um einer Aktivität in der realen Welt mit einer ortsbasierten parallelen Spielrealität zu verknüpfen.</p>
<p id="p0006" num="0006">Die <patcit id="pcit0004" dnum="US9539498B1"><text>US 9,539,498 B1</text></patcit> beschreibt ein Verfahren, zum Abbilden von Aktionen in der realen Welt auf eine virtuelle Welt mit einer parallelen Spielrealität. Die virtuelle Welt weist Erlebnisse auf, welche durch Aktionen in der realen Welt beeinflusst werden.</p>
<p id="p0007" num="0007">Vor diesem Hintergrund ist es eine Aufgabe der Erfindung, den Betrieb eines Hörsystems zu verbessern und für einen Nutzer möglichst intuitiv zu gestalten. Der Betrieb eines Hörsystems und speziell eines Hörgeräts soll für den Nutzer möglichst aufwandsarm sein.</p>
<p id="p0008" num="0008">Die Aufgabe wird erfindungsgemäß gelöst durch ein Verfahren mit den Merkmalen gemäß Anspruch 1, durch ein Hörsystem mit den Merkmalen gemäß Anspruch 14 sowie durch ein Computerprogrammprodukt mit den Merkmalen gemäß Anspruch 15. Vorteilhafte Ausgestaltungen, Weiterbildungen und Varianten sind Gegenstand der Unteransprüche. Die Aufgabe wird weiterhin insbesondere jeweils eigenständig gelöst durch ein Hörgerät und durch ein Zusatzgerät, welche jeweils zur Durchführung des Verfahrens ausgebildet sind. Die Ausführungen im Zusammenhang mit dem Verfahren gelten sinngemäß auch für das Hörsystem, das Computerprogrammprodukt, das Hörgerät sowie das Zusatzgerät und umgekehrt. Sofern nachfolgend Verfahrensschritte des Verfahrens beschrieben werden, ergeben sich vorteilhafte Ausgestaltungen für das Hörsystem, das Hörgerät und das Zusatzsystem insbesondere dadurch, dass dieses ausgebildet ist, einen oder mehrere dieser Verfahrensschritte auszuführen.</p>
<p id="p0009" num="0009">Das Verfahren dient zum Betrieb eines Hörsystems. Das Hörsystem weist ein Hörgerät auf, welches von einem Nutzer getragen wird. Weiter weist das Hörsystem ein Zusatzgerät auf, welches eine Kamera aufweist, mittels welcher von einer aktuellen Umgebung ein Echtzeitbild aufgenommen wird. Das Zusatzgerät weist<!-- EPO <DP n="3"> --> einen Bildschirm auf, auf welchem das Echtzeitbild ausgegeben wird, sodass die Umgebung insbesondere in Echtzeit auf dem Bildschirm dargestellt wird. Damit dient das Verfahren insbesondere auch zum Betrieb des Hörgeräts und des Zusatzgeräts. Die Umgebung ist real und somit eine Realität, das Echtzeitbild ist ein Abbild dieser Realität.</p>
<p id="p0010" num="0010">Ein Kern der Erfindung ist insbesondere die Erzeugung einer erweiterten Realität (auch als "augmented reality" bezeichnet) auf dem Zusatzgerät durch eine Verknüpfung der Umgebung mit Informationen, d.h. Daten, vom Hörgerät. Hierzu übermittelt das Hörgerät an das Zusatzgerät eine Information, welche mit einem Teilbereich der Umgebung verknüpft ist und somit eine Information zu diesem Teilbereich ist. Die Information wird dann auf dem Bildschirm dargestellt, indem ein Bildelement erzeugt wird und mit dem Echtzeitbild derart überlagert wird, dass für den Nutzer erkennbar ist, mit welchem Teilbereich der Umgebung die Information verknüpft ist. Die Information vom Hörgerät wird somit als ein virtuelles Bild in ein Abbild der realen Umgebung projiziert. Daraus ergibt sich der Vorteil, dass dem Nutzer auf dem Bildschirm die Beziehung zwischen der Umgebung und den Informationen vom Hörgerät verdeutlicht wird und weiterhin dem Nutzer ein besonders intuitiver Zugang zum Verständnis des Betriebs des Hörgeräts ermöglicht wird.</p>
<p id="p0011" num="0011">Unter "verknüpft" wird insbesondere verstanden, dass die Information eine Eigenschaft oder einen Aspekt des Teilbereichs oder eines Objekts darin beschreibt oder eine Einstellung des Hörgeräts zur Interaktion mit dem Teilbereich oder einem Objekt darin. Mit anderen Worten: die Information ist allgemein eine Umgebungs- oder Hörgerätinformation und gibt insbesondere an, wie das Hörgerät ein Schallsignal aus einem Teilbereich der Umgebung bewertet (Umgebungsinformation) oder verarbeitet (Hörgerätinformation). Die Information ist z.B. eine konkreter Wert eines Betriebsparameters des Hörgeräts und dann eine Hörgerätinformation oder ein Wert einer Eigenschaft eines Teilbereichs der Umgebung, speziell eines Schallsignals aus diesem Teilbereich, und dann eine Umgebungsinformation.<!-- EPO <DP n="4"> --></p>
<p id="p0012" num="0012">Die konkrete Ausgestaltung der Information ist aber an sich zunächst nicht relevant, wichtiger ist, dass die Information in bestimmter Weise auf dem Bildschirm dargestellt wird, nämlich nicht einfach als bloße Daten ohne Bezug zur Umgebung, sondern als eine Überlagerung derart, dass die Information im Echtzeitbild visuell demjenigen Teilbereich der Umgebung zugeordnet ist, welcher mit der Information verknüpft ist. Hierzu wird die Information zur Darstellung in ein Bildelement übersetzt, welches mit dem Echtzeitbild überlagert wird, sodass auf dem Bildschirm eine erweiterte Realität dargestellt wird, bei welcher das Echtzeitbild die Realität ist und das Bildelement, d.h. die Information, eine Erweiterung dieser Realität. In diesem Sinne ist das Echtzeitbild real, da dessen Elemente von der Kamera erfasst werden, und das Bildelement virtuell, da dieses nicht von der Kamera erfasst wird, sondern zusätzlich erzeugt wird, vorzugsweise von einer Steuereinheit des Zusatzgeräts.</p>
<p id="p0013" num="0013">Die Umgebung ist üblicherweise in mehrere Teilbereiche unterteilt, sodass entsprechend auch das Echtzeitbild in mehrere Bildteile unterteilt, wobei jeder Bildteil einen Teilbereich darstellt und umgekehrt. Ein jeweiliger Teilbereich ist beispielsweise ein Raumbereich, welcher von einem Objekt, z.B. einer Person, eingenommen wird, oder ein Winkel- oder Raumwinkelbereich, z.B. ist die Umgebung ausgehend vom Nutzer in mehrere Winkelbereiche unterteilt, oder der Teilbereich ist ein sonstwie zumindest teilweise begrenzter Bereich der Umgebung. Die genaue Abgrenzung des Teilbereichs gegenüber der übrigen Umgebung ist insbesondere abhängig von der Art der Information.</p>
<p id="p0014" num="0014">Das Bildelement ist geeigneterweise eine Markierung, welche auf den Teilbereich zeigt oder in oder an diesem angezeigt wird, z.B. ein Symbol, ein Icon, ein Pfeil, ein Kreuz, ein Kreis, eine Linie oder dergleichen. Alternativ ist das Bildelement ein Textelement im oder am Teilbereich, ein Rahmen um den Teilbereich herum, eine Umrandung des Teilbereichs, eine Färbung, Transparenz, Bildschärfe oder Kontrast desjenigen Teils des Echtzeitbildes, welcher den Teilbereich zeigt, oder Linien zum Markieren des Teilbereichs. Geeignet sind auch Kombinationen der vorgenannten Ausgestaltungen. Die konkrete Ausgestaltung des Bildelements ist insbesondere abhängig von der Art der Information, welche dargestellt wird.<!-- EPO <DP n="5"> --></p>
<p id="p0015" num="0015">Ein Ausgangspunkt der Erfindung ist insbesondere die Beobachtung, dass ein Hörgerät üblicherweise ein oder mehrere Bedienelemente aufweist, mittels welchen sich ein oder mehrere Betriebsparameter des Hörgeräts vom Nutzer einstellen lassen. Beispiele für solche Betriebsparameter sind ein Verstärkungsfaktor des Hörgeräts, eine Ausrichtung oder eine Breite einer Richtkeule eines Richtmikrofons des Hörgeräts zur räumlichen Fokussierung und dergleichen. Beispiele für Bedienelemente sind Schalter, Taster, Rädchen und Kippschalter. Alternativ oder zusätzlich ist ein Betriebsparameter über ein separates Zusatzgerät einstellbar, z.B. mittels eines Smartphones.</p>
<p id="p0016" num="0016">Ein weiterer Ausgangspunkt der Erfindung ist insbesondere die Beobachtung, dass zur Demonstration eines Hörgeräts und dessen Funktionsumfang im Betrieb z.B. im Rahmen einer Produktpräsentation sogenannte Demo-Apps verwendet werden, um einem potentiellen Nutzer den Betrieb des Hörgeräts in unterschiedlichen Situationen zu demonstrieren.</p>
<p id="p0017" num="0017">Die Einstellung von Betriebsparametern ist durch Bedienelemente am Hörgerät selbst aufgrund der Größe des Hörgeräts typischerweise nur eingeschränkt möglich und auch nicht unbedingt intuitiv, da die Auswirkungen einer Änderung nicht unmittelbar sichtbar sind. Auch eine Rückmeldung an den Nutzer, wie ein oder mehrere Betriebsparameter zum aktuellen Zeitpunkt eingestellt sind ist nur eingeschränkt möglich und für den Nutzer nicht unbedingt komfortabel oder verständlich.</p>
<p id="p0018" num="0018">Im Vergleich zu einem Bedienelement am Hörgerät bietet ein Zusatzgerät zur Einstellung von Betriebsparametern einen erhöhten Komfort und verbesserten Umfang und über eine Anzeige auch eine umfangreichere Rückmeldung. Speziell bei einem Smartphone als Zusatzgerät ist mittels eines Computerprogrammprodukts, z.B. einer App, welches auf dem Zusatzgerät läuft, vorteilhafterweise eine verbesserte Einstellung und Überwachung des Betriebs des Hörgeräts ermöglicht. Das Zusatzgerät zeigt auf einem Bildschirm beispielsweise an, welches von mehreren Betriebsprogrammen des Hörgeräts aktiviert ist oder ermöglicht die Einstellung<!-- EPO <DP n="6"> --> eines Betriebsparameters, z.B. eines räumlichen Fokus, und dadurch auf einfache Weise auch eine Demonstration des Funktionsumfangs eines Hörgeräts.</p>
<p id="p0019" num="0019">Nachteilig ist dabei allerdings, dass weiterhin eine Beziehung zur tatsächlichen Umgebung fehlt. Die Einstellungen und das Verhalten des Hörgeräts im Betrieb sind nicht direkt mit der Umgebung des Nutzers verknüpft und die Interaktion des Hörgeräts mit der Umgebung im Betrieb ist für den Nutzer nicht mühelos erkennbar. Mit anderen Worten: der Nutzer muss immer eine gewisse Denkanstrengung unternehmen, um die vorgenommenen Einstellungen und deren Auswirkungen mit der tatsächlichen Umgebung zu verknüpfen. Beispielsweise wird dem Nutzer auf dem Zusatzgerät zwar angezeigt, dass eine Richtkeule des Hörgeräts in einem bestimmten Winkel z.B. relativ zur Blickrichtung ausgerichtet ist, diese Information steht jedoch nicht in unmittelbarer Beziehung mit der Umgebung, sodass für den Nutzer nicht erkennbar ist, welcher Teilbereich der Umgebung hiervon betroffen ist.</p>
<p id="p0020" num="0020">Vorliegend wird nun in vorteilhafter Weise dem Nutzer eine Verknüpfung einer Information mit einem Teilbereich der Umgebung auch tatsächlich angezeigt, nämlich über die erweiterte Realität auf dem Bildschirm. Die Information wird vorteilhaft dabei derart angezeigt und mit dem Echtzeitbild, d.h. dem Abbild der tatsächlichen Umgebung, überlagert, dass für den Nutzer unmittelbar und intuitiv, d.h. insbesondere ohne Denkanstrengung erkennbar ist, in welcher Beziehung die Information mit der Umgebung steht.</p>
<p id="p0021" num="0021">Das Hörgerät dient vorzugsweise zur Versorgung eines hörgeschädigten Nutzers. Hierzu weist das Hörgerät zumindest ein Mikrofon auf, welches Schall aus der Umgebung aufnimmt und ein elektrisches Eingangssignal erzeugt. Dieses wird zur Modifikation einer Signalverarbeitung des Hörgeräts zugeführt. Die Signalverarbeitung ist vorzugsweise ein Teil der Steuereinheit. Die Modifikation erfolgt insbesondere anhand eines individuellen Audiogramms des Nutzers, welcher dem Hörgerät zugeordnet ist, sodass ein individuelles Hördefizit des Nutzers ausgeglichen wird. Die Signalverarbeitung gibt als Ergebnis ein elektrisches Ausgangssignal aus,<!-- EPO <DP n="7"> --> welches dann über einen Hörer des Hörgeräts wieder in Schall umgewandelt wird und an den Nutzer ausgegeben wird.</p>
<p id="p0022" num="0022">Vorzugsweise ist das Hörgerät ein binaurales Hörgerät, mit zwei Einzelgeräten, welche jeweils zumindest ein Mikrofon und einen Hörer aufweisen und welche vom Nutzer auf unterschiedlichen Seiten des Kopfs getragen werden, nämlich einmal am oder im linken Ohr und einmal am oder im rechten Ohr. Abseits von einem solchen binauralen Hörgerät ist auch eine Ausgestaltung möglich und geeignet, bei welcher das Hörgerät zwei Einzelgeräte wie beschrieben aufweist, von welchen jedoch lediglich eines einen Hörer aufweist und das andere nicht.</p>
<p id="p0023" num="0023">Das Zusatzgerät ist vorzugsweise ein einzelnes Gerät, in welchem die Kamera und der Bildschirm zusammengefasst sind. In einer geeigneten Ausgestaltung hierzu ist das Zusatzgerät ein Smartphone. Alternativ ist aber auch eine Ausgestaltung geeignet, bei welcher das Zusatzgerät die Kamera und den Bildschirm als zwei separate Geräte aufweist.</p>
<p id="p0024" num="0024">Zur Übermittlung der Information weisen das Hörgerät und das Zusatzgerät jeweils eine Schnittstelle zur Datenübertragung auf, z.B. eine Bluetooth-Schnittstelle, und sind über diese Schnittstellen miteinander verbunden oder gekoppelt. Bei der Datenübertragung wird dann zumindest die Information vom Hörgerät zum Zusatzgerät übertragen.</p>
<p id="p0025" num="0025">Zweckmäßigerweise wird eine relative Lage des Hörgeräts und des Zusatzgeräts zueinander bestimmt um auf diese Weise die Verknüpfung der Information mit dem Teilbereich besonders genau wiedergeben zu können. Beispielsweise wird die jeweilige Position des Hörgeräts und des Zusatzgeräts mittels geeigneter Sensoren, z.B. eines Gyroskops, eines Magnetfeldsensors, eines Beschleunigungssensors oder eines GPS-Systems, ermittelt und anhand dessen die relative Lage bestimmt. Zur Verbesserung der Genauigkeit wird geeigneterweise die jeweilige Ausrichtung des Hörgeräts und des Zusatzgeräts z.B. mittels geeigneter Sensoren, z.B. Beschleunigungssensoren, gemessen. Grundsätzlich ist aber auch eine Ausgestaltung geeignet, bei welcher die relative Lage ohne zusätzliche Messung<!-- EPO <DP n="8"> --> geschätzt wird. Beispielsweise wird einfach vorausgesetzt, dass die Kamera in Übereinstimmung mit der Blickrichtung des Nutzers ausgerichtet ist und/oder die Position des Nutzers wird gleichgesetzt mit der Position der Kamera. Alternativ wird beispielsweise bei einem Smartphone als Zusatzgerät davon ausgegangen, dass der Nutzer dieses im Abstand weniger 10 cm vor sich und etwa auf Augenhöhe hält, sodass dann davon ausgegangen wird, dass sich das Zusatzgerät z.B. 20 cm in Blickrichtung vor dem Hörgerät befindet und die Kamera in Blickrichtung ausgerichtet ist. Für das Hörgerät wird davon ausgegangen, dass dieses in oder an einem oder beiden Ohren des Nutzers getragen wird.</p>
<p id="p0026" num="0026">In einer vorteilhaften Ausgestaltung ist die Information ein Vorhandensein einer Schallquelle in dem Teilbereich. Das Hörgerät erkennt das Vorhandensein der Schallquelle und übermittelt dies an das Zusatzgerät, zur Darstellung in dem Echtzeitbild. In dem Echtzeitbild markiert das Bildelement dann den Teilbereich, um in diesem das Vorhandensein der Schallquelle anzuzeigen. Dadurch ist für den Nutzer auf dem Bildschirm unmittelbar erkennbar, wo in der Umgebung das Hörgerät eine Schallquelle erkennt. Wie das Hörgerät die Schallquelle erkennt ist zunächst unwesentlich. Zur Erkennung einer Schallquelle weist das Hörgerät zweckmäßigerweise eine entsprechend ausgebildete Analyseeinheit auf, z.B. als Teil einer Steuereinheit des Hörgeräts.</p>
<p id="p0027" num="0027">Das Hörgerät erkennt zweckmäßigerweise nicht lediglich das bloße Vorhandensein einer Schallquelle, sondern auch deren Position, insbesondere relativ zum Hörgerät, also den Teilbereich, in welchem sich die Schallquelle befindet. Auch diese Position wird zweckmäßigerweise an das Zusatzgerät übermittelt, sodass dieses das Vorhandensein an der entsprechenden Position im Echtzeitbild anzeigt. Das Bildelement zur Darstellung des Vorhandenseins einer Schallquelle in einem bestimmten Teilbereich ist beispielsweise ein Pfeil oder ein Rahmen.</p>
<p id="p0028" num="0028">Zusätzlich bestimmt das Hörgerät vorteilhafterweise auch eine Klasse der Schallquelle, d.h. welcher Art die Schallquelle ist. Hierzu weist das Hörgerät beispielsweise einen Klassifikator auf, z.B. als Teil der Steuereinheit. Das Eingangssignal des Mikrofons wird dem Klassifikator zugeführt und dort klassifiziert. Auch die<!-- EPO <DP n="9"> --> Klasse ist eine Information, welche zweckmäßigerweise an entsprechender Stelle im Echtzeitbild angezeigt wird. Zur Darstellung der Klasse einer Schallquelle ist besonders ein Symbol oder ein Textelement geeignet.</p>
<p id="p0029" num="0029">In einer geeigneten Ausgestaltung ist die Schallquelle ein Gesprächspartner des Nutzers und wird als solcher im Echtzeitbild mittels des Bildelements markiert. Mit anderen Worten: die Schallquelle weist eine Klasse auf, welche vom Hörgerät als "Gesprächspartner" erkannt wird und dann vom Zusatzgerät angezeigt wird. Dadurch ist über den Bildschirm für den Nutzer sofort erkennbar, wo das Hörgerät in der Umgebung einen Gesprächspartner identifiziert hat.</p>
<p id="p0030" num="0030">In einer vorteilhaften Ausgestaltung wird in dem Echtzeitbild ein Winkel angezeigt, in welchem sich die Schallquelle relativ zur Blickrichtung des Nutzers befindet. Beispielsweise wird der Winkel als Paar von zwei Linien oder Pfeilen dargestellt, eine in Blickrichtung und eine weitere vom Nutzer zur Schallquelle hin. Alternativ oder zusätzlich wird der Winkel einfach als Zahl derart in der Nähe der Schallquelle angezeigt, dass der Winkel für den Nutzer möglichst eindeutig dieser Schallquelle zugeordnet ist.</p>
<p id="p0031" num="0031">In einer vorteilhaften Ausgestaltung ist die Information ein Signal-zu-Rauschverhältnis, kurz SNR, des Teilbereichs. Das Hörgerät misst das SNR in dem Teilbereich, z.B. mittels einer Analyseeinheit als Teil der Steuereinheit. Das SNR wird dann als Information zur Darstellung in dem Echtzeitbild an das Zusatzgerät übermittelt. Das Bildelement gibt dann das SNR an, genauer gesagt das SNR für den Teilbereich. Entsprechend wird zweckmäßigerweise das SNR jeweils separat für mehrere unterschiedliche Teilbereiche gemessen und dadurch auf dem Bildschirm dann dem Echtzeitbild sozusagen eine SNR-Karte überlagert, sodass der Nutzer unmittelbar zu einem jeweiligen Teilbereich der Umgebung das SNR ablesen kann.</p>
<p id="p0032" num="0032">In einer vorteilhaften Ausgestaltung gibt die Information an, ob für den Teilbereich eine Störgeräuschunterdrückung des Hörgeräts aktiviert ist. Die Störgeräuschunterdrückung ist z.B. ein Teil der Steuereinheit des Hörgeräts und ist derart ausgebildet,<!-- EPO <DP n="10"> --> dass diese in aktiviertem Zustand Störgeräusche im Eingangssignal unterdrückt. Die Störgeräuschunterdrückung ist insbesondere selektiv für ein oder mehrere Teilbereiche aktivierbar, sodass unterschiedliche Teilbereiche und darin befindliche Störgeräuschquellen unterschiedlich stark unterdrückbar sind. Das Bildelement zeigt nun an, ob für den jeweiligen Teilbereich die Störgeräuschunterdrückung aktiviert ist.</p>
<p id="p0033" num="0033">In einer zweckmäßigen Ausgestaltung gibt die Information nicht nur an, ob für den Teilbereich eine Störgeräuschunterdrückung aktiviert ist, sondern genauer, wie stark Störgeräusche aus dem Teilbereich von der Störgeräuschunterdrückung unterdrückt werden. Hierzu wird beispielsweise ein Dämpfungsfaktor als Textelement im Echtzeitbild angezeigt.</p>
<p id="p0034" num="0034">In einer vorteilhaften Ausgestaltung ist das Bildelement eine eingefärbte oder transparente Fläche oder beides, welche in dem Echtzeitbild mit dem Teilbereich überlagert wird, sodass dieser abhängig von der Information eingefärbt oder transparent dargestellt wird oder beides. Geeignet ist eine diskrete Darstellung, z.B. indem oberhalb eines Schwellwerts eine Einfärbung erfolgt und unterhalb des Schwellwerts nicht, oder eine kontinuierlich Darstellung, bei welcher z.B. die Einfärbung mit einer Farbstärke erfolgt, welche abhängig ist vom konkreten Wert der Information. Beispielsweise werden Teilbereiche der Umgebung mit geringem SNR auf dem Bildschirm grün eingefärbt und mit hohem SNR rot. Speziell bei der Einfärbung ganzer Flächen des Echtzeitbildes ist ein transparentes Bildelement zweckmäßig, um eine optimale Erkennbarkeit des dahinter liegenden Echtzeitbilds zu gewährleisten. Unter "transparent" wird insbesondere eine Transparenz &lt;100% verstanden.</p>
<p id="p0035" num="0035">Die oben beschriebenen Ausgestaltungen befassen sich überwiegend mit Informationen, welche Umgebungsinformationen sind, d.h. Informationen, welche Eigenschaften der Umgebung sind und welche vom Hörgerät durch eine Analyse von Schallsignalen aus der Umgebung ermittelt werden. Bei Hörgerätinformationen ist eine solche Analyse der Umgebung zunächst nicht unbedingt erforderlich, vielmehr zielt eine Darstellung solcher Informationen darauf ab, dem Nutzer das Verhalten<!-- EPO <DP n="11"> --> des Hörgeräts relativ zur Umgebung zu verdeutlichen. Besonders vorteilhaft ist die Darstellung einer Hörgerätinformation im Falle eines Hörgeräts, welches zum direktionalen Hören ausgebildet ist und hierzu ein Mikrofon aufweist, welches als Richtmikrofon ausgebildet ist, um Schallsignale aus einer bestimmten Richtung, d.h. aus einem bestimmten Teilbereich, gegenüber Schallsignalen aus anderen Richtungen, d.h. aus anderen Teilbereichen, hervorzuheben.</p>
<p id="p0036" num="0036">In einer vorteilhaften Ausgestaltung ist das Hörgerät zwischen einem ungerichteten und einem gerichteten Betriebsmodus umschaltbar. Im gerichteten Betriebsmodus zeigt das Bildelement an, welcher Teilbereich der Umgebung gegenüber der übrigen Umgebung hervorgehoben wird. Im ungerichteten Betriebsmodus wird dagegen kein Bildelement dargestellt oder das Bildelement zeigt an, dass kein Teilbereich der Umgebung hervorgehoben wird. Auf dem Bildschirm ist dann für den Nutzer unmittelbar erkennbar, ob das Hörgerät sich im ungerichteten Betriebsmodus (auch: omni-direktionaler Betrieb) befindet oder im gerichteten Betriebsmodus (auch: Richtbetrieb, z.B. monodirektionaler oder mehrdirektionaler Betrieb). In letzterem Fall ist dann für den Nutzer auch unmittelbar erkennbar, auf welchen Teilbereich oder auf welche Teilbereiche das Richtmikrofon gerichtet ist.</p>
<p id="p0037" num="0037">In einer vorteilhaften Ausgestaltung weist das Hörgerät ein Mikrofon auf, welches als Richtmikrofon ausgebildet ist, mit zumindest einer Richtkeule, welche auf den Teilbereich gerichtet ist und diesen abdeckt, sodass entsprechend Schallsignale aus diesem Teilbereich gegenüber Schallsignalen aus anderen Teilbereichen hervorgehoben werden. Die Information ist eine Abmessung, vorzugsweise eine Breite, oder eine Ausrichtung, vorzugsweise eine Richtung, der Richtkeule oder beides. Das Bildelement stellt die Richtkeule dar und zeigt dadurch in dem Echtzeitbild an, welcher Teilbereich der Umgebung von der Richtkeule abgedeckt wird und entsprechend aus welchem Teilbereich Schallsignale hervorgehoben werden. Das Bildelement ist vorzugsweise eine visuelle Repräsentation der Richtkeule, mit entsprechender Abmessung und/oder Ausrichtung. Geeignet ist aber beispielsweise auch eine einfache Linie oder eine andere Darstellung. Da die Richtkeule in der tatsächlichen Umgebung für den Nutzer nicht sichtbar ist, wird auf diese Weise dem Nutzer über den Bildschirm eine intuitive Darstellung der Richtkeule und deren<!-- EPO <DP n="12"> --> Lage in der Umgebung angeboten, sodass der Nutzer unmittelbar und ohne weitere Anstrengung erkennen kann, wie die Richtkeule relativ zur Umgebung dimensioniert und/oder ausgerichtet ist und entsprechend, welche Teilbereiche der Umgebung und somit welche Schallquellen hiervon gegebenenfalls betroffen sind.</p>
<p id="p0038" num="0038">Bevorzugterweise ist der Bildschirm des Zusatzgeräts zugleich als ein Eingabegerät ausgebildet, mittels welchem ein oder mehrere Betriebsparameter des Hörgeräts einstellbar sind. Auf diese Weise ist auch eine besonders intuitive Bedienung realisiert, mit welcher das Hörgerät auf einfache Weise einstellbar ist. Die Auswirkungen einer jeweiligen Einstellung sind für den Nutzer unmittelbar anhand des Echtzeitbilds und der darübergelegten Information erkennbar. Beispielsweise sind die Abmessung oder die Ausrichtung der Richtkeule oder beide durch den Nutzer unmittelbar im Echtzeitbild einstellbar.</p>
<p id="p0039" num="0039">Ebenfalls geeignet ist eine Ausgestaltung, bei welcher alternativ oder zusätzlich zum Bildschirm als Eingabegerät das Zusatzgerät oder das Hörgerät ein oder mehrere Bedienelemente aufweisen, zum Einstellen eines oder mehrere Betriebsparameter des Hörgeräts. Die Auswirkungen einer Einstellung mittels dieser Bedienelemente sind dann für den Nutzer vorteilhaft unmittelbar auf dem Bildschirm erkennbar.</p>
<p id="p0040" num="0040">Zweckmäßig ist auch eine Ausgestaltung, bei welcher ein Avatar mit dem Echtzeitbild überlagert wird, um darin eine Position des Nutzers in der Umgebung anzuzeigen. Der Avatar ist demnach eine virtuelle Repräsentation des Nutzers auf dem Bildschirm und verortet somit den Nutzer innerhalb der erweiterten Realität. Sofern sich Nutzer und Kamera auf unterschiedlichen Seiten des Bildschirms befinden, stellt die Positionierung des Avatars entweder insbesondere lediglich eine Näherung dar, welche jedoch typischerweise ausreichend ist, falls das Zusatzgerät sich hinreichend nah am Hörgerät befindet, z.B. innerhalb eines Abstands von weniger als 0,5 m.</p>
<p id="p0041" num="0041">In einer vorteilhaften Ausgestaltung werden Schallsignale aus der Umgebung von dem Hörgerät aufgenommen und als Eingabesignale für ein Spiel verwendet, welches<!-- EPO <DP n="13"> --> auf dem Zusatzgerät aktiv ist. Das Spiel dient beispielsweise zur Verdeutlichung oder Erläuterung einer Funktion des Hörgeräts oder realisiert ein Training im Umgang mit dem Hörgerät oder ein Hörtraining. Geeignet ist beispielsweise eine Ausgestaltung, bei welcher dem Nutzer im Rahmen des Spiels eine Aufgabe gestellt wird, welche er oder sie lösen soll, z.B. durch das eigene Verhalten und/oder mittels entsprechender Benutzung oder Bedienung des Hörgeräts. Ein beispielhaftes Spiel stellt dem Nutzer die Aufgabe, ein Gespräch zwischen zwei Personen derart zu moderieren, dass diese innerhalb einer Toleranz einen gleichen Gesprächsanteil am Gespräch haben. Für ein Hörtraining wird dem Nutzer beispielsweise die Aufgabe gestellt, eine bestimmte Geräuschsituation, z.B. ein Gespräch, oder einen bestimmten Geräuschtyp, z.B. einen Vogel, eine Person oder Livemusik, in der Umgebung ausfindig zu machen.</p>
<p id="p0042" num="0042">Ein erfindungsgemäßes Hörsystem ist ausgebildet zur Durchführung eines Verfahrens wie vorstehend beschrieben. Vorzugsweise weist das Hörsystem hierzu eine Steuereinheit auf. In der Steuereinheit ist das Verfahren insbesondere programmtechnisch oder schaltungstechnisch realisiert oder eine Kombination hiervon. Beispielswiese ist die Steuereinheit hierfür als ein Mikroprozessor oder als ein ASIC ausgebildet oder als eine Kombination hiervon. Die Steuereinheit ist zweckmäßigerweise auf das Hörgerät und das Zusatzgerät aufgeteilt. Grundsätzlich lassen sich die oben beschriebenen Verfahrensschritte weitgehend beliebig auf das Zusatzgerät und das Hörgerät aufteilen.</p>
<p id="p0043" num="0043">Das erfindungsgemäße Computerprogrammprodukt enthält ein ausführbares Programm, welches bei oder nach einer Installation auf einem Hörsystem wie oben beschrieben das Verfahren wie oben beschrieben automatisch ausführt. Das Programm wird entweder auf dem Hörgerät oder auf dem Zusatzgerät installiert oder beides. Besonders zweckmäßig ist eine Ausgestaltung, bei welcher das Computerprogrammprodukt eine App ist, zur Installation auf dem Zusatzgerät. Mittels der App empfängt das Zusatzgerät die Information vom Hörgerät und erzeugt aus dieser ein geeignetes Bildelement, welches dann mit dem Echtzeitbild von der Kamera überlagert wird, um auf dem Bildschirm eine erweiterte Realität darzustellen.<!-- EPO <DP n="14"> --></p>
<p id="p0044" num="0044">Nachfolgend werden Ausführungsbeispiele anhand einer Zeichnung näher erläutert. Darin zeigen jeweils schematisch:
<dl id="dl0001">
<dt>Fig. 1</dt><dd>einen Nutzer und ein Hörsystem,</dd>
<dt>Fig. 2</dt><dd>das Hörsystem aus <figref idref="f0001">Fig. 1</figref>,</dd>
<dt>Fig. 3</dt><dd>ein Zusatzgerät des Hörsystems aus <figref idref="f0002">Fig. 2</figref>, mit einem erweiterten Echtzeitbild,</dd>
<dt>Fig. 4-10</dt><dd>jeweils das Zusatzgerät aus <figref idref="f0002">Fig. 3</figref>, mit einer Variante des erweiterten Echtzeitbilds,</dd>
</dl></p>
<p id="p0045" num="0045">Anhand der Figuren werden nachfolgend ein Verfahren zum Betrieb eines Hörsystems 2 sowie ein solches Hörsystem 2 beschrieben. In <figref idref="f0001">Fig. 1</figref> ist ein Ausführungsbeispiel für ein Hörsystem 2 gezeigt. Das Hörsystem 2 weist ein Hörgerät 4 auf, welches von einem Nutzer N getragen wird, beispielsweise wie in <figref idref="f0002">Fig. 2</figref> gezeigt. Weiter weist das Hörsystem 2 ein Zusatzgerät 6 auf, welches eine Kamera 8 aufweist, mittels welcher von einer aktuellen Umgebung U ein Echtzeitbild E aufgenommen wird. Das Zusatzgerät 6 weist einen Bildschirm 10 auf, auf welchem das Echtzeitbild E ausgegeben wird, sodass die Umgebung U auf dem Bildschirm 10 dargestellt wird. In <figref idref="f0002">Fig. 2</figref> ist das Zusatzgerät 6 von vorn gezeigt, sodass der Bildschirm 10 sichtbar ist, wohingegen sich die Kamera 8 auf einer Rückseite des Zusatzgeräts 6 befindet und daher gestrichen dargestellt ist.</p>
<p id="p0046" num="0046">Das Hörgerät 4 dient vorliegend zur Versorgung eines hörgeschädigten Nutzers N. Hierzu weist das Hörgerät 4 zumindest ein Mikrofon 12 auf, welches Schall aus der Umgebung U aufnimmt und ein elektrisches Eingangssignal erzeugt. Dieses wird zur Modifikation einer nicht explizit gezeigten Signalverarbeitung des Hörgeräts 4 zugeführt. Die Signalverarbeitung ist hier ein Teil einer Steuereinheit 14 des Hörgeräts 2. Die Signalverarbeitung gibt als Ergebnis ein elektrisches Ausgangssignal aus, welches dann über einen Hörer 16 des Hörgeräts 4 wieder in Schall umgewandelt wird und an den Nutzer N ausgegeben wird. Vorliegend ist das Hörgerät<!-- EPO <DP n="15"> --> 4 sogar ein binaurales Hörgerät, mit zwei Einzelgeräten wie in <figref idref="f0001">Fig. 1</figref> erkennbar, welche jeweils zumindest ein Mikrofon 12 und einen Hörer 16 aufweisen und welche vom Nutzer N auf unterschiedlichen Seiten des Kopfs getragen werden, nämlich einmal am oder im linken Ohr und einmal am oder im rechten Ohr.</p>
<p id="p0047" num="0047">Das Zusatzgerät 6 ist vorliegend ein einzelnes Gerät, in welchem die Kamera 8 und der Bildschirm 10 zusammengefasst sind. Hierzu ist das Zusatzgerät 6 speziell ein Smartphone. In einer nicht gezeigten Alternative weist das Zusatzgerät 6 die Kamera 8 und den Bildschirm 10 als zwei separate Geräte auf.</p>
<p id="p0048" num="0048">Zur Übermittlung der Information weisen das Hörgerät 4 und das Zusatzgerät 6 jeweils eine Schnittstelle 18 zur Datenübertragung auf, z.B. eine Bluetooth-Schnittstelle, und sind über diese Schnittstellen 18 miteinander verbunden oder gekoppelt. Bei der Datenübertragung wird dann zumindest die Information vom Hörgerät 4 zum Zusatzgerät 6 übertragen. Die Datenübertragung erfolgt z.B. von beiden Einzelgeräten jeweils zum Zusatzgerät 6 oder wie in <figref idref="f0002">Fig. 2</figref> gezeigt von einem Einzelgerät zum anderen Einzelgerät und von diesem gesammelt zum Zusatzgerät 6. Die Information I stammt aber nicht zwingend von beiden Einzelgeräten, sondern kann je nach Art der Information I unter Umständen auch von lediglich einem der Einzelgeräte erzeugt werden.</p>
<p id="p0049" num="0049">In den gezeigten Ausführungsbeispielen wird auf dem Zusatzgerät 6 durch eine Verknüpfung der Umgebung U mit Informationen I, d.h. Daten, vom Hörgerät 4 einer erweiterten Realität (auch als "augmented reality" bezeichnet) erzeugt. Hierzu übermittelt das Hörgerät 4 an das Zusatzgerät 6 eine Information I, welche mit einem Teilbereich T der Umgebung U verknüpft ist und somit eine Information I zu diesem Teilbereich T ist. Die Information I wird dann auf dem Bildschirm 10 dargestellt, indem ein Bildelement B erzeugt wird und mit dem Echtzeitbild E derart überlagert wird, dass für den Nutzer N erkennbar ist, mit welchem Teilbereich T der Umgebung U die Information I verknüpft ist. Die Information I vom Hörgerät 4 wird somit als ein virtuelles Bild in ein Abbild der realen Umgebung U projiziert. Damit wird dem Nutzer N auf dem Bildschirm 10 die Beziehung zwischen der Umgebung U und den Informationen I vom Hörgerät 4 verdeutlicht und weiterhin wird<!-- EPO <DP n="16"> --></p>
<p id="p0050" num="0050">dem Nutzer N ein intuitiver Zugang zum Verständnis des Betriebs des Hörgeräts 4 ermöglicht.</p>
<p id="p0051" num="0051">Die Information I beschreibt hier allgemein eine Eigenschaft oder einen Aspekt des Teilbereichs T oder eines Objekts darin oder eine Einstellung des Hörgeräts 4 zur Interaktion mit dem Teilbereich T oder einem Objekt darin. Die Information I ist somit eine Umgebungs- oder Hörgerätinformation und gibt an, wie das Hörgerät 4 ein Schallsignal aus einem Teilbereich T der Umgebung U bewertet (Umgebungsinformation) oder verarbeitet (Hörgerätinformation). Die Information I ist z.B. ein konkreter Wert eines Betriebsparameters des Hörgeräts 4 und dann eine Hörgerätinformation oder ein Wert einer Eigenschaft eines Teilbereichs T der Umgebung U, speziell eines Schallsignals aus diesem Teilbereich T, und dann eine Umgebungsinformation.</p>
<p id="p0052" num="0052">Die Information I wird in bestimmter Weise auf dem Bildschirm 10 dargestellt, nämlich nicht einfach als bloßes Datum ohne Bezug zur Umgebung U, sondern als eine Überlagerung derart, dass die Information I im Echtzeitbild E visuell demjenigen Teilbereich T der Umgebung U zugeordnet ist, welcher mit der Information I verknüpft ist. Hierzu wird die Information I zur Darstellung in ein Bildelement B übersetzt, welches mit dem Echtzeitbild E überlagert wird, sodass auf dem Bildschirm 10 eine erweiterte Realität dargestellt wird, bei welcher das Echtzeitbild E die Realität ist und das Bildelement B, d.h. die Information I, eine Erweiterung dieser Realität ist. In diesem Sinne ist das Echtzeitbild E real, da dessen Elemente von der Kamera 8 erfasst werden, und das Bildelement B virtuell, da dieses nicht von der Kamera 8 erfasst wird, sondern zusätzlich erzeugt wird, vorliegend von einer Steuereinheit 20 des Zusatzgeräts 6.</p>
<p id="p0053" num="0053">Die Umgebung U ist üblicherweise in mehrere Teilbereiche T unterteilt, sodass entsprechend auch das Echtzeitbild E in mehrere Bildteile unterteilt, wobei jeder Bildteil einen Teilbereich T darstellt und umgekehrt, sodass in den Figuren die Bildteile der Einfachheit halber ebenfalls als Teilbereiche T markiert sind. Ein jeweiliger Teilbereich T ist beispielsweise ein Raumbereich, welcher von einem Objekt, z.B. einer Person, eingenommen wird, oder ein Winkel- oder Raumwinkelbereich,<!-- EPO <DP n="17"> --> z.B. ist die Umgebung U ausgehend vom Nutzer N in mehrere Winkelbereiche unterteilt, oder der Teilbereich T ist ein sonstwie zumindest teilweise begrenzter Bereich der Umgebung U. Die genaue Abgrenzung des Teilbereichs T gegenüber der übrigen Umgebung U ist insbesondere abhängig von der Art der Information I.</p>
<p id="p0054" num="0054">Das Bildelement B ist beispielsweise eine Markierung, welche auf den Teilbereich T zeigt oder in oder an diesem angezeigt wird, z.B. ein Symbol, ein Icon, ein Pfeil, ein Kreuz, ein Kreis, eine Linie oder dergleichen. Alternativ ist das Bildelement B ein Textelement im oder am Teilbereich T, ein Rahmen um den Teilbereich T herum, eine Umrandung des Teilbereichs T, eine Färbung, Transparenz, Bildschärfe oder Kontrast desjenigen Teils des Echtzeitbildes E, welcher den Teilbereich T zeigt, oder Linien zum Markieren des Teilbereichs T. Möglich und geeignet sind auch Kombinationen der vorgenannten Ausgestaltungen. Verschiedene Beispiele für Bildelemente B sind in den Figuren gezeigt.</p>
<p id="p0055" num="0055">In einer möglichen Ausgestaltung wird eine relative Lage des Hörgeräts 4 und des Zusatzgeräts 6 zueinander bestimmt, um auf diese Weise die Verknüpfung der Information I mit dem Teilbereich T besonders genau wiedergeben zu können. Grundsätzlich ist aber auch eine Ausgestaltung möglich, bei welcher die relative Lage ohne zusätzliche Messung geschätzt wird. Beispielsweise wird bei einem Smartphone als Zusatzgerät 6 davon ausgegangen, dass der Nutzer N dieses wie in <figref idref="f0002">Fig. 2</figref> gezeigt im Abstand weniger 10 cm vor sich und etwa auf Augenhöhe hält, sodass dann davon ausgegangen wird, dass sich das Zusatzgerät 6 z.B. 20 cm in Blickrichtung R vor dem Hörgerät 4 befindet. Für das Hörgerät 4 wird davon ausgegangen, dass dieses in oder an einem oder beiden Ohren des Nutzers N getragen wird, wie ebenfalls in <figref idref="f0002">Fig. 2</figref> gezeigt.</p>
<p id="p0056" num="0056">In <figref idref="f0002">Fig. 3</figref> ist eine Ausgestaltung gezeigt, bei welcher die Information I ein Vorhandensein einer Schallquelle 22 in dem Teilbereich T ist. Das Hörgerät 4 erkennt das Vorhandensein der Schallquelle 22 und übermittelt dies an das Zusatzgerät 6, zur Darstellung in dem Echtzeitbild E. In diesem markiert das Bildelement B dann den Teilbereich T, um in diesem das Vorhandensein der Schallquelle 22 anzuzeigen.<!-- EPO <DP n="18"> --></p>
<p id="p0057" num="0057">Dadurch ist für den Nutzer N auf dem Bildschirm B unmittelbar erkennbar, wo in der Umgebung U das Hörgerät 4 eine Schallquelle 22 erkennt. Im Ausführungsbeispiel der <figref idref="f0002">Fig. 3</figref> erkennt das Hörgerät 4 zusätzlich auch die Position der Schallquelle relativ zum Hörgerät 4, also den Teilbereich T, in welchem sich die Schallquelle 22 befindet. Auch diese Position wird an das Zusatzgerät 6 übermittelt, sodass dieses das Vorhandensein an der entsprechenden Position im Echtzeitbild E anzeigt. Das Bildelement B zur Darstellung des Vorhandenseins der Schallquelle 22 ist in <figref idref="f0002">Fig. 3</figref> beispielhaft ein Rahmen um die Schallquelle 22 herum.</p>
<p id="p0058" num="0058">Zusätzlich bestimmt das Hörgerät 4 im Ausführungsbeispiel der <figref idref="f0002">Fig. 3</figref> auch eine Klasse der Schallquelle 22, d.h. welcher Art die Schallquelle 22 ist. Hierzu weist das Hörgerät 4 beispielsweise einen nicht explizit gezeigten Klassifikator auf, z.B. als Teil der Steuereinheit 14. Auch die Klasse ist eine Information I, welche an entsprechender Stelle im Echtzeitbild E angezeigt wird. Zur Darstellung der Klasse der Schallquelle 22 wird in <figref idref="f0002">Fig. 3</figref> als Bildelement B ein Textelement verwendet, welches hier explizit die Klasse "speaker" (d.h. Gesprächspartner) angibt und am Rahmen angeordnet ist, sodass erkennbar ist, dass die Klasse zu der markierten Schallquelle 22 gehört.</p>
<p id="p0059" num="0059">In <figref idref="f0002">Fig. 3</figref> ist die Schallquelle 22 konkret ein Gesprächspartner des Nutzers N und wird als solcher im Echtzeitbild E mittels mehrerer Bildelemente B markiert. Dadurch ist über den Bildschirm 10 für den Nutzer N sofort erkennbar, wo das Hörgerät 4 in der Umgebung U einen Gesprächspartner identifiziert hat. Zusätzlich wird in <figref idref="f0002">Fig. 3</figref> in dem Echtzeitbild E noch mit einem weiteren Bildelement B ein Winkel angezeigt, in welchem sich die Schallquelle 22 relativ zur Blickrichtung R des Nutzers N befindet. Vorliegend wird als ein Bildelement B der Winkel einfach als Zahl derart in der Nähe der Schallquelle 22 angezeigt, dass der Winkel für den Nutzer N möglichst eindeutig dieser Schallquelle 22 zugeordnet ist. Alternativ oder zusätzlich wird der Winkel in einer anderen Ausgestaltung als Paar von zwei Linien oder Pfeilen dargestellt, eine in Blickrichtung R und eine weitere vom Nutzer N zur Schallquelle 22 hin, vgl. z.B. <figref idref="f0003">Fig. 6</figref>.<!-- EPO <DP n="19"> --></p>
<p id="p0060" num="0060">In der in <figref idref="f0002">Fig. 4</figref> gezeigten Ausgestaltung ist die Information I ein Signal-zu-Rauschverhältnis, kurz SNR, des Teilbereichs T. Das Hörgerät 4 misst das SNR in dem Teilbereich T, z.B. mittels einer Analyseeinheit als Teil der Steuereinheit 14. Das SNR wird dann als Information I zur Darstellung in dem Echtzeitbild E an das Zusatzgerät 6 übermittelt. Das Bildelement B gibt dann das SNR an, genauer gesagt das SNR für den Teilbereich T. Entsprechend wird das SNR jeweils separat für mehrere unterschiedliche Teilbereiche T gemessen und dadurch auf dem Bildschirm 10 dann dem Echtzeitbild E sozusagen eine SNR-Karte überlagert, sodass der Nutzer N unmittelbar zu einem jeweiligen Teilbereich T der Umgebung U das SNR ablesen kann. In <figref idref="f0002">Fig. 4</figref> ist ein Teilbereich T erkennbar, welcher durch eine Fläche mit Umrandung als Bildelement B markiert ist. In dem Teilbereich T befindet sich ein Objekt, hier beispielhaft ein Fahrzeug, welches in dem Teilbereich T zu einem geringeren SNR als in der übrigen Umgebung U führt.</p>
<p id="p0061" num="0061">In <figref idref="f0003">Fig. 5</figref> ist eine Ausgestaltung gezeigt, bei welcher die Information I angibt, ob für den Teilbereich T eine Störgeräuschunterdrückung 24 des Hörgeräts 4 aktiviert ist. Die Störgeräuschunterdrückung ist hier ein Teil der Steuereinheit 14 des Hörgeräts 4 und derart ausgebildet, dass diese in aktiviertem Zustand Störgeräusche im Eingangssignal unterdrückt. Die Störgeräuschunterdrückung 24 ist selektiv für ein oder mehrere Teilbereiche T aktivierbar, sodass unterschiedliche Teilbereiche T und darin befindliche Störgeräuschquellen unterschiedlich stark unterdrückbar sind. Das Bildelement B zeigt nun an, ob für den jeweiligen Teilbereich T die Störgeräuschunterdrückung aktiviert ist. In einer nicht explizit gezeigten Ausgestaltung gibt die Information I nicht nur an, ob für den Teilbereich T eine Störgeräuschunterdrückung 24 aktiviert ist, sondern genauer, wie stark Störgeräusche aus dem Teilbereich T von der Störgeräuschunterdrückung 24 unterdrückt werden.</p>
<p id="p0062" num="0062">In einer möglichen Ausgestaltung ist das Bildelement B eine eingefärbte oder transparente Fläche oder beides, welche in dem Echtzeitbild E mit dem Teilbereich T überlagert wird, sodass dieser abhängig von der Information I eingefärbt oder transparent dargestellt wird oder beides. Beispielsweise werden in <figref idref="f0002">Fig. 4</figref> Teilbereiche T der Umgebung U mit geringem SNR auf dem Bildschirm 10 grün eingefärbt und mit hohem SNR rot, sodass dann der Teilbereich T mit dem Fahrzeug<!-- EPO <DP n="20"> --> entsprechend rot gefärbt ist und der übrige Teil des Echtzeitbilds E grün gefärbt ist. Speziell bei einer solchen Einfärbung ganzer Flächen des Echtzeitbilds E ist ein transparentes Bildelement B zweckmäßig, um eine optimale Erkennbarkeit des dahinter liegenden Echtzeitbilds E zu gewährleisten. In <figref idref="f0003">Fig. 5</figref> ist die Darstellung beispielsweise diskret derart, dass diejenigen Teilbereiche T, für welche die Störgeräuschunterdrückung aktiv ist, mit Bildelementen B überblendet werden, hier einer Farbe, welche in <figref idref="f0003">Fig. 5</figref> als eine Schraffur dargestellt ist. Derjenige Teilbereich T, für welchen die Störgeräuschunterdrückung hingegen nicht aktiv ist, wird nicht mit einem Bildelement B überblendet.</p>
<p id="p0063" num="0063">Die bisher beschriebenen Ausgestaltungen befassen sich überwiegend mit Informationen I, welche Umgebungsinformationen sind, d.h. Informationen, welche Eigenschaften der Umgebung U sind und welche vom Hörgerät 4 durch eine Analyse von Schallsignalen aus der Umgebung U ermittelt werden. Bei Hörgerätinformationen ist eine solche Analyse der Umgebung U zunächst nicht unbedingt erforderlich, vielmehr zielt eine Darstellung solcher Informationen I darauf ab, dem Nutzer N das Verhalten des Hörgeräts 4 relativ zur Umgebung U zu verdeutlichen. Nachfolgend beschrieben ist die Darstellung einer Hörgerätinformation im Falle eines Hörgeräts 4, welches zum direktionalen Hören ausgebildet ist und hierzu ein Mikrofon 12 aufweist, welches als Richtmikrofon ausgebildet ist, um Schallsignale aus einer bestimmten Richtung, d.h. aus einem bestimmten Teilbereich T, gegenüber Schallsignalen aus anderen Richtungen, d.h. aus anderen Teilbereichen T, hervorzuheben.</p>
<p id="p0064" num="0064">Im Ausführungsbeispiel der <figref idref="f0003">Fig. 6 und 7</figref> ist das Hörgerät 4 zwischen einem ungerichteten und einem gerichteten Betriebsmodus umschaltbar. <figref idref="f0003">Fig. 6</figref> verdeutlicht, wie im gerichteten Betriebsmodus das Bildelement B anzeigt, welcher Teilbereich T der Umgebung U gegenüber der übrigen Umgebung U hervorgehoben wird. Im ungerichteten Betriebsmodus wird dagegen kein Bildelement dargestellt oder wie in <figref idref="f0003">Fig. 7</figref> gezeigt zeigt das Bildelement B an, dass kein Teilbereich T der Umgebung U hervorgehoben wird. Auf dem Bildschirm 10 ist dann für den Nutzer N unmittelbar erkennbar, ob das Hörgerät 4 sich im ungerichteten Betriebsmodus (auch: omni-direktionaler Betrieb) befindet oder im gerichteten Betriebsmodus<!-- EPO <DP n="21"> --> (auch: Richtbetrieb, z.B. monodirektionaler oder mehrdirektionaler Betrieb). In letzterem Fall ist dann für den Nutzer auch unmittelbar erkennbar, auf welchen Teilbereich T oder auf welche Teilbereiche T das Richtmikrofon gerichtet ist.</p>
<p id="p0065" num="0065">In einer Ausgestaltung weist das Hörgerät 4 ein Mikrofon 12 zumindest eine Richtkeule auf, welche auf einen Teilbereich T gerichtet ist und diesen abdeckt, sodass entsprechend Schallsignale aus diesem Teilbereich T gegenüber Schallsignalen aus anderen Teilbereichen T hervorgehoben werden. Die Information I ist dann z.B. eine Abmessung A1, hier eine Breite, du eine Ausrichtung A2, hier eine Richtung, der Richtkeule. Das Bildelement B stellt wie in den <figref idref="f0004">Fig. 8 und 9</figref> gezeigt die Richtkeule dar und zeigt dadurch in dem Echtzeitbild E an, welcher Teilbereich T der Umgebung U von der Richtkeule abgedeckt wird und entsprechend aus welchem Teilbereich T Schallsignale hervorgehoben werden. Das Bildelement B ist hier eine visuelle Repräsentation der Richtkeule. Geeignet ist aber beispielsweise auch eine einfache Linie wie z.B. in <figref idref="f0003">Fig. 6</figref> gezeigt oder eine andere Darstellung. Da die Richtkeule in der tatsächlichen Umgebung U für den Nutzer N nicht sichtbar ist, wird auf diese Weise dem Nutzer N über den Bildschirm 10 eine intuitive Darstellung der Richtkeule und deren Lage in der Umgebung U angeboten, sodass der Nutzer N unmittelbar und ohne weitere Anstrengung erkennen kann, wie die Richtkeule relativ zur Umgebung U dimensioniert und/oder ausgerichtet ist und entsprechend, welche Teilbereiche T der Umgebung U und somit welche Schallquellen hiervon gegebenenfalls betroffen sind.</p>
<p id="p0066" num="0066">In den <figref idref="f0004">Fig. 8 und 9</figref> ist der Bildschirm 10 des Zusatzgeräts 6 zugleich als ein Eingabegerät ausgebildet, mittels welchem ein oder mehrere Betriebsparameter des Hörgeräts 4 einstellbar sind. Die Auswirkungen einer jeweiligen Einstellung sind für den Nutzer N unmittelbar anhand des Echtzeitbilds E und der darübergelegten Information I erkennbar. So sind in den <figref idref="f0004">Fig. 8 und 9</figref> die Abmessung A1 und die Ausrichtung A2 der Richtkeule durch den Nutzer N unmittelbar im Echtzeitbild E einstellbar, sodass der Nutzer z.B. die in <figref idref="f0004">Fig. 8</figref> in Blickrichtung R ausgerichtete Richtkeule einfach wie in <figref idref="f0004">Fig. 9</figref> gezeigt in eine andere Richtung ausrichten kann.<!-- EPO <DP n="22"> --></p>
<p id="p0067" num="0067">In einer nicht explizit gezeigten Ausgestaltung weist alternativ oder zusätzlich zum Bildschirm 10 als Eingabegerät das Zusatzgerät 6 und/oder das Hörgerät 4 ein oder mehrere Bedienelemente auf, zum Einstellen eines oder mehrere Betriebsparameter des Hörgeräts 4. Die Auswirkungen einer Einstellung mittels dieser Bedienelemente sind dann für den Nutzer N unmittelbar auf dem Bildschirm 10 erkennbar.</p>
<p id="p0068" num="0068">In <figref idref="f0004">Fig. 10</figref> ist eine Ausgestaltung gezeigt, bei welcher ein Avatar 26 mit dem Echtzeitbild E überlagert wird, um darin eine Position des Nutzers N in der Umgebung U anzuzeigen. Der Avatar 26 ist eine virtuelle Repräsentation des Nutzers N auf dem Bildschirm 10 und verortet somit den Nutzer N innerhalb der erweiterten Realität. Da sich im gezeigten Fall der Nutzer N und die Kamera 8 auf unterschiedlichen Seiten des Bildschirms 10 befinden, stellt die Positionierung des Avatars 26 lediglich eine Näherung dar, welche jedoch ausreichend ist, da das Zusatzgerät 6 sich hinreichend nah am Hörgerät 4 befindet.</p>
<p id="p0069" num="0069">In einer nicht explizit gezeigten Ausgestaltung werden Schallsignale aus der Umgebung U von dem Hörgerät 4 mittels zumindest eines Mikrofons 12 aufgenommen und als Eingabesignale für ein Spiel verwendet, welches auf dem Zusatzgerät 6 aktiv ist.</p>
<p id="p0070" num="0070">Das gezeigte Hörsystem 2 ist ausgebildet zur Durchführung eines Verfahrens wie vorstehend beschrieben. Das Hörsystem 2 weist hierzu eine Steuereinheit auf, welche wie in <figref idref="f0001">Fig. 1</figref> erkennbar auf das Hörgerät 4 und das Zusatzgerät 6 aufgeteilt und aus deren Steuereinheiten 14, 20 gebildet ist. Grundsätzlich lassen sich die beschriebenen Verfahrensschritte weitgehend beliebig auf das Zusatzgerät 6 und das Hörgerät 4 aufteilen.</p>
<p id="p0071" num="0071">Die im Zusammenhang mit den Figuren beschriebenen Konzepte sind wie auch die diversen gezeigten Ausgestaltungen grundsätzlich unabhängig voneinander, sodass sich weitere Ausgestaltungen und Ausführungsbeispiele durch andere Kombinationen der beschriebenen Konzepte ergeben.<!-- EPO <DP n="23"> --></p>
<heading id="h0001">Bezugszeichenliste</heading>
<p id="p0072" num="0072">
<dl id="dl0002" compact="compact">
<dt>2</dt><dd>Hörsystem</dd>
<dt>4</dt><dd>Hörgerät</dd>
<dt>6</dt><dd>Zusatzgerät</dd>
<dt>8</dt><dd>Kamera</dd>
<dt>10</dt><dd>Bildschirm</dd>
<dt>12</dt><dd>Mikrofon</dd>
<dt>14</dt><dd>Steuereinheit (des Hörgeräts)</dd>
<dt>16</dt><dd>Hörer</dd>
<dt>18</dt><dd>Schnittstelle</dd>
<dt>20</dt><dd>Steuereinheit (des Zusatzgeräts)</dd>
<dt>22</dt><dd>Schallquelle</dd>
<dt>24</dt><dd>Störgeräuschunterdrückung</dd>
<dt>26</dt><dd>Avatar</dd>
<dt>A1</dt><dd>Abmessung</dd>
<dt>A2</dt><dd>Ausrichtung</dd>
<dt>B</dt><dd>Bildelement</dd>
<dt>E</dt><dd>Echtzeitbild</dd>
<dt>I</dt><dd>Information</dd>
<dt>N</dt><dd>Nutzer</dd>
<dt>R</dt><dd>Blickrichtung</dd>
<dt>T</dt><dd>Teilbereich</dd>
<dt>U</dt><dd>Umgebung</dd>
</dl></p>
</description>
<claims id="claims01" lang="de"><!-- EPO <DP n="24"> -->
<claim id="c-de-0001" num="0001">
<claim-text>Verfahren zum Betrieb eines Hörsystems (2),
<claim-text>- wobei das Hörsystem (2) ein Hörgerät (4) aufweist, welches von einem Nutzer (N) getragen wird,</claim-text>
<claim-text>- wobei das Hörsystem (2) ein Zusatzgerät (6) aufweist, welches eine Kamera (8) aufweist, mittels welcher von einer aktuellen Umgebung (U) ein Echtzeitbild (E) aufgenommen wird,</claim-text>
<claim-text>- wobei das Zusatzgerät (6) einen Bildschirm (10) aufweist, auf welchem das Echtzeitbild (E) ausgegeben wird, sodass die Umgebung (U) auf dem Bildschirm (10) dargestellt wird,</claim-text>
<claim-text>- wobei das Hörgerät (4) an das Zusatzgerät (6) eine Information (I) übermittelt, welche mit einem Teilbereich (T) der Umgebung (U) verknüpft ist und somit eine Information (I) zu diesem Teilbereich (T) ist,</claim-text>
<claim-text>- wobei die Information (I) ebenfalls auf dem Bildschirm (10) dargestellt wird, indem ein Bildelement (B) erzeugt wird und mit dem Echtzeitbild (E) derart überlagert wird, dass für den Nutzer (N) erkennbar ist, mit welchem Teilbereich (T) der Umgebung (U) die Information (I) verknüpft ist.</claim-text></claim-text></claim>
<claim id="c-de-0002" num="0002">
<claim-text>Verfahren nach Anspruch 1,<br/>
wobei die Information (I) ein Vorhandensein einer Schallquelle (22) in dem Teilbereich (T) ist,<br/>
wobei das Hörgerät (4) das Vorhandensein der Schallquelle (22) erkennt,<br/>
wobei in dem Echtzeitbild (E) das Bildelement (B) den Teilbereich (T) markiert, um in diesem das Vorhandensein der Schallquelle (22) anzuzeigen.</claim-text></claim>
<claim id="c-de-0003" num="0003">
<claim-text>Verfahren nach Anspruch 2,<br/>
wobei die Schallquelle (22) ein Gesprächspartner des Nutzers (N) ist und als solcher im Echtzeitbild (E) mittels des Bildelements (B) markiert wird.<!-- EPO <DP n="25"> --></claim-text></claim>
<claim id="c-de-0004" num="0004">
<claim-text>Verfahren nach Anspruch 2 oder 3,<br/>
wobei in dem Echtzeitbild (E) ein Winkel angezeigt wird, in welchem sich die Schallquelle (22) relativ zur Blickrichtung (R) des Nutzers (N) befindet.</claim-text></claim>
<claim id="c-de-0005" num="0005">
<claim-text>Verfahren nach einem der Ansprüche 1 bis 4,<br/>
wobei die Information (I) ein Signal-zu-Rauschverhältnis des Teilbereichs (T) ist,<br/>
wobei das Hörgerät (4) das Signal-zu-Rauschverhältnis in dem Teilbereich (T) misst,<br/>
wobei das Bildelement (B) das Signal-zu-Rauschverhältnis angibt.</claim-text></claim>
<claim id="c-de-0006" num="0006">
<claim-text>Verfahren nach einem der Ansprüche 1 bis 5,<br/>
wobei die Information (I) angibt, ob für den Teilbereich (T) eine Störgeräuschunterdrückung (24) des Hörgeräts (4) aktiviert ist, sodass das Bildelement (B) anzeigt, ob für den Teilbereich (T) die Störgeräuschunterdrückung (24) aktiviert ist.</claim-text></claim>
<claim id="c-de-0007" num="0007">
<claim-text>Verfahren nach einem der Ansprüche 1 bis 6,<br/>
wobei das Bildelement (B) eine eingefärbte oder transparente Fläche ist oder beides, welche in dem Echtzeitbild (E) mit dem Teilbereich (T) überlagert wird, sodass dieser abhängig von der Information (I) eingefärbt oder transparent dargestellt wird oder beides.</claim-text></claim>
<claim id="c-de-0008" num="0008">
<claim-text>Verfahren nach einem der Ansprüche 1 bis 6,<br/>
wobei das Hörgerät (4) zwischen einem ungerichteten und einem gerichteten Betriebsmodus umschaltbar ist,<br/>
wobei im gerichteten Betriebsmodus das Bildelement (B) anzeigt, welcher Teilbereich (T) der Umgebung (U) gegenüber der übrigen Umgebung hervorgehoben wird,<br/>
wobei im ungerichteten Betriebsmodus kein Bildelement (B) dargestellt wird oder das Bildelement (B) anzeigt, dass kein Teilbereich (T) der Umgebung (U) hervorgehoben wird.<!-- EPO <DP n="26"> --></claim-text></claim>
<claim id="c-de-0009" num="0009">
<claim-text>Verfahren nach einem der Ansprüche 1 bis 7,<br/>
wobei das Hörgerät (4) ein Mikrofon (12) aufweist, welches als Richtmikrofon ausgebildet ist, mit zumindest einer Richtkeule, welche auf den Teilbereich (T) gerichtet ist und diesen abdeckt,<br/>
wobei die Information (I) eine Abmessung (A1) oder eine Ausrichtung (A2) der Richtkeule ist oder beides,<br/>
wobei das Bildelement (B) die Richtkeule darstellt und dadurch in dem Echtzeitbild (E) anzeigt, welcher Teilbereich (T) der Umgebung (U) von der Richtkeule abgedeckt wird.</claim-text></claim>
<claim id="c-de-0010" num="0010">
<claim-text>Verfahren nach einem der Ansprüche 1 bis 9,<br/>
wobei der Bildschirm (B) zugleich als ein Eingabegerät ausgebildet ist, mittels welchem ein oder mehrere Betriebsparameter des Hörgeräts (4) einstellbar sind.</claim-text></claim>
<claim id="c-de-0011" num="0011">
<claim-text>Verfahren nach einem der Ansprüche 1 bis 10,<br/>
wobei ein Avatar (26) mit dem Echtzeitbild (E) überlagert wird, um darin eine Position des Nutzers (N) in der Umgebung (U) anzuzeigen.</claim-text></claim>
<claim id="c-de-0012" num="0012">
<claim-text>Verfahren nach einem der Ansprüche 1 bis 11,<br/>
wobei Schallsignale aus der Umgebung (U) von dem Hörgerät (4) aufgenommen werden und als Eingabesignale für ein Spiel verwendet werden, welches auf dem Zusatzgerät (6) aktiv ist.</claim-text></claim>
<claim id="c-de-0013" num="0013">
<claim-text>Verfahren nach einem der Ansprüche 1 bis 12,<br/>
wobei das Zusatzgerät (6) ein mobiles Endgerät ist, insbesondere ein Smartphone.</claim-text></claim>
<claim id="c-de-0014" num="0014">
<claim-text>Hörsystem (2), welches ausgebildet ist zur Durchführung eines Verfahrens nach einem der Ansprüche 1 bis 13.<!-- EPO <DP n="27"> --></claim-text></claim>
<claim id="c-de-0015" num="0015">
<claim-text>Computerprogrammprodukt, welches ein ausführbares Programm enthält, welches bei oder nach einer Installation auf einem Hörsystem (2) das Verfahren nach einem der Ansprüche 1 bis 13 automatisch ausführt.</claim-text></claim>
</claims>
<drawings id="draw" lang="de"><!-- EPO <DP n="28"> -->
<figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="109" he="206" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="29"> -->
<figure id="f0002" num="2,3,4"><img id="if0002" file="imgf0002.tif" wi="104" he="222" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="30"> -->
<figure id="f0003" num="5,6,7"><img id="if0003" file="imgf0003.tif" wi="88" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="31"> -->
<figure id="f0004" num="8,9,10"><img id="if0004" file="imgf0004.tif" wi="87" he="233" img-content="drawing" img-format="tif"/></figure>
</drawings>
<search-report-data id="srep" lang="de" srep-office="EP" date-produced=""><doc-page id="srep0001" file="srep0001.tif" wi="157" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="155" he="233" type="tif"/></search-report-data><search-report-data date-produced="20210702" id="srepxml" lang="de" srep-office="EP" srep-type="ep-sr" status="n"><!--
 The search report data in XML is provided for the users' convenience only. It might differ from the search report of the PDF document, which contains the officially published data. The EPO disclaims any liability for incorrect or incomplete data in the XML for search reports.
 -->

<srep-info><file-reference-id>P190645E-MD/NM/CS</file-reference-id><application-reference><document-id><country>EP</country><doc-number>21158828.0</doc-number></document-id></application-reference><applicant-name><name>Sivantos Pte. Ltd.</name></applicant-name><srep-established srep-established="yes"/><srep-invention-title title-approval="yes"/><srep-abstract abs-approval="yes"/><srep-figure-to-publish figinfo="by-applicant"><figure-to-publish><fig-number>2</fig-number></figure-to-publish></srep-figure-to-publish><srep-info-admin><srep-office><addressbook><text>DH</text></addressbook></srep-office><date-search-report-mailed><date>20210713</date></date-search-report-mailed></srep-info-admin></srep-info><srep-for-pub><srep-fields-searched><minimum-documentation><classifications-ipcr><classification-ipcr><text>H04R</text></classification-ipcr></classifications-ipcr></minimum-documentation></srep-fields-searched><srep-citations><citation id="sr-cit0001"><patcit dnum="US2018088900A1" id="sr-pcit0001" url="http://v3.espacenet.com/textdoc?DB=EPODOC&amp;IDX=US2018088900&amp;CY=ep"><document-id><country>US</country><doc-number>2018088900</doc-number><kind>A1</kind><name>GLASER WILLIAM [US] ET AL</name><date>20180329</date></document-id></patcit><category>X</category><rel-claims>1-15</rel-claims><rel-passage><passage>* Absätze [0021],  [0032],  [0034] *</passage><passage>* Absatz [0041] - Absatz [0047]; Abbildung 5 *</passage><passage>* Absätze [0059],  [0102] *</passage></rel-passage></citation><citation id="sr-cit0002"><patcit dnum="EP3054706A2" id="sr-pcit0002" url="http://v3.espacenet.com/textdoc?DB=EPODOC&amp;IDX=EP3054706&amp;CY=ep"><document-id><country>EP</country><doc-number>3054706</doc-number><kind>A2</kind><name>OTICON AS [DK]</name><date>20160810</date></document-id></patcit><category>A</category><rel-claims>1-15</rel-claims><rel-passage><passage>* Absatz [0078] - Absatz [0080]; Abbildung 5 *</passage></rel-passage></citation><citation id="sr-cit0003"><patcit dnum="EP2469323A1" id="sr-pcit0003" url="http://v3.espacenet.com/textdoc?DB=EPODOC&amp;IDX=EP2469323&amp;CY=ep"><document-id><country>EP</country><doc-number>2469323</doc-number><kind>A1</kind><name>SONY CORP [JP]</name><date>20120627</date></document-id></patcit><category>A</category><rel-claims>1-15</rel-claims><rel-passage><passage>* Absätze [0017],  [0043],  [0047]; Abbildungen 7A-7C *</passage></rel-passage></citation><citation id="sr-cit0004"><patcit dnum="EP2680615A1" id="sr-pcit0004" url="http://v3.espacenet.com/textdoc?DB=EPODOC&amp;IDX=EP2680615&amp;CY=ep"><document-id><country>EP</country><doc-number>2680615</doc-number><kind>A1</kind><name>LG ELECTRONICS INC [KR]</name><date>20140101</date></document-id></patcit><category>A</category><rel-claims>1-15</rel-claims><rel-passage><passage>* Absatz [0092] - Absatz [0128]; Abbildungen 5-9E *</passage></rel-passage></citation></srep-citations><srep-admin><examiners><primary-examiner><name>Betgen, Benjamin</name></primary-examiner></examiners><srep-office><addressbook><text>The Hague</text></addressbook></srep-office><date-search-completed><date>20210702</date></date-search-completed></srep-admin><!--							The annex lists the patent family members relating to the patent documents cited in the above mentioned European search report.							The members are as contained in the European Patent Office EDP file on							The European Patent Office is in no way liable for these particulars which are merely given for the purpose of information.							For more details about this annex : see Official Journal of the European Patent Office, No 12/82						--><srep-patent-family><patent-family><priority-application><document-id><country>US</country><doc-number>2018088900</doc-number><kind>A1</kind><date>20180329</date></document-id></priority-application><family-member><document-id><country>US</country><doc-number>2018088900</doc-number><kind>A1</kind><date>20180329</date></document-id></family-member><family-member><document-id><country>US</country><doc-number>2019354343</doc-number><kind>A1</kind><date>20191121</date></document-id></family-member><family-member><document-id><country>US</country><doc-number>2020192629</doc-number><kind>A1</kind><date>20200618</date></document-id></family-member></patent-family><patent-family><priority-application><document-id><country>EP</country><doc-number>3054706</doc-number><kind>A2</kind><date>20160810</date></document-id></priority-application><family-member><document-id><country>CN</country><doc-number>105872924</doc-number><kind>A</kind><date>20160817</date></document-id></family-member><family-member><document-id><country>EP</country><doc-number>3054706</doc-number><kind>A2</kind><date>20160810</date></document-id></family-member><family-member><document-id><country>US</country><doc-number>2016234609</doc-number><kind>A1</kind><date>20160811</date></document-id></family-member></patent-family><patent-family><priority-application><document-id><country>EP</country><doc-number>2469323</doc-number><kind>A1</kind><date>20120627</date></document-id></priority-application><family-member><document-id><country>CN</country><doc-number>102543099</doc-number><kind>A</kind><date>20120704</date></document-id></family-member><family-member><document-id><country>EP</country><doc-number>2469323</doc-number><kind>A1</kind><date>20120627</date></document-id></family-member><family-member><document-id><country>JP</country><doc-number>2012133250</doc-number><kind>A</kind><date>20120712</date></document-id></family-member><family-member><document-id><country>US</country><doc-number>2012162259</doc-number><kind>A1</kind><date>20120628</date></document-id></family-member></patent-family><patent-family><priority-application><document-id><country>EP</country><doc-number>2680615</doc-number><kind>A1</kind><date>20140101</date></document-id></priority-application><family-member><document-id><country>CN</country><doc-number>103516894</doc-number><kind>A</kind><date>20140115</date></document-id></family-member><family-member><document-id><country>CN</country><doc-number>103516895</doc-number><kind>A</kind><date>20140115</date></document-id></family-member><family-member><document-id><country>CN</country><doc-number>105592283</doc-number><kind>A</kind><date>20160518</date></document-id></family-member><family-member><document-id><country>EP</country><doc-number>2680615</doc-number><kind>A1</kind><date>20140101</date></document-id></family-member><family-member><document-id><country>EP</country><doc-number>2680616</doc-number><kind>A1</kind><date>20140101</date></document-id></family-member><family-member><document-id><country>US</country><doc-number>2013342730</doc-number><kind>A1</kind><date>20131226</date></document-id></family-member><family-member><document-id><country>US</country><doc-number>2013342731</doc-number><kind>A1</kind><date>20131226</date></document-id></family-member></patent-family></srep-patent-family></srep-for-pub></search-report-data>
<ep-reference-list id="ref-list">
<heading id="ref-h0001"><b>IN DER BESCHREIBUNG AUFGEFÜHRTE DOKUMENTE</b></heading>
<p id="ref-p0001" num=""><i>Diese Liste der vom Anmelder aufgeführten Dokumente wurde ausschließlich zur Information des Lesers aufgenommen und ist nicht Bestandteil des europäischen Patentdokumentes. Sie wurde mit größter Sorgfalt zusammengestellt; das EPA übernimmt jedoch keinerlei Haftung für etwaige Fehler oder Auslassungen.</i></p>
<heading id="ref-h0002"><b>In der Beschreibung aufgeführte Patentdokumente</b></heading>
<p id="ref-p0002" num="">
<ul id="ref-ul0001" list-style="bullet">
<li><patcit id="ref-pcit0001" dnum="EP3120578B1"><document-id><country>EP</country><doc-number>3120578</doc-number><kind>B1</kind></document-id></patcit><crossref idref="pcit0001">[0003]</crossref></li>
<li><patcit id="ref-pcit0002" dnum="EP2928214A1"><document-id><country>EP</country><doc-number>2928214</doc-number><kind>A1</kind></document-id></patcit><crossref idref="pcit0002">[0004]</crossref></li>
<li><patcit id="ref-pcit0003" dnum="US9669296B1"><document-id><country>US</country><doc-number>9669296</doc-number><kind>B1</kind></document-id></patcit><crossref idref="pcit0003">[0005]</crossref></li>
<li><patcit id="ref-pcit0004" dnum="US9539498B1"><document-id><country>US</country><doc-number>9539498</doc-number><kind>B1</kind></document-id></patcit><crossref idref="pcit0004">[0006]</crossref></li>
</ul></p>
</ep-reference-list>
</ep-patent-document>
