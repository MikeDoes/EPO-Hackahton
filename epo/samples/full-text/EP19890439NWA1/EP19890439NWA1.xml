<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE ep-patent-document PUBLIC "-//EPO//EP PATENT DOCUMENT 1.5.1//EN" "ep-patent-document-v1-5-1.dtd">
<!-- This XML data has been generated under the supervision of the European Patent Office -->
<ep-patent-document id="EP19890439A1" file="EP19890439NWA1.xml" lang="en" country="EP" doc-number="3889589" kind="A1" date-publ="20211006" status="n" dtd-version="ep-patent-document-v1-5-1">
<SDOBI lang="en"><B000><eptags><B001EP>ATBECHDEDKESFRGBGRITLILUNLSEMCPTIESILTLVFIROMKCYALTRBGCZEEHUPLSKBAHRIS..MTNORSMESMMAKHTNMD..........</B001EP><B005EP>J</B005EP><B007EP>BDM Ver 2.0.12 (4th of August) -  1100000/0</B007EP></eptags></B000><B100><B110>3889589</B110><B120><B121>EUROPEAN PATENT APPLICATION</B121><B121EP>published in accordance with Art. 153(4) EPC</B121EP></B120><B130>A1</B130><B140><date>20211006</date></B140><B190>EP</B190></B100><B200><B210>19890439.3</B210><B220><date>20191108</date></B220><B240><B241><date>20210601</date></B241></B240><B250>ja</B250><B251EP>en</B251EP><B260>en</B260></B200><B300><B310>2018224403</B310><B320><date>20181130</date></B320><B330><ctry>JP</ctry></B330></B300><B400><B405><date>20211006</date><bnum>202140</bnum></B405><B430><date>20211006</date><bnum>202140</bnum></B430></B400><B500><B510EP><classification-ipcr sequence="1"><text>G01N  21/88        20060101AFI20200605BHEP        </text></classification-ipcr><classification-ipcr sequence="2"><text>G01N  21/892       20060101ALI20200605BHEP        </text></classification-ipcr></B510EP><B520EP><classifications-cpc><classification-cpc sequence="1"><text>G01N  21/88        20130101 LI20200626BCEP        </text></classification-cpc><classification-cpc sequence="2"><text>G01N  21/892       20130101 LI20200626BCEP        </text></classification-cpc></classifications-cpc></B520EP><B540><B541>de</B541><B542>OBERFLÄCHENFEHLERDETEKTIONSVERFAHREN, OBERFLÄCHENFEHLERDETEKTOR, VERFAHREN ZUR HERSTELLUNG VON STAHLMATERIAL, VERFAHREN ZUR QUALITÄTSKONTROLLE VON STAHLMATERIAL, VERFAHREN ZUR HERSTELLUNG EINES OBERFLÄCHENFEHLERBESTIMMUNGSMODELLS UND OBERFLÄCHENFEHLERBESTIMMUNGSMODELL</B542><B541>en</B541><B542>SURFACE DEFECT DETECTING METHOD, SURFACE DEFECT DETECTING DEVICE, METHOD FOR MANUFACTURING STEEL MATERIAL, STEEL MATERIAL QUALITY CONTROL METHOD, STEEL MATERIAL MANUFACTURING EQUIPMENT, METHOD FOR CREATING SURFACE DEFECT DETERMINATION MODEL, AND SURFACE DEFECT DETERMINATION MODEL</B542><B541>fr</B541><B542>PROCÉDÉ ET DISPOSITIF DE DÉTECTION DE DÉFAUTS DE SURFACE, PROCÉDÉ ET ÉQUIPEMENT DE FABRICATION DE MATÉRIAU EN ACIER, PROCÉDÉ DE CONTRÔLE DE QUALITÉ DE MATÉRIAU EN ACIER, PROCÉDÉ DE CRÉATION DE MODÈLE DE DÉTERMINATION DE DÉFAUTS DE SURFACE ET MODÈLE DE DÉTERMINATION DE DÉFAUTS DE SURFACE</B542></B540><B590><B598>1</B598></B590></B500><B700><B710><B711><snm>JFE Steel Corporation</snm><iid>101159443</iid><irf>236 896 a/scho</irf><adr><str>2-3, Uchisaiwai-cho 2-chome 
Chiyoda-ku</str><city>Tokyo 100-0011</city><ctry>JP</ctry></adr></B711></B710><B720><B721><snm>ONO, Hiroaki</snm><adr><str>c/o Intellectual Property Dept., JFE STEEL  
CORPORATION, 2-3, Uchisaiwai-cho 2-chome, Chiyoda-
ku</str><city>Tokyo 100-0011</city><ctry>JP</ctry></adr></B721><B721><snm>TATE, Masami</snm><adr><str>c/o Intellectual Property Dept., JFE STEEL  
CORPORATION, 2-3, Uchisaiwai-cho 2-chome, Chiyoda-
ku</str><city>Tokyo 100-0011</city><ctry>JP</ctry></adr></B721></B720><B740><B741><snm>Hoffmann Eitle</snm><iid>100061036</iid><adr><str>Patent- und Rechtsanwälte PartmbB 
Arabellastraße 30</str><city>81925 München</city><ctry>DE</ctry></adr></B741></B740></B700><B800><B840><ctry>AL</ctry><ctry>AT</ctry><ctry>BE</ctry><ctry>BG</ctry><ctry>CH</ctry><ctry>CY</ctry><ctry>CZ</ctry><ctry>DE</ctry><ctry>DK</ctry><ctry>EE</ctry><ctry>ES</ctry><ctry>FI</ctry><ctry>FR</ctry><ctry>GB</ctry><ctry>GR</ctry><ctry>HR</ctry><ctry>HU</ctry><ctry>IE</ctry><ctry>IS</ctry><ctry>IT</ctry><ctry>LI</ctry><ctry>LT</ctry><ctry>LU</ctry><ctry>LV</ctry><ctry>MC</ctry><ctry>MK</ctry><ctry>MT</ctry><ctry>NL</ctry><ctry>NO</ctry><ctry>PL</ctry><ctry>PT</ctry><ctry>RO</ctry><ctry>RS</ctry><ctry>SE</ctry><ctry>SI</ctry><ctry>SK</ctry><ctry>SM</ctry><ctry>TR</ctry></B840><B844EP><B845EP><ctry>BA</ctry></B845EP><B845EP><ctry>ME</ctry></B845EP></B844EP><B848EP><B849EP><ctry>KH</ctry></B849EP><B849EP><ctry>MA</ctry></B849EP><B849EP><ctry>MD</ctry></B849EP><B849EP><ctry>TN</ctry></B849EP></B848EP><B860><B861><dnum><anum>JP2019043930</anum></dnum><date>20191108</date></B861><B862>ja</B862></B860><B870><B871><dnum><pnum>WO2020110667</pnum></dnum><date>20200604</date><bnum>202023</bnum></B871></B870></B800></SDOBI>
<abstract id="abst" lang="en">
<p id="pa01" num="0001">A surface-defect detecting method according to the present invention is a surface-defect detecting method of optically detecting a surface defect of a steel material and includes an irradiation step of irradiating a same examination target part with illumination light beams from different directions by using two or more distinguishable light sources; and a detection step of detecting a surface defect in the examination target part based on the degree of overlapping of bright portions extracted from two or more images formed by reflected light beams of the illumination light beams.<img id="iaf01" file="imgaf001.tif" wi="78" he="79" img-content="drawing" img-format="tif"/></p>
</abstract>
<description id="desc" lang="en"><!-- EPO <DP n="1"> -->
<heading id="h0001">Field</heading>
<p id="p0001" num="0001">The present invention relates to a surface-defect detecting method of optically detecting a surface defect of a steel material, a surface-defect detecting apparatus, a steel-material manufacturing method, a steel-material quality management method, a steel-material manufacturing facility, a surface-defect determination model generating method, and a surface-defect determination model. Background</p>
<p id="p0002" num="0002">Recently, in the manufacturing process of an iron steel product, a surface defect of a steel material in hot rolling or cold rolling has been required to be detected for yield improvement through prevention of a large amount of non-conformance. A steel material in the present description means an iron steel product such as a steel pipe (a seamless steel pipe, a welding steel pipe, or the like), a steel plate (a hot-rolled steel plate, a coldrolled steel plate, a thick plate, or the like), or a shaped steel, or a half-finished product (a slab or the like) generated in a process through which the iron steel product is manufactured. When a surface defect of a steel material is to be detected through optical surface examination, it is sometimes difficult to distinguish a harmful concave-convex surface defect and a harmless flat scale pattern (attributable to, for example, cooling unevenness) through simple image capturing of the steel material.<!-- EPO <DP n="2"> --></p>
<p id="p0003" num="0003">In a disclosed method of accurately distinguishing a concave-convex surface defect and a flat scale pattern, distinguishable light beams are emitted from different directions, images are acquired by receiving reflected light of each light beam, and a subtraction image of the acquired images is obtained to detect a surface defect (refer to Patent Literature 1). In another disclosed method, a bright-dark pattern generated by the shape of a surface defect is recognized based on an obtained subtraction image, and whether the surface defect is concave or convex is determined to further improve the accuracy of surface-defect detection (refer to Patent Literature 2).</p>
<heading id="h0002">Citation List</heading>
<heading id="h0003">Patent Literature</heading>
<p id="p0004" num="0004">
<ul id="ul0001" list-style="none" compact="compact">
<li>Patent Literature 1: <patcit id="pcit0001" dnum="JP2015125089A"><text>Japanese Patent Application Laid-open No. 2015-125089</text></patcit></li>
<li>Patent Literature 2: <patcit id="pcit0002" dnum="JP2015210150A"><text>Japanese Patent Application Laid-open No. 2015-210150</text></patcit></li>
</ul></p>
<heading id="h0004">Summary</heading>
<heading id="h0005">Technical Problem</heading>
<p id="p0005" num="0005">With the methods disclosed in Patent Literatures 1 and 2, a concave-convex surface defect and a flat scale pattern can be accurately distinguished based on a subtraction image. However, studies by the inventors of the present invention found that, in the methods disclosed in Patent Literatures 1 and 2, a signal of a base steel portion, which has almost no concave and convex portions and has a high surface reflectance, after subtraction is similar to a signal of a concave surface defect and thus difficult to distinguish in some cases. Note that a base steel portion is generated due to flaking of a mill scale, which is caused by rubbing, collision, and the like mainly<!-- EPO <DP n="3"> --> at a temperature lower than a temperature at which the mill scale is generated on the surface, and for example, a cold-rolling scratch is a base steel portion. A concave-convex surface defect is normally generated as a steel material is transferred with pressing of a protrusion or the like baked on a roll while the steel material is soft in hot rolling. Thus, the concave-convex surface defect has a well-defined concave-convex shape, and is oxidized like a sound portion through a cooling process and obtains a reflectance equivalent to that of the sound portion. As a result, as illustrated in <figref idref="f0019">FIG. 22 (a)</figref>, a clear bright-dark pattern is generated by light irradiation from one side. However, a base steel portion is typically generated as a steel material is rubbed with a structure such as a roll in cold rolling, and when a mill scale is flaked and base steel is exposed, the base steel portion obtains a reflectance higher than that of a sound portion covered by the mill scale. As a result, as illustrated in <figref idref="f0019">FIG. 22 (b)</figref>, the base steel portion has substantially no depth but has a high reflectance, and thus is captured as a high-luminance signal irrespective of the irradiation direction.</p>
<p id="p0006" num="0006">When the base steel portion slightly has concave and convex portions, a bright-dark pattern similar to a concave-convex surface defect is sometimes generated in a subtraction image acquired by applying the methods disclosed in Patent Literatures 1 and 2. The base steel portion is a surface defect that can be harmful or harmless depending on the purpose of an examination, and causes no detection and excessive detection of a surface defect. In particular, the concave-convex surface defect and the base steel portion are often treated as harmful and harmless, respectively, in an examination, such as thickness safeguard, for which depth is important, and it is<!-- EPO <DP n="4"> --> desirable to accurately distinguish the concave-convex surface defect and the base steel portion.</p>
<p id="p0007" num="0007">The present invention is intended to solve the above-described problem and provide a surface-defect detecting method, a surface-defect detecting apparatus, a surface-defect determination model generating method, and a surface-defect determination model that are capable of accurately distinguishing a base steel portion and a surface defect. The present invention is also intended to provide a steel-material manufacturing method, a steel-material quality management method, and a steel-material manufacturing facility that are capable of improving a manufacturing yield of a steel material by accurately distinguishing a base steel portion and a surface defect. Solution to Problem</p>
<p id="p0008" num="0008">To solve the problem and achieve the object, a surface-defect detecting method of optically detecting a surface defect of a steel material, according to the present invention includes: an irradiation step of irradiating an examination target part with illumination light beams from different directions by using two or more distinguishable light sources; and a detection step of detecting a surface defect in the examination target part based on the degree of overlapping of bright portions extracted from two or more images formed by reflected light beams of the illumination light beams.</p>
<p id="p0009" num="0009">Moreover, in the surface-defect detecting method according to the present invention, the degree of overlapping of the bright portions is a ratio at which an overlapping portion of the bright portions occupies a surface-defect candidate portion in the examination target part.</p>
<p id="p0010" num="0010">Moreover, in the surface-defect detecting method<!-- EPO <DP n="5"> --> according to the present invention, the detection step includes a step of calculating a surface-defect candidate portion in the examination target part based on the bright portions extracted from two or more images formed by reflected light beams of the illumination light beams, and a step of detecting a surface defect in the examination target part based on a ratio at which an overlapping portion of the bright portions occupies the surface-defect candidate portion.</p>
<p id="p0011" num="0011">Moreover, in the surface-defect detecting method according to the present invention, the detection step includes a step of detecting a surface defect in the examination target part by using a surface-defect determination model subjected to machine learning such that a determination value indicating whether or not the surface defect exists in the examination target part corresponding to the two or more images is output, when the degree of overlapping of bright portions extracted from the two or more images is input.</p>
<p id="p0012" num="0012">Moreover, a surface-defect detecting apparatus configured to optically detect a surface defect of a steel material, according to the present invention includes: an irradiation unit configured to irradiate an examination target part with illumination light beams from different directions by using two or more distinguishable light sources; and a detection unit configured to detect a surface defect in the examination target part based on the degree of overlapping of bright portions extracted from two or more images formed by reflected light beams of the illumination light beams.</p>
<p id="p0013" num="0013">Moreover, a steel-material manufacturing method according to the present invention includes a step of manufacturing a steel material while detecting a surface<!-- EPO <DP n="6"> --> defect of the steel material by using the surface-defect detecting method according to the present invention.</p>
<p id="p0014" num="0014">Moreover, a steel-material quality management method according to the present invention includes a step of managing the quality of a steel material by classifying the steel material based on existence of a surface defect by using the surface-defect detecting method according to the present invention.</p>
<p id="p0015" num="0015">Moreover, a steel-material manufacturing facility according to the present invention includes: a manufacturing facility configured to manufacture a steel material; and the surface-defect detecting apparatus according to the present invention that is configured to examine the steel material manufactured by the manufacturing facility.</p>
<p id="p0016" num="0016">Moreover, a surface-defect determination model generating method according to the present invention includes: using the degree of overlapping of bright portions extracted from two or more images formed by reflected light beams of illumination light beams with which an examination target portion is irradiated from different directions by using two or more distinguishable light sources and a result of determination of whether or not a surface defect exists in the examination target portion, as teacher data; and generating a learning-completed model by machine learning as a surface-defect determination model, where an input value of the learning-completed model being the degree of overlapping of bright portions extracted from the two or more images and an output value of the learning-completed model being a value of determination of whether or not a surface defect exists in the examination target portion corresponding to the two or more images.<!-- EPO <DP n="7"> --></p>
<p id="p0017" num="0017">Moreover, a surface-defect determination model according to the present invention is the model generated by the surface-defect determination model generating method according to the present invention.</p>
<heading id="h0006">Advantageous Effects of Invention</heading>
<p id="p0018" num="0018">With a surface-defect detecting method, a surface-defect detecting apparatus, a surface-defect determination model generating method, and a surface-defect determination model according to the present invention, it is possible to accurately distinguish a base steel portion and a surface defect. With a steel-material manufacturing method, a steel-material quality management method, and a steel-material manufacturing facility according to the present invention, it is possible to improve a manufacturing yield of a steel material by accurately distinguishing a base steel portion and a surface defect. Brief Description of Drawings
<ul id="ul0002" list-style="none" compact="compact">
<li><figref idref="f0001">FIG. 1</figref> is a schematic diagram illustrating the configuration of a surface-defect detecting apparatus as an embodiment of the present invention.</li>
<li><figref idref="f0002">FIG. 2</figref> is a diagram illustrating exemplary subtraction images of a base steel portion.</li>
<li><figref idref="f0003">FIG. 3</figref> is a diagram illustrating a result of AND processing performed on a bright-portion image of a concave surface defect.</li>
<li><figref idref="f0003">FIG. 4</figref> is a diagram illustrating a result of AND processing performed on a bright-portion image of a base steel portion.</li>
<li><figref idref="f0004">FIG. 5</figref> is a flowchart illustrating the process of a detection step in a surface-defect detecting method as a first embodiment of the present invention.</li>
<li><figref idref="f0005">FIG. 6</figref> is a flowchart illustrating the process of a detection step in a surface-defect detecting method as a<!-- EPO <DP n="8"> --> second embodiment of the present invention.</li>
<li><figref idref="f0006">FIG. 7</figref> is a flowchart illustrating the process of a detection step in a surface-defect detecting method as a third embodiment of the present invention.</li>
<li><figref idref="f0007">FIG. 8</figref> is a diagram for describing exemplary labeling processing illustrated in <figref idref="f0006">FIG. 7</figref>.</li>
<li><figref idref="f0008">FIG. 9</figref> is a flowchart illustrating the process of a detection step in a surface-defect detecting method as a fourth embodiment of the present invention.</li>
<li><figref idref="f0009">FIG. 10</figref> is a diagram illustrating two exemplary two-dimensional images obtained through image capturing of a concave-convex surface defect and scale and/or harmless pattern, and an exemplary subtraction image thereof.</li>
<li><figref idref="f0010">FIG. 11</figref> is a diagram illustrating shade and shadow when light is incident from one side in cases in which the surface shape of an examination target part is concave and convex.</li>
<li><figref idref="f0011">FIG. 12</figref> is a diagram illustrating an exemplary subtraction image of a concave surface defect.</li>
<li><figref idref="f0012">FIG. 13</figref> is a flowchart illustrating the process of a method of calculating the positional relation between a bright portion and a dark portion by using expansion processing.</li>
<li><figref idref="f0013">FIG. 14</figref> is a diagram for describing expansion-contraction processing.</li>
<li><figref idref="f0014">FIG. 15</figref> is a diagram illustrating an exemplary subtraction image and an exemplary one-dimensional profile of a bright-dark pattern.</li>
<li><figref idref="f0014">FIG. 16</figref> is a diagram illustrating an exemplary two-dimensional image of a filter and an exemplary one-dimensional profile thereof.</li>
<li><figref idref="f0015">FIG. 17</figref> is a diagram illustrating an exemplary subtraction image subjected to filter processing by using<!-- EPO <DP n="9"> --> the filter illustrated in <figref idref="f0014">FIG. 16</figref> and an exemplary one-dimensional profile thereof.</li>
<li><figref idref="f0015">FIG. 18</figref> is a diagram illustrating calculation results of combined-bright-portion occupancy histograms of a base steel portion and a concave-convex surface defect.</li>
<li><figref idref="f0016">FIG. 19</figref> is a flowchart illustrating the process of a detection step in a surface-defect detecting method as a fifth embodiment of the present invention.</li>
<li><figref idref="f0017">FIG. 20</figref> is a schematic diagram illustrating a modification of the disposition positions of light sources.</li>
<li><figref idref="f0018">FIG. 21</figref> is a schematic diagram illustrating bright-dark patterns obtained with the disposition positions of the light sources illustrated in <figref idref="f0017">FIG. 20</figref>.</li>
<li><figref idref="f0019">FIG. 22</figref> is a schematic diagram for describing characteristics of a concave-convex surface defect and a base steel portion.</li>
</ul></p>
<heading id="h0007">Description of Embodiments</heading>
<p id="p0019" num="0019">The configuration and operation of a surface-defect detecting apparatus as an embodiment of the present invention will be described below with reference to the accompanying drawings.</p>
<heading id="h0008">[Configuration of surface-defect detecting apparatus]</heading>
<p id="p0020" num="0020"><figref idref="f0001">FIG. 1</figref> is a schematic diagram illustrating the configuration of a surface-defect detecting apparatus as an embodiment of the present invention. As illustrated in <figref idref="f0001">FIG. 1</figref>, this surface-defect detecting apparatus 1 as an embodiment of the present invention is a device configured to detect a surface defect of a cylindrical steel pipe P conveyed in the illustrated arrow direction and includes, as main components, light sources 2a and 2b, a function generator 3, area sensors 4a and 4b, an image processing device 5, and a monitor 6.<!-- EPO <DP n="10"> --></p>
<p id="p0021" num="0021">The light sources 2a and 2b are irradiation units. The light sources 2a and 2b emit distinguishable illumination light beams L to a same examination target part on the surface of the steel pipe P in accordance with a trigger signal from the function generator 3. The light sources 2a and 2b are disposed symmetrically with respect to the examination target part. Specifically, the light sources 2a and 2b are each shifted by a same incident angle from the normal vector of the surface of the steel pipe P and disposed so that an irradiation direction vector of the illumination light beams L and the normal vector of the surface of the steel pipe P are on a same plane.</p>
<p id="p0022" num="0022">The purpose of the same incident angle of the illumination light beams L is to have same optical conditions as possible when light sources from different incident directions are distinguished. The incident angles are empirically regarded as same when the difference between the incident angles is equal to or smaller than 20°. In addition, it is empirically desirable that the incident angle of each light source is 25° to 82.5°. It is desirable to select the incident angle in the range of 25° to 55° when the light quantity is desired to be increased, or in the range of 60° to 82.5° when the light quantity is sufficient and the S/N ratio is desired to be increased.</p>
<p id="p0023" num="0023">Note that each incident angle in the present specification means the angle between the incident direction of a light beam from the light source 2a or 2b and the normal of the surface of the examination target part. The normal of the surface of the examination target part is set at 0°. Although the number of light sources is two in the present embodiment, the number of light sources may be three or more as long as they are distinguishable.<!-- EPO <DP n="11"> --> Such distinguishable light sources mean light sources for each of which the amount of reflected light beams obtained from the examination target part can be separately calculated.</p>
<p id="p0024" num="0024">The area sensors 4a and 4b are image capturing units. The area sensors 4a and 4b capture two-dimensional images formed by reflected light beams of the illumination light beams L emitted from the light sources 2a and 2b in accordance with the trigger signal from the function generator 3. The area sensors 4a and 4b input data of the captured two-dimensional images to the image processing device 5. The area sensors 4a and 4b are installed on the normal vector of the examination target part as closely as possible while image capturing visual fields thereof are maintained. Note that although area sensors are used in the present embodiment, line sensors may be used. In this case, captured images are one-dimensional images, but a surface-defect detecting method to be described later is applicable.</p>
<p id="p0025" num="0025">The image processing device 5 is a detection unit. The image processing device 5 is a device configured to perform processing of determining a harmless base steel portion in the examination target part by using two two-dimensional images input from the area sensors 4a and 4b. This base-steel-portion determination processing is the most important technology of the present invention, and thus will be described later in detail. The image processing device 5 may perform defect determination by machine learning. In addition, the image processing device 5 may detect a surface defect in the examination target part as necessary by performing subtraction processing to be described later. The image processing device 5 outputs, to the monitor 6, two-dimensional images input from the<!-- EPO <DP n="12"> --> area sensors 4a and 4b and information related to a result of surface-defect detection.</p>
<p id="p0026" num="0026">The surface-defect detecting apparatus 1 having such a configuration performs the processing of determining a base steel portion in the examination target part by executing the surface-defect detecting method described below. In addition, the surface-defect detecting apparatus 1 distinguishes scale or harmless pattern, a concave-convex surface defect, and a base steel portion in the examination target part as necessary. Note that scale or harmless pattern means portions including a surface film or a surface texture having a thickness of several µm to several tens of µm approximately and optical properties different from those of the base steel portion, and portions that cause noise in the surface-defect detecting method.</p>
<heading id="h0009">[Surface-defect detecting method]</heading>
<p id="p0027" num="0027">In surface-defect detecting methods disclosed in Patent Literatures 1 and 2, the same subtraction processing on a two-dimensional image of a base steel portion of a cold-rolling scratch or the like generates bright-dark patterns as illustrated in <figref idref="f0002">FIGS. 2 (b) to (e)</figref> like the bright-dark pattern of a concave-convex surface defect as illustrated in <figref idref="f0002">FIG. 2 (a)</figref> in some cases. This is because the base steel portion has a high reflectance and luminance variance and thus bright and dark portions are randomly generated. In the field of a steel material, such as a thick plate or a steel pipe, for which the depth of a surface defect is important, in particular, the base steel portion extremely frequently occurs as compared to a surface defect, and thus is difficult to distinguish based on the characteristic amount or the like.</p>
<p id="p0028" num="0028">However, the base steel portion needs to be determined to be harmful or harmless, depending on<!-- EPO <DP n="13"> --> examination needs. Thus, when the base steel portion having a bright-dark pattern similar to the bright-dark pattern of the surface defect cannot be distinguished, excessive detection occurs and the performance of surface-defect detection decreases. In addition, the base steel portion needs to be distinguished as a surface defect in some cases when the base steel portion needs to be determined to be harmful. Furthermore, the base steel portion has various shapes and needs to be determined to be harmless in many cases.</p>
<p id="p0029" num="0029">To stably detect such a base steel portion, its characteristic that the base steel portion is brighter than a stationary portion when irradiated with illumination light beam from any direction can be used. The stationary portion in the present description is a mill scale portion, which is not the surface defect nor the base steel portion. Specifically, the base steel portion can be detected by detecting an overlapping portion of bright portions in the region of a surface-defect candidate portion extracted through threshold value processing, labeling, or the like from two two-dimensional images input from the area sensors 4a and 4b.</p>
<p id="p0030" num="0030"><figref idref="f0003">FIGS. 3 and 4</figref> illustrate exemplary results of detecting, through binarization processing, bright portions of two two-dimensional images input from the area sensors 4a and 4b and performing AND processing on images of the detected bright portions for a concave surface defect and a base steel portion, respectively, at a surface-defect candidate portion. As illustrated in <figref idref="f0003">FIGS. 3 (c) to (e)</figref>, the positions of the bright portions of the two two-dimensional images (<figref idref="f0003">FIGS. 3 (c) and (d)</figref>) are different from each other for the concave surface defect, and thus no signals are not detected through the AND processing (<figref idref="f0003">FIG. 3<!-- EPO <DP n="14"> --> (e)</figref>). However, as illustrated in <figref idref="f0003">FIGS. 4 (c) to (e)</figref>, the positions of the bright portions of the two two-dimensional images (<figref idref="f0003">FIGS. 4 (c) and (d)</figref>) coincide with each other for the base steel portion, and thus signals are detected at almost all places of bright portions and dark portions through the AND processing (<figref idref="f0003">FIG. 4 (e)</figref>).</p>
<p id="p0031" num="0031">Note that a well-known method may be used as the method of detecting a surface-defect candidate portion at an examination target part. In particular, a method using a subtraction image, which is disclosed in Patent Literatures 1 and 2 has such an advantage that the method can eliminate a scale pattern and a harmless pattern through subtraction processing and use a unique bright-dark pattern generated by a concave-convex surface defect, and thus can accurately detect a surface-defect candidate portion, in particular, a concave-convex surface-defect candidate portion, and accordingly, the method is preferable.</p>
<p id="p0032" num="0032">Note that the timing of detection of a surface-defect candidate portion may be any timing as long as the detection step to be described later is performed before the step (S5, S15, S25, S37, or S48 to be described later) of calculating a combined-surface-portion occupancy. For example, a surface-defect candidate portion may be detected in advance, separately from the detection step to be described later (refer to first and second embodiments). Alternatively, for example, in the detection step to be described later, a surface-defect candidate portion may be detected based on copies of a bright-portion binarized image "a" and a bright-portion binarized image "b" used in the detection step (refer to a third embodiment). Alternatively, for example, in parallel to the detection step to be described later, a concave-convex surface defect<!-- EPO <DP n="15"> --> may be detected by using subtraction images obtained from copies of a raw image "a", a raw image "b", a correction image "a", a correction image "b", and the like used in the detection step, and the detected concave-convex surface defect may be set as a surface-defect candidate portion.</p>
<p id="p0033" num="0033">Thus, whether a surface-defect candidate portion is a surface defect or a base steel portion can be determined by extracting a combined bright-portion image through AND processing on bright-portion images of two two-dimensional images and evaluating the surface-defect candidate portion based on the combined bright-portion image. A base steel portion can be detected by extracting bright portions of the two two-dimensional images through threshold value processing and performing AND processing on the bright portions. In a case of a surface defect or the like as well as a base steel portion, bright portions of two two-dimensional images obtained through irradiation from different directions slightly overlap by accident in some cases. However, in a case of a base steel portion, the reflectance is high in two two-dimensional images obtained through irradiation from different directions, and bright portions overlap almost in the entire region. Thus, the degree of overlapping of the bright portions may be calculated as a characteristic amount, and a base steel portion and a surface defect may be distinguished by using this index. This method can more accurately perform distinguishment than in a case in which determination is performed on the existence of an overlapping portion, and thus is preferable.</p>
<p id="p0034" num="0034">The following describes surface-defect detecting methods as the first to fifth embodiments of the present invention, which are thought of based on the above-described idea.<!-- EPO <DP n="16"> --></p>
<heading id="h0010">[First embodiment]</heading>
<p id="p0035" num="0035">First, a surface-defect detecting method as the first embodiment of the present invention will be described below with reference to <figref idref="f0004">FIG. 5</figref>.</p>
<p id="p0036" num="0036">The surface-defect detecting method as the first embodiment of the present invention includes an irradiation step, an image capturing step, and a detection step. In the irradiation step, the light sources 2a and 2b emit distinguishable illumination light beams L to a same examination target part on the surface of the steel pipe P in accordance with a trigger signal from the function generator 3. In the image capturing step, the area sensors 4a and 4b capture, in accordance with a trigger signal from the function generator 3, two-dimensional images formed by reflected light beams of the illumination light beams L emitted from the light sources 2a and 2b. In the detection step, the image processing device 5 determines a harmless base steel portion by using the two two-dimensional images input from the area sensors 4a and 4b.</p>
<p id="p0037" num="0037"><figref idref="f0004">FIG. 5</figref> is a flowchart illustrating the process of the detection step in the surface-defect detecting method as the first embodiment of the present invention. As illustrated in <figref idref="f0004">FIG. 5</figref>, first in the detection step of the present embodiment, the image processing device 5 performs image correction processing on two two-dimensional images (raw images "a" and "b") input from the area sensors 4a and 4b, thereby generating correction images "a" and "b" (steps S1a and S1b). The image correction processing in the present description includes processing of cutting out an examination target region, and processing such as shading correction of correcting entire luminance unevenness attributable to an optical system.</p>
<p id="p0038" num="0038">Subsequently, the image processing device 5<!-- EPO <DP n="17"> --> performs, on each of the correction images "a" and "b", bright portion binarization processing of detecting a bright portion by setting one to the value of a pixel having a luminance equal to or higher than a threshold value and setting zero to the value of a pixel having a luminance lower than the threshold value. Through this processing, the image processing device 5 generates a bright-portion binarized image "a" and a bright-portion binarized image "b" (steps S2a and S2b). In <figref idref="f0004">FIG. 5</figref>, an exemplary bright-portion binarized image "a" is illustrated to the left of the label "bright-portion binarized image "a"", and an exemplary bright-portion binarized image "b" is illustrated to the right of the label "bright-portion binarized image "b"". Subsequently, the image processing device 5 performs AND processing on the bright-portion binarized images "a" and "b". Through this processing, the image processing device 5 extracts a pixel having the value of one in both bright-portion binarized images "a" and "b", thereby generating a combined bright-portion image (step S3). In <figref idref="f0004">FIG. 5</figref>, an exemplary combined bright-portion image is illustrated to the right of the label "combined bright-portion image".</p>
<p id="p0039" num="0039">Subsequently, the image processing device 5 performs masking calculation processing on the combined bright-portion image by using a surface-defect candidate portion. Through this processing, the image processing device 5 generates a cut-out combined bright-portion image obtained by cutting out a target region of determination as a base steel portion (in other words, a region that is a surface-defect candidate portion and a bright portion) (step S4). Subsequently, the image processing device 5 calculates, as a combined-bright-portion occupancy, the ratio at which the cut-out combined bright-portion image<!-- EPO <DP n="18"> --> occupies the entire surface-defect candidate portion (step S5). In addition, the image processing device 5 determines whether the surface-defect candidate portion is a base steel portion or a surface defect through threshold value processing or the like using the calculated combined-bright-portion occupancy. When having determined that the surface-defect candidate portion is not a base steel portion, the image processing device 5 determines that the surface-defect candidate portion is a surface defect (step S6). Note that the present embodiment is an example in which the degree of overlapping of the combined bright-portion image over the surface-defect candidate portion is calculated, but another processing method is applicable as long as the degree of overlapping of the combined bright-portion image over the entire surface-defect candidate portion can be calculated. For example, a surface-defect candidate portion may be measured by another method such as eddy current flaw detection or ultrasonic wave flaw detection, and the ratio at which the combined bright-portion image occupies the surface-defect candidate portion may be calculated.</p>
<heading id="h0011">[Second embodiment]</heading>
<p id="p0040" num="0040">Subsequently, a surface-defect detecting method as the second embodiment of the present invention will be described below with reference to <figref idref="f0005">FIG. 6</figref>.</p>
<p id="p0041" num="0041">The surface-defect detecting method as the second embodiment of the present invention includes an irradiation step, an image capturing step, and a detection step. In the irradiation step, the light sources 2a and 2b emit distinguishable illumination light beams L to a same examination target part on the surface of the steel pipe P in accordance with a trigger signal from the function generator 3. In the image capturing step, the area sensors<!-- EPO <DP n="19"> --> 4a and 4b capture, in accordance with a trigger signal from the function generator 3, two-dimensional images formed by reflected light beams of the illumination light beams L emitted from the light sources 2a and 2b. In the detection step, the image processing device 5 determines a harmless base steel portion by using the two two-dimensional images input from the area sensors 4a and 4b.</p>
<p id="p0042" num="0042"><figref idref="f0005">FIG. 6</figref> is a flowchart illustrating the process of the detection step in the surface-defect detecting method as the second embodiment of the present invention. As illustrated in <figref idref="f0005">FIG. 6</figref>, first in the detection step of the present embodiment, the image processing device 5 performs masking calculation processing using a surface-defect candidate portion on each of two two-dimensional images (raw images "a" and "b") input from the area sensors 4a and 4b, thereby generating a cut-out raw image "a" and a cut-out raw image "b" by cutting out a target region of determination as a base steel portion (steps S11a and S11b). Subsequently, the image processing device 5 performs image correction processing on the cut-out raw images "a" and "b", thereby generating a cut-out correction image "a" and a cut-out correction image "b" (steps S12a and S12b). The image correction processing in the present description includes processing such as shading correction of correcting entire luminance unevenness attributable to an optical system.</p>
<p id="p0043" num="0043">Subsequently, the image processing device 5 performs, on each of the cut-out correction images "a" and "b", bright portion binarization processing of detecting a bright portion by setting one to the value of a pixel having a luminance equal to or higher than a threshold value and setting zero to the value of a pixel having a luminance lower than the threshold value. Through this<!-- EPO <DP n="20"> --> processing, the image processing device 5 generates a cut-out bright-portion binarized image "a" and a cut-out bright-portion binarized image "b" (steps S13a and S13b). Subsequently, the image processing device 5 performs AND processing on the cut-out bright-portion binarized images "a" and "b". Through this processing, the image processing device 5 extracts a pixel having the value of one in both cut-out bright-portion binarized images "a" and "b", thereby generating a cut-out combined bright-portion image (step S14). Subsequently, the image processing device 5 calculates, as a combined-bright-portion occupancy, the ratio at which the cut-out combined bright-portion image occupies the entire surface-defect candidate portion (step S15). In addition, the image processing device 5 determines whether the surface-defect candidate portion is a base steel portion or a surface defect through threshold value processing or the like using the calculated combined-bright-portion occupancy. When having determined that the surface-defect candidate portion is not a base steel portion, the image processing device 5 determines that the surface-defect candidate portion is a surface defect (step S16) .</p>
<heading id="h0012">[Third embodiment]</heading>
<p id="p0044" num="0044">Subsequently, a surface-defect detecting method as the third embodiment of the present invention will be described below with reference to <figref idref="f0006">FIG. 7</figref>.</p>
<p id="p0045" num="0045">The surface-defect detecting method as the third embodiment of the present invention includes an irradiation step, an image capturing step, and a detection step. In the irradiation step, the light sources 2a and 2b emit distinguishable illumination light beams L to a same examination target part on the surface of the steel pipe P in accordance with a trigger signal from the function<!-- EPO <DP n="21"> --> generator 3. In the image capturing step, the area sensors 4a and 4b capture, in accordance with a trigger signal from the function generator 3, two-dimensional images formed by reflected light beams of the illumination light beams L emitted from the light sources 2a and 2b. In the detection step, the image processing device 5 determines a harmless base steel portion by using the two two-dimensional images input from the area sensors 4a and 4b.</p>
<p id="p0046" num="0046"><figref idref="f0006">FIG. 7</figref> is a flowchart illustrating the process of the detection step in the surface-defect detecting method as the third embodiment of the present invention. As illustrated in <figref idref="f0006">FIG. 7</figref>, first in the detection step of the present embodiment, the image processing device 5 performs image correction processing, such as calibration, shading correction, and noise removal, using camera parameters derived in advance on each of two two-dimensional images (raw images "a" and "b") input from the area sensors 4a and 4b, thereby generating a correction image "a" and a correction image "b" (steps S21a and S21b). Through this image correction processing, the following bright-portion extraction processing and the like can be accurately performed.</p>
<p id="p0047" num="0047">Subsequently, the image processing device 5 performs, on each of the correction images "a" and "b", bright portion binarization processing of detecting a bright portion by setting one to the value of a pixel having a luminance equal to or higher than a threshold value and setting zero to the value of a pixel having a luminance lower than the threshold value. Through this processing, the image processing device 5 generates a bright-portion binarized image "a" and a bright-portion binarized image "b" (steps S22a and S22b). Subsequently, the image processing device 5 performs AND processing on<!-- EPO <DP n="22"> --> the bright-portion binarized images "a" and "b". Through this processing, the image processing device 5 extracts a pixel having the value of one in both bright-portion binarized images "a" and "b", thereby generating a combined bright-portion image (step S23). A set of pixels having the value of one in the combined bright-portion image form a bright-portion overlapping portion at which bright portions of the bright-portion binarized images "a" and "b" overlap. Accordingly, a portion at which high-reflectance portions overlap in the bright-portion binarized images "a" and "b" can be extracted. <figref idref="f0007">FIG. 8 (a)</figref> illustrates an exemplary bright-portion binarized image "a", <figref idref="f0007">FIG. 8 (b)</figref> illustrates an exemplary bright-portion binarized image "b", and <figref idref="f0007">FIG. 8 (c)</figref> illustrates an exemplary combined bright-portion image.</p>
<p id="p0048" num="0048">Subsequently, the image processing device 5 labels pixels of a bright portion having the value of one in the generated combined bright-portion image and sets each blob (set of labeled pixels) as a base-steel-portion candidate portion. A white portion (which is a bright portion) in the combined bright-portion image in <figref idref="f0007">FIG. 8 (c)</figref> is the base-steel-portion candidate portion and corresponds to an overlapping portion of bright portions of the bright-portion binarized images "a" and "b". The image processing device 5 performs OR processing on the bright-portion binarized images "a" and "b" generated at steps S22a and S22b this time. Through this processing, the image processing device 5 generates a bright-portion OR image. <figref idref="f0007">FIG. 8 (d)</figref> illustrates an exemplary bright-portion OR image. Then, the image processing device 5 labels the above-described base-steel-portion candidate portion in the bright-portion OR image obtained through this processing. Then, the image processing device 5 extracts, as a blob,<!-- EPO <DP n="23"> --> each bunch of bright portions including the labeled base-steel-portion candidate portion. Each blob is set as a surface-defect candidate portion (step S24). <figref idref="f0007">FIG. 8 (e)</figref> illustrates an exemplary surface-defect candidate portion. A white portion (which is a bright portion) is the surface-defect candidate portion. In the combined bright-portion image in <figref idref="f0007">FIG. 8 (c)</figref>, a bright portion that is unlikely to be a surface defect is deleted through the AND processing at step S23. As clearly understood from <figref idref="f0007">FIG. 8 (d)</figref>, all bright portions remain through the OR processing irrespective of whether they are defects. Thus, the surface-defect candidate portion can be reliably detected through labeling with the base-steel-portion candidate portion.</p>
<p id="p0049" num="0049">Subsequently, the image processing device 5 calculates, for each surface-defect candidate portion, as a combined-bright-portion occupancy, a value obtained dividing the area of the base-steel-portion candidate portion by the area of the surface-defect candidate portion (step S25). Lastly, the image processing device 5 detects a base steel portion by determining whether the surface-defect candidate portion is a base steel portion based on the calculated combined-bright-portion occupancy. When having determined that the surface-defect candidate portion is not a base steel portion, the image processing device 5 determines that the surface-defect candidate portion is a surface defect (step S26).</p>
<p id="p0050" num="0050">Note that a plurality of indexes are available for indicating the degree of overlapping of the base-steel-portion candidate portion over the surface-defect candidate portion. For example, the ratio at which the area of each base-steel-portion candidate portion occupies the area of the surface-defect candidate portion of the two images<!-- EPO <DP n="24"> --> before subjected to the AND processing can be used. In this case, the area of the surface-defect candidate portion is, for example, the area of a portion obtained through OR processing on two surface-defect candidate portions, or the sum or maximum value of the areas of surface-defect candidate portions. A surface-defect candidate portion is more likely to be a base steel portion as its combined-bright-portion occupancy is higher. Thus, a certain threshold value may be used to determine that the surface-defect candidate portion is a base steel portion when the combined-bright-portion occupancy is equal to or larger than the threshold value.</p>
<p id="p0051" num="0051">Alternatively, the combined-bright-portion occupancy may be used as a characteristic amount, and a base steel portion may be detected by using a well-known machine learning method such as a binary decision tree method. Specifically, the combined-bright-portion occupancy and a result of determination of whether a surface defect exists in the examination target part are used as teacher data to generate a learning-completed model by machine learning, an input value of the learning-completed model being the combined-bright-portion occupancy calculated from two or more images, an output value of the learning-completed model being the value of determination of whether a surface defect exists in the examination target part corresponding to the two or more images. The generated learning-completed model may be set as a surface defect model, the combined-bright-portion occupancy may be input to the surface-defect determination model, and a base steel portion may be detected by determining whether the surface-defect candidate portion is a base steel portion by using the output value of the surface-defect determination model. Accordingly, it is possible to accurately<!-- EPO <DP n="25"> --> distinguish a base steel portion and a surface defect, which have been difficult to distinguish by a conventionally method.</p>
<p id="p0052" num="0052">Whether the surface-defect candidate portion is a base steel portion may be determined based on the positional relation between the surface-defect candidate portion and the base steel portion calculated in the first to third embodiments. Specifically, the surface-defect candidate portion is likely to be a base steel portion when the surface-defect candidate portion and the base steel portion calculated in the first to third embodiments are at substantially same positions. Similarly to the first to third embodiments, another processing method is applicable when the degree of overlapping of bright portions in the surface-defect candidate portion can be calculated.</p>
<heading id="h0013">[Fourth embodiment]</heading>
<p id="p0053" num="0053">When concave and convex portions slightly exist at a base steel portion, a bright-dark pattern similar to a concave-convex surface defect occurs, and the base steel portion and the concave-convex surface defect cannot be accurately distinguished in some cases. Thus, in the present embodiment, the base steel portion and the concave-convex surface defect are accurately distinguished by using, as a surface-defect candidate portion, a concave-convex surface defect that can be calculated by the methods disclosed in Patent Literatures 1 and 2. Subsequently, a surface-defect detecting method as the fourth embodiment of the present invention will be described below with reference to <figref idref="f0008">FIG. 9</figref>.</p>
<p id="p0054" num="0054">The surface-defect detecting method as the fourth embodiment of the present invention includes an irradiation step, an image capturing step, and a detection step. In the irradiation step, the light sources 2a and 2b emit<!-- EPO <DP n="26"> --> distinguishable illumination light beams L to a same examination target part on the surface of the steel pipe P in accordance with a trigger signal from the function generator 3. In the image capturing step, the area sensors 4a and 4b capture, in accordance with a trigger signal from the function generator 3, two-dimensional images formed by reflected light beams of the illumination light beams L emitted from the light sources 2a and 2b. In the detection step, the image processing device 5 distinguishes scale and/or harmless pattern, a concave-convex surface defect, and a base steel portion by using two two-dimensional images input from the area sensors 4a and 4b.</p>
<p id="p0055" num="0055"><figref idref="f0008">FIG. 9</figref> is a flowchart illustrating the process of the detection step in the surface-defect detecting method as the fourth embodiment of the present invention. As illustrated in <figref idref="f0008">FIG. 9</figref>, first in the detection step of the present embodiment, the image processing device 5 performs image correction processing, such as calibration, shading correction, and noise removal, using camera parameters derived in advance on each of two two-dimensional images (raw images "a" and "b") input from the area sensors 4a and 4b, thereby generating a correction image "a" and a correction image "b" (steps S31a and S31b). Subsequently, the image processing device 5 performs subtraction processing on the correction images "a" and "b", thereby generating a subtraction image (step S32). Subsequently, the image processing device 5 calculates a concave-convex surface-defect candidate portion in the examination target part based on the generated subtraction image and outputs information related to scale and/or harmless pattern removed through the subtraction processing (step S33).</p>
<p id="p0056" num="0056">The image processing device 5 performs, on each of the correction images "a" and "b" generated at steps<!-- EPO <DP n="27"> --> S31a and S31b, bright portion binarization processing of detecting a bright portion by setting one to the value of a pixel having a luminance equal to or higher than a threshold value and setting zero to the value of a pixel having a luminance lower than the threshold value. Through this processing, the image processing device 5 generates a bright-portion binarized image "a" and a bright-portion binarized image "b" (steps S34a and S34b). Subsequently, the image processing device 5 performs AND processing on the bright-portion binarized images "a" and "b". Through this processing, the image processing device 5 extracts a pixel having the value of one in both bright-portion binarized images "a" and "b", thereby generating a combined bright-portion image (step S35). Subsequently, the image processing device 5 performs masking calculation processing on the combined bright-portion image by using the concave-convex surface-defect candidate portion calculated through the processing at step S33. Through this processing, the image processing device 5 generates a cut-out combined bright-portion image by cutting out a target region of determination as a base steel portion (step S36). Subsequently, the image processing device 5 calculates, as the combined-bright-portion occupancy, the ratio at which the cut-out combined bright-portion image occupies the entire concave-convex surface-defect candidate portion (step S37). In addition, the image processing device 5 determines whether the concave-convex surface-defect candidate portion is a base steel portion or a concave-convex surface defect through threshold value processing or the like using the calculated combined-bright-portion occupancy. When having determined that the concave-convex surface-defect candidate portion is not a base steel portion, the image processing device 5 determines that the<!-- EPO <DP n="28"> --> concave-convex surface-defect candidate portion is a surface defect (step S38). The base steel portion leads to a bright signal across the concave-convex surface-defect candidate portion for two irradiation directions, but the concave-convex surface defect has shade and shadow that are different between two irradiation directions, and thus bright and dark portions are generated at different positions across the concave-convex surface-defect candidate portion. Accordingly, the combined-bright-portion occupancy of the base steel portion is high, and the combined-bright-portion occupancy of the concave-convex surface defect is low.</p>
<p id="p0057" num="0057">Note that a well-known method may be used as the method of detecting a concave-convex surface-defect candidate portion in the examination target part by using the subtraction image obtained through the processing at step S33. In particular, the methods disclosed in Patent Literatures 1 and 2 can eliminate scale and/or harmless pattern through subtraction processing and use a unique bright-dark pattern generated by a concave-convex surface defect, and thus have such an advantage that the methods can accurately detect a concave-convex surface-defect candidate portion, and accordingly, the methods are preferable. The following describes, as an example of the processing at step S33, an example using the technologies disclosed in Patent Literatures 1 and 2.</p>
<p id="p0058" num="0058">When Ia(x, y) (the number of pixels is X×Y, the x coordinate satisfies 1 ≤ x ≤ X, and the y coordinate satisfies 1 ≤ y ≤ Y) represents the luminance value of each pixel included in a two-dimensional image Ia obtained in a case in which the illumination light beam L is emitted from the light source 2a, and Ib(x, y) represents the luminance<!-- EPO <DP n="29"> --> value of each pixel included in a two-dimensional image Ib obtained in a case in which the illumination light beam L is emitted from the light source 2b, the luminance value I_diff(x, y) of each pixel of a subtraction image I_diff that can be obtained through the subtraction processing at step S32 is expressed by Expression (1) described below.<maths id="math0001" num="(1)"><math display="block"><mi>I_diff</mi><mfenced separators=""><mi mathvariant="normal">x</mi><mi>,y</mi></mfenced><mo>=</mo><mi>Ia</mi><mfenced separators=""><mi mathvariant="normal">x</mi><mi>,y</mi></mfenced><mo>−</mo><mi>Ib</mi><mfenced separators=""><mi mathvariant="normal">x</mi><mi>,y</mi></mfenced></math><img id="ib0001" file="imgb0001.tif" wi="142" he="7" img-content="math" img-format="tif"/></maths></p>
<p id="p0059" num="0059"><figref idref="f0009">FIGS. 10 (a), (b), and (c)</figref> illustrate exemplary two-dimensional images Ia and Ib obtained by capturing sound scale and/or harmless pattern, which are not concave-convex surface defects nor surface defects, and an exemplary subtraction image I_diff thereof, respectively. As illustrated in <figref idref="f0009">FIGS. 10 (a), (b), and (c)</figref>, the angle between the normal vector of the surface and the light source 2a is equal to the angle between the normal vector of the surface and the light source 2b irrespective of the existence of scale and/or harmless pattern at a sound portion, and thus the luminance value Ia(x, y) = the luminance value Ib(x, y), in other words, the luminance value I_diff(x, y) = 0 holds.</p>
<p id="p0060" num="0060">However, the surface has a concave-convex shape at a concave-convex surface defect portion, and thus there always exists a place where the angle between the normal vector of the surface and the light source 2a is not equal to the angle between the normal vector of the surface and the light source 2b, and the luminance value Ia(x, y) # the luminance value Ib(x, y), in other words, the luminance value I_diff(x, y) # 0 holds. Thus, images of sound scale and/or harmless pattern, which are not surface defects, can be removed by generating the subtraction image I_diff of two two-dimensional images through subtraction processing<!-- EPO <DP n="30"> --> by a differentiator 11.</p>
<p id="p0061" num="0061">The following describes the logic of detection of a concave-convex surface-defect candidate portion from the subtraction image I_diff. <figref idref="f0010">FIGS. 11 (a) and (b)</figref> are diagrams illustrating shade and shadow when illumination light beam is emitted to the examination target part from one of the light sources when the surface shape of the examination target part is a concave shape and a convex shape, respectively. As illustrated in <figref idref="f0010">FIG. 11 (a)</figref>, when the surface shape of the examination target part is a concave shape, the side closer to the light source is dark due to decrease of the quantity of irradiation light per unit area, and the side farther from the light source is bright due to approach to the direction of regular reflection. However, when the surface shape of the examination target part is a convex shape as illustrated in <figref idref="f0010">FIG. 11 (b)</figref>, the side closer to the light source is bright due to approach to the direction of regular reflection, and the side farther from the light source is dark in the shadow of the convex shape.</p>
<p id="p0062" num="0062">Specifically, the bright-dark pattern of reflected light beams of illumination light beams differs, depending on whether the surface shape of the examination target part is a concave shape or a convex shape. Thus, the existence of a concave-convex surface-defect candidate portion can be detected by recognizing the bright-dark pattern of reflected light beam. Thus, next follows a description of a method of detecting a concave-convex surface-defect candidate portion by recognizing the bright-dark pattern of reflected light beam. Note that a concave surface-defect candidate portion in a concave-convex surface-defect candidate portion is detected in the following description, but a convex surface-defect<!-- EPO <DP n="31"> --> candidate portion can be detected by the same logic. A bright portion in the following description means a blob having an area equal to or larger than a predetermined value and obtained by performing coupling processing on pixels having a luminance equal to or larger than a predetermined threshold value in the subtraction image I_diff. A dark portion in the following description means a blob having an area equal to or larger than a predetermined value and obtained by performing coupling processing on pixels having a luminance equal to or smaller than a predetermined threshold value in the subtraction image I_diff. A blob means a set of labeled pixels.</p>
<p id="p0063" num="0063">Note that the above-described predetermined threshold values for detecting bright and dark portions, and the above-described predetermined values for determining the areas are adjusted on consideration of net detection performance. In other words, as the predetermined threshold values and the predetermined values are set to be larger, only a defect having a stronger signal can be detected, but an excessive detection signal due to surface roughness and noise can be reduced. Thus, adjustment is preferably performed to satisfy target detection performance and an allowed excessive detection degree based on definition of a harmful defect, usage, and distinguishment performance of determining a defect from the bright-dark pattern.</p>
<p id="p0064" num="0064">In the present embodiment, the bright-dark pattern is recognized by extracting adjacent bright and dark portions through threshold value processing. Specifically, in the surface-defect detecting apparatus 1 illustrated in <figref idref="f0001">FIG. 1</figref>, since the light sources 2a and 2b are symmetrically disposed in the right-left direction with respect to the normal vector of the examination target<!-- EPO <DP n="32"> --> part, the bright-dark pattern of reflected light attributable to the concave-convex shape of the surface is generated in the right-left direction. The right-left direction of bright and dark portions is reserved depending on the order of subtraction processing, and thus in this example, a concave shape is defined to be a case in which the bright portion is on the right and the dark portion is on the left, and a convex shape is defined to be a case in which the dark portion is on the right and the bright portion is on the left. Thus, the subtraction image I_diff of a concave surface defect is as illustrated in <figref idref="f0011">FIG. 12</figref>. When images of the bright and dark portions are binarized with luminance threshold values "The" and "-The", respectively, binarized images I_bright and I_dark of the bright and dark portions are expressed by Expression (2) described below.<maths id="math0002" num="(2)"><math display="block"><mtable columnalign="left"><mtr><mtd><mrow><mi>I_bright</mi><mfenced separators=""><mi mathvariant="normal">x</mi><mi>,y</mi></mfenced><mo>=</mo><mn>1</mn><mfenced separators=""><mi>when</mi><mspace width="1ex"/><mi>I_diff</mi><mfenced separators=""><mi mathvariant="normal">x</mi><mi>,y</mi></mfenced><mo>≥</mo><mi>The</mi></mfenced></mrow></mtd></mtr><mtr><mtd><mrow><mi>I_bright</mi><mfenced separators=""><mi mathvariant="normal">x</mi><mi>,y</mi></mfenced><mo>=</mo><mn>0</mn><mfenced separators=""><mi>when</mi><mspace width="1ex"/><mi>I_diff</mi><mfenced separators=""><mi mathvariant="normal">x</mi><mi>,y</mi></mfenced><mo>&lt;</mo><mi>The</mi></mfenced></mrow></mtd></mtr><mtr><mtd><mrow><mi>I_dark</mi><mfenced separators=""><mi mathvariant="normal">x</mi><mi>,y</mi></mfenced><mo>=</mo><mn>1</mn><mfenced separators=""><mi>when</mi><mspace width="1ex"/><mi>I_diff</mi><mfenced separators=""><mi mathvariant="normal">x</mi><mi>,y</mi></mfenced><mo>≤</mo><mo>−</mo><mi>The</mi></mfenced></mrow></mtd></mtr><mtr><mtd><mrow><mi>I_dark</mi><mfenced separators=""><mi mathvariant="normal">x</mi><mi>,y</mi></mfenced><mo>=</mo><mn>0</mn><mfenced separators=""><mi>when</mi><mspace width="1ex"/><mi>I_diff</mi><mfenced separators=""><mi mathvariant="normal">x</mi><mi>,y</mi></mfenced><mo>&gt;</mo><mo>−</mo><mi>The</mi></mfenced></mrow></mtd></mtr></mtable><mo>}</mo></math><img id="ib0002" file="imgb0002.tif" wi="147" he="30" img-content="math" img-format="tif"/></maths></p>
<p id="p0065" num="0065">After the images of the bright and dark portions are binarized in this manner and coupling and isolated-point removal are performed as necessary, the positional relation between adjacent bright and dark portions is calculated to detect the existence of a concave-convex surface defect. Note that various methods are available as the method of calculating the positional relation between adjacent bright and dark portions and three typical calculation methods are described below, but any other calculation method is applicable as long as the method can<!-- EPO <DP n="33"> --> calculate the positional relation between bright and dark portions.</p>
<p id="p0066" num="0066">The first positional relation calculation method calculates the positional relation between adjacent bright and dark portions by performing, on the adjacent bright and dark portions, expansion-contraction processing in a specific direction. <figref idref="f0012">FIG. 13</figref> illustrates a flowchart of the present calculation method. Since a concave surface defect is detected in the present embodiment, the following description is made on recognition of a bright-dark pattern in which the bright portion is on the right and the dark portion is on the left. Since the bright portion is on the right and the dark portion is on the left, the dark portion always exists on the left side of the bright portion, and the bright portion always exists on the right side of the dark portion. Thus, first in the present calculation method, the image processing device 5 performs rightward expansion processing on the dark portion and performs leftward expansion processing on the bright portion (steps S331a and S331b). When I_bright_extend and I_dark_extend represent images of the bright and dark portions, respectively, subjected to the extension processing and W represents the length of extension, the extension processing is expressed by Expression (3) described below. The origin is defined to be at the upper-left corner of each two-dimensional image, the positive y-axis direction is defined to be the downward direction, and the positive x-axis direction is defined to be the right direction.<maths id="math0003" num="(3)"><math display="block"><mtable columnalign="left"><mtr><mtd><mrow><mi>I_bright_extend</mi><mfenced separators=""><mi>x1</mi><mi>,y</mi></mfenced><mo>=</mo><mn>1</mn></mrow></mtd><mtd><mrow><mi mathvariant="normal">x</mi><mo>−</mo><mi mathvariant="normal">W</mi><mo>≤</mo><mi mathvariant="normal">x</mi><mn>1</mn><mo>≤</mo><mi mathvariant="normal">x</mi><mfenced separators=""><mi>when</mi><mspace width="1ex"/><mi>I_bright</mi><mfenced separators=""><mi mathvariant="normal">x</mi><mi>,y</mi></mfenced><mo>=</mo><mn>1</mn></mfenced></mrow></mtd></mtr><mtr><mtd><mrow><mi>I_dark_extend</mi><mfenced separators=""><mi>x1</mi><mi>,y</mi></mfenced><mo>=</mo><mn>1</mn></mrow></mtd><mtd><mrow><mi mathvariant="normal">x</mi><mo>≤</mo><mi mathvariant="normal">x</mi><mn>1</mn><mo>≤</mo><mi mathvariant="normal">x</mi><mo>+</mo><mi mathvariant="normal">W</mi><mfenced separators=""><mi>when</mi><mspace width="1ex"/><mi>I_dark</mi><mfenced separators=""><mi mathvariant="normal">x</mi><mi>,y</mi></mfenced><mo>=</mo><mn>1</mn></mfenced></mrow></mtd></mtr></mtable></math><img id="ib0003" file="imgb0003.tif" wi="145" he="15" img-content="math" img-format="tif"/></maths></p>
<p id="p0067" num="0067">Note that although the bright and dark portions<!-- EPO <DP n="34"> --> are extended by the same length W in the present embodiment, the length W of extension does not necessarily need to be same, and extension processing may be performed on only one of the bright and dark portions in an extreme case. In addition, the length W of extension depends on the size of a surface defect to be detected.</p>
<p id="p0068" num="0068">Subsequently, the image processing device 5 performs and processing on the images I_bright_extend and I_dark_extend of the bright and dark portions subjected to extension processing as in Expression (4) described below, thereby extracting, as a concave defect candidate portion image I_defect, an overlapping portion of the images I_bright_extend and I_dark_extend of the bright and dark portions subjected to extension processing (steps S332a and S332b) .<maths id="math0004" num="(4)"><math display="block"><mi>I_defect</mi><mo>=</mo><mi>I_bright_extend</mi><mo>&amp;</mo><mi>I_dark_extend</mi></math><img id="ib0004" file="imgb0004.tif" wi="136" he="6" img-content="math" img-format="tif"/></maths></p>
<p id="p0069" num="0069">Subsequently, the image processing device 5 performs coupling and isolated-point removal processing on each obtained concave defect candidate portion image I_defect as necessary, and then performs labeling processing to generate a concave defect candidate blob I_defect_blob (step S333). Then, the image processing device 5 extracts the characteristic amount of each concave defect candidate blob I_defect_blob, and determines whether the concave defect candidate blob I_defect_blob is a concave surface defect based on a result of the extraction (steps S334a and S334b). Note that information of the bright and dark portions is needed to investigate the characteristic amount of the concave defect candidate blob I_defect_blob, and thus the bright and dark portions are restored from the concave defect candidate blob<!-- EPO <DP n="35"> --> I_defect_blob.</p>
<p id="p0070" num="0070">Specifically, since the bright portion always exists on the right side of a concave defect candidate portion and the dark portion always exists on the left side thereof, the image processing device 5 searches the dark-portion binarized image I_dark to the left side with the barycenter of the concave defect candidate blob I_defect_blob as the starting point, and sets a blob found first as a dark-portion concave defect candidate blob I_dark_blob. Similarly, the image processing device 5 searches the bright-portion binarized image I_bright to the right with the barycenter of the concave defect candidate blob I_defect_blob as the starting point, and sets a blob found first as a bright-portion concave defect candidate blob I_bright_blob. Then, the image processing device 5 extracts a characteristic amount from the bright-portion concave defect candidate blob I_bright_blob and the dark-portion concave defect candidate blob I_dark_blob restored in this manner, and determines whether each concave defect candidate blob I_defect_blob is a concave surface defect based on the extracted characteristic amount. A specific characteristic amount differs depending on a defect, and thus is not described here but is described later in an example.</p>
<p id="p0071" num="0071">A concave-convex surface-defect candidate portion used in combined-bright-portion occupancy calculation to be described later can be calculated based on the restored bright-portion concave defect candidate blob and dark-portion concave defect candidate blob. Specifically, the concave-convex surface-defect candidate portion is calculated as a region obtained by calculating blobs of the bright and dark portions to acquire binarized images thereof and performing OR processing on the binarized<!-- EPO <DP n="36"> --> images, or as a region obtained by further performing extension-contraction processing to fill a portion between the bright and dark portions. Note that although description is made on a concave defect candidate portion in the present embodiment for simplification of description, the bright-dark pattern is reversed for a convex defect candidate portion as illustrated in <figref idref="f0010">FIGS. 11 (a) and (b)</figref>, and thus calculation can be performed through the same processing by reversing the positional relation between bright and dark portions in the processing illustrated in <figref idref="f0012">FIG. 13</figref>.</p>
<p id="p0072" num="0072">Note that, in the above-described extension-contraction processing, as illustrated in <figref idref="f0013">FIG. 14</figref>, extension processing with a certain shape (replacement of pixels forming an outline portion of the target blob by using a defined shape) is first performed on an image (<figref idref="f0013">FIG. 14 (d)</figref>) obtained through AND processing on a dark-portion binarized image (<figref idref="f0013">FIG. 14 (b)</figref>) and a bright-portion binarized image (<figref idref="f0013">FIG. 14 (c)</figref>) generated from a raw image (<figref idref="f0013">FIG. 14 (a)</figref>), and thereafter, contraction processing with a certain shape (deletion of pixels forming an outline portion of the target blob by using a defined shape) is performed to obtain an image (<figref idref="f0013">FIG. 14 (e)</figref>). As for an extension-contraction distance parameter, any shape is applicable as long as the blob is larger than the distance between the bright and dark portions, but the shape is desirably same between the extension processing and the contraction processing. The same result can be obtained by performing the extension-contraction processing a plurality of times for respective pixels.</p>
<p id="p0073" num="0073">In the second positional relation calculation method, after the above-described threshold value processing is performed and coupling and isolated-point<!-- EPO <DP n="37"> --> removal processing is performed as necessary, bright and dark portions are extracted and labeling is performed to recognize the positional relation between adjacent bright and dark portions, thereby detecting a concave surface defect. Specifically, first, the image processing device 5 individually recognizes bright and dark portions through labeling and obtains barycenter information of the bright and dark portions. Subsequently, the image processing device 5 determines whether the barycenter of a dark portion exists in a predetermined range on the right side of each bright portion based on the barycenter information of the bright and dark portions. When the barycenter of a dark portion exists, the image processing device 5 recognizes the pair of bright and dark portions as a bright-dark pattern and performs characteristic amount analysis on the bright-dark pattern to determine whether the pair corresponds to a concave surface defect. Note that although the bright-dark pattern is recognized by using the barycenter information in this example, information used to recognize the bright-dark pattern does not necessarily need to be the barycenter information as long as the information is information (for example, an upper-end position or a lower-end position) with which the positions of the adjacent bright and dark portions can be understood. Note that although description is made on a concave defect candidate portion in the present embodiment for simplification of description, the bright-dark pattern is reversed for a convex defect candidate portion as illustrated in <figref idref="f0010">FIGS. 11 (a) and (b)</figref>, and thus calculation can be performed through the same processing by reserving the positional relation between bright and dark portions in the processing illustrated in <figref idref="f0012">FIG. 13</figref>.</p>
<p id="p0074" num="0074">In the third positional relation calculation<!-- EPO <DP n="38"> --> method, the above-described threshold value processing is not performed, and a concave surface defect is detected by recognizing a bright-dark pattern by using a filter. Specifically, in the surface-defect detecting apparatus 1 illustrated in <figref idref="f0001">FIG. 1</figref>, since the light sources 2a and 2b are symmetrically disposed in the right-left direction with respect to the normal of the examination target part, a bright-dark pattern attributable to concave and convex portions of the surface is generated in the right-left direction. <figref idref="f0014">FIGS. 15 (a) and (b)</figref> are a diagram illustrating an exemplary subtraction image and a diagram illustrating the one-dimensional profile of a bright-dark pattern along line segment L illustrated in <figref idref="f0014">FIG. 15 (a)</figref>, respectively.</p>
<p id="p0075" num="0075">As illustrated in <figref idref="f0014">FIGS. 15 (a) and (b)</figref>, since the bright portion is on the right and the dark portion is on the left in a concave surface defect, the one-dimensional profile of the bright-dark pattern is a characteristic one-dimensional profile having a mountain shape on the right side and a valley shape on the left side. Thus, in the present embodiment, a filter H for a mountain shape on the right side and a valley shape on the left side is produced in advance and applied to the subtraction image I_diff as indicated in Expression (5) below, thereby generating a two-dimensional image I_cont in which high-frequency noise is reduced and only the bright-dark pattern is enhanced.<maths id="math0005" num="(5)"><math display="block"><mi>I_cont</mi><mo>=</mo><mi mathvariant="normal">H</mi><mo>∗</mo><mi>I_diff</mi></math><img id="ib0005" file="imgb0005.tif" wi="135" he="6" img-content="math" img-format="tif"/></maths></p>
<p id="p0076" num="0076"><figref idref="f0014">FIGS. 16 (a) and (b)</figref> are a diagram illustrating a two-dimensional image of the filter H produced in advance and a diagram illustrating an exemplary one-dimensional profile thereof in the right-left direction, respectively. <figref idref="f0015">FIGS. 17 (a) and (b)</figref> are a diagram illustrating a<!-- EPO <DP n="39"> --> subtraction image subjected to filter processing using the filter H illustrated in <figref idref="f0014">FIGS. 16 (a) and (b)</figref> and a diagram illustrating the one-dimensional profile thereof in the right-left direction, respectively. As illustrated in <figref idref="f0015">FIGS. 17 (a) and (b)</figref>, a two-dimensional image in which high-frequency noise is reduced and only the bright-dark pattern is enhanced is obtained. Note that although description is made on a concave defect candidate portion in the present embodiment for simplification of description, the bright-dark pattern is reversed for a convex defect candidate portion as illustrated in <figref idref="f0010">FIGS. 11 (a) and (b)</figref>, and thus, calculation can be performed through the same processing by reversing the shape of the filter.</p>
<p id="p0077" num="0077">Note that several kinds of filters having ranges different from each other in a width direction may be prepared as necessary to support a large number of surface defect sizes. The image processing device 5 performs coupling and isolated-point removal processing as necessary on the two-dimensional image in which the bright-dark pattern is enhanced in this manner, and then performs threshold value processing to extract a defect candidate portion image I_defect. Then, the image processing device 5 detects a concave surface defect by performing, on the extracted defect candidate portion image I_defect, processing same as that of the first positional relation calculation method. Note that a scale or harmless pattern, which has the same appearance between two images before the subtraction and forms no bright-dark pattern after the subtraction, can be extracted by excluding a candidate portion that forms a bright-dark pattern after the subtraction from among concave-convex surface-defect candidate portions extracted by binarizing and labeling the images before the subtraction.<!-- EPO <DP n="40"> --></p>
<heading id="h0014">[Example]</heading>
<p id="p0078" num="0078"><figref idref="f0015">FIG. 18</figref> illustrates an exemplary histogram of the combined-bright-portion occupancy calculated in an actualmachine test by using the surface-defect detecting method according to the fourth embodiment and a surface-defect apparatus 1. In <figref idref="f0015">FIG. 18</figref>, the horizontal axis represents the combined-bright-portion occupancy in percentage, and the vertical axis represents the frequency of a base steel portion or a concave-convex surface defect in percentage. In <figref idref="f0015">FIG. 18</figref>, each black rhombus indicates how much 100% of places visually checked as a "base steel portion" are distributed to the corresponding combined-bright-portion occupancy. In <figref idref="f0015">FIG. 18</figref>, each white rectangle indicates how much 100% of places visually checked as a "concave-convex surface defect" are distributed to the corresponding combined-bright-portion occupancy. Note that in the present example, a bright portion was defined to be a portion having a luminance more than 1.5 times higher than that of a sound portion. A concave-convex surface-defect candidate portion was detected by using bright-dark pattern detection and extension-contraction processing.</p>
<p id="p0079" num="0079">As illustrated in <figref idref="f0015">FIG. 18</figref>, it can be checked that the concave-convex surface defect and the base steel portion are extremely well separated at a threshold value at which the combined-bright-portion occupancy is 30% approximately. In a case of an examination in which the base steel portion is excessively detected, a concave-convex surface-defect candidate portion having a combined-bright-portion occupancy of, for example, 30% or higher is determined as the base steel portion. With this method, 95% or more of the base steel portion can be removed without excluding the concave-convex surface defect at all. Note that the method of performing distinguishment by<!-- EPO <DP n="41"> --> directly using the combined-bright-portion occupancy as the threshold value is effective, but the same result can be obtained through distinguishment using machine learning with the combined-bright-portion occupancy as one characteristic amount.</p>
<heading id="h0015">[Fifth embodiment]</heading>
<p id="p0080" num="0080">Lastly, a surface-defect detecting method as the fifth embodiment of the present invention will be described below with reference to <figref idref="f0016">FIG. 19</figref>.</p>
<p id="p0081" num="0081">The surface-defect detecting method as the fifth embodiment of the present invention includes an irradiation step, an image capturing step, and a detection step. In the irradiation step, the light sources 2a and 2b emit distinguishable illumination light beams L to a same examination target part on the surface of the steel pipe P in accordance with a trigger signal from the function generator 3. In the image capturing step, the area sensors 4a and 4b capture, in accordance with a trigger signal from the function generator 3, two-dimensional images formed by reflected light beams of the illumination light beams L emitted from the light sources 2a and 2b. In the detection step, the image processing device 5 distinguishes scale and/or harmless pattern, a concave-convex surface defect, and a base steel portion by using two two-dimensional images input from the area sensors 4a and 4b.</p>
<p id="p0082" num="0082"><figref idref="f0016">FIG. 19</figref> is a flowchart illustrating the process of the detection step in the surface-defect detecting method as the fifth embodiment of the present invention. As illustrated in <figref idref="f0016">FIG. 19</figref>, first in the detection step of the present embodiment, the image processing device 5 performs image correction processing, such as calibration, shading correction, and noise removal, using camera parameters derived in advance on each of two two-dimensional<!-- EPO <DP n="42"> --> images (raw images "a" and "b") input from the area sensors 4a and 4b, thereby generating a correction image "a" and a correction image "b" (steps S41a and S41b). Subsequently, the image processing device 5 performs subtraction processing on the correction images "a" and "b", thereby generating a subtraction image (step S42). A concave-convex surface-defect candidate portion in the examination target part is calculated based on the generated subtraction image (step S43). Specifically, the image processing device 5 calculates a concave-convex surface-defect candidate portion in the examination target part based on the generated subtraction image and outputs information related to scale and/or harmless pattern removed through the subtraction processing.</p>
<p id="p0083" num="0083">Subsequently, the image processing device 5 performs, on each of two two-dimensional images (raw images "a" and "b") input from the area sensors 4a and 4b, masking calculation processing using the concave-convex surface-defect candidate portion calculated at the processing at step S43. Through this processing, the image processing device 5 generates a cut-out raw image "a" and a cut-out raw image "b" obtained by cutting out a target region of determination as a base steel portion (steps S44a and S44b). Subsequently, the image processing device 5 performs image correction processing on the cut-out raw images "a" and "b", thereby generating a cut-out correction image "a" and a cut-out correction image "b" (steps S45a and S45b).</p>
<p id="p0084" num="0084">Subsequently, the image processing device 5 performs, on each of the cut-out correction images "a" and "b", bright portion binarization processing of detecting a bright portion by setting one to the value of a pixel having a luminance equal to or higher than a threshold<!-- EPO <DP n="43"> --> value and setting zero to the value of a pixel having a luminance lower than the threshold value. Through this processing, the image processing device 5 generates a cut-out bright-portion binarized image "a" and a cut-out bright-portion binarized image "b" (steps S46a and S46b). Subsequently, the image processing device 5 performs AND processing on the cut-out bright-portion binarized images "a" and "b". Through this processing, the image processing device 5 extracts a pixel having the value of one in both cut-out bright-portion binarized images "a" and "b", thereby generating a cut-out combined bright-portion image (step S47). Subsequently, the image processing device 5 calculates, as the combined-bright-portion occupancy, the ratio at which the cut-out combined bright-portion image occupies the entire concave-convex surface-defect candidate portion (step S48). In addition, the image processing device 5 determines whether the concave-convex surface-defect candidate portion is a base steel portion or a concave-convex surface defect through threshold value processing or the like using the calculated combined-bright-portion occupancy. When having determined that the concave-convex surface-defect candidate portion is not a base steel portion, the image processing device 5 determines that the concave-convex surface-defect candidate portion is a surface defect (step S49).</p>
<p id="p0085" num="0085">Note that a well-known method may be used as the method of detecting a concave-convex surface-defect candidate portion in the examination target part by using the subtraction image obtained through the processing at step S43. In particular, the methods disclosed in Patent Literatures 1 and 2 can eliminate scale and/or harmless pattern through subtraction processing and use a unique bright-dark pattern generated by a concave-convex surface<!-- EPO <DP n="44"> --> defect, and thus have such an advantage that the methods can accurately detect a concave-convex surface-defect candidate portion, and accordingly, the methods are preferable. The above-described processing at step S33 may be exemplary processing at step S43.</p>
<p id="p0086" num="0086">Although each embodiment to which the invention achieved by the inventors is applied is described above, the present invention is not limited by description and drawings as parts of the disclosure of the present invention according to the present embodiment. For example, although the light sources 2a and 2b are symmetrically installed in the right-left direction and thus a bright-dark pattern in the right-left direction is recognized in the present embodiment, a concave-convex surface defect can be detected through the same processing when the installation positions of the light sources 2a and 2b are symmetric in the up-down direction instead of the right-left direction or are not symmetric. Specifically, when the light sources are symmetrically disposed in the up-down direction, the bright-dark pattern only changes from the right-left direction to the up-down direction, and thus a concave-convex surface defect can be detected through the same processing by rotating the bright-dark pattern by 90°.</p>
<p id="p0087" num="0087">When the light sources 2a and 2b are installed so that the irradiation directions of illumination light beams are different from each other by 90° as illustrated in <figref idref="f0017">FIG. 20</figref>, the side closer to a light source is dark and the side farther from the light source is bright for a concave surface defect, or the side closer to the light source is bright and the side farther from the light source is dark for a convex surface defect. Specifically, in the case of a concave surface defect, a two-dimensional image obtained<!-- EPO <DP n="45"> --> by illumination light beam from the light source 2a is as illustrated in <figref idref="f0018">FIG. 21 (a)</figref>, and a two-dimensional image obtained by illumination light beam from the light source 2b is as illustrated in <figref idref="f0018">FIG. 21 (b)</figref>. Accordingly, their subtraction image is a bright-dark pattern having contrast from the lower-left corner to the upper-right corner as illustrated in <figref idref="f0018">FIG. 21 (c)</figref>. Thus, when the bright-dark pattern is rotated by 45°, the concave surface defect can be detected by a method same as that for a bright-dark pattern in the right-left direction. When three or more light sources are used, a subtraction image of a plurality of patterns can be obtained, and thus the accuracy of surface-defect detection can be further improved.</p>
<p id="p0088" num="0088">In the present embodiment, a concave-convex surface defect is detected when illumination light beams is irradiated in directions symmetric with respect to the normal of an examination target part, but the irradiation directions of illumination light beams do not necessarily need to be symmetric. The surface-defect detecting method of the present embodiment is applicable to any steel-material production line irrespective of hot rolling and cold rolling. When high-reflectance marking is applied to the product surface for product distinguishment, as well, only a marking portion can be detected by the same method. The marking has a unique shape in many cases, and thus can be distinguished by using a typical image characteristic amount.</p>
<p id="p0089" num="0089">When a steel material is manufactured while a surface defect of the steel material is detected by using the surface-defect detecting apparatus 1 or the surface-defect detecting method as an embodiment of the present invention, a base steel portion and a harmful surface defect can be accurately distinguished to improve the<!-- EPO <DP n="46"> --> manufacturing yield of the steel material. For example, a cold-rolling scratch is one of most typical base steel portions in an iron steel process. A surface defect (concave-convex surface defect, in particular) is typically generated by pressing of a protrusion such as a roll during hot rolling, and a cold-rolling scratch is typically generated by surface rubbing during conveyance. Thus, when these defects can be distinguished and detected, a defect generation factor can be easily specified. As a result, a factor on a production line can be promptly removed to prevent further generation. The surface-defect detecting apparatus 1 as an embodiment of the present invention may be applied as an examination device included in a steel-material manufacturing facility. Specifically, a steel material manufactured by the manufacturing facility by using the surface-defect detecting apparatus according to the present invention is examined to detect a surface defect of the steel material. For the above-described reason in this case as well, a base steel portion and a harmful surface defect can be accurately distinguished to improve the manufacturing yield of the steel material.</p>
<p id="p0090" num="0090">The quality of a steel material can be managed by classifying the steel material based on the existence of a surface defect by using the surface-defect detecting apparatus 1 or the surface-defect detecting method as an embodiment of the present invention. In other words, a base steel portion and a harmful surface defect (concave-convex surface defect, in particular) can be accurately distinguished to improve the manufacturing yield of the steel material. For example, a cold-rolling scratch is one of most typical base steel portions in an iron steel process. When a concave-convex surface defect is harmful and a cold-rolling scratch is harmless, false sensing of<!-- EPO <DP n="47"> --> the cold-rolling scratch leads to determination that a sound steel material has a defect, and reduces the manufacturing yield in some cases. When the degree of seriousness is different between a concave-convex surface defect and a cold-rolling scratch in this manner, distinguishment and detection of these defects allow determination in accordance with needs for examination of a steel material, thereby preventing decrease of the manufacturing yield of the steel material. In this manner, for example, other embodiments, examples, and applied technologies achieved by the skilled person in the art or the like based on the present embodiment are all included in the scope of the present invention.</p>
<heading id="h0016">Industrial Applicability</heading>
<p id="p0091" num="0091">According to the present invention, it is possible to provide a surface-defect detecting method, a surface-defect detecting apparatus, a surface-defect determination model generating method, and a surface-defect determination model that are capable of accurately distinguishing a base steel portion and a surface defect. In addition, according to the present invention, it is possible to provide a steel-material manufacturing method, a steel-material quality management method, and a steel-material manufacturing facility that are capable of improving a manufacturing yield of a steel material by accurately distinguishing a base steel portion and a surface defect.</p>
<heading id="h0017">Reference Signs List</heading>
<p id="p0092" num="0092">
<dl id="dl0001" compact="compact">
<dt>1</dt><dd>surface-defect detecting apparatus</dd>
<dt>2a, 2b</dt><dd>light source</dd>
<dt>3</dt><dd>function generator</dd>
<dt>4a, 4b</dt><dd>area sensor</dd>
<dt>5</dt><dd>image processing device<!-- EPO <DP n="48"> --></dd>
<dt>6</dt><dd>monitor</dd>
<dt>L</dt><dd>illumination light beam</dd>
<dt>P</dt><dd>steel pipe</dd>
</dl></p>
</description>
<claims id="claims01" lang="en"><!-- EPO <DP n="49"> -->
<claim id="c-en-0001" num="0001">
<claim-text>A surface-defect detecting method of optically detecting a surface defect of a steel material, the method comprising:
<claim-text>an irradiation step of irradiating an examination target part with illumination light beams from different directions by using two or more distinguishable light sources; and</claim-text>
<claim-text>a detection step of detecting a surface defect in the examination target part based on the degree of overlapping of bright portions extracted from two or more images formed by reflected light beams of the illumination light beams.</claim-text></claim-text></claim>
<claim id="c-en-0002" num="0002">
<claim-text>The surface-defect detecting method according to claim 1, wherein the degree of overlapping of the bright portions is a ratio at which an overlapping portion of the bright portions occupies a surface-defect candidate portion in the examination target part.</claim-text></claim>
<claim id="c-en-0003" num="0003">
<claim-text>The surface-defect detecting method according to claim 1, wherein the detection step includes
<claim-text>a step of calculating a surface-defect candidate portion in the examination target part based on the bright portions extracted from two or more images formed by reflected light beams of the illumination light beams, and</claim-text>
<claim-text>a step of detecting a surface defect in the examination target part based on a ratio at which an overlapping portion of the bright portions occupies the surface-defect candidate portion.</claim-text></claim-text></claim>
<claim id="c-en-0004" num="0004">
<claim-text>The surface-defect detecting method according to any one of claims 1 to 3, wherein the detection step includes a step of detecting a surface defect in the examination<!-- EPO <DP n="50"> --> target part by using a surface-defect determination model subjected to machine learning such that a determination value indicating whether or not the surface defect exists in the examination target part corresponding to the two or more images is output, when the degree of overlapping of bright portions extracted from the two or more images is input.</claim-text></claim>
<claim id="c-en-0005" num="0005">
<claim-text>A surface-defect detecting apparatus configured to optically detect a surface defect of a steel material, the apparatus comprising:
<claim-text>an irradiation unit configured to irradiate an examination target part with illumination light beams from different directions by using two or more distinguishable light sources; and</claim-text>
<claim-text>a detection unit configured to detect a surface defect in the examination target part based on the degree of overlapping of bright portions extracted from two or more images formed by reflected light beams of the illumination light beams.</claim-text></claim-text></claim>
<claim id="c-en-0006" num="0006">
<claim-text>A steel-material manufacturing method comprising a step of manufacturing a steel material while detecting a surface defect of the steel material by using the surface-defect detecting method according to any one of claims 1 to 4.</claim-text></claim>
<claim id="c-en-0007" num="0007">
<claim-text>A steel-material quality management method comprising a step of managing the quality of a steel material by classifying the steel material based on existence of a surface defect by using the surface-defect detecting method according to any one of claims 1 to 4.<!-- EPO <DP n="51"> --></claim-text></claim>
<claim id="c-en-0008" num="0008">
<claim-text>A steel-material manufacturing facility comprising:
<claim-text>a manufacturing facility configured to manufacture a steel material; and</claim-text>
<claim-text>the surface-defect detecting apparatus according to claim 5 that is configured to examine the steel material manufactured by the manufacturing facility.</claim-text></claim-text></claim>
<claim id="c-en-0009" num="0009">
<claim-text>A surface-defect determination model generating method, comprising:
<claim-text>using the degree of overlapping of bright portions extracted from two or more images formed by reflected light beams of illumination light beams with which an examination target portion is irradiated from different directions by using two or more distinguishable light sources and a result of determination of whether or not a surface defect exists in the examination target portion, as teacher data; and</claim-text>
<claim-text>generating a learning-completed model by machine learning as a surface-defect determination model, where an input value of the learning-completed model being the degree of overlapping of bright portions extracted from the two or more images and an output value of the learning-completed model being a value of determination of whether or not a surface defect exists in the examination target portion corresponding to the two or more images.</claim-text></claim-text></claim>
<claim id="c-en-0010" num="0010">
<claim-text>A surface-defect determination model generated by the surface-defect determination model generating method according to claim 9.</claim-text></claim>
</claims>
<drawings id="draw" lang="en"><!-- EPO <DP n="52"> -->
<figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="155" he="150" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="53"> -->
<figure id="f0002" num="2(a),2(b),2(c),2(d),2(e)"><img id="if0002" file="imgf0002.tif" wi="165" he="145" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="54"> -->
<figure id="f0003" num="3a,3b,3c,3d,3e,4a,4b,4c,4d,4e"><img id="if0003" file="imgf0003.tif" wi="95" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="55"> -->
<figure id="f0004" num="5"><img id="if0004" file="imgf0004.tif" wi="165" he="197" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="56"> -->
<figure id="f0005" num="6"><img id="if0005" file="imgf0005.tif" wi="159" he="203" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="57"> -->
<figure id="f0006" num="7"><img id="if0006" file="imgf0006.tif" wi="136" he="164" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="58"> -->
<figure id="f0007" num="8a,8b,8c,8d,8e"><img id="if0007" file="imgf0007.tif" wi="161" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="59"> -->
<figure id="f0008" num="9"><img id="if0008" file="imgf0008.tif" wi="160" he="226" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="60"> -->
<figure id="f0009" num="10a,10b,10c"><img id="if0009" file="imgf0009.tif" wi="165" he="134" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="61"> -->
<figure id="f0010" num="11(a),11(b)"><img id="if0010" file="imgf0010.tif" wi="148" he="179" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="62"> -->
<figure id="f0011" num="12"><img id="if0011" file="imgf0011.tif" wi="123" he="107" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="63"> -->
<figure id="f0012" num="13"><img id="if0012" file="imgf0012.tif" wi="161" he="212" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="64"> -->
<figure id="f0013" num="14a,14b,14c,14d,14e"><img id="if0013" file="imgf0013.tif" wi="113" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="65"> -->
<figure id="f0014" num="15(a),15(b),16(a),16(b)"><img id="if0014" file="imgf0014.tif" wi="165" he="203" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="66"> -->
<figure id="f0015" num="17(a),17(b),18"><img id="if0015" file="imgf0015.tif" wi="165" he="216" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="67"> -->
<figure id="f0016" num="19"><img id="if0016" file="imgf0016.tif" wi="158" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="68"> -->
<figure id="f0017" num="20"><img id="if0017" file="imgf0017.tif" wi="136" he="66" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="69"> -->
<figure id="f0018" num="21(a),21(b),21(c)"><img id="if0018" file="imgf0018.tif" wi="117" he="213" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="70"> -->
<figure id="f0019" num="22(a),22(b)"><img id="if0019" file="imgf0019.tif" wi="164" he="65" img-content="drawing" img-format="tif"/></figure>
</drawings>
<search-report-data id="srep" lang="en" srep-office="EP" date-produced=""><doc-page id="srep0001" file="srep0001.tif" wi="163" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="163" he="233" type="tif"/></search-report-data>
<ep-reference-list id="ref-list">
<heading id="ref-h0001"><b>REFERENCES CITED IN THE DESCRIPTION</b></heading>
<p id="ref-p0001" num=""><i>This list of references cited by the applicant is for the reader's convenience only. It does not form part of the European patent document. Even though great care has been taken in compiling the references, errors or omissions cannot be excluded and the EPO disclaims all liability in this regard.</i></p>
<heading id="ref-h0002"><b>Patent documents cited in the description</b></heading>
<p id="ref-p0002" num="">
<ul id="ref-ul0001" list-style="bullet">
<li><patcit id="ref-pcit0001" dnum="JP2015125089A"><document-id><country>JP</country><doc-number>2015125089</doc-number><kind>A</kind></document-id></patcit><crossref idref="pcit0001">[0004]</crossref></li>
<li><patcit id="ref-pcit0002" dnum="JP2015210150A"><document-id><country>JP</country><doc-number>2015210150</doc-number><kind>A</kind></document-id></patcit><crossref idref="pcit0002">[0004]</crossref></li>
</ul></p>
</ep-reference-list>
</ep-patent-document>
