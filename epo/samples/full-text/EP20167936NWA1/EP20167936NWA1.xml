<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE ep-patent-document PUBLIC "-//EPO//EP PATENT DOCUMENT 1.5.1//EN" "ep-patent-document-v1-5-1.dtd">
<!-- This XML data has been generated under the supervision of the European Patent Office -->
<ep-patent-document id="EP20167936A1" file="EP20167936NWA1.xml" lang="en" country="EP" doc-number="3889900" kind="A1" date-publ="20211006" status="n" dtd-version="ep-patent-document-v1-5-1">
<SDOBI lang="en"><B000><eptags><B001EP>ATBECHDEDKESFRGBGRITLILUNLSEMCPTIESILTLVFIROMKCYALTRBGCZEEHUPLSKBAHRIS..MTNORSMESMMAKHTNMD..........</B001EP><B005EP>J</B005EP><B007EP>BDM Ver 2.0.12 (4th of August) -  1100000/0</B007EP></eptags></B000><B100><B110>3889900</B110><B120><B121>EUROPEAN PATENT APPLICATION</B121></B120><B130>A1</B130><B140><date>20211006</date></B140><B190>EP</B190></B100><B200><B210>20167936.2</B210><B220><date>20200403</date></B220><B250>en</B250><B251EP>en</B251EP><B260>en</B260></B200><B400><B405><date>20211006</date><bnum>202140</bnum></B405><B430><date>20211006</date><bnum>202140</bnum></B430></B400><B500><B510EP><classification-ipcr sequence="1"><text>G06T   7/30        20170101AFI20200923BHEP        </text></classification-ipcr></B510EP><B520EP><classifications-cpc><classification-cpc sequence="1"><text>G06T   5/006       20130101 LI20210806BHEP        </text></classification-cpc><classification-cpc sequence="2"><text>G06T2207/10056     20130101 LA20200918BHEP        </text></classification-cpc><classification-cpc sequence="3"><text>G02B  21/26        20130101 LI20200702BHEP        </text></classification-cpc><classification-cpc sequence="4"><text>G02B  21/367       20130101 LI20210831BHEP        </text></classification-cpc><classification-cpc sequence="5"><text>G01Q  30/06        20130101 FI20200924BHEP        </text></classification-cpc><classification-cpc sequence="6"><text>G06T2207/20084     20130101 LA20200918BHEP        </text></classification-cpc><classification-cpc sequence="7"><text>G06T2207/20081     20130101 LA20200918BHEP        </text></classification-cpc><classification-cpc sequence="8"><text>G02B  21/245       20130101 LI20200702BHEP        </text></classification-cpc></classifications-cpc></B520EP><B540><B541>de</B541><B542>VORRICHTUNG UND VERFAHREN ZUR KORREKTUR VON RICHTUNGSVERSCHIEBUNGEN IN TOPOGRAPHISCHEN BILDDATEN</B542><B541>en</B541><B542>DEVICE AND METHOD FOR CORRECTING DIRECTIONAL DRIFTS IN TOPOGRAPHIC IMAGE DATA</B542><B541>fr</B541><B542>DISPOSITIF ET PROCÉDÉ DE CORRECTION DES DÉRIVES DIRECTIONNELLES DANS DES DONNÉES D'IMAGES TOPOGRAPHIQUES</B542></B540><B590><B598>1</B598></B590></B500><B700><B710><B711><snm>Imec VZW</snm><iid>101833320</iid><irf>P55511/EP</irf><adr><str>Kapeldreef 75</str><city>3001 Leuven</city><ctry>BE</ctry></adr></B711></B710><B720><B721><snm>CERBU, Dorin</snm><adr><str>c/o IMEC VZW, patent department
Kapeldreef 75</str><city>3001 Leuven</city><ctry>BE</ctry></adr></B721><B721><snm>PAREDIS, Kristof</snm><adr><str>c/o IMEC VZW, patent department
Kapeldreef 75</str><city>3001 Leuven</city><ctry>BE</ctry></adr></B721><B721><snm>LERAY, Philippe</snm><adr><str>c/o IMEC VZW, patent department
Kapeldreef 75</str><city>3001 Leuven</city><ctry>BE</ctry></adr></B721><B721><snm>MOUSSA, Alain</snm><adr><str>c/o IMEC VZW, patent department
Kapeldreef 75</str><city>3001 Leuven</city><ctry>BE</ctry></adr></B721><B721><snm>CHARLEY, Anne-Laure</snm><adr><str>c/o IMEC VZW, patent department
Kapeldreef 75</str><city>3001 Leuven</city><ctry>BE</ctry></adr></B721></B720><B740><B741><snm>Roth, Sebastian</snm><iid>101662426</iid><adr><str>Mitscherlich PartmbB 
Patent- und Rechtsanwälte 
Sonnenstraße 33</str><city>80331 München</city><ctry>DE</ctry></adr></B741></B740></B700><B800><B840><ctry>AL</ctry><ctry>AT</ctry><ctry>BE</ctry><ctry>BG</ctry><ctry>CH</ctry><ctry>CY</ctry><ctry>CZ</ctry><ctry>DE</ctry><ctry>DK</ctry><ctry>EE</ctry><ctry>ES</ctry><ctry>FI</ctry><ctry>FR</ctry><ctry>GB</ctry><ctry>GR</ctry><ctry>HR</ctry><ctry>HU</ctry><ctry>IE</ctry><ctry>IS</ctry><ctry>IT</ctry><ctry>LI</ctry><ctry>LT</ctry><ctry>LU</ctry><ctry>LV</ctry><ctry>MC</ctry><ctry>MK</ctry><ctry>MT</ctry><ctry>NL</ctry><ctry>NO</ctry><ctry>PL</ctry><ctry>PT</ctry><ctry>RO</ctry><ctry>RS</ctry><ctry>SE</ctry><ctry>SI</ctry><ctry>SK</ctry><ctry>SM</ctry><ctry>TR</ctry></B840><B844EP><B845EP><ctry>BA</ctry></B845EP><B845EP><ctry>ME</ctry></B845EP></B844EP><B848EP><B849EP><ctry>KH</ctry></B849EP><B849EP><ctry>MA</ctry></B849EP><B849EP><ctry>MD</ctry></B849EP><B849EP><ctry>TN</ctry></B849EP></B848EP></B800></SDOBI>
<abstract id="abst" lang="en">
<p id="pa01" num="0001">The invention relates to a device (100) for correcting directional drifts in topographic image data, comprising a receiver (103) configured to receive the topographic image data in a raw data format, wherein the topographic image data comprises values representing spatial coordinates of a topography, and wherein the values are in a first range, a processor (105) configured to normalize said values of the topographic image data to a second range, and a trainable neural network (107) configured to receive the topographic image data with normalized values and to remove a directional drift of the normalized values, wherein, following removal of the directional drift by the neural network (107), the processor (105) is configured to denormalize the values, in particular to the first range, to generate corrected topographic image data.
<img id="iaf01" file="imgaf001.tif" wi="139" he="79" img-content="drawing" img-format="tif"/></p>
</abstract>
<description id="desc" lang="en"><!-- EPO <DP n="1"> -->
<heading id="h0001">TECHNICAL FIELD OF THE INVENTION</heading>
<p id="p0001" num="0001">The present disclosure relates to a device and a method for correcting directional drifts in topographic image data.</p>
<heading id="h0002">BACKGROUND OF THE INVENTION</heading>
<p id="p0002" num="0002">3D topography imaging systems, such as atomic force microscopes (AFMs) or profilometers, can be used to record topographic images of surfaces with micro- or nanometric resolutions. For instance, such systems are used for defect inspection and dimensional measurements of semiconductor devices.</p>
<p id="p0003" num="0003">However, often during the acquisition of a topographic image, a drift in vertical direction is superimposed on the recorded topography. This drift can be caused by imperfections or misalignments of the imaging system, e.g. drifts or non-linearities of a probe head or a piezo scanner of a profilometer. Further, the drift can be caused by the fact that the sample or a stage for the sample are not perfectly flat.</p>
<p id="p0004" num="0004">Such a drift represents an artefact in the topographic image that is difficult to remove. For instance, removal of the drift requires manual input and a subsequent assessment whether the removal was done appropriately. Hence, the correction may be time-consuming and may vary from image to image, depending on the operator.</p>
<heading id="h0003">SUMMARY OF THE INVENTION</heading>
<p id="p0005" num="0005">Thus, it is an objective to provide an improved device and an improved method for correcting directional drifts in topographic image data. In particular, the above-mentioned disadvantages should be avoided.<!-- EPO <DP n="2"> --></p>
<p id="p0006" num="0006">The objective is achieved by the solution provided in the enclosed independent claims. Advantageous implementations of the present invention are further defined in the dependent claims.</p>
<p id="p0007" num="0007">According to a first aspect, the present disclosure relates to a device for correcting directional drifts in topographic image data, comprising: a receiver configured to receive the topographic image data in a raw data format, wherein the topographic image data comprises values representing spatial coordinates of a topography, and wherein the values are in a first range, a processor configured to normalize said values of the topographic image data to a second range, and a trainable neural network configured to receive the topographic image data with normalized values and to remove a directional drift of the normalized values, wherein, following removal of the directional drift by the neural network, the processor is configured to denormalize the values, in particular to the first range, to generate corrected topographic image data.</p>
<p id="p0008" num="0008">This achieves the advantage that directional drifts in the topographic image data can be corrected efficiently. In particular, this correction can be a faster, more accurate and more scalable (i.e. uniformly for different images) compared to a correction carried out by an operator. Hence, the correction of a topographic image can be automated.</p>
<p id="p0009" num="0009">Preferably, the topographic image data comprises raw data of a topographic image, in particular a 3D topographic image, of a surface, e.g. the surface of a wafer or a semiconductor device. In particular, the topographic image shows a topography of the surface. For example, the topographic image shows a surface which essentially extends over a horizontal xy-direction and which comprises structures that at least partially extend in a vertical z-direction.</p>
<p id="p0010" num="0010">The directional drift can be a vertical drift in the image data. In particular, the directional drift comprises a drift in z-direction perpendicular to an xy-direction in which the recorded surface extends. Alternatively or additionally, the directional drift<!-- EPO <DP n="3"> --> can be a horizontal drift, e.g. the directional drift comprises a drift in x- and/or y-direction. The directional drift can be an unwanted artefact in the topographic image.</p>
<p id="p0011" num="0011">The directional drift can be superimposed on the spatial coordinates of the topography. The spatial coordinates can be three dimensional coordinates comprising x, y and z components. In particular, the spatial coordinates comprise z-values, i.e. coordinates in z-direction.</p>
<p id="p0012" num="0012">In particular, the topographic image data was recorded with a topography imaging system such as an atomic force microscope (AFM), a scanning tunneling microscope (STM), a mechanical profilometer, or an optical profilometer, e.g. an interferometry-based profiler. The directional drift can be caused by imperfections or misalignments of this imaging systems.</p>
<p id="p0013" num="0013">The device can be a data processing device, e.g. a computer. The receiver can comprise an interface for receiving the topographic image data. In particular, the receiver can be connected to the topographic imaging system via a communication link to directly receive the topographic image data. Alternatively, the receiver can comprise an interface for connecting a data storage, e.g. an USB interface, or a communication network for uploading the topographic image data.</p>
<p id="p0014" num="0014">In another embodiment, the device is integrated in a topography image system, e.g. an AFM. In this way the image system can generate already corrected topographic images.</p>
<p id="p0015" num="0015">The trainable neural network can be executed by a further processor of the device. Alternatively, the trainable neural network may be executed by the processor that performs the normalization. In particular, the neural network, preferably the processor in which the neural network is implemented, carries out a machine learning algorithm to correct the topographic image data.<!-- EPO <DP n="4"> --></p>
<p id="p0016" num="0016">Preferably, the second range is a range extending from a minimum of -1 to a maximum of +1.</p>
<p id="p0017" num="0017">In an embodiment, the processor is configured to normalize the values by centering said values around zero.</p>
<p id="p0018" num="0018">This achieves the advantage that the topographic image data can be normalized efficiently. In particular, the normalized image data can be better processed by the neural network which was trained with images having the same normalization.</p>
<p id="p0019" num="0019">In an embodiment, the processor is configured to normalize the values by subtracting a mean of the values from said values, and by subsequently dividing the values by an integer multiple of a standard deviation.</p>
<p id="p0020" num="0020">This achieves the advantage that the topographic image data can be normalized efficiently. In particular, the normalized image data can be better processed by the neural network which was trained with images having the same normalization.</p>
<p id="p0021" num="0021">In an embodiment, the processor is configured to denormalize the values by multiplying them with a factor.</p>
<p id="p0022" num="0022">This achieves the advantage that a corrected topographic image in the same range as the original image and with corrected drift can be generated efficiently.</p>
<p id="p0023" num="0023">In an embodiment, the processor is configured to determine the factor based on a spatial gradient of the values in the first range prior to the removal of the directional drift, and on a spatial gradient of the values in the second range after removal of the directional drift.</p>
<p id="p0024" num="0024">This achieves the advantage that the denormalization can be performed efficiently.<!-- EPO <DP n="5"> --></p>
<p id="p0025" num="0025">In an embodiment, the raw data format is an ASCII data format.</p>
<p id="p0026" num="0026">In an embodiment, the trainable neural network comprises a Generative Adversarial Network (GAN) or a convolutional neural network (CNN).</p>
<p id="p0027" num="0027">According to a second aspect, the present disclosure relates to a method for correcting directional drifts in topographic image data, comprising:
<ul id="ul0001" list-style="dash" compact="compact">
<li>receiving the topographic image data in a raw data format, wherein the topographic image data comprises values representing spatial coordinates of a topography, and wherein the values are in a first range,</li>
<li>normalizing said values to a second range,</li>
<li>removing a directional drift of the normalized values by a trainable neural network, and</li>
<li>following removal of the directional drift, denormalizing the values, in particular to the first range, to generate corrected topographic image data.</li>
</ul></p>
<p id="p0028" num="0028">This achieves the advantage that directional drifts in the topographic image data can be corrected efficiently. In particular, this correction can be a faster, more accurate and more scalable (i.e. uniformly for different images) compared to a correction carried out by an operator. Hence, the correction of a topographic image can be automated.</p>
<p id="p0029" num="0029">In an embodiment, the step of normalizing said values to the second range comprises centering said values around zero.</p>
<p id="p0030" num="0030">This achieves the advantage that the topographic image data can be normalized efficiently. In particular, the normalized image data can be better processed by the neural network which was trained with images having the same normalization.</p>
<p id="p0031" num="0031">In an embodiment, the step of normalizing said values to the second range further comprises subtracting a mean of the values from the values, and subsequently dividing the values by an integer multiple of a standard deviation.<!-- EPO <DP n="6"> --></p>
<p id="p0032" num="0032">This achieves the advantage that the topographic image data can be normalized efficiently. In particular, the normalized image data can be better processed by the neural network which was trained with images having the same normalization.</p>
<p id="p0033" num="0033">In an embodiment, the step of denormalizing the values comprises multiplying the corrected values by a factor.</p>
<p id="p0034" num="0034">This achieves the advantage that a corrected topographic image in the same range as the original image and with corrected drift can be generated efficiently.</p>
<p id="p0035" num="0035">In an embodiment, the factor is determined based on a spatial gradient of the values in the first range prior to the removal of the directional drift, and on a spatial gradient of the values in the second range after removal of the directional drift.</p>
<p id="p0036" num="0036">This achieves the advantage that the denormalization can be performed efficiently.</p>
<p id="p0037" num="0037">In an embodiment, the trainable neural network is trained by:
<ul id="ul0002" list-style="dash" compact="compact">
<li>providing training data in the raw data format, wherein the training data comprises further values representing spatial coordinates of a training topography,</li>
<li>normalizing the further values,</li>
<li>removing a directional drift of the normalized further values by the trainable neural network, and</li>
<li>following removal of the directional drift, comparing the training data to reference data.</li>
</ul></p>
<p id="p0038" num="0038">This achieves the advantage that the neural network can be trained efficiently based on suitable reference data.</p>
<p id="p0039" num="0039">In an embodiment, the trainable neural network is further trained by:<!-- EPO <DP n="7"> -->
<ul id="ul0003" list-style="dash" compact="compact">
<li>determining a loss function, wherein the loss function represents a deviation between the training data after removal of the directional drift and the reference data, and</li>
<li>adapting the trainable neural network to decrease the loss function.</li>
</ul></p>
<p id="p0040" num="0040">This achieves the advantage that the neural network can be trained efficiently based on suitable reference data.</p>
<p id="p0041" num="0041">In an embodiment, the comparison of the training data after removal of the directional drift and the reference data is carried out by a further neural network.</p>
<p id="p0042" num="0042">This achieves the advantage that the neural network can be trained efficiently based on two neural networks.</p>
<p id="p0043" num="0043">The further neural network can be executed by the processor or the further processor of the device. Alternatively, the further neural network is implemented in another device.</p>
<p id="p0044" num="0044">The above description with regard to the device according to the first aspect of the present disclosure is correspondingly valid for the method according to the second aspect of the present disclosure.</p>
<p id="p0045" num="0045">According to a third aspect, the present disclosure relates to a computer program, which comprises a program code for performing the method according to the second aspect of the present disclosure when executed on a computer.</p>
<heading id="h0004">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p0046" num="0046">The invention will be explained in the followings together with the figures.<!-- EPO <DP n="8"> -->
<dl id="dl0001">
<dt>Fig. 1</dt><dd>shows a schematic diagram of a device for correcting directional drifts in topographic image data according to an embodiment;</dd>
<dt>Fig. 2</dt><dd>shows a schematic diagram of the trained neural network of the device shown in <figref idref="f0001">Fig. 1</figref>, according to an embodiment;</dd>
<dt>Figs. 3</dt><dd>shows a normalization and a denormalization of values representing spatial coordinates of a topography according to an embodiment;</dd>
<dt>Fig. 4a-b</dt><dd>shows visual schematics of z-value parameters of topographic image data according to an embodiment;</dd>
<dt>Fig. 5</dt><dd>shows a schematic diagram of a method for correcting directional drifts in topographic image data according to an embodiment;</dd>
<dt>Fig. 6</dt><dd>shows a schematic diagram of a method for training a trainable neural network according to an embodiment; and</dd>
<dt>Fig. 7</dt><dd>shows a schematic diagram of a system for training a trainable neural network according to an embodiment.</dd>
</dl></p>
<heading id="h0005">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
<p id="p0047" num="0047"><figref idref="f0001">Figs 1</figref> shows a schematic diagram of a device 100 for correcting directional drifts in topographic image data according to an embodiment.</p>
<p id="p0048" num="0048">The device 100 comprises a receiver 103 configured to receive the topographic image data in a raw data format, wherein the topographic image data comprises values representing spatial coordinates of a topography, and wherein the values are in a first range. The device 100 further comprises a processor 105 configured to normalize said<!-- EPO <DP n="9"> --> values of the topographic image data to a second range, and a trainable neural network 107 configured to receive the topographic image data with normalized values and to remove a directional drift of the normalized values, wherein, following removal of the directional drift by the trainable neural network 107, the processor 105 is configured to denormalize the values, in particular to the first range, to generate corrected topographic image data.</p>
<p id="p0049" num="0049">The topographic image data can comprise raw data of a topographic image, in particular a 3D topographic image, of a surface. In particular, the topographic image shows a topography of a surface.</p>
<p id="p0050" num="0050">The directional drift can be a vertical drift in the image data. In particular, the directional drift comprises a drift in z-direction perpendicular to an xy-direction in which the surface extends. Alternatively or additionally, the directional drift can comprise a horizontal drift, e.g. a drift in x- and/or y-direction. The directional drift can be superimposed on the spatial coordinates of the topography.</p>
<p id="p0051" num="0051">The raw data format can be a data format with which the topography image system, e.g. an AFM, generates the topographic image data. For example, the raw data format is an ASCII data format. Using this raw data format allows preserving a vertical resolution in the image data which is especially important for 3D topographic image data. In particular, using raw data such as ASCII allows preserving the absolute values, e.g. in nm or Angstroms, of the spatial coordinates in the vertical z-direction. Thus, a loss of vertical resolution which may occur when encoding the image data using an image format such as jpeg or tiff can be avoided.</p>
<p id="p0052" num="0052">Alternatively, the raw data format can be a data format different to ASCII. For example, the raw data format can be any data format that preserves a height information of a topography and that comprises coordinates, in particular x-y-coordinates, of the topography at which heights, i.e. z-coordinates, were recorded. In particular, the raw data format can be a suitable document format that allows accessing the raw data and<!-- EPO <DP n="10"> --> a transformation of said raw data into a matrix which comprises matrix elements representing topographical height information.</p>
<p id="p0053" num="0053"><figref idref="f0002">Fig. 2</figref> shows a schematic diagram of the trained neural network 107 of the device 100 shown in <figref idref="f0001">Fig. 1</figref>, according to an embodiment.</p>
<p id="p0054" num="0054">The trained neural network 107 is configured to receive the topographic image data with the directional drift (degraded image) following the normalization of this data, and to generate the corrected topographic image data by removing the directional drift.</p>
<p id="p0055" num="0055">For example, the topographic image data comprises raw data of a topographic image 201 of a structured substrate, e.g. a substrate having pores extending along a z-direction. This topographic image 201 is superimposed by the directional drift which forms an artifact that degrades the quality of the image. The corrected topographic image data comprises data from a corrected version of the topographic image 203. In the corrected image 203 the artifact is removed.</p>
<p id="p0056" num="0056">In particular, the directional drift is an unwanted artefact in the topographic image data. The directional drift can comprise linear, parabolic or cubic shifts in the image data. The directional drift can further comprise random noise, streaks, spikes or single steps in the topographic image data.</p>
<p id="p0057" num="0057">The trainable neural network 107 can comprise Generative Adversarial Network (GAN). The GAN may comprise convolution blocks or layers. In particular, the CCN comprises an input layer, an output layer and hidden layers.</p>
<p id="p0058" num="0058">In particular, the GAN receives the topographic image data in the form of an input matrix, which may comprise pixel values of the topographic image. The GAN can calculate a sum of an element-wise multiplication of the input matrix and a kernel matrix or filter. This operation can retain positional connectivity between the input values and the output values while reducing a dimensionality of the input matrix. Thus,<!-- EPO <DP n="11"> --> a convolved feature map of the input matrix can be generated by the neural network 107.</p>
<p id="p0059" num="0059">Alternatively, the trainable neural network 107 comprises a Convolutional Neural Network (CNN) or any other suitable type of neural network.</p>
<p id="p0060" num="0060">The trainable neural network 107 can be executed by a further processor of the device 100. Alternatively, the trainable neural network 107 maybe executed by the processor 103. In particular, the processor 103 comprises a microprocessor or microchip of the device 100.</p>
<p id="p0061" num="0061"><figref idref="f0003">Fig. 3</figref> shows a normalization and a denormalization of values representing spatial coordinates of the topography according to an embodiment. In particular, <figref idref="f0003">Fig. 3</figref> shows the normalization and denormalization that is performed by the processor 105 prior to forwarding the values to the trainable neural network (NN) 107, respectively following the removal of the directional drift by the neural network (NN) 107.</p>
<p id="p0062" num="0062">A first plot 301 in <figref idref="f0003">Fig. 3</figref> shows a distribution of z-values, i.e. the z-direction components of the spatial coordinates of the topography, in a first range. This z-values are spatial coordinates from degraded topographic image data (DEG) which has the directional drift. In particular, <figref idref="f0003">Fig. 3</figref> shows the z-values of a line scan across the topographic image which, in the example shown in <figref idref="f0003">Fig. 3</figref>, range from -3 to 4 nm.</p>
<p id="p0063" num="0063">A second plot 303 in <figref idref="f0003">Fig. 3</figref> shows a normalization of the z-values from plot 301. The values, e.g. two-dimensional arrays derived from the ASCII files, are normalized by centering the distribution of z-values around 0.</p>
<p id="p0064" num="0064">Preferably, this centering is achieved by subtracting a mean of the z-values and subsequently dividing the z-values by k<sup>∗</sup>sigma, wherein sigma is the standard deviation of the z-values in the array and k is a factor of choice. For example, using k=6 ensures that most z-values with the exception of extreme outliers are normalized to the second<!-- EPO <DP n="12"> --> range, which is between -1 and 1. This type of normalization has the advantage that it is not dependent on outliers. In particular, the normalization is a standardization and the generated data is standardized degraded topographic image data (DEGs).</p>
<p id="p0065" num="0065">A third plot 305 in <figref idref="f0003">Fig. 3</figref> shows the normalized z-values of the corrected topographic image data (GENs) that is generated by the trained neural network 107.</p>
<p id="p0066" num="0066">The above described normalization ensures a high stability of the neural network 107 performance. In particular, the neural network 107 receives a standardized input in the same range as training data and generates a standardized output.</p>
<p id="p0067" num="0067">Subsequently, the z-values of the corrected topographic image data is denormalized, i.e. destandardized, back to the first range to generate the corrected topographic image data (GEN). The denormalized z-values are shown in a fourth plot 307 of <figref idref="f0003">Fig. 3</figref>. By means of this denormalization, the absolute z-values of the original topographic image data, e.g. in nm or Angstrom, can be restored.</p>
<p id="p0068" num="0068">The denormalization can be performed by multiplying the z-values of the image data by a factor F. This factor can be determined based on a spatial gradient of the z-values in the first range prior to the removal of the directional drift, and on a spatial gradient of the z-values in the second range after removal of the directional drift.</p>
<p id="p0069" num="0069">In the following, a detailed derivation of the factor F is shown:<br/>
The z-values of the degraded topographic image data (Z<sub>DEG</sub>) can be assessed as a sum of z-values of a ground truth data (Z<sub>GT</sub>), i.e. z-values of a topography without the directional drift, and the drift in z-direction (Z<sub>ENV</sub>) which can expressed as envelope function on the ground truth data, according to: <maths id="math0001" num=""><math display="block"><mrow><msub><mi mathvariant="normal">Z</mi><mi mathvariant="normal">DEG</mi></msub><mo>=</mo><msub><mi mathvariant="normal">Z</mi><mi mathvariant="normal">GT</mi></msub><mo>+</mo><msub><mi mathvariant="normal">Z</mi><mi mathvariant="normal">ENV</mi></msub></mrow></math><img id="ib0001" file="imgb0001.tif" wi="36" he="6" img-content="math" img-format="tif"/></maths><!-- EPO <DP n="13"> --></p>
<p id="p0070" num="0070"><figref idref="f0004">Fig. 4a</figref> shows a visual schematic of the parameters Z<sub>DEG</sub>, Z<sub>GT</sub> and Z<sub>ENV</sub> according to an embodiment. The spatial derivatives of these values can be expressed according to the following relation: <maths id="math0002" num=""><math display="block"><mrow><mfrac><mrow><msub><mi mathvariant="normal">ΔZ</mi><mi>DEG</mi></msub></mrow><mrow><msub><mi mathvariant="normal">Δp</mi><mi>xl</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><msub><mi mathvariant="normal">ΔZ</mi><mi>GT</mi></msub></mrow><mrow><msub><mi mathvariant="normal">Δp</mi><mi>xl</mi></msub></mrow></mfrac><mo>+</mo><mfrac><mrow><msub><mi mathvariant="normal">ΔZ</mi><mi>ENV</mi></msub></mrow><mrow><msub><mi mathvariant="normal">Δp</mi><mi>xl</mi></msub></mrow></mfrac></mrow></math><img id="ib0002" file="imgb0002.tif" wi="45" he="12" img-content="math" img-format="tif"/></maths></p>
<p id="p0071" num="0071">Here, p<sub>xl</sub> represents the pixels in the raw image data, wherein Z is the z-value at each pixel, i.e. the pixel height. <figref idref="f0004">Fig. 4b</figref> shows a visual schematic of the parameters ΔZ<sub>DEG</sub>/Δp<sub>xl</sub>, ΔZ<sub>GT</sub>/Δp<sub>xl</sub> and ΔZ<sub>ENV</sub>/Δp<sub>xl</sub> according to an embodiment.</p>
<p id="p0072" num="0072">Since the spatial gradient of the envelope function is relatively small compared to the ground truth data, the following assessment can be made: <maths id="math0003" num=""><math display="block"><mrow><mfrac><mrow><msub><mi mathvariant="normal">ΔZ</mi><mi>GT</mi></msub></mrow><mrow><msub><mi mathvariant="normal">Δp</mi><mi>xl</mi></msub></mrow></mfrac><mo>≫</mo><mfrac><mrow><msub><mi mathvariant="normal">ΔZ</mi><mi>ENV</mi></msub></mrow><mrow><msub><mi mathvariant="normal">Δp</mi><mi>xl</mi></msub></mrow></mfrac><mo>⇒</mo><mfrac><mrow><msub><mi mathvariant="normal">ΔZ</mi><mi>DEG</mi></msub></mrow><mrow><msub><mi mathvariant="normal">Δp</mi><mi>xl</mi></msub></mrow></mfrac><mo>≈</mo><mfrac><mrow><msub><mi mathvariant="normal">ΔZ</mi><mi>GT</mi></msub></mrow><mrow><msub><mi mathvariant="normal">Δp</mi><mi>xl</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><msub><mi mathvariant="normal">ΔZ</mi><mi>GEN</mi></msub></mrow><mrow><msub><mi mathvariant="normal">Δp</mi><mi>xl</mi></msub></mrow></mfrac></mrow></math><img id="ib0003" file="imgb0003.tif" wi="80" he="12" img-content="math" img-format="tif"/></maths></p>
<p id="p0073" num="0073">Here, Z<sub>GEN</sub> represents the z-values of the corrected and denormalized topographic image data. It can be assumed that the spatial gradients of Z<sub>GEN</sub> and Z<sub>GT</sub> are essentially identical. Further assuming a good correction performance of the neural network 107, it can be estimated that the ground truth z-values Z<sub>GT</sub> and the z-values Z<sub>GEN</sub> of the corrected image data are identical. Thus, the factor F can be derived in the following way: <maths id="math0004" num=""><math display="block"><mrow><msub><mi mathvariant="normal">Z</mi><mi mathvariant="normal">GT</mi></msub><mo>=</mo><msub><mi mathvariant="normal">Z</mi><mi mathvariant="normal">GEN</mi></msub><mo>=</mo><mi mathvariant="normal">F</mi><mo>∗</mo><msub><mfenced><msub><mi mathvariant="normal">Z</mi><mi mathvariant="normal">GEN</mi></msub></mfenced><mi mathvariant="normal">S</mi></msub><mo>,</mo></mrow></math><img id="ib0004" file="imgb0004.tif" wi="51" he="6" img-content="math" img-format="tif"/></maths> wherein (Z<sub>GEN</sub>)<sub>S</sub> are the z-values of the topographic image data after removal of the directional drift and prior to denormalization, i.e. normalized z-values in the second range. A spatial derivation provides: <maths id="math0005" num=""><math display="block"><mrow><mfrac><mrow><msub><mi mathvariant="normal">ΔZ</mi><mi mathvariant="normal">GT</mi></msub></mrow><mrow><msub><mi mathvariant="normal">Δp</mi><mi mathvariant="normal">xl</mi></msub></mrow></mfrac><mo>=</mo><mi mathvariant="normal">F</mi><mo>∗</mo><mfrac><mrow><mi mathvariant="normal">Δ</mi><msub><mfenced><msub><mi mathvariant="normal">Z</mi><mi mathvariant="normal">GEN</mi></msub></mfenced><mi mathvariant="normal">S</mi></msub></mrow><mrow><msub><mi mathvariant="normal">Δp</mi><mi mathvariant="normal">xl</mi></msub></mrow></mfrac></mrow></math><img id="ib0005" file="imgb0005.tif" wi="41" he="12" img-content="math" img-format="tif"/></maths><!-- EPO <DP n="14"> --></p>
<p id="p0074" num="0074">With the previous assumptions this can be rewritten as: <maths id="math0006" num=""><math display="block"><mrow><mfrac><mrow><msub><mi mathvariant="normal">ΔZ</mi><mi mathvariant="normal">DEG</mi></msub></mrow><mrow><msub><mi mathvariant="normal">Δp</mi><mi mathvariant="normal">xl</mi></msub></mrow></mfrac><mo>≈</mo><mfrac><mrow><msub><mi mathvariant="normal">ΔZ</mi><mi mathvariant="normal">GEN</mi></msub></mrow><mrow><msub><mi mathvariant="normal">Δp</mi><mi mathvariant="normal">xl</mi></msub></mrow></mfrac><mo>=</mo><mi mathvariant="normal">F</mi><mo>∗</mo><mfrac><mrow><mi mathvariant="normal">Δ</mi><msub><mfenced><msub><mi mathvariant="normal">Z</mi><mi mathvariant="normal">GEN</mi></msub></mfenced><mi mathvariant="normal">S</mi></msub></mrow><mrow><msub><mi mathvariant="normal">Δp</mi><mi mathvariant="normal">xl</mi></msub></mrow></mfrac><mo>,</mo></mrow></math><img id="ib0006" file="imgb0006.tif" wi="60" he="12" img-content="math" img-format="tif"/></maths> which can be rearranged to derive a formula for the factor F: <maths id="math0007" num=""><math display="block"><mrow><mi mathvariant="normal">F</mi><mo>≈</mo><mfrac><mrow><mi mathvariant="normal">Δ</mi><msub><mfenced><msub><mi mathvariant="normal">Z</mi><mi mathvariant="normal">GEN</mi></msub></mfenced><mi mathvariant="normal">S</mi></msub></mrow><mrow><msub><mi mathvariant="normal">Δp</mi><mi mathvariant="normal">xl</mi></msub></mrow></mfrac><mo>/</mo><mfrac><mrow><msub><mi mathvariant="normal">ΔZ</mi><mi mathvariant="normal">DEG</mi></msub></mrow><mrow><msub><mi mathvariant="normal">Δp</mi><mi mathvariant="normal">xl</mi></msub></mrow></mfrac></mrow></math><img id="ib0007" file="imgb0007.tif" wi="42" he="13" img-content="math" img-format="tif"/></maths></p>
<p id="p0075" num="0075">In particular, the first order spatial derivates preserve information on a relative difference between the first and second range which allows deriving the factor F. The factor F can be used to restore the absolute z-values of the corrected topographic image data to the first range, e.g. in nm or Angstrom.</p>
<p id="p0076" num="0076"><figref idref="f0005">Fig. 5</figref> shows a schematic diagram of a method 500 for correcting directional drifts in topographic image data according to an embodiment.</p>
<p id="p0077" num="0077">The method 500 comprises the following steps:
<ul id="ul0004" list-style="dash" compact="compact">
<li>receiving 501 the topographic image data in a raw data format, wherein the topographic image data comprises values representing spatial coordinates of a topography, and wherein the values are in a first range;</li>
<li>normalizing 503 the values to a second range,</li>
<li>removing 505 the directional drift of the normalized values by the trainable neural network 107, and</li>
<li>following removal 505 of the directional drift, denormalizing 507 the values, in particular to the first range, to generate the corrected topographic image data.</li>
</ul></p>
<p id="p0078" num="0078">Preferably, the step of normalizing 503 said values to the second range comprises centering said values around zero. In particular, the step of normalizing 503 said values to the second range further comprises subtracting the mean of the values from the<!-- EPO <DP n="15"> --> values, and subsequently dividing the values by the integer multiple of a standard deviation.</p>
<p id="p0079" num="0079">In an embodiment, the step of denormalizing 507 the values comprises multiplying the corrected values by the factor F. Preferably, the factor F is determined based on the spatial gradient of the values in the first range prior to the removal of the directional drift, and on the spatial gradient of the values in the second range after removal of the directional drift. An exemplary derivation of the factor F is shown above.</p>
<p id="p0080" num="0080"><figref idref="f0006">Fig. 6</figref> shows a schematic diagram of a method 600 for training the trainable neural network 107 according to an embodiment.</p>
<p id="p0081" num="0081">The method 600 comprises the following steps:
<ul id="ul0005" list-style="dash" compact="compact">
<li>providing 601 training data in the raw data format, wherein the training data comprises further values representing spatial coordinates of a training topography,</li>
<li>normalizing 603 the further values, in particular to the second range,</li>
<li>removing 605 a directional drift of the normalized further values by the trainable neural network 107, and</li>
<li>following removal 605 of the directional drift, comparing 607 the training data to reference data.</li>
</ul></p>
<p id="p0082" num="0082">Preferably, the method 600 comprises the additional steps of:
<ul id="ul0006" list-style="dash" compact="compact">
<li>determining 609 a loss function, wherein the loss function represents a deviation between the training data after removal 605 of the directional drift and the reference data, and</li>
<li>adapting 611 the trainable neural network 107 to decrease the loss function.</li>
</ul></p>
<p id="p0083" num="0083">In particular, the method 500 for correcting directional drifts in topographic image data may comprise the method 600 for training the trainable neural network 107. Hence, all steps of the training method 600 are also steps of the method 500. For<!-- EPO <DP n="16"> --> instance, the training steps 601-611 for the neural network 107 can be performed prior to method step 501.</p>
<p id="p0084" num="0084"><figref idref="f0007">Fig. 7</figref> shows a schematic diagram of a system 700 for training the trainable neural network 107 according to an embodiment.</p>
<p id="p0085" num="0085">The system 700 comprises the trainable neural network 107 and a further neural network 701. In particular, the further neural network 701 comprises a discriminator network.</p>
<p id="p0086" num="0086">During training, the trainable neural network 107 is fed with the training data, which comprises topographic image data from a degraded topographic image (DEG) 703, i.e. from a training topography. The DEG image 703 can be either a raw topographic image, e.g. an AFM image, that comprises the directional drift due to imperfections of the topography image system. Alternatively, the directional drift can be a simulated envelope that is superimposed on topographic image data. For instance, the envelope may simulate the following types of directional drift: linear shifts, parabolic shifts, cubic shifts, random noise, streaks, spikes, or single steps. Preferably, the z-values of the DEG image 703 are normalized to the second range, e.g. the range from -1 to 1.</p>
<p id="p0087" num="0087">The trained neural network 107 is configured to remove the directional drift from the image data of the topographic image 703 and generate image data of a reconstructed topographic image 705. The image data of this reconstructed topographic image 705 is subsequently compared to reference data. Preferably, the reference data comprises image data of a ground truth (GT) reference image 707, e.g. a topographic image of the same topography with, for instance, manually removed directional drift.</p>
<p id="p0088" num="0088">The further neural network 701 can be configured to compare the image data of the reconstructed topographic image 705 and the reference image 707, and to determine the loss function that represents a deviation between both images 705, 707. Ideally,<!-- EPO <DP n="17"> --> this deviation is as small as possible. Subsequently, the trainable neural network can be adapted to decrease the loss function.</p>
<p id="p0089" num="0089">All features of all embodiments described, shown and/or claimed herein can be combined with each other.</p>
</description>
<claims id="claims01" lang="en"><!-- EPO <DP n="18"> -->
<claim id="c-en-0001" num="0001">
<claim-text>Device (100) for correcting directional drifts in topographic image data, comprising:
<claim-text>a receiver (103) configured to receive the topographic image data in a raw data format, wherein the topographic image data comprises values representing spatial coordinates of a topography, and wherein the values are in a first range,</claim-text>
<claim-text>a processor (105) configured to normalize said values of the topographic image data to a second range, and</claim-text>
<claim-text>a trainable neural network (107) configured to receive the topographic image data with normalized values and to remove a directional drift of the normalized values,</claim-text>
<claim-text>wherein, following removal of the directional drift by the neural network (107), the processor (105) is configured to denormalize the values, in particular to the first range, to generate corrected topographic image data.</claim-text></claim-text></claim>
<claim id="c-en-0002" num="0002">
<claim-text>Device (100) according to claim 1, wherein the processor (105) is configured to normalize the values by centering said values around zero.</claim-text></claim>
<claim id="c-en-0003" num="0003">
<claim-text>Device (100) according to claim 1 or 2, wherein the processor (105) is configured to normalize the values by subtracting a mean of the values from said values, and by subsequently dividing the values by an integer multiple of a standard deviation.</claim-text></claim>
<claim id="c-en-0004" num="0004">
<claim-text>Device (100) according to any one of the preceding claims, wherein the processor (105) is configured to denormalize the values by multiplying them with a factor.</claim-text></claim>
<claim id="c-en-0005" num="0005">
<claim-text>Device (100) according to claim 4, wherein the processor (105) is configured to determine the factor based on a spatial gradient of the values in the first range prior to the removal of the directional drift, and on a spatial gradient of the values in the second range after removal of the directional drift.</claim-text></claim>
<claim id="c-en-0006" num="0006">
<claim-text>Device (100) according to any one of the preceding claims, wherein the raw data format is an ASCII data format.<!-- EPO <DP n="19"> --></claim-text></claim>
<claim id="c-en-0007" num="0007">
<claim-text>Device (100) according to any one of the preceding claims, wherein the trainable neural network (107) comprises a Generative Adversarial Network, GAN, or a convolutional neural network, CNN.</claim-text></claim>
<claim id="c-en-0008" num="0008">
<claim-text>Method (500) for correcting directional drifts in topographic image data, comprising:
<claim-text>- receiving (501) the topographic image data in a raw data format, wherein the topographic image data comprises values representing spatial coordinates of a topography, and wherein the values are in a first range,</claim-text>
<claim-text>- normalizing (503) said values to a second range,</claim-text>
<claim-text>- removing (505) a directional drift of the normalized values by a trainable neural network (107), and</claim-text>
<claim-text>- following removal (505) of the directional drift, denormalizing (507) the values, in particular to the first range, to generate corrected topographic image data.</claim-text></claim-text></claim>
<claim id="c-en-0009" num="0009">
<claim-text>Method (500) according to claim 8, wherein the step of normalizing (503) said values to the second range comprises centering said values around zero.</claim-text></claim>
<claim id="c-en-0010" num="0010">
<claim-text>Method (500) according to claim 8 or 9, wherein the step of normalizing (503) said values to the second range further comprises subtracting a mean of the values from the values, and subsequently dividing the values by an integer multiple of a standard deviation.</claim-text></claim>
<claim id="c-en-0011" num="0011">
<claim-text>Method (500) according to any one of claims 8 to 10, wherein the step of denormalizing (507) the values comprises multiplying the corrected values by a factor.</claim-text></claim>
<claim id="c-en-0012" num="0012">
<claim-text>Method (500) according to claim 11, wherein the factor is determined based on a spatial gradient of the values in the first range prior to the removal (505) of the directional drift, and on a spatial gradient of the values in the second range after removal (505) of the directional drift.</claim-text></claim>
<claim id="c-en-0013" num="0013">
<claim-text>Method (500) according to any one of claims 8 to 12, wherein the trainable neural network (107) is trained by:<!-- EPO <DP n="20"> -->
<claim-text>- providing (601) training data in the raw data format, wherein the training data comprises further values representing spatial coordinates of a training topography,</claim-text>
<claim-text>- normalizing (603) the further values,</claim-text>
<claim-text>- removing (605) a directional drift of the normalized further values by the trainable neural network, and</claim-text>
<claim-text>- following removal (605) of the directional drift, comparing (607) the training data to reference data.</claim-text></claim-text></claim>
<claim id="c-en-0014" num="0014">
<claim-text>Method (500) according to claim 13, wherein the trainable neural network (107) is further trained by:
<claim-text>- determining (609) a loss function, wherein the loss function represents a deviation between the training data after removal (605) of the directional drift and the reference data, and</claim-text>
<claim-text>- adapting (611) the trainable neural network (107) to decrease the loss function.</claim-text></claim-text></claim>
<claim id="c-en-0015" num="0015">
<claim-text>Method (500) according to claim 13 or 14, wherein the comparison (607) of the training data after removal (605) of the directional drift and the reference data is carried out by a further neural network (701).</claim-text></claim>
</claims>
<drawings id="draw" lang="en"><!-- EPO <DP n="21"> -->
<figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="88" he="155" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="22"> -->
<figure id="f0002" num="2"><img id="if0002" file="imgf0002.tif" wi="81" he="172" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="23"> -->
<figure id="f0003" num="3"><img id="if0003" file="imgf0003.tif" wi="104" he="193" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="24"> -->
<figure id="f0004" num="4a,4b"><img id="if0004" file="imgf0004.tif" wi="73" he="124" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="25"> -->
<figure id="f0005" num="5"><img id="if0005" file="imgf0005.tif" wi="93" he="167" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="26"> -->
<figure id="f0006" num="6"><img id="if0006" file="imgf0006.tif" wi="98" he="173" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="27"> -->
<figure id="f0007" num="7"><img id="if0007" file="imgf0007.tif" wi="104" he="197" img-content="drawing" img-format="tif"/></figure>
</drawings>
<search-report-data id="srep" lang="en" srep-office="EP" date-produced=""><doc-page id="srep0001" file="srep0001.tif" wi="157" he="233" type="tif"/></search-report-data><search-report-data date-produced="20200921" id="srepxml" lang="en" srep-office="EP" srep-type="ep-sr" status="n"><!--
 The search report data in XML is provided for the users' convenience only. It might differ from the search report of the PDF document, which contains the officially published data. The EPO disclaims any liability for incorrect or incomplete data in the XML for search reports.
 -->

<srep-info><file-reference-id>P55511/EP</file-reference-id><application-reference><document-id><country>EP</country><doc-number>20167936.2</doc-number></document-id></application-reference><applicant-name><name>Imec VZW</name></applicant-name><srep-established srep-established="yes"/><srep-invention-title title-approval="yes"/><srep-abstract abs-approval="yes"/><srep-figure-to-publish figinfo="by-applicant"><figure-to-publish><fig-number>1</fig-number></figure-to-publish></srep-figure-to-publish><srep-info-admin><srep-office><addressbook><text>MN</text></addressbook></srep-office><date-search-report-mailed><date>20200929</date></date-search-report-mailed></srep-info-admin></srep-info><srep-for-pub><srep-fields-searched><minimum-documentation><classifications-ipcr><classification-ipcr><text>G06T</text></classification-ipcr><classification-ipcr><text>G01Q</text></classification-ipcr><classification-ipcr><text>G02B</text></classification-ipcr></classifications-ipcr></minimum-documentation></srep-fields-searched><srep-citations><citation id="sr-cit0001"><nplcit id="sr-ncit0001" npl-type="s"><article><author><name>RAHE P ET AL</name></author><atl>Vertical and lateral drift corrections of scanning probe microscopy images</atl><serial><sertitle>JOURNAL OF VACUUM SCIENCE AND TECHNOLOGY: PART B, AVS / AIP, MELVILLE, NEW YORK, NY, US</sertitle><pubdate>20100520</pubdate><vid>28</vid><ino>3</ino><doi>10.1116/1.3360909</doi><issn>1071-1023</issn></serial><location><pp><ppf>C4E31</ppf><ppl>C4E38</ppl></pp></location><refno>XP012144167</refno></article></nplcit><category>A</category><rel-claims>1-15</rel-claims><rel-passage><passage>* abstract *</passage><passage>* page C4E31, paragraph II - page C4E32 *</passage><passage>* page C4E33, paragraph IV - page C4E35 *</passage></rel-passage></citation><citation id="sr-cit0002"><nplcit id="sr-ncit0002" npl-type="s"><article><author><name>ROSTISLAV V LAPSHIN</name></author><atl>Automatic drift elimination in probe microscope images based on techniques of counter-scanning and topography feature recognition; Automatic drift elimination in probe microscope images</atl><serial><sertitle>MEASUREMENT SCIENCE AND TECHNOLOGY, IOP, BRISTOL, GB</sertitle><pubdate>20070301</pubdate><vid>18</vid><ino>3</ino><doi>10.1088/0957-0233/18/3/046</doi><issn>0957-0233</issn></serial><location><pp><ppf>907</ppf><ppl>927</ppl></pp></location><refno>XP020118568</refno></article></nplcit><category>A</category><rel-claims>1-15</rel-claims><rel-passage><passage>* abstract *</passage><passage>* page 908, paragraph 2.1.1 - page 911 *</passage><passage>* page 912, paragraph 2.3 - page 913, paragraph 2.4 *</passage></rel-passage></citation></srep-citations><srep-admin><examiners><primary-examiner><name>Zamuner, Umberto</name></primary-examiner></examiners><srep-office><addressbook><text>Munich</text></addressbook></srep-office><date-search-completed><date>20200921</date></date-search-completed></srep-admin></srep-for-pub></search-report-data>
</ep-patent-document>
