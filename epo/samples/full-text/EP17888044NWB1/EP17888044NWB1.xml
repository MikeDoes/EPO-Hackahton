<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE ep-patent-document PUBLIC "-//EPO//EP PATENT DOCUMENT 1.5.1//EN" "ep-patent-document-v1-5-1.dtd">
<!-- This XML data has been generated under the supervision of the European Patent Office -->
<ep-patent-document id="EP17888044B1" file="EP17888044NWB1.xml" lang="en" country="EP" doc-number="3550263" kind="B1" date-publ="20211006" status="n" dtd-version="ep-patent-document-v1-5-1">
<SDOBI lang="en"><B000><eptags><B001EP>ATBECHDEDKESFRGBGRITLILUNLSEMCPTIESILTLVFIROMKCYALTRBGCZEEHUPLSK..HRIS..MTNORS..SM..................</B001EP><B005EP>J</B005EP><B007EP>BDM Ver 2.0.12 (4th of August) -  2100000/0</B007EP></eptags></B000><B100><B110>3550263</B110><B120><B121>EUROPEAN PATENT SPECIFICATION</B121></B120><B130>B1</B130><B140><date>20211006</date></B140><B190>EP</B190></B100><B200><B210>17888044.9</B210><B220><date>20170706</date></B220><B240><B241><date>20190702</date></B241></B240><B250>zh</B250><B251EP>en</B251EP><B260>en</B260></B200><B300><B310>201611270205</B310><B320><date>20161229</date></B320><B330><ctry>CN</ctry></B330></B300><B400><B405><date>20211006</date><bnum>202140</bnum></B405><B430><date>20191009</date><bnum>201941</bnum></B430><B450><date>20211006</date><bnum>202140</bnum></B450><B452EP><date>20210727</date></B452EP></B400><B500><B510EP><classification-ipcr sequence="1"><text>G01C  21/00        20060101AFI20200704BHEP        </text></classification-ipcr><classification-ipcr sequence="2"><text>G01C  11/06        20060101ALI20200704BHEP        </text></classification-ipcr><classification-ipcr sequence="3"><text>G06K   9/00        20060101ALI20200704BHEP        </text></classification-ipcr><classification-ipcr sequence="4"><text>G06T   7/70        20170101ALI20200704BHEP        </text></classification-ipcr><classification-ipcr sequence="5"><text>G06K   9/32        20060101ALI20200704BHEP        </text></classification-ipcr><classification-ipcr sequence="6"><text>G06T   7/73        20170101ALI20200704BHEP        </text></classification-ipcr></B510EP><B520EP><classifications-cpc><classification-cpc sequence="1"><text>G01C  11/06        20130101 FI20200612BHEP        </text></classification-cpc><classification-cpc sequence="2"><text>G06T2207/30244     20130101 LA20200623BHEP        </text></classification-cpc><classification-cpc sequence="3"><text>G06K2209/21        20130101 LA20200619BHEP        </text></classification-cpc><classification-cpc sequence="4"><text>G06K   9/3233      20130101 LI20200619BHEP        </text></classification-cpc><classification-cpc sequence="5"><text>G06K   9/0063      20130101 LI20200612BHEP        </text></classification-cpc><classification-cpc sequence="6"><text>G06T   7/74        20170101 LI20200623BHEP        </text></classification-cpc></classifications-cpc></B520EP><B540><B541>de</B541><B542>ORTUNGSVERFAHREN UND -VORRICHTUNG</B542><B541>en</B541><B542>LOCATING METHOD AND APPARATUS</B542><B541>fr</B541><B542>PROCÉDÉ ET APPAREIL DE LOCALISATION</B542></B540><B560><B561><text>CN-A- 101 509 782</text></B561><B561><text>CN-A- 101 620 671</text></B561><B561><text>CN-A- 103 914 855</text></B561><B561><text>CN-A- 105 549 060</text></B561><B561><text>CN-A- 105 761 242</text></B561><B561><text>US-A1- 2008 074 639</text></B561><B561><text>US-A1- 2011 122 257</text></B561><B561><text>US-A1- 2014 376 821</text></B561><B565EP><date>20200709</date></B565EP></B560></B500><B700><B720><B721><snm>LIU, Ruopeng</snm><adr><str>Software Building
No. 9 GaoxinZhong 1st Road
High-Tech Industrial Estate
Nanshan District</str><city>Shenzhen, Guangdong 518057</city><ctry>CN</ctry></adr></B721><B721><snm>LUAN, Lin</snm><adr><str>Software Building
No. 9 GaoxinZhong 1st Road
High-Tech Industrial Estate
Nanshan District</str><city>Shenzhen, Guangdong 518057</city><ctry>CN</ctry></adr></B721><B721><snm>XU, Faguo</snm><adr><str>Software Building
No. 9 GaoxinZhong 1st Road
High-Tech Industrial Estate
Nanshan District</str><city>Shenzhen, Guangdong 518057</city><ctry>CN</ctry></adr></B721></B720><B730><B731><snm>Dongguan Frontier Technology Institute</snm><iid>101662478</iid><irf>D11905WOEP</irf><adr><str>Floor 5 Building 1 
Songshan Lake 
Science And Technology Industrial Park</str><city>Dongguan, Guangdong 523000</city><ctry>CN</ctry></adr></B731></B730><B740><B741><snm>Goddar, Heinz J.</snm><iid>100002032</iid><adr><str>Boehmert &amp; Boehmert 
Anwaltspartnerschaft mbB 
Pettenkoferstrasse 22</str><city>80336 München</city><ctry>DE</ctry></adr></B741></B740></B700><B800><B840><ctry>AL</ctry><ctry>AT</ctry><ctry>BE</ctry><ctry>BG</ctry><ctry>CH</ctry><ctry>CY</ctry><ctry>CZ</ctry><ctry>DE</ctry><ctry>DK</ctry><ctry>EE</ctry><ctry>ES</ctry><ctry>FI</ctry><ctry>FR</ctry><ctry>GB</ctry><ctry>GR</ctry><ctry>HR</ctry><ctry>HU</ctry><ctry>IE</ctry><ctry>IS</ctry><ctry>IT</ctry><ctry>LI</ctry><ctry>LT</ctry><ctry>LU</ctry><ctry>LV</ctry><ctry>MC</ctry><ctry>MK</ctry><ctry>MT</ctry><ctry>NL</ctry><ctry>NO</ctry><ctry>PL</ctry><ctry>PT</ctry><ctry>RO</ctry><ctry>RS</ctry><ctry>SE</ctry><ctry>SI</ctry><ctry>SK</ctry><ctry>SM</ctry><ctry>TR</ctry></B840><B860><B861><dnum><anum>CN2017091953</anum></dnum><date>20170706</date></B861><B862>zh</B862></B860><B870><B871><dnum><pnum>WO2018120735</pnum></dnum><date>20180705</date><bnum>201827</bnum></B871></B870></B800></SDOBI>
<description id="desc" lang="en"><!-- EPO <DP n="1"> -->
<heading id="h0001"><b>TECHNICAL FIELD</b></heading>
<p id="p0001" num="0001">The present invention relates to the surveying and mapping field, and in particular, to a positioning method and apparatus.</p>
<heading id="h0002"><b>BACKGROUND</b></heading>
<p id="p0002" num="0002">In the prior art, the positioning of an observation object by a floating platform requires that a high-precision inertial navigation system is fixed on the pan/tilt axis of an optical device to obtain an attitude, and the positioning of the observation object is completed by combining a high-precision ranging device.</p>
<p id="p0003" num="0003">However, the completion of the positioning of the observation object through this solution requires a relatively large hardware cost, and also requires a large hardware upgrade and transformation of the existing platform that has been put into use. Therefore, practicability is relatively low.</p>
<p id="p0004" num="0004">The attitude is obtained by fixing the high-precision inertial navigation system on the stable pan/tilt axis inside the optical device, and the positioning operation is completed by combining the high-precision ranging device.</p>
<p id="p0005" num="0005">In view of the above-mentioned high cost of accurately locating the observation object, no effective solution is currently proposed.</p>
<p id="p0006" num="0006"><patcit id="pcit0001" dnum="US2011122257A1"><text>US 2011/122257 A1</text></patcit> provides related technical solutions for geolocating objects of interest in an area of interest with an imaging system, wherein each point within an area of interest is covered by the field of view of at least two cameras, each camera capturing an image of its field of view and a plurality of calibration points within the area of interest, and a processor calibrates the imaging system by at least associating the coordinates of each of the plurality of calibration points with a calibration pixel corresponding to an image of the calibration point in the image of each of the cameras, and geolocates the object of interest within the area of interest by at least comparing the location an image of the object of interest to the calibration pixels in the images generated by each of the plurality of cameras. However, the above mentioned problem still remains unsolved.</p>
<heading id="h0003"><b>SUMMARY</b></heading>
<p id="p0007" num="0007">Embodiments of the present invention provide a positioning method and apparatus, to at least resolve a technical problem that costs of accurately locating an observation object are high.</p>
<heading id="h0004"><b>BRIEF DESCRIPTION OF DRAWINGS</b></heading>
<p id="p0008" num="0008">The drawings described herein provide further understanding of the present invention, and form a part of this application. Schematic embodiments of the present invention and<!-- EPO <DP n="2"> --><!-- EPO <DP n="3"> --> descriptions thereof are used to explain the present invention but do not constitute an inappropriate limitation on the present invention. In the drawings:
<ul id="ul0001" list-style="none" compact="compact">
<li><figref idref="f0001">FIG. 1</figref> is a flowchart of a positioning method according to an embodiment of the present invention;</li>
<li><figref idref="f0002">FIG. 2</figref> is a flowchart of an optional positioning method according to an embodiment of the present invention; and</li>
<li><figref idref="f0003">FIG. 3</figref> is a schematic diagram of a locating apparatus according to an embodiment of the present invention.</li>
</ul></p>
<heading id="h0005"><b>DESCRIPTION OF EMBODIMENTS</b></heading>
<p id="p0009" num="0009">To make a person skilled in the art better understand solutions of the present invention, the following clearly and completely describes the technical solutions in the embodiments of the present invention with reference to the accompanying drawings in the embodiments of the present invention.</p>
<p id="p0010" num="0010">According to the invention, a positioning<!-- EPO <DP n="4"> --> method as defined in independent claim 1 is provided. It should be noted that steps shown in a flowchart of the drawings may be performed in a computer system of a group of computer executable instructions. In addition, although a logical sequence is shown in the flowchart, in some circumstances, the shown or described steps may be performed in a sequence different from the sequence herein.</p>
<p id="p0011" num="0011"><figref idref="f0001">FIG. 1</figref> is a flowchart of a positioning method according to an embodiment of the present invention. As shown in <figref idref="f0001">FIG. 1</figref>, the positioning method includes the following steps:
<ul id="ul0002" list-style="none" compact="compact">
<li>Step S102: acquiring a first image captured by an optical device; wherein the first image includes an observation object and a plurality of predetermined objects, and the predetermined objects are objects that have known geographic coordinates.</li>
<li>Step S104: selecting a first predetermined object from the predetermined objects based on the first image.</li>
<li>Step S106: acquiring a second image; wherein the first predetermined object is located at a center of the second image.</li>
<li>Step S108: determining a first attitude angle of the optical device based on measurement data obtained by an inertial navigation system and the first predetermined object in the second image.</li>
<li>Step S110: modifying the first attitude angle, based on a positional relationship between the observation object and the first predetermined object in the second image, to obtain a second attitude angle.</li>
<li>Step S112: calculating the geographic coordinate of the observation object based on the second attitude angle.</li>
</ul></p>
<p id="p0012" num="0012">In the above embodiment, the optical device mounted on the floating platform captures an image of the ground observation object, extracts an image, including the observation object and the predetermined objects that have known geographic coordinates, from the captured image; and determines the extracted image as a first image; then selects a predetermined object from the first image, determines the predetermined object as a reference object for accurately positioning the observation object subsequently, and names the reference object as the first predetermined object; then selects a second image from the first image, wherein the first predetermined object is located at the center of the second image; determines a first attitude angle at which the optical device captures the second image, based on known<!-- EPO <DP n="5"> --> coordinates of the first predetermined object and measurement data captured by the inertial navigation system of the floating platform; then modifies the first attitude angle, based on a positional relationship between the observation object and the first predetermined object in the second image, to obtain a second attitude angle; and further calculates geographic coordinates of the observation object based on the modified second attitude angle, such that the floating platform can achieve accurate positioning the observation object based on the optical device of the floating platform, the inertial navigation system of the floating platform, and the predetermined object on the ground, without the need to additionally add a distance measuring module and an attitude measuring module to the floating platform so as to facilitate positioning the observation object, thereby solving the technical problem that costs of accurately positioning the observation object are high in the prior art.</p>
<p id="p0013" num="0013">It should be noted that the inertial navigation system is an autonomous navigation system that does not rely on external information and does not radiate energy to the outside. An estimating navigation manner is used, that is, self position coordinates are calculated based on a position of a known point and its own motion state.</p>
<p id="p0014" num="0014">In an optional embodiment, the step of acquiring a first image captured by an optical device includes: acquiring the first image of a target area captured by the optical device; wherein the target area includes the observation object and the predetermined objects, and a range of the target area is determined according to an angle of field of view of the optical device.</p>
<p id="p0015" num="0015">Optionally, a target area is determined by manually selecting the observation object as a center, and a plurality of predetermined objects are uniformly disposed in the target area, such that the optical device can more easily capture the first image including the observation object and the predetermined objects.</p>
<p id="p0016" num="0016">Optionally, the target area may be determined based on the angle of field of view of the optical device. A range of an adjustable angle of field of view of the optical device and a flying height of the floating platform are obtained in advance. Such that a range of a ground image captured by the floating platform during flight may be determined, and then the target area is determined based on the range.</p>
<p id="p0017" num="0017">It should be noted that, in the current imaging state, the angle of field of view represents<!-- EPO <DP n="6"> --> an image coverage area relative to a field angle of the optical device. For a zoom optical system, the angle of field of view changes only with the adjustment of the local length while ensuring that other optical parameters are unchanged.</p>
<p id="p0018" num="0018">In an optional embodiment, the step of acquiring a first image captured by an optical device includes: detecting whether an image, captured by the optical device, includes the observation object and the predetermined objects; increasing an angle of field of view of the optical device and reacquiring an image captured by the optical device if the image captured by the optical device does not include the observation object and the predetermined objects; or determining that the first image is captured if the image captured by the optical device includes the observation object and the predetermined objects.</p>
<p id="p0019" num="0019">Optionally, the angle of field of view of the optical device is expanded to expand the range of captured images, such that the first image can be obtained without changing the position of the floating platform and the attitude angle of the optical device.</p>
<p id="p0020" num="0020">In an optional embodiment, the step of detecting whether an image captured by the optical device includes the observation object and the predetermined objects includes:<br/>
obtaining a predetermined image database of the observation object and the predetermined objects, the predetermined image database storing features of the observation object and the predetermined objects; detecting whether the image captured by the optical device includes the features of the observation object and the predetermined objects; and determining that the image captured by the optical device includes the observation object and the predetermined objects if it is detected that the image captured by the optical device includes the features of the observation object and the predetermined objects.</p>
<p id="p0021" num="0021">Specifically, the image captured by the optical device may be compared with the image database in which the observation object and the predetermined objects are stored in advance, and the image captured by the optical device including the observation object and the predetermined objects may be determined.</p>
<p id="p0022" num="0022">In an optional embodiment, the step of selecting a first predetermined object from the predetermined objects based on the first image includes: determining distances between the observation object and the predetermined objects in the first image; and determining the predetermined object, having the shortest distance from the observation object, as the first<!-- EPO <DP n="7"> --> predetermined object. Coordinates of the predetermined object closest to the observation object are obtained and used as parameters of subsequent operation, so as to facilitate operation.</p>
<p id="p0023" num="0023">According to the invention, the step of determining a first attitude angle of the optical device based on measurement data captured by an inertial navigation system and the first predetermined object in the second image includes: calculating, by using a first formula, the first attitude angle of the optical device based on measurement data captured by an inertial navigation system and the first predetermined object in the second image, where the first formula is <maths id="math0001" num=""><math display="inline"><mi>A</mi><mfenced open="[" close="]"><mtable><mtr><mtd><mrow><mi>cos</mi><mi>α</mi><mi>cos</mi><mi>β</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>sin</mi><mi>α</mi><mi>cos</mi><mi>β</mi></mrow></mtd></mtr><mtr><mtd><mrow><mo>−</mo><mi>sin</mi><mi>β</mi></mrow></mtd></mtr></mtable></mfenced><mo>=</mo><mi>B</mi><mfenced open="[" close="]"><mtable><mtr><mtd><mrow><mi>N</mi><mspace width="1ex"/><mi>cos</mi><mspace width="1ex"/><mi>c</mi><mspace width="1ex"/><mi>cos</mi><mspace width="1ex"/><mi>d</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>N</mi><mspace width="1ex"/><mi>cos</mi><mspace width="1ex"/><mi>c</mi><mspace width="1ex"/><mi>sin</mi><mspace width="1ex"/><mi>d</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>N</mi><mfenced separators=""><mn>1</mn><mo>−</mo><msup><mi>e</mi><mn>2</mn></msup></mfenced><mi>sin</mi><mspace width="1ex"/><mi>c</mi></mrow></mtd></mtr></mtable></mfenced></math><img id="ib0001" file="imgb0001.tif" wi="62" he="21" img-content="math" img-format="tif" inline="yes"/></maths>, where <i>A</i> and <i>B</i> represent preset rotation matrices that are determined based on the measurement data captured by the inertial navigation system; <i>c</i> and <i>d</i> are geographic coordinates of the center location of the second image, <i>c</i> represents a longitude coordinate, and <i>d</i> represents a latitude coordinate; <i>α</i> and <i>β</i> are first attitude angles at which the optical device captures the second image, <i>α</i> is an azimuth angle, and <i>β</i> is a pitch angle; and <maths id="math0002" num=""><math display="inline"><mi>e</mi><mo>=</mo><mfrac><msqrt><mrow><msup><mi>a</mi><mn>2</mn></msup><mo>−</mo><msup><mi>b</mi><mn>2</mn></msup></mrow></msqrt><mi>a</mi></mfrac></math><img id="ib0002" file="imgb0002.tif" wi="26" he="15" img-content="math" img-format="tif" inline="yes"/></maths> and <maths id="math0003" num=""><math display="inline"><mi>N</mi><mo>=</mo><mfrac><mi>a</mi><msqrt><mfenced separators=""><mn>1</mn><mo>−</mo><msup><mi>e</mi><mn>2</mn></msup><mo>×</mo><msup><mi>sin</mi><mn>2</mn></msup><mi>d</mi></mfenced></msqrt></mfrac></math><img id="ib0003" file="imgb0003.tif" wi="39" he="16" img-content="math" img-format="tif" inline="yes"/></maths>, where <i>a</i> represents the longest radius of the earth, and <i>b</i> represents the shortest radius of the earth.</p>
<p id="p0024" num="0024">It should be noted that <i>a</i> represents the longest radius of the earth and <i>a</i> = 6378137<i>m</i>, and <i>b</i> represents the shortest radius of the earth and <i>b</i> = 6356752.3142<i>m</i>.</p>
<p id="p0025" num="0025">Specifically, based on geographic coordinates of the first predetermined object in the second image and the measurement data captured by the inertial navigation system of the floating platform, the first attitude angle at which the optical device captures the second image may be calculated by using the first formula, and data of the first attitude angle may be used in a subsequent calculation process. A correspondence between an attitude angle at which the optical device captures the second image and the geographic coordinates of the center location of the second image is established based on the first formula. The first attitude<!-- EPO <DP n="8"> --> angle of the second image may be obtained by calculating based on the known geographic coordinates of the center location of the second image.</p>
<p id="p0026" num="0026">It should be noted that an image capturing direction of the optical device may be represented by a directional line of a direction from the optical device to an image capturing center. The optical device may rotate around a fixed point in an image capturing process. A rotation direction includes both a horizontal direction and a vertical direction. To accurately express the image capturing direction of the optical device, a concept of an attitude angle is used. The attitude angle includes an azimuth angle and a pitch angle. The azimuth angle represents a horizontal included angle between the directional line of the optical device and a north direction, and the azimuth angle increases as the directional line rotates clockwise around the fixed point. The pitch angle represents an included angle between the directional line of the optical device and a horizontal direction. If the directional line is above the horizontal direction, the pitch angle is positive; or if the directional line is under the horizontal direction, the pitch angle is negative.</p>
<p id="p0027" num="0027">In an optional embodiment, the step of modifying the first attitude angle, based on a positional relationship between the observation object and the first predetermined object in the second image, to obtain a second attitude angle includes: modifying, by using a second formula, the first attitude angle based on the positional relationship between the observation object and the first predetermined object in the second image, to obtain the second attitude angle, where the second formula is <maths id="math0004" num=""><math display="inline"><mi mathvariant="normal">Δ</mi><mi>β</mi><mo>=</mo><mrow><mo>{</mo><mtable><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>h</mi><mo>−</mo><mn>540</mn></mfenced><mn>1080</mn></mfrac><mi>ξ</mi><mo>⋯</mo><mi>h</mi><mo>&lt;</mo><mn>540</mn></mrow></mtd></mtr><mtr><mtd><mrow><mn>0</mn><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mi>h</mi><mo>=</mo><mn>540</mn><mi mathvariant="italic">or</mi><mn>541</mn></mrow></mtd></mtr><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>h</mi><mo>−</mo><mn>541</mn></mfenced><mn>1080</mn></mfrac><mi>ξ</mi><mo>⋯</mo><mi>h</mi><mo>&gt;</mo><mn>541</mn></mrow></mtd></mtr></mtable></mrow></math><img id="ib0004" file="imgb0004.tif" wi="62" he="33" img-content="math" img-format="tif" inline="yes"/></maths> and <maths id="math0005" num=""><math display="inline"><mi mathvariant="normal">Δ</mi><mi>α</mi><mo>=</mo><mrow><mo>{</mo><mtable><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>l</mi><mo>−</mo><mn>960</mn></mfenced><mn>1920</mn></mfrac><mi>ω</mi><mo>⋯</mo><mi>l</mi><mo>&lt;</mo><mn>960</mn></mrow></mtd></mtr><mtr><mtd><mrow><mn>0</mn><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mi>l</mi><mo>=</mo><mn>960</mn><mi mathvariant="italic">or</mi><mn>961</mn></mrow></mtd></mtr><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>l</mi><mo>−</mo><mn>961</mn></mfenced><mn>1920</mn></mfrac><mi>ω</mi><mo>⋯</mo><mi>l</mi><mo>&gt;</mo><mn>961</mn></mrow></mtd></mtr></mtable></mrow></math><img id="ib0005" file="imgb0005.tif" wi="58" he="34" img-content="math" img-format="tif" inline="yes"/></maths>, where <i>h</i> is a row number of pixels of the observation object in the second image, and <i>l</i> is a column number of pixels of the observation object in the second image; <i>α</i> and <i>β</i> are first attitude angles at which the optical device captures the<!-- EPO <DP n="9"> --> second image, <i>α</i> is an azimuth angle, and <i>β</i> is a pitch angle; Δ<i>β</i> is a modified value of the pitch angle, and Δ<i>α</i> is a modified value of the azimuth angle; <i>ξ</i> and <i>ω</i> are angles of field of view of the optical device that captures the second image, <i>ξ</i> represents the angle of field of view of the optical device in a vertical direction, and <i>ω</i> represents the angle of field of view of the optical device in a horizontal direction; and <i>β'</i> = <i>β -</i> Δ<i>β</i> is a modified pitch angle, <i>α'</i> = <i>α</i> + Δ<i>α</i> is a modified azimuth angle, and the second attitude angle includes the modified pitch angle and the modified azimuth angle.</p>
<p id="p0028" num="0028">Specifically, the positional relationship between the observation object and the first predetermined object in the second image is determined based on the second image. Then the first attitude angle is modified by using the second formula and based on the known first attitude angle for capturing the second image and the positional relationship between the first predetermined object and the observation object in the second image, to obtain the second attitude angle. The second attitude angle represents an attitude angle at which the optical device captures the observation object when the observation object is in the center location of the image.</p>
<p id="p0029" num="0029">It should be noted that the second image captured by the optical device is a rectangular image. A vertical distance of the rectangular image is related to <i>ξ</i>, that is, <i>ξ</i> represents an angle of field of view of the optical device in a vertical direction. A horizontal distance of the rectangular image is related to <i>ω</i>, that is, <i>ω</i> represents an angle of field of view of the optical device in a horizontal direction.</p>
<p id="p0030" num="0030">Optionally, based on a location of a object in a known image, an attitude angle of the optical device for capturing the object when the object is in a center location of the image may be calculated by using the second formula. That is, when the first predetermined object is not in a center of an image captured by the optical device, an attitude angle of the optical device for capturing a first object when the first object is in a center location of the image, namely, the first attitude angle, may be calculated by using the second formula.</p>
<p id="p0031" num="0031">It should be noted that, before the first attitude angle is calculated by using the second formula, a third image in which the first predetermined object is in a center location is first<!-- EPO <DP n="10"> --> captured, where the third image is an image in which the first predetermined object is located in the image center. Then the first attitude angle for acquiring the second image is calculated by using the first calculation formula, and while the first attitude angle remains unchanged, the first image including the first predetermined object and the observation object is captured. Then an attitude angle under an assumption that the first predetermined object is located in a center of a current image, namely, an assumptive attitude, is calculated by using the second formula. The original first attitude angle is updated by using the assumptive attitude angle, and the assumptive attitude angle is used as a first attitude angle for subsequent calculation.</p>
<p id="p0032" num="0032">In an optional embodiment, the calculating geographic coordinates of the observation object based on the second attitude angle includes: calculating the geographic coordinates of the observation object based on the second attitude angle by using the first formula.</p>
<p id="p0033" num="0033">Specifically, the geographic coordinates of the observation object are calculated based on the known second attitude angle and by using the first formula that can represent a correspondence between the geographic coordinates of the observation object and the second attitude angle.</p>
<p id="p0034" num="0034"><figref idref="f0002">FIG. 2</figref> is a flowchart of an alternative positioning method according to an embodiment of the present invention. As shown in <figref idref="f0002">FIG. 2</figref>, the method includes the following steps:<br/>
Step S202: obtaining a first image.</p>
<p id="p0035" num="0035">An optical device of a floating platform captures an image of an observation ground; compares the captured image with an image database that stores an image including an observation object and a predetermined object; determines whether the captured image includes the observation object that needs to be located and the predetermined object; and if the captured image includes the observation object and the predetermined object, determines that the image captured by the optical device is the first image; or if the captured image does not include the observation object and the predetermined object, stores a current attitude of the optical device, enlarges an angle of field of view, and re-captures an image of the observation ground, until a captured image includes the observation object and the predetermined object.</p>
<p id="p0036" num="0036">The angle of field of view is an angle of an image coverage area relative to a camera in a current imaging status. For a zoom optical system of the optical device, if it is ensured that<!-- EPO <DP n="11"> --> other optical parameters remain unchanged, an angle of field of view of the system changes only with adjustment of a local length.</p>
<p id="p0037" num="0037">It should be noted that the predetermined object is a reference point with known geographic coordinates that is disposed near the observation object. In the floating platform, the predetermined object of the image is used as a reference point, to improve accuracy of locating the observation object.</p>
<p id="p0038" num="0038">Optionally, to improve convenience of capturing, by the optical device of the floating platform, the first image including the observation object and the predetermined object, a plurality of predetermined objects may be disposed in a target area near the observation object. The target area is an area in a regular shape that is centered around the observation object. A range of the target area may be determined based on an angle of field of view of the optical device of the floating platform for capturing the first image. If the angle of field of view of the optical device is large, a target area with a relatively large range is determined; or if the angle of field of view of the optical device is small, a target area with a relatively small range is determined. In addition, the predetermined objects disposed in the target area may be evenly arranged in the target area.</p>
<p id="p0039" num="0039">Optionally, to improve convenience of identifying the predetermined object in the first image, the predetermined object may be disposed in open space or higher ground in the target area, so that the predetermined object is not covered and can be easily identified.</p>
<p id="p0040" num="0040">Step S204: extracting a first predetermined object from the first image.</p>
<p id="p0041" num="0041">A predetermined object is selected from the first image as the first predetermined object. In addition, a pixel location of the first predetermined object in the first image is determined, to provide reference data for accurately locating the observation object subsequently.</p>
<p id="p0042" num="0042">Optionally, the first image includes the observation object and the predetermined object. There may be one or more predetermined objects. If there is one predetermined object in the first image, it is determined that the predetermined object is the first predetermined object; or if there are a plurality of predetermined objects in the first image, one of the predetermined objects may be selected as the first predetermined object.</p>
<p id="p0043" num="0043">In an optional embodiment, a predetermined object closest to the observation object may<!-- EPO <DP n="12"> --> be selected as the first predetermined object.</p>
<p id="p0044" num="0044">Optionally, distances between the observation object and the predetermined objects in the first image may be measured, and the predetermined object closest to the observation object is selected as the first predetermined object.</p>
<p id="p0045" num="0045">Step S206: obtaining a second image.</p>
<p id="p0046" num="0046">When the first predetermined object is determined, the optical device re-obtains a first image in which the first predetermined object is located in an image center, and uses the re-obtained image as the second image.</p>
<p id="p0047" num="0047">Step S208: determining a first attitude angle of an optical device.</p>
<p id="p0048" num="0048">An accurate conversion matrix, namely, a first formula, is established based on a coordinate conversion principle and measurement data captured by an inertial navigation system of the floating platform. The first formula represents an attitude angle of the optical device for capturing the second image, namely, a correspondence between the first attitude angle and geographic coordinates of a center location of the second image. The first attitude angle may be determined based on the geographic coordinates of the center location of the second image.</p>
<p id="p0049" num="0049">According to the invention, the first formula is <maths id="math0006" num=""><math display="inline"><mi>A</mi><mfenced open="[" close="]"><mtable><mtr><mtd><mrow><mi>cos</mi><mi>α</mi><mi>cos</mi><mi>β</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>sin</mi><mi>α</mi><mi>cos</mi><mi>β</mi></mrow></mtd></mtr><mtr><mtd><mrow><mo>−</mo><mi>sin</mi><mi>β</mi></mrow></mtd></mtr></mtable></mfenced><mo>=</mo><mi>B</mi><mfenced open="[" close="]"><mtable><mtr><mtd><mrow><mi>N</mi><mspace width="1ex"/><mi>cos</mi><mspace width="1ex"/><mi>c</mi><mspace width="1ex"/><mi>cos</mi><mspace width="1ex"/><mi>d</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>N</mi><mspace width="1ex"/><mi>cos</mi><mspace width="1ex"/><mi>c</mi><mspace width="1ex"/><mi>sin</mi><mspace width="1ex"/><mi>d</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>N</mi><mfenced separators=""><mn>1</mn><mo>−</mo><msup><mi>e</mi><mn>2</mn></msup></mfenced><mi>sin</mi><mspace width="1ex"/><mi>c</mi></mrow></mtd></mtr></mtable></mfenced></math><img id="ib0006" file="imgb0006.tif" wi="62" he="23" img-content="math" img-format="tif" inline="yes"/></maths>. In the formula, <i>A</i> and <i>B</i> are preset rotation matrices, where the rotation matrices are determined based on the measurement data captured by the inertial navigation system of the floating platform; <i>c</i> and <i>d</i> are the geographic coordinates of the center location of the second image, <i>c</i> represents a longitude coordinate, and <i>d</i> represents a latitude coordinate; <i>α</i> and <i>β</i> are first attitude angles of the optical device for capturing the second image, <i>α</i> is an azimuth angle, and <i>β</i> is a pitch angle; <i>e</i> is calculated by using a formula <maths id="math0007" num=""><math display="inline"><mi>e</mi><mo>=</mo><mfrac><msqrt><mrow><msup><mi>a</mi><mn>2</mn></msup><mo>−</mo><msup><mi>b</mi><mn>2</mn></msup></mrow></msqrt><mi>a</mi></mfrac></math><img id="ib0007" file="imgb0007.tif" wi="25" he="16" img-content="math" img-format="tif" inline="yes"/></maths>; <i>N</i> is calculated by using a formula <maths id="math0008" num=""><math display="inline"><mi>N</mi><mo>=</mo><mfrac><mi>a</mi><msqrt><mfenced separators=""><mn>1</mn><mo>−</mo><msup><mi>e</mi><mn>2</mn></msup><mo>×</mo><msup><mi>sin</mi><mn>2</mn></msup><mi>d</mi></mfenced></msqrt></mfrac></math><img id="ib0008" file="imgb0008.tif" wi="39" he="15" img-content="math" img-format="tif" inline="yes"/></maths>; <i>a</i> represents the longest radius of the earth and <i>a</i> = 6378137<i>m</i>; and<!-- EPO <DP n="13"> --> <i>b</i> represents the shortest radius of the earth and <i>b</i> = 6356752.3142<i>m</i>.</p>
<p id="p0050" num="0050">Step S210: obtaining a modified second attitude angle of the optical device.</p>
<p id="p0051" num="0051">Based on a positional relationship between the observation object and the first predetermined object, an attitude angle under an assumption that the observation object is located in the center of the second image is calculated by using a second formula, that is, the second attitude angle is obtained.</p>
<p id="p0052" num="0052">Optionally, the second formula may be <maths id="math0009" num=""><math display="inline"><mi mathvariant="normal">Δ</mi><mi>β</mi><mo>=</mo><mrow><mo>{</mo><mtable><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>h</mi><mo>−</mo><mn>540</mn></mfenced><mn>1080</mn></mfrac><mi>ξ</mi><mo>⋯</mo><mi>h</mi><mo>&lt;</mo><mn>540</mn></mrow></mtd></mtr><mtr><mtd><mrow><mn>0</mn><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mi>h</mi><mo>=</mo><mn>540</mn><mi mathvariant="italic">or</mi><mn>541</mn></mrow></mtd></mtr><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>h</mi><mo>−</mo><mn>541</mn></mfenced><mn>1080</mn></mfrac><mi>ξ</mi><mo>⋯</mo><mi>h</mi><mo>&gt;</mo><mn>541</mn></mrow></mtd></mtr></mtable></mrow></math><img id="ib0009" file="imgb0009.tif" wi="60" he="33" img-content="math" img-format="tif" inline="yes"/></maths> and <maths id="math0010" num=""><math display="inline"><mi mathvariant="normal">Δ</mi><mi>α</mi><mo>=</mo><mrow><mo>{</mo><mtable><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>l</mi><mo>−</mo><mn>960</mn></mfenced><mn>1920</mn></mfrac><mi>ω</mi><mo>⋯</mo><mi>l</mi><mo>&lt;</mo><mn>960</mn></mrow></mtd></mtr><mtr><mtd><mrow><mn>0</mn><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mi>l</mi><mo>=</mo><mn>960</mn><mi mathvariant="italic">or</mi><mn>961</mn></mrow></mtd></mtr><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>l</mi><mo>−</mo><mn>961</mn></mfenced><mn>1920</mn></mfrac><mi>ω</mi><mo>⋯</mo><mi>l</mi><mo>&gt;</mo><mn>961</mn></mrow></mtd></mtr></mtable></mrow></math><img id="ib0010" file="imgb0010.tif" wi="58" he="32" img-content="math" img-format="tif" inline="yes"/></maths>. Because the first predetermined object is located in the center of the second image, the observation object may be modified based on the center location of the second image. <i>h</i> is a row number of a pixel of the observation object in the second image, and <i>l</i> is a column number of the pixel of the observation object in the second image. A pixel format of the captured second image is 1920×1080. <i>ξ</i> and <i>ω</i> are angles of field of view of the optical device for capturing the second image, <i>ξ</i> represents an angle of field of view of the optical device in a vertical direction, and <i>ω</i> represents an angle of field of view of the optical device in a horizontal direction. <i>α</i> and <i>β</i> are first attitude angles of the optical device for capturing the second image, <i>α</i> is an azimuth angle, and <i>β</i> is a pitch angle. <i>β'</i> = <i>β</i> - Δ<i>β</i> is a modified pitch angle, <i>α'</i> = <i>α</i> + Δ<i>α</i> is a modified azimuth angle, and the second attitude angle includes the modified pitch angle and the modified azimuth angle.</p>
<p id="p0053" num="0053">Step S212: determining geographic coordinates of an observation object.</p>
<p id="p0054" num="0054">The modified second attitude angle is substituted into the first formula, and it is<!-- EPO <DP n="14"> --> determined that the geographic coordinates of the center of the second image are the geographic coordinates of the observation object.</p>
<p id="p0055" num="0055">In the foregoing embodiment, the optical device carried on the floating platform performs ground monitoring. The geographic coordinates of the observation object can be determined during detection. In addition, precision of the determined geographic coordinates of the observation object is high. This can improve functions of the floating platform in actual application. Therefore, when there is no ranging module or precise attitude determination module on an optical platform, locating precision of an observation object can be effectively improved by using an existing optical device and inertial navigation system and limited ground control points, and locating costs are also reduced.</p>
<p id="p0056" num="0056">According to the invention, a positioning apparatus as defined in independent claim 7 is provided.</p>
<p id="p0057" num="0057"><figref idref="f0003">FIG. 3</figref> is a schematic diagram of a positioning apparatus according to an embodiment of the present invention. As shown in <figref idref="f0003">FIG. 3</figref>, the positioning apparatus includes: a first acquiring unit 31, configured to acquire a first image captured by an optical device; wherein the first image includes an observation object and a plurality of predetermined objects, and the predetermined objects are objects having known geographic coordinates; a first selection unit 33, configured to select a first predetermined object from the predetermined objects based on the first image; a second acquiring unit 35, acquire a second image, wherein the first predetermined object is located at a center of the second image; a first arithmetic unit 37, configured to determine a first attitude angle of the optical device based on measurement data captured by an inertial navigation system and the first predetermined object in the second image; a second arithmetic unit 39, configured to modify the first attitude angle, based on a positional relationship between the observation object and the first predetermined object in the second image, to obtain a second attitude angle; and a third arithmetic unit 41, configured to calculate the geographic coordinate of the observation object based on the second attitude angle.</p>
<p id="p0058" num="0058">In the above embodiment, the optical device mounted on the floating platform captures an image of the ground observation object, extracts an image, including the observation object and the predetermined objects that have known geographic coordinates, from the captured image; and determines the extracted image as a first image; then selects a predetermined object from the first image, determines the predetermined object as a reference object for<!-- EPO <DP n="15"> --> accurately positioning the observation object subsequently, and names the reference object as the first predetermined object; then selects a second image from the first image, wherein the first predetermined object is located at the center of the second image; determines a first attitude angle at which the optical device captures the second image, based on known coordinates of the first predetermined object and measurement data captured by the inertial navigation system of the floating platform; then modifies the first attitude angle, based on a positional relationship between the observation object and the first predetermined object in the second image, to obtain a second attitude angle; and further calculates geographic coordinates of the observation object based on the modified second attitude angle, such that the floating platform can achieve accurate positioning the observation object based on the optical device of the floating platform, the inertial navigation system of the floating platform, and the predetermined object on the ground, without the need to additionally add a distance measuring module and an attitude measuring module to the floating platform so as to facilitate positioning the observation object, thereby solving the technical problem that costs of accurately positioning the observation object are high in the prior art.</p>
<p id="p0059" num="0059">In an optional embodiment, the first acquiring unit includes a first acquiring module, configured to acquire the first image of a target area captured by the optical device; wherein the target area includes the observation object and the predetermined objects, and a range of the target area is determined according to an angle of field of view of the optical device.</p>
<p id="p0060" num="0060">In an optional embodiment, the first acquiring unit includes: a detection module, configured to detect whether an image captured by the optical device includes the observation object and the predetermined objects; a first detection sub-module, configured to increase an angle of field of view of the optical device and reacquire an image captured by the optical device if the image captured by the optical device does not include the observation object and the predetermined objects; and a second detection sub-module, configured to determine that the first image is captured if the image captured by the optical device includes the observation object and the predetermined objects.</p>
<p id="p0061" num="0061">In an optional embodiment, the detection module includes: a second acquiring module, configured to obtain a predetermined image database of the observation object and the predetermined objects, wherein the predetermined image database stores features of the<!-- EPO <DP n="16"> --> observation object and the predetermined objects; a second detection module, configured to detect whether the image captured by the optical device includes the features of the observation object and the predetermined objects; and a third detection sub-module, configured to determine that the image captured by the optical device includes the observation object and the predetermined objects if it is detected that the image captured by the optical device includes the features of the observation object and the predetermined objects.</p>
<p id="p0062" num="0062">In an optional embodiment, the first selection unit is specifically configured to: determine distances between the observation object and the predetermined objects in the first image; and determine a predetermined object, having the shortest distance from the observation object, as the first predetermined object.</p>
<p id="p0063" num="0063">According to the invention, the first arithmetic unit is specifically configured to: calculate, by using a first formula, the first attitude angle of the optical device based on measurement data captured by an inertial navigation system and the first predetermined object in the second image, where the first formula is <maths id="math0011" num=""><math display="inline"><mi>A</mi><mfenced open="[" close="]"><mtable><mtr><mtd><mrow><mi>cos</mi><mi>α</mi><mi>cos</mi><mi>β</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>sin</mi><mi>α</mi><mi>cos</mi><mi>β</mi></mrow></mtd></mtr><mtr><mtd><mrow><mo>−</mo><mi>sin</mi><mi>β</mi></mrow></mtd></mtr></mtable></mfenced><mo>=</mo><mi>B</mi><mfenced open="[" close="]"><mtable><mtr><mtd><mrow><mi>N</mi><mspace width="1ex"/><mi>cos</mi><mspace width="1ex"/><mi>c</mi><mspace width="1ex"/><mi>cos</mi><mspace width="1ex"/><mi>d</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>N</mi><mspace width="1ex"/><mi>cos</mi><mspace width="1ex"/><mi>c</mi><mspace width="1ex"/><mi>sin</mi><mspace width="1ex"/><mi>d</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>N</mi><mfenced separators=""><mn>1</mn><mo>−</mo><msup><mi>e</mi><mn>2</mn></msup></mfenced><mi>sin</mi><mspace width="1ex"/><mi>c</mi></mrow></mtd></mtr></mtable></mfenced></math><img id="ib0011" file="imgb0011.tif" wi="62" he="21" img-content="math" img-format="tif" inline="yes"/></maths>, where <i>A</i> and <i>B</i> represent preset rotation matrices and are determined based on the measurement data captured by the inertial navigation system; <i>c</i> and <i>d</i> are geographic coordinates of the center location of the second image, <i>c</i> represents a longitude coordinate, and <i>d</i> represents a latitude coordinate; <i>α</i> and <i>β</i> are first attitude angles at which the optical device captures the second image, <i>α</i> is an azimuth angle, and <i>β</i> is a pitch angle; and <maths id="math0012" num=""><math display="inline"><mi>e</mi><mo>=</mo><mfrac><msqrt><mrow><msup><mi>a</mi><mn>2</mn></msup><mo>−</mo><msup><mi>b</mi><mn>2</mn></msup></mrow></msqrt><mi>a</mi></mfrac></math><img id="ib0012" file="imgb0012.tif" wi="25" he="15" img-content="math" img-format="tif" inline="yes"/></maths> and <maths id="math0013" num=""><math display="inline"><mi>N</mi><mo>=</mo><mfrac><mi>a</mi><msqrt><mfenced separators=""><mn>1</mn><mo>−</mo><msup><mi>e</mi><mn>2</mn></msup><mo>×</mo><msup><mi>sin</mi><mn>2</mn></msup><mi>d</mi></mfenced></msqrt></mfrac></math><img id="ib0013" file="imgb0013.tif" wi="40" he="15" img-content="math" img-format="tif" inline="yes"/></maths>, where <i>a</i> represents the longest radius of the earth, and <i>b</i> represents the shortest radius of the earth.</p>
<p id="p0064" num="0064">In an optional embodiment, the second arithmetic unit is specifically configured to modify, by using a second formula, the first attitude angle based on the positional relationship between the observation object and the first predetermined object in the second image, to obtain the second attitude angle, where the second formula is<!-- EPO <DP n="17"> --> <maths id="math0014" num=""><math display="inline"><mi mathvariant="normal">Δ</mi><mi>β</mi><mo>=</mo><mrow><mo>{</mo><mtable><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>h</mi><mo>−</mo><mn>540</mn></mfenced><mn>1080</mn></mfrac><mi>ξ</mi><mo>⋯</mo><mi>h</mi><mo>&lt;</mo><mn>540</mn></mrow></mtd></mtr><mtr><mtd><mrow><mn>0</mn><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mi>h</mi><mo>=</mo><mn>540</mn><mi mathvariant="italic">or</mi><mn>541</mn></mrow></mtd></mtr><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>h</mi><mo>−</mo><mn>541</mn></mfenced><mn>1080</mn></mfrac><mi>ξ</mi><mo>⋯</mo><mi>h</mi><mo>&gt;</mo><mn>541</mn></mrow></mtd></mtr></mtable></mrow></math><img id="ib0014" file="imgb0014.tif" wi="61" he="32" img-content="math" img-format="tif" inline="yes"/></maths> and <maths id="math0015" num=""><math display="inline"><mi mathvariant="normal">Δ</mi><mi>α</mi><mo>=</mo><mrow><mo>{</mo><mtable><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>l</mi><mo>−</mo><mn>960</mn></mfenced><mn>1920</mn></mfrac><mi>ω</mi><mo>⋯</mo><mi>l</mi><mo>&lt;</mo><mn>960</mn></mrow></mtd></mtr><mtr><mtd><mrow><mn>0</mn><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mi>l</mi><mo>=</mo><mn>960</mn><mi mathvariant="italic">or</mi><mn>961</mn></mrow></mtd></mtr><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>l</mi><mo>−</mo><mn>961</mn></mfenced><mn>1920</mn></mfrac><mi>ω</mi><mo>⋯</mo><mi>l</mi><mo>&gt;</mo><mn>961</mn></mrow></mtd></mtr></mtable></mrow></math><img id="ib0015" file="imgb0015.tif" wi="58" he="33" img-content="math" img-format="tif" inline="yes"/></maths>; where <i>h</i> is a row number of pixels of the observation object in the second image, and <i>l</i> is a column number of pixels of the observation object in the second image; <i>α</i> and <i>β</i> are first attitude angles at which the optical device captures the second image, <i>α</i> is an azimuth angle, and <i>β</i> is a pitch angle; Δ<i>β</i> is a modified value of the pitch angle, and Δ<i>α</i> is a modified value of the azimuth angle; <i>ξ</i> and <i>ω</i> are angles of field of view of the optical device that captures the second image, <i>ξ</i> represents the angle of field of view of the optical device in a vertical direction, and <i>ω</i> represents the angle of field of view of the optical device in a horizontal direction; and <i>β'</i> = <i>β</i> - Δ<i>β</i> is a modified pitch angle, <i>α'</i> = <i>α</i> + Δ<i>α</i> is a modified azimuth angle, and the second attitude angle includes the modified pitch angle and the modified azimuth angle.</p>
<p id="p0065" num="0065">Sequence numbers of the foregoing embodiments of the present invention are merely used for description, and do not represent superiority or inferiority of the embodiments.</p>
<p id="p0066" num="0066">In the foregoing embodiments of the present invention, descriptions of the embodiments have respective emphases. For a part not described in detail in an embodiment, reference may be made to related descriptions in another embodiment.</p>
<p id="p0067" num="0067">In the several embodiments provided in this application, it should be understood that the disclosed technical content may be implemented in other manners. The described apparatus embodiments are merely examples. For example, the unit division is merely logical function division and may be other division in actual implementation. For example, a plurality of units or components may be combined or integrated into another system.</p>
<p id="p0068" num="0068">In addition, the shown or discussed mutual couplings or direct couplings or communication connections may be implemented by using some interfaces. The indirect couplings or communication connections between the units or modules may be<!-- EPO <DP n="18"> --> implemented in electrical or other forms.</p>
<p id="p0069" num="0069">The units described as separate parts may or may not be physically separated, and parts shown as units may or may not be physical units, may be located in one position, or may be distributed on a plurality of units. Some or all of the units may be selected according to actual requirements to achieve the objectives of the solutions of the embodiments.</p>
<p id="p0070" num="0070">In addition, functional units in the embodiments of the present invention may be integrated into one processing unit, or each of the units may exist alone physically, or two or more units are integrated into one unit. The integrated unit may be implemented in a form of hardware, or may be implemented in a form of a software functional unit.</p>
<p id="p0071" num="0071">When the integrated unit is implemented in the form of a software functional unit and sold or used as an independent product, the integrated unit may be stored in a computer-readable storage medium. Based on such an understanding, the technical solutions of the present invention essentially, or the part contributing to the prior art, or all or some of the technical solutions may be implemented in the form of a software product. The computer software product is stored in a storage medium and includes several instructions for instructing a computer device (which may be a personal computer, a server, a network device, or the like) to perform all or some of the steps of the methods described in the embodiments of the present invention. The foregoing storage medium includes any medium that can store program code, such as a USB flash drive, a read-only memory (ROM, Read-Only Memory), a random access memory (RAM, Random Access Memory), a removable hard disk, a magnetic disk, or an optical disc.</p>
<p id="p0072" num="0072">The foregoing descriptions are merely preferred implementations of the present invention. It should be noted that, improvements and modifications may be further made by a person of ordinary skill in the art without departing from the scope of the present invention, as defined in the appended claims.</p>
</description>
<claims id="claims01" lang="en"><!-- EPO <DP n="19"> -->
<claim id="c-en-01-0001" num="0001">
<claim-text>A positioning method, comprising:
<claim-text>acquiring (S102) a first image captured by an optical device; the first image comprising images of a ground observation object and a plurality of predetermined objects, and the predetermined objects having known geographic coordinates;</claim-text>
<claim-text>selecting (S104) a first predetermined object from the predetermined objects based on the first image;</claim-text>
<claim-text>acquiring (S106) a second image; the first predetermined object being located at the center of the second image;</claim-text>
<claim-text>determining (S108) a first attitude angle of the optical device based on measurement data obtained by an inertial navigation system and the first predetermined object in the second image;</claim-text>
<claim-text>modifying (S110) the first attitude angle, based on a position relationship between the ground observation object and the first predetermined object in the second image, to obtain a second attitude angle that is based on the first attitude angle and a modified value of the first attitude angle;</claim-text>
<claim-text>calculating (S112) a geographic coordinate of the ground observation object based on the second attitude angle, wherein the geographic coordinate comprises a longitude coordinate and a latitude coordinate;</claim-text>
<claim-text>wherein the step of determining a first attitude angle of the optical device based on measurement data obtained by an inertial navigation system and the first predetermined object in the second image comprises:
<claim-text>calculating the first attitude angle of the optical device, based on the measurement data obtained by the inertial navigation system and the first predetermined object in the second image, by using a first formula; wherein the first formula is <maths id="math0016" num=""><math display="block"><mi>A</mi><mfenced open="[" close="]"><mtable columnalign="left"><mtr><mtd><mrow><mi>cos</mi><mi mathvariant="normal"> </mi><mi>α</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>β</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>sin</mi><mi mathvariant="normal"> </mi><mi>α</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>β</mi></mrow></mtd></mtr><mtr><mtd><mrow><mo>−</mo><mi>sin</mi><mi mathvariant="normal"> </mi><mi>β</mi></mrow></mtd></mtr></mtable></mfenced><mo>=</mo><mi>B</mi><mfenced open="[" close="]"><mtable columnalign="left"><mtr><mtd><mrow><mi>N</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>c</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>d</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>N</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>c</mi><mi mathvariant="normal"> </mi><mi>sin</mi><mi mathvariant="normal"> </mi><mi>d</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>N</mi><mfenced separators=""><mn>1</mn><mo>−</mo><msup><mi>e</mi><mn>2</mn></msup></mfenced><mi>sin</mi><mi mathvariant="normal"> </mi><mi>c</mi></mrow></mtd></mtr></mtable></mfenced><mo>:</mo></math><img id="ib0016" file="imgb0016.tif" wi="64" he="21" img-content="math" img-format="tif"/></maths></claim-text>
<claim-text>wherein <i>A</i> and <i>B</i> represent preset rotation matrices that are determined based on the<!-- EPO <DP n="20"> --> measurement data obtained by the inertial navigation system;</claim-text>
<claim-text><i>c</i> and <i>d</i> are geographic coordinates of the center location of the second image, <i>c</i> represents a longitude coordinate, and <i>d</i> represents a latitude coordinate;</claim-text>
<claim-text><i>α</i> and <i>β</i> are first attitude angles at which the optical device captures the second image, <i>α</i> is an azimuth angle, and <i>β</i> is a pitch angle; and</claim-text>
<claim-text><maths id="math0017" num=""><math display="inline"><mi>e</mi><mo>=</mo><mfrac><msqrt><mrow><msup><mi>a</mi><mn>2</mn></msup><mo>−</mo><msup><mi>b</mi><mn>2</mn></msup></mrow></msqrt><mi>a</mi></mfrac></math><img id="ib0017" file="imgb0017.tif" wi="26" he="14" img-content="math" img-format="tif" inline="yes"/></maths> and <maths id="math0018" num=""><math display="inline"><mi>N</mi><mo>=</mo><mfrac><mi>a</mi><msqrt><mfenced separators=""><mn>1</mn><mo>−</mo><msup><mi>e</mi><mn>2</mn></msup><mo>×</mo><msup><mi>sin</mi><mn>2</mn></msup><mi>d</mi></mfenced></msqrt></mfrac></math><img id="ib0018" file="imgb0018.tif" wi="39" he="14" img-content="math" img-format="tif" inline="yes"/></maths>, wherein <i>a</i> represents the longest radius of the earth, and <i>b</i> represents the shortest radius of the earth.</claim-text></claim-text></claim-text></claim>
<claim id="c-en-01-0002" num="0002">
<claim-text>The positioning method according to claim 1, wherein the step of acquiring a first image captured by an optical device comprises:<br/>
acquiring the first image in a target area captured by the optical device; the target area comprising the ground observation object and the predetermined objects, and a range of the target area being determined according to an angle of field of view of the optical device.</claim-text></claim>
<claim id="c-en-01-0003" num="0003">
<claim-text>The positioning method according to claim 1, wherein the step of acquiring a first image captured by an optical device comprises:
<claim-text>detecting whether an image, captured by the optical device, comprises images of the ground observation object and the predetermined objects;</claim-text>
<claim-text>increasing an angle of field of view of the optical device and reacquiring the image captured by the optical device if the image captured by the optical device does not comprise images of the ground observation object and the predetermined objects;</claim-text>
<claim-text>determining that the first image is captured if the image captured by the optical device comprises images of the ground observation object and the predetermined objects.</claim-text></claim-text></claim>
<claim id="c-en-01-0004" num="0004">
<claim-text>The positioning method according to claim 3, wherein the step of detecting whether an image captured by the optical device comprises images of the ground observation object and the predetermined objects comprises:
<claim-text>obtaining a predetermined image database of the ground observation object and the predetermined objects, the predetermined image database storing features of the ground<!-- EPO <DP n="21"> --> observation object and the predetermined objects;</claim-text>
<claim-text>detecting whether the image captured by the optical device comprises the features of the ground observation object and the predetermined objects; and</claim-text>
<claim-text>determining that the image captured by the optical device comprises images of the ground observation object and the predetermined objects if it is detected that the image captured by the optical device comprises the features of the ground observation object and the predetermined objects.</claim-text></claim-text></claim>
<claim id="c-en-01-0005" num="0005">
<claim-text>The positioning method according to claim 1, wherein the step of selecting a first predetermined object from the predetermined objects based on the first image comprises:
<claim-text>determining distances between the ground observation object and the predetermined objects in the first image; and</claim-text>
<claim-text>determining the predetermined object, having the shortest distance from the ground observation object, as the first predetermined object.</claim-text></claim-text></claim>
<claim id="c-en-01-0006" num="0006">
<claim-text>The positioning method according to claim 1, wherein the step of modifying the first attitude angle, based on a position relationship between the ground observation object and the first predetermined object in the second image, to obtain a second attitude angle comprises:
<claim-text>modifying the first attitude angle, based on the position relationship between the ground observation object and the first predetermined object in the second image, by using a second formula to obtain the second attitude angle; wherein the second formula is <maths id="math0019" num=""><math display="block"><mtable><mtr><mtd><mrow><mi mathvariant="italic">Δβ</mi><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>h</mi><mo>−</mo><mn>540</mn></mfenced><mn>1080</mn></mfrac><mi>ξ</mi><mo>⋯</mo><mi>h</mi><mo>&lt;</mo><mn>540</mn></mrow></mtd></mtr><mtr><mtd><mrow><mn>0</mn><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mi>h</mi><mo>=</mo><mn>540</mn><mi mathvariant="italic">or</mi><mn>541</mn></mrow></mtd></mtr><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>h</mi><mo>−</mo><mn>541</mn></mfenced><mn>1080</mn></mfrac><mi>ξ</mi><mo>⋯</mo><mi>h</mi><mo>&gt;</mo><mn>541</mn></mrow></mtd></mtr></mtable></mrow></mrow></mtd><mtd><mtable><mtr><mtd><mrow/></mtd></mtr><mtr><mtd><mrow/></mtd></mtr><mtr><mtd><mrow/></mtd></mtr><mtr><mtd><mrow/></mtd></mtr><mtr><mtd><mi>and</mi></mtd></mtr></mtable></mtd><mtd><mrow><mi mathvariant="italic">Δα</mi><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>l</mi><mo>−</mo><mn>960</mn></mfenced><mn>1920</mn></mfrac><mi>ω</mi><mo>⋯</mo><mi>l</mi><mo>&lt;</mo><mn>960</mn></mrow></mtd></mtr><mtr><mtd><mrow><mn>0</mn><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mi>l</mi><mo>=</mo><mn>960</mn><mi mathvariant="italic">or</mi><mn>961</mn></mrow></mtd></mtr><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>l</mi><mo>−</mo><mn>961</mn></mfenced><mn>1920</mn></mfrac><mi>ω</mi><mo>⋯</mo><mi>l</mi><mo>&gt;</mo><mn>961</mn></mrow></mtd></mtr></mtable></mrow><mo>;</mo></mrow></mtd></mtr></mtable></math><img id="ib0019" file="imgb0019.tif" wi="129" he="32" img-content="math" img-format="tif"/></maths></claim-text>
<claim-text>wherein <i>h</i> is a row number of pixels of the ground observation object in the second image, and <i>l</i> is a column number of pixels of the ground observation object in the second image;</claim-text>
<claim-text><i>α</i> and <i>β</i> are the first attitude angles at which the optical device captures the second image, <i>α</i> is an azimuth angle, and <i>β</i> is a pitch angle;<!-- EPO <DP n="22"> --></claim-text>
<claim-text>Δ<i>β</i> is a modified value of the pitch angle, and Δ<i>α</i> is a modified value of the azimuth angle, and the modified value of the first attitude angle comprises the modified value of the pitch angle and the modified value of the azimuth angle;</claim-text>
<claim-text><i>ξ</i> and <i>ω</i> are angles of field of view at which the optical device captures the second image, <i>ξ</i> represents the angle of field of view of the optical device in a vertical direction, and <i>ω</i> represents the angle of field of view of the optical device in a horizontal direction; and</claim-text>
<claim-text><i>β'</i> = <i>β</i> - Δ<i>β</i> represents a modified pitch angle, <i>α'</i> = <i>α</i> + Δ<i>α</i> represents a modified azimuth angle, and the second attitude angle comprises the modified pitch angle and the modified azimuth angle.</claim-text></claim-text></claim>
<claim id="c-en-01-0007" num="0007">
<claim-text>A positioning apparatus, comprising:
<claim-text>a first acquiring unit (31), configured to acquire a first image captured by an optical device; wherein the first image comprises images of a ground observation object and a plurality of predetermined objects, and the predetermined objects have known geographic coordinates;</claim-text>
<claim-text>a first selection unit (33), configured to select a first predetermined object from the predetermined objects based on the first image;</claim-text>
<claim-text>a second acquiring unit (35), configured to acquire a second image, wherein the first predetermined object is located at the center of the second image;</claim-text>
<claim-text>a first arithmetic unit (37), configured to determine a first attitude angle of the optical device based on measurement data obtained by an inertial navigation system and the first predetermined object in the second image;</claim-text>
<claim-text>a second arithmetic unit (39), configured to modify the first attitude angle, based on a position relationship between the ground observation object and the first predetermined object in the second image, to obtain a second attitude angle that is based on the first attitude angle and a modified value of the first attitude angle; and</claim-text>
<claim-text>a third arithmetic unit (41), configured to calculate a geographic coordinate of the ground observation object based on the second attitude angle, wherein the geographic coordinate comprises a longitude coordinate and a latitude coordinate;</claim-text>
<claim-text>wherein the first arithmetic unit is specifically configured to:<!-- EPO <DP n="23"> -->
<claim-text>calculate the first attitude angle of the optical device, based on the measurement data obtained by the inertial navigation system and the first predetermined object in the second image, by using a first formula; wherein the first formula is <maths id="math0020" num=""><math display="block"><mi>A</mi><mfenced open="[" close="]"><mtable columnalign="left"><mtr><mtd><mrow><mi>cos</mi><mi mathvariant="normal"> </mi><mi>α</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>β</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>sin</mi><mi mathvariant="normal"> </mi><mi>α</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>β</mi></mrow></mtd></mtr><mtr><mtd><mrow><mo>−</mo><mi>sin</mi><mi mathvariant="normal"> </mi><mi>β</mi></mrow></mtd></mtr></mtable></mfenced><mo>=</mo><mi>B</mi><mfenced open="[" close="]"><mtable columnalign="left"><mtr><mtd><mrow><mi>N</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>c</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>d</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>N</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>c</mi><mi mathvariant="normal"> </mi><mi>sin</mi><mi mathvariant="normal"> </mi><mi>d</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>N</mi><mfenced separators=""><mn>1</mn><mo>−</mo><msup><mi>e</mi><mn>2</mn></msup></mfenced><mi>sin</mi><mi mathvariant="normal"> </mi><mi>c</mi></mrow></mtd></mtr></mtable></mfenced><mo>;</mo></math><img id="ib0020" file="imgb0020.tif" wi="64" he="21" img-content="math" img-format="tif"/></maths></claim-text>
<claim-text>wherein <i>A</i> and <i>B</i> represent preset rotation matrices that are determined based on the measurement data obtained by the inertial navigation system;</claim-text>
<claim-text><i>c</i> and <i>d</i> are geographic coordinates of the center location of the second image, <i>c</i> represents a longitude coordinate, and <i>d</i> represents a latitude coordinate;</claim-text>
<claim-text><i>α</i> and <i>β</i> are first attitude angles at which the optical device captures the second image, <i>α</i> is an azimuth angle, and <i>β</i> is a pitch angle; and</claim-text>
<claim-text><maths id="math0021" num=""><math display="inline"><mi>e</mi><mo>=</mo><mfrac><msqrt><mrow><msup><mi>a</mi><mn>2</mn></msup><mo>−</mo><msup><mi>b</mi><mn>2</mn></msup></mrow></msqrt><mi>a</mi></mfrac></math><img id="ib0021" file="imgb0021.tif" wi="26" he="15" img-content="math" img-format="tif" inline="yes"/></maths> and <maths id="math0022" num=""><math display="inline"><mi>N</mi><mo>=</mo><mfrac><mi>a</mi><msqrt><mfenced separators=""><mn>1</mn><mo>−</mo><msup><mi>e</mi><mn>2</mn></msup><mo>×</mo><msup><mi>sin</mi><mn>2</mn></msup><mi>d</mi></mfenced></msqrt></mfrac></math><img id="ib0022" file="imgb0022.tif" wi="39" he="16" img-content="math" img-format="tif" inline="yes"/></maths>, wherein <i>a</i> represents the longest radius of the earth, and <i>b</i> represents the shortest radius of the earth.</claim-text></claim-text></claim-text></claim>
<claim id="c-en-01-0008" num="0008">
<claim-text>The positioning apparatus according to claim 7, wherein the first acquiring unit comprises:<br/>
a first acquiring module, configured to acquire the first image in a target area captured by the optical device; wherein the target area comprises the ground observation object and the predetermined objects, and a range of the target area is determined according to an angle of field of view of the optical device.</claim-text></claim>
<claim id="c-en-01-0009" num="0009">
<claim-text>The positioning apparatus according to claim 7, wherein the first acquiring unit comprises:
<claim-text>a detection module, configured to detect whether an image captured by the optical device comprises images of the ground observation object and the predetermined objects;</claim-text>
<claim-text>a first detection sub-module, configured to increase an angle of field of view of the optical device and reacquire the image captured by the optical device if the image captured by the optical device does not comprise images of the ground observation object and the<!-- EPO <DP n="24"> --> predetermined objects; and</claim-text>
<claim-text>a second detection sub-module, configured to determine that the first image is captured if the image captured by the optical device comprises images of the ground observation object and the predetermined objects.</claim-text></claim-text></claim>
<claim id="c-en-01-0010" num="0010">
<claim-text>The positioning apparatus according to claim 9, wherein the detection module comprises:
<claim-text>a second acquiring module, configured to obtain a predetermined image database of the ground observation object and the predetermined objects, wherein the predetermined image database stores features of the ground observation object and the predetermined objects;</claim-text>
<claim-text>a second detection module, configured to detect whether the image captured by the optical device comprises the features of the ground observation object and the predetermined objects; and</claim-text>
<claim-text>a third detection sub-module, configured to determine that the image captured by the optical device comprises images of the ground observation object and the predetermined objects if it is detected that the image captured by the optical device comprises the features of the ground observation object and the predetermined objects.</claim-text></claim-text></claim>
<claim id="c-en-01-0011" num="0011">
<claim-text>The positioning apparatus according to claim 7, wherein the first selection unit is specifically configured to:
<claim-text>determine distances between the ground observation object and the predetermined objects in the first image; and</claim-text>
<claim-text>determine a predetermined object, having the shortest distance from the ground observation object, as the first predetermined object.</claim-text></claim-text></claim>
<claim id="c-en-01-0012" num="0012">
<claim-text>The positioning apparatus according to claim 7, wherein the second arithmetic unit is specifically configured to:
<claim-text>modify the first attitude angle, based on the position relationship between the ground observation object and the first predetermined object in the second image, by using a second formula to obtain the second attitude angle; wherein the second formula is<!-- EPO <DP n="25"> --> <maths id="math0023" num=""><math display="block"><mtable><mtr><mtd><mrow><mi mathvariant="italic">Δβ</mi><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>h</mi><mo>−</mo><mn>540</mn></mfenced><mn>1080</mn></mfrac><mi>ξ</mi><mo>⋯</mo><mi>h</mi><mo>&lt;</mo><mn>540</mn></mrow></mtd></mtr><mtr><mtd><mrow><mn>0</mn><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mi>h</mi><mo>=</mo><mn>540</mn><mi mathvariant="italic">or</mi><mn>541</mn></mrow></mtd></mtr><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>h</mi><mo>−</mo><mn>541</mn></mfenced><mn>1080</mn></mfrac><mi>ξ</mi><mo>⋯</mo><mi>h</mi><mo>&gt;</mo><mn>541</mn></mrow></mtd></mtr></mtable></mrow></mrow></mtd><mtd><mtable><mtr><mtd><mrow/></mtd></mtr><mtr><mtd><mrow/></mtd></mtr><mtr><mtd><mrow/></mtd></mtr><mtr><mtd><mrow/></mtd></mtr><mtr><mtd><mi>and</mi></mtd></mtr></mtable></mtd><mtd><mrow><mi mathvariant="italic">Δα</mi><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>l</mi><mo>−</mo><mn>960</mn></mfenced><mn>1920</mn></mfrac><mi>ω</mi><mo>⋯</mo><mi>l</mi><mo>&lt;</mo><mn>960</mn></mrow></mtd></mtr><mtr><mtd><mrow><mn>0</mn><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mi>l</mi><mo>=</mo><mn>960</mn><mi mathvariant="italic">or</mi><mn>961</mn></mrow></mtd></mtr><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>l</mi><mo>−</mo><mn>961</mn></mfenced><mn>1920</mn></mfrac><mi>ω</mi><mo>⋯</mo><mi>l</mi><mo>&gt;</mo><mn>961</mn></mrow></mtd></mtr></mtable></mrow><mo>;</mo></mrow></mtd></mtr></mtable></math><img id="ib0023" file="imgb0023.tif" wi="129" he="32" img-content="math" img-format="tif"/></maths></claim-text>
<claim-text>wherein <i>h</i> is a row number of pixels of the ground observation object in the second image, and <i>l</i> is a column number of pixels of the ground observation object in the second image;</claim-text>
<claim-text><i>α</i> and <i>β</i> are the first attitude angles at which the optical device captures the second image, <i>α</i> is an azimuth angle, and <i>β</i> is a pitch angle;</claim-text>
<claim-text>Δ<i>β</i> is a modified value of the pitch angle, and Δ<i>α</i> is a modified value of the azimuth angle, and the modified value of the first attitude angle comprises the modified value of the pitch angle and the modified value of the azimuth angle;</claim-text>
<claim-text><i>ξ</i> and <i>ω</i> are angles of field of view at which the optical device that captures the second image, <i>ξ</i> represents the angle of field of view of the optical device in a vertical direction, and <i>ω</i> represents the angle of field of view of the optical device in a horizontal direction; and</claim-text>
<claim-text><i>β'</i> = <i>β</i>- Δ<i>β</i> represents a modified pitch angle, <i>α'</i> = <i>α</i> + Δ<i>α</i> represents a modified azimuth angle, and the second attitude angle comprises the modified pitch angle and the modified azimuth angle.</claim-text></claim-text></claim>
<claim id="c-en-01-0013" num="0013">
<claim-text>A floating platform, comprising an optical device, an inertial navigation system, and a positioning apparatus according to any one of claims 7-12, wherein the optical device of the floating platform is configured to capture the first image and the second image, and wherein the first arithmetic unit (37) of the positioning apparatus is configured to calculate the first attitude angle based on the measurement data obtained by the inertial navigation system of the floating platform.</claim-text></claim>
</claims>
<claims id="claims02" lang="de"><!-- EPO <DP n="26"> -->
<claim id="c-de-01-0001" num="0001">
<claim-text>Positionierungsverfahren, das Folgendes umfasst:
<claim-text>Erfassen (S102) eines ersten Bildes, das von einer optischen Vorrichtung aufgenommen wurde; wobei das erste Bild Bilder eines Bodenbeobachtungsobjekts und einer Vielzahl von vorbestimmten Objekten umfasst und die vorbestimmten Objekte bekannte geografische Koordinaten haben;</claim-text>
<claim-text>Auswählen (S104) eines ersten vorbestimmten Objekts aus den vorbestimmten Objekten auf der Grundlage des ersten Bildes;</claim-text>
<claim-text>Erfassen (S106) eines zweiten Bildes, wobei sich das erste vorbestimmte Objekt in der Mitte des zweiten Bildes befindet;</claim-text>
<claim-text>Bestimmen (S108) eines ersten Lagewinkels der optischen Vorrichtung auf der Grundlage von Messdaten, die von einem Trägheitsnavigationssystem erhalten wurden, und des ersten vorbestimmten Objekts in dem zweiten Bild;</claim-text>
<claim-text>Modifizieren (S110) des ersten Lagewinkels, auf der Grundlage einer Positionsbeziehung zwischen dem Bodenbeobachtungsobjekt und dem ersten vorbestimmten Objekt in dem zweiten Bild, um einen zweiten Lagewinkel zu erhalten;</claim-text>
<claim-text>Berechnen (S112) einer geographischen Koordinate des Bodenbeobachtungsobjekts auf der Grundlage des zweiten Lagewinkels, wobei die geographische Koordinate eine Längengradkoordinate und eine Breitengradkoordinate umfasst;</claim-text>
<claim-text>wobei der Schritt des Bestimmens eines ersten Lagewinkels der optischen Vorrichtung auf der Grundlage von Messdaten, die durch ein Trägheitsnavigationssystem erhalten werden, und des ersten vorbestimmten Objekts in dem zweiten Bild umfasst:
<claim-text>Berechnen des ersten Lagewinkels der optischen Vorrichtung auf der Grundlage der durch das Trägheitsnavigationssystem erhaltenen Messdaten und des ersten vorbestimmten Objekts in dem zweiten Bild unter Verwendung einer ersten Formel; wobei die erste Formel lautet: <maths id="math0024" num=""><math display="block"><mi>A</mi><mfenced open="[" close="]"><mtable columnalign="left"><mtr><mtd><mrow><mi>cos</mi><mi mathvariant="normal"> </mi><mi>α</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>β</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>sin</mi><mi mathvariant="normal"> </mi><mi>α</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>β</mi></mrow></mtd></mtr><mtr><mtd><mrow><mo>−</mo><mi>sin</mi><mi mathvariant="normal"> </mi><mi>β</mi></mrow></mtd></mtr></mtable></mfenced><mo>=</mo><mi>B</mi><mfenced open="[" close="]"><mtable columnalign="left"><mtr><mtd><mrow><mi>N</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>c</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>d</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>N</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>c</mi><mi mathvariant="normal"> </mi><mi>sin</mi><mi mathvariant="normal"> </mi><mi>d</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>N</mi><mfenced separators=""><mn>1</mn><mo>−</mo><msup><mi>e</mi><mn>2</mn></msup></mfenced><mi>sin</mi><mi mathvariant="normal"> </mi><mi>c</mi></mrow></mtd></mtr></mtable></mfenced></math><img id="ib0024" file="imgb0024.tif" wi="62" he="20" img-content="math" img-format="tif"/></maths> wobei <i>A</i> und <i>B</i> voreingestellte Rotationsmatrizen darstellen, die auf der Grundlage der durch das Trägheitsnavigationssystem erhaltenen Messdaten bestimmt werden;</claim-text>
<claim-text><i>c</i> und <i>d</i> geographische Koordinaten des Mittelpunkts des zweiten Bildes sind, <i>c</i> eine Längengradkoordinate darstellt und <i>d</i> eine Breitengradkoordinate darstellt;</claim-text>
<claim-text><i>α</i> und <i>β</i> erste Lagewinkel sind, unter denen die optische Vorrichtung das zweite Bild aufnimmt, <i>α</i> ein Azimutwinkel ist und <i>β</i> ein Neigungswinkel ist; und<!-- EPO <DP n="27"> --></claim-text>
<claim-text><maths id="math0025" num=""><math display="inline"><mi>e</mi><mo>=</mo><mfrac><msqrt><mrow><msup><mi>a</mi><mn>2</mn></msup><mo>−</mo><msup><mi>b</mi><mn>2</mn></msup></mrow></msqrt><mi>a</mi></mfrac></math><img id="ib0025" file="imgb0025.tif" wi="24" he="15" img-content="math" img-format="tif" inline="yes"/></maths> und <maths id="math0026" num=""><math display="inline"><mi>N</mi><mo>=</mo><mfrac><mi>a</mi><msqrt><mfenced separators=""><mn>1</mn><mo>−</mo><msup><mi>e</mi><mn>2</mn></msup><mo>×</mo><msup><mi>sin</mi><mn>2</mn></msup><mi>d</mi></mfenced></msqrt></mfrac></math><img id="ib0026" file="imgb0026.tif" wi="39" he="16" img-content="math" img-format="tif" inline="yes"/></maths>, wobei <i>a</i> den längsten Radius der Erde darstellt und <i>b</i> den kürzesten Radius der Erde darstellt.</claim-text></claim-text></claim-text></claim>
<claim id="c-de-01-0002" num="0002">
<claim-text>Positionierungsverfahren nach Anspruch 1, wobei der Schritt des Erfassens eines ersten Bildes, das von einer optischen Vorrichtung aufgenommen wird, umfasst:<br/>
Erfassen des ersten Bildes in einem von der optischen Vorrichtung aufgenommenen Zielbereich, wobei der Zielbereich das Bodenbeobachtungsobjekt und die vorbestimmten Objekte umfasst und ein Bereich des Zielbereichs entsprechend einem Sichtfeldwinkel der optischen Vorrichtung bestimmt wird.</claim-text></claim>
<claim id="c-de-01-0003" num="0003">
<claim-text>Positionierungsverfahren nach Anspruch 1, wobei der Schritt des Erfassens eines ersten von einer optischen Vorrichtung aufgenommenen Bildes umfasst:
<claim-text>Erkennen, ob ein von der optischen Vorrichtung aufgenommenes Bild Bilder des Bodenbeobachtungsobjekts und der vorbestimmten Objekte enthält;</claim-text>
<claim-text>Vergrößern eines Sichtfeldwinkels der optischen Vorrichtung und erneutes Erfassen des von der optischen Vorrichtung aufgenommenen Bildes, wenn das von der optischen Vorrichtung aufgenommenen Bild keine Bilder des Bodenbeobachtungsobjekts und der vorbestimmten Objekte umfasst;</claim-text>
<claim-text>Bestimmen, dass das erste Bild aufgenommen wurde, wenn das von der optischen Vorrichtung aufgenommene Bild Bilder des Bodenbeobachtungsobjekts und der vorbestimmten Objekte enthält.</claim-text></claim-text></claim>
<claim id="c-de-01-0004" num="0004">
<claim-text>Positionierungsverfahren nach Anspruch 3, wobei der Schritt des Erkennens, ob ein von der optischen Vorrichtung aufgenommenes Bild Bilder des Bodenbeobachtungsobjekts und der vorbestimmten Objekte umfasst, umfasst:
<claim-text>Beschaffen einer vorbestimmten Bilddatenbank des Bodenbeobachtungsobjekts und der vorbestimmten Objekte, wobei die vorbestimmte Bilddatenbank Merkmale des Bodenbeobachtungsobjekts und der vorbestimmten Objekte speichert;</claim-text>
<claim-text>Erkennen, ob das von der optischen Vorrichtung aufgenommene Bild die Merkmale des Bodenbeobachtungsobjekts und der vorbestimmten Objekte umfasst; und</claim-text>
<claim-text>Bestimmen, dass das von der optischen Vorrichtung aufgenommene Bild Bilder des Bodenbeobachtungsobjekts und der vorbestimmten Objekte umfasst, wenn erkennt wird, dass das von der optischen Vorrichtung aufgenommene Bild die Merkmale des Bodenbeobachtungsobjekts und der vorbestimmten Objekte umfasst.</claim-text><!-- EPO <DP n="28"> --></claim-text></claim>
<claim id="c-de-01-0005" num="0005">
<claim-text>Positionierungsverfahren nach Anspruch 1, wobei der Schritt des Auswählens eines ersten vorbestimmten Objekts aus den vorbestimmten Objekten auf der Grundlage des ersten Bildes umfasst:
<claim-text>Bestimmen von Entfernungen zwischen dem Bodenbeobachtungsobjekt und den vorbestimmten Objekten in dem ersten Bild; und</claim-text>
<claim-text>Bestimmen des vorbestimmten Objekts, das den kürzesten Abstand von dem Bodenbeobachtungsobjekt hat, als das erste vorbestimmte Objekt.</claim-text></claim-text></claim>
<claim id="c-de-01-0006" num="0006">
<claim-text>Positionierungsverfahren nach Anspruch 1, wobei der Schritt des Modifizierens des ersten Lagewinkels auf der Grundlage einer Positionsbeziehung zwischen dem Bodenbeobachtungsobjekt und dem ersten vorbestimmten Objekt in dem zweiten Bild, um einen zweiten Lagewinkel zu erhalten, umfasst:<br/>
Modifizieren des ersten Lagewinkels, auf der Grundlage der Positionsbeziehung zwischen dem Bodenbeobachtungsobjekt und dem ersten vorbestimmten Objekt in dem zweiten Bild, unter Verwendung einer zweiten Formel, um den zweiten Lagewinkel zu erhalten; wobei die zweite Formel lautet <maths id="math0027" num=""><math display="block"><mtable columnalign="left"><mtr><mtd><mspace width="1ex"/></mtd></mtr><mtr><mtd><mtable><mtr><mtd><mrow><mi mathvariant="italic">Δβ</mi><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>h</mi><mo>−</mo><mn>540</mn></mfenced><mn>1080</mn></mfrac><mi>ξ</mi><mo>⋯</mo><mi>h</mi><mo>&lt;</mo><mn>540</mn></mrow></mtd></mtr><mtr><mtd><mrow><mn>0</mn><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mi>h</mi><mo>=</mo><mn>540</mn><mi mathvariant="italic">or</mi><mn>541</mn></mrow></mtd></mtr><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>h</mi><mo>−</mo><mn>541</mn></mfenced><mn>1080</mn></mfrac><mi>ξ</mi><mo>⋯</mo><mi>h</mi><mo>&gt;</mo><mn>541</mn></mrow></mtd></mtr></mtable></mrow></mrow></mtd><mtd><mtable><mtr><mtd><mrow/></mtd></mtr><mtr><mtd><mrow/></mtd></mtr><mtr><mtd><mrow/></mtd></mtr><mtr><mtd><mrow/></mtd></mtr><mtr><mtd><mi>und</mi></mtd></mtr></mtable></mtd><mtd><mrow><mi mathvariant="italic">Δα</mi><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>l</mi><mo>−</mo><mn>960</mn></mfenced><mn>1920</mn></mfrac><mi>ω</mi><mo>⋯</mo><mi>l</mi><mo>&lt;</mo><mn>960</mn></mrow></mtd></mtr><mtr><mtd><mrow><mn>0</mn><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mi>l</mi><mo>=</mo><mn>960</mn><mi mathvariant="italic">or</mi><mn>961</mn></mrow></mtd></mtr><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>l</mi><mo>−</mo><mn>961</mn></mfenced><mn>1920</mn></mfrac><mi>ω</mi><mo>⋯</mo><mi>l</mi><mo>&gt;</mo><mn>961</mn></mrow></mtd></mtr></mtable></mrow><mo>;</mo></mrow></mtd></mtr></mtable></mtd></mtr></mtable></math><img id="ib0027" file="imgb0027.tif" wi="126" he="32" img-content="math" img-format="tif"/></maths> wobei <i>h</i> eine Zeilenzahl von Pixeln des Bodenbeobachtungsobjekts in dem zweiten Bild ist und <i>l</i> eine Spaltenzahl von Pixeln des Bodenbeobachtungsobjekts in dem zweiten Bild ist;
<claim-text><i>α</i> und <i>β</i> die ersten Lagewinkel sind, bei denen die optische Vorrichtung das zweite Bild aufnimmt, <i>α</i> ein Azimutwinkel ist und <i>β</i> ein Neigungswinkel ist;</claim-text>
<claim-text>Δ<i>β</i> ein modifizierter Wert des Neigungswinkels ist und Δ<i>α</i> ein modifizierter Wert des Azimutwinkels ist;</claim-text>
<claim-text><i>ξ</i> und <i>ω</i> Sichtfeldwinkel sind, bei denen die optische Vorrichtung das zweite Bild aufnimmt, <i>ξ</i> den Sichtfeldwinkel der optischen Vorrichtung in einer vertikalen Richtung darstellt und <i>ω</i> den Sichtfeldwinkel der optischen Vorrichtung in einer horizontalen Richtung darstellt; und</claim-text>
<claim-text><i>β'</i> = <i>β</i> - Δ<i>β</i> einen modifizierten Neigungswinkel darstellt, <i>α'</i> = <i>α</i> + Δ<i>α</i> einen modifizierten Azimutwinkel darstellt, und der zweite Lagewinkel den modifizierten Neigungswinkel und den modifizierten Azimutwinkel umfasst.</claim-text><!-- EPO <DP n="29"> --></claim-text></claim>
<claim id="c-de-01-0007" num="0007">
<claim-text>Positionierungsvorrichtung, die Folgendes umfasst:
<claim-text>eine erste Erfassungseinheit (31), die so konfiguriert ist, dass sie ein erstes Bild erfasst, das von einer optischen Vorrichtung aufgenommen wurde; wobei das erste Bild Bilder eines Bodenbeobachtungsobjekts und einer Vielzahl von vorbestimmten Objekten umfasst und die vorbestimmten Objekte bekannte geografische Koordinaten haben;</claim-text>
<claim-text>eine erste Auswahleinheit (33), die konfiguriert ist, um ein erstes vorbestimmtes Objekt aus den vorbestimmten Objekten auf der Grundlage des ersten Bildes auszuwählen;</claim-text>
<claim-text>eine zweite Erfassungseinheit (35), die so konfiguriert ist, dass sie ein zweites Bild erfasst, wobei sich das erste vorbestimmte Objekt in der Mitte des zweiten Bildes befindet;</claim-text>
<claim-text>eine erste Recheneinheit (37), die so konfiguriert ist, dass sie einen ersten Lagewinkel der optischen Vorrichtung auf der Grundlage von Messdaten, die durch ein Trägheitsnavigationssystem erhalten sind, und des ersten vorbestimmten Objekts in dem zweiten Bild bestimmt;</claim-text>
<claim-text>eine zweite Recheneinheit (39), die so konfiguriert ist, dass sie den ersten Lagewinkel auf der Grundlage einer Positionsbeziehung zwischen dem Bodenbeobachtungsobjekt und dem ersten vorbestimmten Objekt in dem zweiten Bild modifiziert, um einen zweiten Lagewinkel zu erhalten; und</claim-text>
<claim-text>eine dritte Recheneinheit (41), die so konfiguriert ist, dass sie eine geographische Koordinate des Bodenbeobachtungsobjekts auf der Grundlage des zweiten Lagewinkels berechnet, wobei die geographische Koordinate eine Längengradkoordinate und eine Breitengradkoordinate umfasst;</claim-text>
wobei die erste Recheneinheit speziell konfiguriert ist zum:
<claim-text>Berechnen des ersten Lagewinkels der optischen Vorrichtung auf der Grundlage der durch das Trägheitsnavigationssystem erhaltenen Messdaten und des ersten vorbestimmten Objekts in dem zweiten Bild unter Verwendung einer ersten Formel; wobei die erste Formel lautet <maths id="math0028" num=""><math display="block"><mi>A</mi><mfenced open="[" close="]"><mtable columnalign="left"><mtr><mtd><mrow><mi>cos</mi><mi mathvariant="normal"> </mi><mi>α</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>β</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>sin</mi><mi mathvariant="normal"> </mi><mi>α</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>β</mi></mrow></mtd></mtr><mtr><mtd><mrow><mo>−</mo><mi>sin</mi><mi mathvariant="normal"> </mi><mi>β</mi></mrow></mtd></mtr></mtable></mfenced><mo>=</mo><mi>B</mi><mfenced open="[" close="]"><mtable columnalign="left"><mtr><mtd><mrow><mi>N</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>c</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>d</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>N</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>c</mi><mi mathvariant="normal"> </mi><mi>sin</mi><mi mathvariant="normal"> </mi><mi>d</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>N</mi><mfenced separators=""><mn>1</mn><mo>−</mo><msup><mi>e</mi><mn>2</mn></msup></mfenced><mi>sin</mi><mi mathvariant="normal"> </mi><mi>c</mi></mrow></mtd></mtr></mtable></mfenced></math><img id="ib0028" file="imgb0028.tif" wi="62" he="20" img-content="math" img-format="tif"/></maths> wobei <i>A</i> und B voreingestellte Rotationsmatrizen darstellen, die auf der Grundlage der durch das Trägheitsnavigationssystem erhaltenen Messdaten bestimmt werden;
<claim-text><i>c</i> und <i>d</i> geographische Koordinaten des Mittelpunkts des zweiten Bildes sind, <i>c</i> eine Längengradkoordinate darstellt und <i>d</i> eine Breitengradkoordinate darstellt;</claim-text>
<claim-text><i>α</i> und <i>β</i> erste Lagewinkel sind, unter denen die optische Vorrichtung das zweite Bild aufnimmt, <i>α</i> ein Azimutwinkel ist und ein <i>β</i> Neigungswinkel ist; und<!-- EPO <DP n="30"> --></claim-text>
<claim-text><maths id="math0029" num=""><math display="inline"><mi>e</mi><mo>=</mo><mfrac><msqrt><mrow><msup><mi>a</mi><mn>2</mn></msup><mo>−</mo><msup><mi>b</mi><mn>2</mn></msup></mrow></msqrt><mi>a</mi></mfrac></math><img id="ib0029" file="imgb0029.tif" wi="26" he="14" img-content="math" img-format="tif" inline="yes"/></maths> und <maths id="math0030" num=""><math display="inline"><mi>N</mi><mo>=</mo><mfrac><mi>a</mi><msqrt><mfenced separators=""><mn>1</mn><mo>−</mo><msup><mi>e</mi><mn>2</mn></msup><mo>×</mo><msup><mi>sin</mi><mn>2</mn></msup><mi>d</mi></mfenced></msqrt></mfrac></math><img id="ib0030" file="imgb0030.tif" wi="38" he="16" img-content="math" img-format="tif" inline="yes"/></maths>, wobei <i>a</i> den längsten Radius der Erde darstellt und</claim-text>
<claim-text><i>b</i> den kürzesten Radius der Erde darstellt.</claim-text></claim-text></claim-text></claim>
<claim id="c-de-01-0008" num="0008">
<claim-text>Positionierungsvorrichtung nach Anspruch 7, wobei die erste Erfassungseinheit umfasst:<br/>
ein erstes Erfassungsmodul, das so konfiguriert ist, dass es das erste Bild in einem von der optischen Vorrichtung aufgenommenen Zielbereich erfasst; wobei der Zielbereich das Bodenbeobachtungsobjekt und die vorbestimmten Objekte umfasst und ein Bereich des Zielbereichs gemäß einem Sichtfeldwinkel der optischen Vorrichtung bestimmt wird.</claim-text></claim>
<claim id="c-de-01-0009" num="0009">
<claim-text>Positionierungsvorrichtung nach Anspruch 7, wobei die erste Erfassungseinheit umfasst:
<claim-text>ein Erkennungsmodul, das konfiguriert ist, um zu erkennen, ob ein von der optischen Vorrichtung aufgenommenes Bild Bilder des Bodenbeobachtungsobjekts und der vorbestimmten Objekte umfasst;</claim-text>
<claim-text>ein erstes Erkennungsuntermodul, das so konfiguriert ist, dass es einen Blickwinkel der optischen Vorrichtung vergrößert und das von der optischen Vorrichtung aufgenommene Bild erneut erfasst, wenn das von der optischen Vorrichtung aufgenommene Bild keine Bilder des Bodenbeobachtungsobjekts und der vorbestimmten Objekte enthält; und</claim-text>
<claim-text>ein zweites Erkennungsuntermodul, das konfiguriert ist, um zu bestimmen, dass das erste Bild aufgenommen ist, wenn das von der optischen Vorrichtung aufgenommene Bild Bilder des Bodenbeobachtungsobjekts und der vorbestimmten Objekte umfasst.</claim-text></claim-text></claim>
<claim id="c-de-01-0010" num="0010">
<claim-text>Positionierungsvorrichtung nach Anspruch 9, wobei das Erkennungsmodul umfasst:
<claim-text>ein zweites Erfassungsmodul, das konfiguriert ist, um eine vorbestimmte Bilddatenbank des Bodenbeobachtungsobjekts und der vorbestimmten Objekte zu erhalten, wobei die vorbestimmte Bilddatenbank die Merkmale des Bodenbeobachtungsobjekts und der vorbestimmten Objekte speichert;</claim-text>
<claim-text>ein zweites Erkennungsmodul, das konfiguriert ist, um zu erkennen, ob das von der optischen Vorrichtung aufgenommenne Bild die Merkmale des Bodenbeobachtungsobjekts und der vorbestimmten Objekte umfasst; und</claim-text>
<claim-text>ein drittes Erkennungsuntermodul, das konfiguriert ist, um zu bestimmen, dass das von der optischen Vorrichtung aufgenommene Bild Bilder des Bodenbeobachtungsobjekts und der vorbestimmten Objekte umfasst, wenn erkannt wird, dass das von der optischen Vorrichtung aufgenommene Bild die Merkmale des Bodenbeobachtungsobjekts und der vorbestimmten Objekte umfasst.</claim-text><!-- EPO <DP n="31"> --></claim-text></claim>
<claim id="c-de-01-0011" num="0011">
<claim-text>Positionierungsvorrichtung nach Anspruch 7, wobei die erste Auswahleinheit speziell konfiguriert ist zum:
<claim-text>Bestimmen von Abständen zwischen dem Bodenbeobachtungsobjekt und den vorbestimmten Objekten in dem ersten Bild; und</claim-text>
<claim-text>Bestimmen eines vorbestimmten Objekts, das den kürzesten Abstand von dem Bodenbeobachtungsobjekt hat, als das erste vorbestimmte Objekt.</claim-text></claim-text></claim>
<claim id="c-de-01-0012" num="0012">
<claim-text>Positionierungsvorrichtung nach Anspruch 7, wobei die zweite Recheneinheit speziell konfiguriert ist zum:<br/>
Modifizieren des ersten Lagewinkels auf der Grundlage der Positionsbeziehung zwischen dem Bodenbeobachtungsobjekt und dem ersten vorbestimmten Objekt in dem zweiten Bild, unter Verwendung einer zweiten Formel, um den zweiten Lagewinkel zu erhalten; wobei die zweite Formel lautet <maths id="math0031" num=""><math display="block"><mspace width="1ex"/><mspace width="1ex"/><mtable><mtr><mtd><mrow><mi mathvariant="italic">Δβ</mi><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>h</mi><mo>−</mo><mn>540</mn></mfenced><mn>1080</mn></mfrac><mi>ξ</mi><mo>⋯</mo><mi>h</mi><mo>&lt;</mo><mn>540</mn></mrow></mtd></mtr><mtr><mtd><mrow><mn>0</mn><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mi>h</mi><mo>=</mo><mn>540</mn><mi mathvariant="italic">or</mi><mn>541</mn></mrow></mtd></mtr><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>h</mi><mo>−</mo><mn>541</mn></mfenced><mn>1080</mn></mfrac><mi>ξ</mi><mo>⋯</mo><mi>h</mi><mo>&gt;</mo><mn>541</mn></mrow></mtd></mtr></mtable></mrow></mrow></mtd><mtd><mtable><mtr><mtd><mrow/></mtd></mtr><mtr><mtd><mrow/></mtd></mtr><mtr><mtd><mrow/></mtd></mtr><mtr><mtd><mrow/></mtd></mtr><mtr><mtd><mi>und</mi></mtd></mtr></mtable></mtd><mtd><mrow><mi mathvariant="italic">Δα</mi><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>l</mi><mo>−</mo><mn>960</mn></mfenced><mn>1920</mn></mfrac><mi>ω</mi><mo>⋯</mo><mi>l</mi><mo>&lt;</mo><mn>960</mn></mrow></mtd></mtr><mtr><mtd><mrow><mn>0</mn><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mi>l</mi><mo>=</mo><mn>960</mn><mi mathvariant="italic">or</mi><mn>961</mn></mrow></mtd></mtr><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>l</mi><mo>−</mo><mn>961</mn></mfenced><mn>1920</mn></mfrac><mi>ω</mi><mo>⋯</mo><mi>l</mi><mo>&gt;</mo><mn>961</mn></mrow></mtd></mtr></mtable></mrow></mrow></mtd></mtr></mtable></math><img id="ib0031" file="imgb0031.tif" wi="124" he="31" img-content="math" img-format="tif"/></maths> ist; wobei <i>h</i> eine Zeilenzahl von Pixeln des Bodenbeobachtungsobjekts in dem zweiten Bild ist und <i>l</i> eine Spaltenzahl von Pixeln des Bodenbeobachtungsobjekts in dem zweiten Bild ist;
<claim-text><i>α</i> und <i>β</i> die ersten Lagewinkel sind, bei denen die optische Vorrichtung das zweite Bild aufnimmt, <i>α</i> ein Azimutwinkel ist und <i>β</i> ein Neigungswinkel ist;</claim-text>
<claim-text>Δ<i>β</i> ein modifizierter Wert des Neigungswinkels ist und Δ<i>α</i> ein modifizierter Wert des Azimutwinkels ist;</claim-text>
<claim-text><i>ξ</i> und <i>ω</i> Sichtwinkel sind, bei denen die optische Vorrichtung, die das zweite Bild aufnimmt, <i>ξ</i> den Sichtwinkel der optischen Vorrichtung in einer vertikalen Richtung darstellt und <i>ω</i> den Sichtwinkel der optischen Vorrichtung in einer horizontalen Richtung darstellt; und</claim-text>
<claim-text><i>β'</i> = <i>β</i> - Δ<i>β</i> einen modifizierten Neigungswinkel darstellt, <i>α'</i> = <i>α</i> + Δ<i>α</i> einen modifizierten Azimutwinkel darstellt, und der zweite Lagewinkel den modifizierten Neigungswinkel und den modifizierten Azimutwinkel umfasst.</claim-text></claim-text></claim>
<claim id="c-de-01-0013" num="0013">
<claim-text>Schwimmende Plattform, die eine optische Vorrichtung und ein Trägheitsnavigationssystem umfasst, wobei die schwimmende Plattform so konfiguriert ist, dass sie das Positionierungsverfahren nach einem der Ansprüche 1 bis 6 durchführt.</claim-text></claim>
</claims>
<claims id="claims03" lang="fr"><!-- EPO <DP n="32"> -->
<claim id="c-fr-01-0001" num="0001">
<claim-text>Procédé de positionnement, comprenant les étapes consistant à :
<claim-text>acquérir (S102) une première image saisie par un dispositif optique ; la première image comprenant des images d'un objet d'observation au sol et d'une pluralité d'objets prédéterminés, et les objets prédéterminés ayant des coordonnées géographiques connues ;</claim-text>
<claim-text>sélectionner (S104) un premier objet prédéterminé parmi les objets prédéterminés sur la base de la première image ;</claim-text>
<claim-text>acquérir (S106) une deuxième image ; le premier objet prédéterminé étant situé au centre de la deuxième image ;</claim-text>
<claim-text>déterminer (S108) un premier angle d'attitude du dispositif optique sur la base de données de mesure obtenues par un système de navigation inertielle et le premier objet prédéterminé dans la deuxième image ;</claim-text>
<claim-text>modifier (S110) le premier angle d'attitude, sur la base d'une relation de position entre l'objet d'observation au sol et le premier objet prédéterminé dans la deuxième image, pour obtenir un deuxième angle d'attitude qui est basé sur le premier angle d'attitude et sur une valeur modifiée du premier angle d'attitude ;</claim-text>
<claim-text>calculer (S112) une coordonnée géographique de l'objet d'observation au sol sur la base du deuxième angle d'attitude, la coordonnée géographique comprenant une coordonnée de longitude et une coordonnée de latitude ;</claim-text>
<claim-text>dans lequel l'étape consistant à déterminer un premier angle d'attitude du dispositif optique sur la base de données de mesure obtenues par un système de navigation inertielle et le premier objet prédéterminé dans la deuxième image comprend ce qui suit :<!-- EPO <DP n="33"> -->
<claim-text>calculer le premier angle d'attitude du dispositif optique, sur la base des données de mesure obtenues par le système de navigation inertielle et le premier objet prédéterminé dans la deuxième image, en utilisant une première formule ; la première formule étant : <maths id="math0032" num=""><math display="block"><mi>A</mi><mfenced open="[" close="]"><mtable columnalign="left"><mtr><mtd><mrow><mi>cos</mi><mi mathvariant="normal"> </mi><mi>α</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>β</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>sin</mi><mi mathvariant="normal"> </mi><mi>α</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>β</mi></mrow></mtd></mtr><mtr><mtd><mrow><mo>−</mo><mi>sin</mi><mi mathvariant="normal"> </mi><mi>β</mi></mrow></mtd></mtr></mtable></mfenced><mo>=</mo><mi>B</mi><mfenced open="[" close="]"><mtable columnalign="left"><mtr><mtd><mrow><mi>N</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>c</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>d</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>N</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>c</mi><mi mathvariant="normal"> </mi><mi>sin</mi><mi mathvariant="normal"> </mi><mi>d</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>N</mi><mfenced separators=""><mn>1</mn><mo>−</mo><msup><mi>e</mi><mn>2</mn></msup></mfenced><mi>sin</mi><mi mathvariant="normal"> </mi><mi>c</mi></mrow></mtd></mtr></mtable></mfenced><mo>:</mo></math><img id="ib0032" file="imgb0032.tif" wi="81" he="27" img-content="math" img-format="tif"/></maths></claim-text>
<claim-text>dans laquelle <i>A</i> et <i>B</i> représentent des matrices de rotation présélectionnées qui sont déterminées sur la base des données de mesure obtenues par le système de navigation inertielle,</claim-text>
<claim-text><i>c</i> et <i>d</i> représentent des coordonnées géographiques de l'emplacement central de la deuxième image, <i>c</i> désigne une coordonnée de longitude et <i>d</i> désigne une coordonnée de latitude ;</claim-text>
<claim-text><i>α</i> et <i>β</i> représentent des premiers angles d'attitude au niveau desquels le dispositif optique saisit la deuxième image,</claim-text>
<claim-text><i>α</i> représente un angle d'azimuth et <i>β</i> représente un angle d'inclinaison ; et <maths id="math0033" num=""><math display="block"><mtable><mtr><mtd><mrow><mi>e</mi><mo>=</mo><mfrac><msqrt><mrow><msup><mi>a</mi><mn>2</mn></msup><mo>−</mo><msup><mi>b</mi><mn>2</mn></msup></mrow></msqrt><mi>a</mi></mfrac></mrow></mtd><mtd><mtable><mtr><mtd><mrow/></mtd></mtr><mtr><mtd><mi>et</mi></mtd></mtr></mtable></mtd><mtd><mi>N</mi></mtd></mtr></mtable><mo>=</mo><mfrac><mi>a</mi><msqrt><mfenced separators=""><mn>1</mn><mo>−</mo><msup><mi>e</mi><mn>2</mn></msup><mo>×</mo><msup><mi>sin</mi><mn>2</mn></msup><mi>d</mi></mfenced></msqrt></mfrac><mo>,</mo></math><img id="ib0033" file="imgb0033.tif" wi="103" he="18" img-content="math" img-format="tif"/></maths> où <i>a</i> représente le rayon le plus long de la terre et <i>b</i> représente le rayon le plus court de la terre.</claim-text></claim-text></claim-text></claim>
<claim id="c-fr-01-0002" num="0002">
<claim-text>Procédé de positionnement selon la revendication 1, dans lequel l'étape d'acquisition d'une première image saisie par un dispositif optique comprend ce qui suit :<br/>
<!-- EPO <DP n="34"> -->acquérir la première image dans une zone cible saisie par le dispositif optique ; la zone cible comprenant l'objet d'observation au sol et les objets prédéterminés, et un périmètre de la zone cible étant déterminé en fonction d'un angle de champ de vision du dispositif optique.</claim-text></claim>
<claim id="c-fr-01-0003" num="0003">
<claim-text>Procédé de positionnement selon la revendication 1, dans lequel l'étape d'acquisition d'une première image saisie par un dispositif optique comprend ce qui suit :
<claim-text>détecter si une image saisie par le dispositif optique comprend des images de l'objet d'observation au sol et des objets prédéterminés ;</claim-text>
<claim-text>augmenter un angle de champ de vision du dispositif optique et réacquérir l'image saisie par le dispositif optique si l'image saisie par le dispositif optique ne comprend pas d'images de l'objet d'observation au sol et des objets prédéterminés ;</claim-text>
<claim-text>établir que la première image est saisie si l'image saisie par le dispositif optique comprend des images de l'objet d'observation au sol et des objets prédéterminés.</claim-text></claim-text></claim>
<claim id="c-fr-01-0004" num="0004">
<claim-text>Procédé de positionnement selon la revendication 3, dans laquelle l'étape consistant à détecter si une image saisie par le dispositif optique comprend des images de l'objet d'observation au sol et des objets prédéterminés comprend ce qui suit :
<claim-text>obtenir une base de données d'images prédéterminées de l'objet d'observation au sol et des objets prédéterminés, la base de données d'images prédéterminées stockant des caractéristiques de l'objet d'observation au sol et des objets prédéterminés</claim-text>
<claim-text>détecter si l'image saisie par le dispositif optique comprend les caractéristiques de l'objet d'observation au sol et des objets<!-- EPO <DP n="35"> --> prédéterminés ; et</claim-text>
<claim-text>établir que l'image saisie par le dispositif optique comprend des images de l'objet d'observation au sol et des objets prédéterminés s'il est détecté que l'image saisie par le dispositif optique comprend les caractéristiques de l'objet d'observation au sol et des objets prédéterminés.</claim-text></claim-text></claim>
<claim id="c-fr-01-0005" num="0005">
<claim-text>Procédé de positionnement selon la revendication 1, dans lequel l'étape de sélection d'un premier objet prédéterminé parmi les objets prédéterminés sur la base de la première image comprend ce qui suit :
<claim-text>déterminer des distances entre l'objet d'observation au sol et les objets prédéterminés dans la première image ; et</claim-text>
<claim-text>établir que l'objet prédéterminé se situant à</claim-text>
<claim-text>la distance la plus courte par rapport à l'objet d'observation au sol est le premier objet prédéterminé.</claim-text></claim-text></claim>
<claim id="c-fr-01-0006" num="0006">
<claim-text>Procédé de positionnement selon la revendication 1, dans lequel l'étape consistant à modifier le premier angle d'attitude, sur la base d'une relation de position entre l'objet d'observation au sol et le premier objet prédéterminé dans la deuxième image, pour obtenir un deuxième angle d'attitude, comprend ce qui suit :<br/>
modifier le premier angle d'attitude, sur la base de la relation de position entre l'objet d'observation au sol et le premier objet prédéterminé dans la deuxième image, en utilisant une deuxième formule pour obtenir le deuxième angle d'attitude ; dans lequel la deuxième formule est :<!-- EPO <DP n="36"> --> <maths id="math0034" num=""><math display="block"><mtable><mtr><mtd><mrow><mi mathvariant="italic">Δβ</mi><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>h</mi><mo>−</mo><mn>540</mn></mfenced><mn>1080</mn></mfrac><mi>ξ</mi><mo>⋯</mo><mi>h</mi><mo>&lt;</mo><mn>540</mn></mrow></mtd></mtr><mtr><mtd><mrow><mn>0</mn><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mi>h</mi><mo>=</mo><mn>540</mn><mi mathvariant="italic">or</mi><mn>541</mn></mrow></mtd></mtr><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>h</mi><mo>−</mo><mn>541</mn></mfenced><mn>1080</mn></mfrac><mi>ξ</mi><mo>⋯</mo><mi>h</mi><mo>&gt;</mo><mn>541</mn></mrow></mtd></mtr></mtable></mrow></mrow></mtd><mtd><mtable><mtr><mtd><mrow/></mtd></mtr><mtr><mtd><mrow/></mtd></mtr><mtr><mtd><mrow/></mtd></mtr><mtr><mtd><mrow/></mtd></mtr><mtr><mtd><mi>and</mi></mtd></mtr></mtable></mtd><mtd><mrow><mi mathvariant="italic">Δα</mi><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>l</mi><mo>−</mo><mn>960</mn></mfenced><mn>1920</mn></mfrac><mi>ω</mi><mo>⋯</mo><mi>l</mi><mo>&lt;</mo><mn>960</mn></mrow></mtd></mtr><mtr><mtd><mrow><mn>0</mn><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mi>l</mi><mo>=</mo><mn>960</mn><mi mathvariant="italic">or</mi><mn>961</mn></mrow></mtd></mtr><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>l</mi><mo>−</mo><mn>961</mn></mfenced><mn>1920</mn></mfrac><mi>ω</mi><mo>⋯</mo><mi>l</mi><mo>&gt;</mo><mn>961</mn></mrow></mtd></mtr></mtable></mrow></mrow></mtd></mtr></mtable><mo>;</mo></math><img id="ib0034" file="imgb0034.tif" wi="132" he="32" img-content="math" img-format="tif"/></maths> and : et
<claim-text>dans laquelle <i>h</i> représente un nombre de pixels <i>l</i> par ligne de l'objet d'observation au sol dans la deuxième image, et représente un nombre de pixels par colonne de l'objet d'observation au sol dans la deuxième image ;</claim-text>
<claim-text><i>α</i> et <i>β</i> représentent les premiers angles d'attitude au niveau desquels le dispositif optique saisit la deuxième image,<i>α</i> représente un angle d'azimuth et <i>β</i> représente un angle d'inclinaison ;</claim-text>
<claim-text>Δ<i>β</i> représente une valeur modifiée de l'angle d'inclinaison et Δ<i>α</i> désigne une valeur modifiée de l'angle d'azimuth et la valeur modifiée du premier angle d'attitude comprend la valeur modifiée de l'angle d'inclinaison et la valeur modifiée de l'angle d'azimuth ;</claim-text>
<claim-text><i>ξ</i> et <i>ω</i> représentent des angles de champ de vision au niveau desquels le dispositif optique saisit la deuxième image, <i>ξ</i> désigne l'angle de champ de vision du dispositif optique dans une direction verticale et <i>ω</i> représente l'angle de champ de vision du dispositif optique dans une direction horizontale et<!-- EPO <DP n="37"> --></claim-text>
<claim-text><i>β'</i> = <i>β</i> - Δ<i>β</i> représente un angle d'inclinaison modifié, <i>α'</i> = <i>α</i> + Δ<i>α</i> désigne un angle d'azimuth modifié et le deuxième angle d'attitude comprend l'angle d'inclinaison modifié et l'angle d'azimuth modifié.</claim-text></claim-text></claim>
<claim id="c-fr-01-0007" num="0007">
<claim-text>Appareil de positionnement, comprenant
<claim-text>une première unité d'acquisition (31) configurée pour acquérir une première image saisie par un dispositif optique ; dans lequel la première image comprend des images d'un objet d'observation au sol et une pluralité d'objets prédéterminés et les objets prédéterminés ont des coordonnées géographiques connues ;</claim-text>
<claim-text>une première unité de sélection (33) configurée pour sélectionner un premier objet prédéterminé parmi les objets prédéterminés sur la base de la première image ;</claim-text>
<claim-text>une deuxième unité d'acquisition (35) configurée pour acquérir une deuxième image, le premier objet prédéterminé étant situé au centre de la deuxième image ;</claim-text>
<claim-text>une première unité arithmétique (37) configurée pour déterminer un premier angle d'attitude du dispositif optique sur la base de données de mesure obtenues par un système de navigation inertielle et le premier objet prédéterminé dans la deuxième image ;</claim-text>
<claim-text>une deuxième unité arithmétique (39) configurée pour modifier le premier angle d'attitude, sur la base d'une relation de position entre l'objet d'observation au sol et le premier objet prédéterminé dans la deuxième image de manière à obtenir un deuxième angle d'attitude qui est basé sur le premier angle d'attitude et une valeur modifiée du premier angle d'attitude ;</claim-text>
<claim-text>une troisième unité arithmétique (41) configurée pour calculer une coordonnée géographique de l'objet d'observation au sol sur la base du deuxième angle d'attitude, la coordonnée géographique comprenant une coordonnée de longitude et une coordonnée de latitude ;</claim-text>
<claim-text>dans lequel la première unité arithmétique est spécifiquement<!-- EPO <DP n="38"> --> configurée pour :</claim-text>
<claim-text>calculer le premier angle d'attitude du dispositif optique, sur la base des données de mesure obtenues par le système de navigation inertielle et le premier objet prédéterminé dans la deuxième image, en utilisant une première formule, la première formule étant : <maths id="math0035" num=""><math display="block"><mi>A</mi><mfenced open="[" close="]"><mtable columnalign="left"><mtr><mtd><mrow><mi>cos</mi><mi mathvariant="normal"> </mi><mi>α</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>β</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>sin</mi><mi mathvariant="normal"> </mi><mi>α</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>β</mi></mrow></mtd></mtr><mtr><mtd><mrow><mo>−</mo><mi>sin</mi><mi mathvariant="normal"> </mi><mi>β</mi></mrow></mtd></mtr></mtable></mfenced><mo>=</mo><mi>B</mi><mfenced open="[" close="]"><mtable columnalign="left"><mtr><mtd><mrow><mi>N</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>c</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>d</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>N</mi><mi mathvariant="normal"> </mi><mi>cos</mi><mi mathvariant="normal"> </mi><mi>c</mi><mi mathvariant="normal"> </mi><mi>sin</mi><mi mathvariant="normal"> </mi><mi>d</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>N</mi><mfenced separators=""><mn>1</mn><mo>−</mo><msup><mi>e</mi><mn>2</mn></msup></mfenced><mi>sin</mi><mi mathvariant="normal"> </mi><mi>c</mi></mrow></mtd></mtr></mtable></mfenced><mo>;</mo></math><img id="ib0035" file="imgb0035.tif" wi="81" he="27" img-content="math" img-format="tif"/></maths></claim-text>
<claim-text>dans laquelle <i>A</i> et <i>B</i> représentent des matrices de rotation qui sont déterminés sur la base des données de mesure obtenues par le système de navigation inertielle,</claim-text>
<claim-text><i>c</i> et <i>d</i> représentent des coordonnées géographiques de l'emplacement central de la deuxième image, <i>c</i> représente une coordonnée de longitude et <i>d</i> représente une coordonnée de latitude ;</claim-text>
<claim-text><i>α</i> et <i>β</i> représentent des premiers angles d'attitude au niveau desquels le dispositif optique saisit la deuxième image,</claim-text>
<claim-text><i>α</i> représente un angle d'azimuth et <i>β</i> représente un angle d'inclinaison ; et <maths id="math0036" num=""><math display="block"><mtable><mtr><mtd><mrow><mi>e</mi><mo>=</mo><mfrac><msqrt><mrow><msup><mi>a</mi><mn>2</mn></msup><mo>−</mo><msup><mi>b</mi><mn>2</mn></msup></mrow></msqrt><mi>a</mi></mfrac></mrow></mtd><mtd><mtable><mtr><mtd><mrow/></mtd></mtr><mtr><mtd><mi>et</mi></mtd></mtr></mtable></mtd><mtd><mi>N</mi></mtd></mtr></mtable><mo>=</mo><mfrac><mi>a</mi><msqrt><mfenced separators=""><mn>1</mn><mo>−</mo><msup><mi>e</mi><mn>2</mn></msup><mo>×</mo><msup><mi>sin</mi><mn>2</mn></msup><mi>d</mi></mfenced></msqrt></mfrac><mo>,</mo></math><img id="ib0036" file="imgb0036.tif" wi="103" he="18" img-content="math" img-format="tif"/></maths> où <i>α</i> représente le rayon le plus long de la terre et <i>b</i> représente le rayon le plus court de la terre.</claim-text></claim-text></claim>
<claim id="c-fr-01-0008" num="0008">
<claim-text>Appareil de positionnement selon la revendication 7, dans lequel la première unité d'acquisition comprend :<br/>
<!-- EPO <DP n="39"> -->un premier module d'acquisition configuré pour acquérir la première image dans une zone cible saisie par le dispositif optique ; la zone cible comprenant l'objet d'observation au sol et les objets prédéterminés et un périmètre de la zone cible est déterminé selon un angle de champ de vision du dispositif optique.</claim-text></claim>
<claim id="c-fr-01-0009" num="0009">
<claim-text>Appareil de positionnement selon la revendication 7, dans lequel la première unité d'acquisition comprend :
<claim-text>un module de détection configuré pour détecter si l'image saisie par le dispositif optique comprend des images de l'objet d'observation au sol et les objets prédéterminés ;</claim-text>
<claim-text>un premier sous-module de détection configuré pour augmenter un angle du champ de vision du dispositif optique et pour réacquérir l'image saisie par le dispositif optique si l'image saisie par le dispositif optique ne comprend pas d'images de l'objet d'observation au sol et les objets prédéterminés ; et</claim-text>
<claim-text>un deuxième sous-module de détection, configuré pour établir que la première image est saisie si l'image saisie par le dispositif optique comprend des images de l'objet d'observation au sol et les objets prédéterminés.</claim-text></claim-text></claim>
<claim id="c-fr-01-0010" num="0010">
<claim-text>Appareil de positionnement selon la revendication 9, dans lequel le module de détection comprend :
<claim-text>un deuxième module d'acquisition, configuré pour obtenir une base de données d'images prédéterminées de l'objet d'observation au sol et les objets prédéterminés, la base de données d'images prédéterminées stockant des caractéristiques de l'objet d'observation au sol et les objets prédéterminés ;</claim-text>
<claim-text>un deuxième module de détection, configuré pour détecter si l'image saisie par le dispositif optique comprend les caractéristiques de l'objet d'observation au sol et les objets prédéterminés ; et<!-- EPO <DP n="40"> --></claim-text>
<claim-text>un troisième sous-module de détection, configuré pour établir que l'image saisie par le dispositif optique comprend des images de l'objet d'observation au sol et les objets prédéterminés s'il est détecté que l'image saisie par le dispositif optique comprend les caractéristiques de l'objet d'observation au sol et les objets prédéterminés.</claim-text></claim-text></claim>
<claim id="c-fr-01-0011" num="0011">
<claim-text>Appareil de positionnement selon la revendication 7, dans lequel la première unité de sélection est spécifiquement configurée pour :
<claim-text>déterminer les distances entre l'objet d'observation au sol et les objets prédéterminés dans la première image ; et</claim-text>
<claim-text>établir qu'un objet prédéterminé, se situant à la distance la plus courte par rapport à l'objet d'observation au sol, est le premier objet prédéterminé.</claim-text></claim-text></claim>
<claim id="c-fr-01-0012" num="0012">
<claim-text>Appareil de positionnement selon la revendication 7, dans lequel la deuxième unité arithmétique est spécifiquement configurée pour :
<claim-text>modifier le premier angle d'attitude, sur la base de la relation de position entre l'objet d'observation au sol et le premier objet prédéterminé dans la deuxième image, en utilisant une deuxième formule pour obtenir le deuxième angle d'attitude ; dans lequel la deuxième formule est <maths id="math0037" num=""><math display="block"><mtable><mtr><mtd><mrow><mi mathvariant="italic">Δβ</mi><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>h</mi><mo>−</mo><mn>540</mn></mfenced><mn>1080</mn></mfrac><mi>ξ</mi><mo>⋯</mo><mi>h</mi><mo>&lt;</mo><mn>540</mn></mrow></mtd></mtr><mtr><mtd><mrow><mn>0</mn><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mi>h</mi><mo>=</mo><mn>540</mn><mi mathvariant="italic">or</mi><mn>541</mn></mrow></mtd></mtr><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>h</mi><mo>−</mo><mn>541</mn></mfenced><mn>1080</mn></mfrac><mi>ξ</mi><mo>⋯</mo><mi>h</mi><mo>&gt;</mo><mn>541</mn></mrow></mtd></mtr></mtable></mrow></mrow></mtd><mtd><mtable><mtr><mtd><mrow/></mtd></mtr><mtr><mtd><mrow/></mtd></mtr><mtr><mtd><mrow/></mtd></mtr><mtr><mtd><mrow/></mtd></mtr><mtr><mtd><mi>and</mi></mtd></mtr></mtable></mtd><mtd><mrow><mi mathvariant="italic">Δα</mi><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>l</mi><mo>−</mo><mn>960</mn></mfenced><mn>1920</mn></mfrac><mi>ω</mi><mo>⋯</mo><mi>l</mi><mo>&lt;</mo><mn>960</mn></mrow></mtd></mtr><mtr><mtd><mrow><mn>0</mn><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mo>⋯</mo><mi>l</mi><mo>=</mo><mn>960</mn><mi mathvariant="italic">or</mi><mn>961</mn></mrow></mtd></mtr><mtr><mtd><mrow><mfrac><mfenced separators=""><mi>l</mi><mo>−</mo><mn>961</mn></mfenced><mn>1920</mn></mfrac><mi>ω</mi><mo>⋯</mo><mi>l</mi><mo>&gt;</mo><mn>961</mn></mrow></mtd></mtr></mtable></mrow></mrow></mtd></mtr></mtable><mo>;</mo></math><img id="ib0037" file="imgb0037.tif" wi="132" he="32" img-content="math" img-format="tif"/></maths> and : et</claim-text>
<claim-text>dans laquelle <i>h</i> représente un nombre de pixels <i>l</i> par ligne de l'objet d'observation au sol dans la deuxième image, et représente<!-- EPO <DP n="41"> --> un nombre de pixels par colonne de l'objet d'observation au sol dans la deuxième image ;</claim-text>
<claim-text><i>α</i> et <i>β</i> représentent les premiers angles d'attitude au niveau desquels le dispositif optique saisit la deuxième image,<i>α</i> représente un angle d'azimuth et <i>β</i> représente un angle d'inclinaison ;</claim-text>
<claim-text>Δ<i>β</i> représente une valeur modifiée de l'angle d'inclinaison et désigne une valeur modifiée de l'angle d'azimuth et la valeur modifiée du premier angle d'attitude comprend la valeur modifiée de l'angle d'inclinaison et la valeur modifiée de l'angle d'azimuth ;</claim-text>
<claim-text><i>ξ</i> et <i>ω</i> représentent des angles de champ de vision au niveau desquels le dispositif optique saisit la deuxième image,<i>ξ</i> représente l'angle de champ de vision du dispositif optique dans une direction verticale et <i>ω</i> représente l'angle de champ de vision du dispositif optique dans une direction horizontale et</claim-text>
<claim-text><i>β'</i> = <i>β</i> - Δ<i>β</i> représente un angle d'inclinaison modifié, <i>α'</i> = <i>α</i> + Δ<i>α</i> représente un angle d'azimuth modifié et le deuxième angle d'attitude comprend l'angle d'inclinaison modifié et l'angle d'azimuth modifié.</claim-text></claim-text></claim>
<claim id="c-fr-01-0013" num="0013">
<claim-text>Plate-forme flottante comprenant un dispositif optique, un système de navigation inertielle et un appareil de positionnement selon l'une quelconque des revendications 7 à 12, dans laquelle le dispositif optique de la plate-forme flottante est configuré pour saisir la première<!-- EPO <DP n="42"> --> image, et dans laquelle la première unité arithmétique (37) de l'appareil de positionnement est configurée pour calculer le premier angle d'attitude sur la base des données de mesure obtenues par le système de navigation inertielle de la plate-forme flottante.</claim-text></claim>
</claims>
<drawings id="draw" lang="en"><!-- EPO <DP n="43"> -->
<figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="105" he="189" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="44"> -->
<figure id="f0002" num="2"><img id="if0002" file="imgf0002.tif" wi="105" he="185" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="45"> -->
<figure id="f0003" num="3"><img id="if0003" file="imgf0003.tif" wi="51" he="100" img-content="drawing" img-format="tif"/></figure>
</drawings>
<ep-reference-list id="ref-list">
<heading id="ref-h0001"><b>REFERENCES CITED IN THE DESCRIPTION</b></heading>
<p id="ref-p0001" num=""><i>This list of references cited by the applicant is for the reader's convenience only. It does not form part of the European patent document. Even though great care has been taken in compiling the references, errors or omissions cannot be excluded and the EPO disclaims all liability in this regard.</i></p>
<heading id="ref-h0002"><b>Patent documents cited in the description</b></heading>
<p id="ref-p0002" num="">
<ul id="ref-ul0001" list-style="bullet">
<li><patcit id="ref-pcit0001" dnum="US2011122257A1"><document-id><country>US</country><doc-number>2011122257</doc-number><kind>A1</kind></document-id></patcit><crossref idref="pcit0001">[0006]</crossref></li>
</ul></p>
</ep-reference-list>
</ep-patent-document>
