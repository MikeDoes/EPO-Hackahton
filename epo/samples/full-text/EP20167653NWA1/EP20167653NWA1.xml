<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE ep-patent-document PUBLIC "-//EPO//EP PATENT DOCUMENT 1.5.1//EN" "ep-patent-document-v1-5-1.dtd">
<!-- This XML data has been generated under the supervision of the European Patent Office -->
<ep-patent-document id="EP20167653A1" file="EP20167653NWA1.xml" lang="en" country="EP" doc-number="3889969" kind="A1" date-publ="20211006" status="n" dtd-version="ep-patent-document-v1-5-1">
<SDOBI lang="en"><B000><eptags><B001EP>ATBECHDEDKESFRGBGRITLILUNLSEMCPTIESILTLVFIROMKCYALTRBGCZEEHUPLSKBAHRIS..MTNORSMESMMAKHTNMD..........</B001EP><B005EP>J</B005EP><B007EP>BDM Ver 2.0.12 (4th of August) -  1100000/0</B007EP></eptags></B000><B100><B110>3889969</B110><B120><B121>EUROPEAN PATENT APPLICATION</B121></B120><B130>A1</B130><B140><date>20211006</date></B140><B190>EP</B190></B100><B200><B210>20167653.3</B210><B220><date>20200402</date></B220><B250>en</B250><B251EP>en</B251EP><B260>en</B260></B200><B400><B405><date>20211006</date><bnum>202140</bnum></B405><B430><date>20211006</date><bnum>202140</bnum></B430></B400><B500><B510EP><classification-ipcr sequence="1"><text>G16H  40/20        20180101AFI20200819BHEP        </text></classification-ipcr><classification-ipcr sequence="2"><text>G16H  40/63        20180101ALI20200819BHEP        </text></classification-ipcr><classification-ipcr sequence="3"><text>G06Q  10/06        20120101ALN20200819BHEP        </text></classification-ipcr></B510EP><B520EP><classifications-cpc><classification-cpc sequence="1"><text>G16H  40/20        20180101 FI20200811BHEP        </text></classification-cpc><classification-cpc sequence="2"><text>G16H  50/70        20180101 LA20200811BHEP        </text></classification-cpc><classification-cpc sequence="3"><text>G16H  40/63        20180101 LI20200811BHEP        </text></classification-cpc><classification-cpc sequence="4"><text>A61B   6/032       20130101 LA20201223BHEP        </text></classification-cpc><classification-cpc sequence="5"><text>A61B   6/548       20130101 LA20201223BHEP        </text></classification-cpc></classifications-cpc></B520EP><B540><B541>de</B541><B542>SYSTEM ZUR MEDIZINISCHEN BILDGEBUNG</B542><B541>en</B541><B542>MEDICAL IMAGING SYSTEM</B542><B541>fr</B541><B542>SYSTÈME D'IMAGERIE MÉDICALE</B542></B540><B590><B598>1</B598></B590></B500><B700><B710><B711><snm>Koninklijke Philips N.V.</snm><iid>101851185</iid><irf>2019P01021EP</irf><adr><str>High Tech Campus 52</str><city>5656 AG Eindhoven</city><ctry>NL</ctry></adr></B711></B710><B720><B721><snm>HELLE, Michael Günter</snm><adr><str>c/o Philips International B.V. - Intellectual
Property &amp; Standards High Tech Campus 5</str><city>5656 AE Eindhoven</city><ctry>NL</ctry></adr></B721><B721><snm>AMTHOR, Thomas</snm><adr><str>c/o Philips International B.V. - Intellectual
Property &amp; Standards High Tech Campus 5</str><city>5656 AE Eindhoven</city><ctry>NL</ctry></adr></B721><B721><snm>VUPPALA, Sunil Kumar</snm><adr><str>c/o Philips International B.V. - Intellectual
Property &amp; Standards High Tech Campus 5</str><city>5656 AE Eindhoven</city><ctry>NL</ctry></adr></B721><B721><snm>WEISS, Steffen</snm><adr><str>c/o Philips International B.V. - Intellectual
Property &amp; Standards High Tech Campus 5</str><city>5656 AE Eindhoven</city><ctry>NL</ctry></adr></B721><B721><snm>SISODIA, Rajendra Singh</snm><adr><str>c/o Philips International B.V. - Intellectual
Property &amp; Standards High Tech Campus 5</str><city>5656 AE Eindhoven</city><ctry>NL</ctry></adr></B721><B721><snm>JOHNSON, Mark</snm><adr><str>c/o Philips International B.V. - Intellectual
Property &amp; Standards High Tech Campus 5</str><city>5656 AE Eindhoven</city><ctry>NL</ctry></adr></B721><B721><snm>VOGMEIER, Gereon</snm><adr><str>c/o Philips International B.V. - Intellectual
Property &amp; Standards High Tech Campus 5</str><city>5656 AE Eindhoven</city><ctry>NL</ctry></adr></B721></B720><B740><B741><snm>Philips Intellectual Property &amp; Standards</snm><iid>101808802</iid><adr><str>High Tech Campus 5</str><city>5656 AE Eindhoven</city><ctry>NL</ctry></adr></B741></B740></B700><B800><B840><ctry>AL</ctry><ctry>AT</ctry><ctry>BE</ctry><ctry>BG</ctry><ctry>CH</ctry><ctry>CY</ctry><ctry>CZ</ctry><ctry>DE</ctry><ctry>DK</ctry><ctry>EE</ctry><ctry>ES</ctry><ctry>FI</ctry><ctry>FR</ctry><ctry>GB</ctry><ctry>GR</ctry><ctry>HR</ctry><ctry>HU</ctry><ctry>IE</ctry><ctry>IS</ctry><ctry>IT</ctry><ctry>LI</ctry><ctry>LT</ctry><ctry>LU</ctry><ctry>LV</ctry><ctry>MC</ctry><ctry>MK</ctry><ctry>MT</ctry><ctry>NL</ctry><ctry>NO</ctry><ctry>PL</ctry><ctry>PT</ctry><ctry>RO</ctry><ctry>RS</ctry><ctry>SE</ctry><ctry>SI</ctry><ctry>SK</ctry><ctry>SM</ctry><ctry>TR</ctry></B840><B844EP><B845EP><ctry>BA</ctry></B845EP><B845EP><ctry>ME</ctry></B845EP></B844EP><B848EP><B849EP><ctry>KH</ctry></B849EP><B849EP><ctry>MA</ctry></B849EP><B849EP><ctry>MD</ctry></B849EP><B849EP><ctry>TN</ctry></B849EP></B848EP></B800></SDOBI>
<abstract id="abst" lang="en">
<p id="pa01" num="0001">The present disclosure relates to a method for operating a medical imaging system (100), the method carried out by use of a data processing unit (120), the method comprising:<br/>
- obtaining (S1), by a computational prediction model, time-invariant patient information,<br/>
- generating (S2), by the computational prediction model, a patient profile parametrized based on at least the obtained time-invariant patient information,<br/>
- obtaining (S3), by the computational prediction model, at least one current clinical workflow parameter, and<br/>
- providing (S4), by the computational prediction model, a prediction comprising at least a patient-specific operation workflow based on at least correlating the generated patient profile with the obtained current clinical workflow parameter, the predicted patient-specific operation workflow to be used for operating the medical imaging system (100).
<img id="iaf01" file="imgaf001.tif" wi="100" he="70" img-content="drawing" img-format="tif"/></p>
</abstract>
<description id="desc" lang="en"><!-- EPO <DP n="1"> -->
<heading id="h0001">FIELD OF THE INVENTION</heading>
<p id="p0001" num="0001">The present disclosure relates to medical imaging. In particular, the present disclosure relates to a medical imaging system, a method for operating a medical imaging system, a method for training a computational model at least partly adapted for operating a medical imaging device, a computer program element, and a computer-readable medium.</p>
<heading id="h0002">BACKGROUND OF THE INVENTION</heading>
<p id="p0002" num="0002">It may be desired for medical imaging facilities to have a high patient throughput. At the same time, patient engagement and experience are becoming more important and may be even part of reimbursement in selected markets. Moreover, medical imaging is to become more and more autonomous with less operator-dependent actions and more automated workflow steps.</p>
<p id="p0003" num="0003">Decreased patient throughput can be a consequence of multiple different issues within the medical imaging workflow. For example, delayed patient show-up, unexpected patient behavior, e.g. due to lack of information presented to the patient, patient's anxiety etc., patients not able to follow instructions, such as instructions regarding e.g. breath holds, lying still etc. Moreover, image degradation due to artifacts and repeated measurements or even revisits of patients may be caused by improper patient information, so that changes of the medical imaging workflow or imaging protocol adaptions are to be made on-the-fly by, for example, an operator of the medical imaging system.</p>
<heading id="h0003">SUMMARY OF THE INVENTION</heading>
<p id="p0004" num="0004">There is, therefore, a need to improve a medical imaging system in terms of optimizing a medical imaging workflow. The object of the present invention is solved by the subject-matter of the appended independent claims, wherein further embodiments are incorporated in the dependent claims.</p>
<p id="p0005" num="0005">According to a first aspect, there is provided a method for operating a medical imaging system, the method carried out by use of a data processing unit, the method comprising:<!-- EPO <DP n="2"> -->
<ul id="ul0001" list-style="dash" compact="compact">
<li>obtaining, by a computational prediction model, time-invariant patient information;</li>
<li>generating, by the computational prediction model, a patient profile parametrized based on at least the obtained time-invariant patient information;</li>
<li>obtaining, by the computational prediction model, at least one current clinical workflow parameter, and</li>
<li>providing, by the computational prediction model, a prediction comprising at least a patient-specific operation workflow based on at least correlating the generated patient profile with the obtained current clinical workflow parameter, the predicted patient-specific operation workflow to be used for operating the medical imaging system.</li>
</ul></p>
<p id="p0006" num="0006">In other words, the predicted patient-specific operation workflow may be applied to the medical imaging system in a real-time manner to operate the medical imaging system based on that workflow.</p>
<p id="p0007" num="0007">The method may be computer-implemented and may at least partly be carried out by use of the data processing unit, which may be part of the medical imaging system itself or an interrelated system or device. The data processing unit may be functionally coupled to one or more input data interfaces, one or more output data interfaces, one or more data communication interfaces, etc. The method may be implemented in one or more software modules, and/or may be implemented in suitable hardware.</p>
<p id="p0008" num="0008">The medical imaging system may further comprise one or more of a Magnetic Resonance Imaging (MRI) device, a computed tomography (CT) device, an X-ray imaging device, or a similar device adapted to acquire medical images, a imaging controller, a database, a data interface to a clinical patient information system, a communication interface, etc.</p>
<p id="p0009" num="0009">The computational prediction model may be understood as a model that uses, for example, a functional relationship established by e.g. a regression method or the like to provide a forecast of a dependent variable. It may also be understood as a simulation that outputs a system behavior in response to input data. The prediction model may also comprise at least one neural network, where e.g. dynamic and physical connections of the medical image system are represented by a network structure. There, it is assumed that the system output is a sum of several parts composed of input variables. The model may be compiled based on one or more input data, and may be adapted to be trained and/or adapted by suitable machine learning algorithms.<!-- EPO <DP n="3"> --></p>
<p id="p0010" num="0010">An effect of this method is that the overall workflow for the medical imaging can be optimized in an at least semi-automated manner, where a computational prediction model, predicts, e.g. calculates, by use of one or more of an algorithm, a neural network, etc., from fed input data, the overall workflow or at least one or more parts of it. The overall workflow may be adapted to a large extent to the specific patient, especially to the patient's behavior. For example, a schedule for examination, a scan protocol based on which the medical imaging system may be operated, a level of staff engagement, etc. may be adapted to the patient's individual needs. This may increase the throughput of a medical imaging facility, as the scan protocol including image acquisition sequences, or the like, may be dynamically adapted and/or optimized. It may also improve the patient engagement and experience, as the workflow may also be adapted to the patient's individual needs in terms of personal support by human staff or by human-machine communication, etc. Further, the method may allow for deciding whether an autonomous imaging process can be used at all or to which extent for the specific patient.</p>
<p id="p0011" num="0011">In an embodiment, the method may further comprise:
<ul id="ul0002" list-style="dash" compact="compact">
<li>determining, by the computational prediction model, a patient-specific risk level assigned to a specific one of a selection of operational modes of the medical imaging system, and</li>
<li>operating the medical imaging system based on the specific one of the selection of operational modes that is selected depending from the determined risk level.</li>
</ul></p>
<p id="p0012" num="0012">For example, based on the profiling information and an individual risk analysis calculation for each patient with a personal risk level or factor for an autonomous imaging procedure may be determined, e.g. calculated. Depending on the determination result, the decision for fully-autonomous, semi-autonomous and fully staff supported imaging may be approved and, optionally, documented.</p>
<p id="p0013" num="0013">According to an embodiment, the operational mode may be selected depending on whether the determined patient-specific risk level matches an assigned threshold value or an assigned threshold range.</p>
<p id="p0014" num="0014">For example, there may be a first threshold value or range assigned to a fully-autonomous operation mode, a second threshold or value or range assigned to a semi-autonomous operation mode, and third threshold value or range assigned to a fully-staff supported. If the risk level matches, for example, the third threshold, semi-autonomous or fully-autonomous operation of the medical imaging system may be prevented by e.g. the data processing unit. Further, if the risk level matches one of the first and second threshold, the<!-- EPO <DP n="4"> --> level of staff engagement may be decreased by output of respective instructions presented to the staff. Thus, autonomous imaging may be facilitated.</p>
<p id="p0015" num="0015">In an embodiment, the selection of operational modes may comprise a fully-autonomous operation mode, a semi-autonomous operation mode, and a fully-staff supported operation mode.</p>
<p id="p0016" num="0016">For example, the different operation modes may differ with regard to their degree of automation.</p>
<p id="p0017" num="0017">According to an embodiment, the time-invariant patient information may comprise one or more of at least one psychological patient parameter, at least one physiological patient parameter, a patient health status, and historical patient-specific clinical workflow data.</p>
<p id="p0018" num="0018">For example, the psychological patient parameter may comprise one or more of or may be indicative for one or more of a certain behavioral pattern, a proneness to anxiety, a risk for unexpected claustrophobia etc., a type of biorhythm, such as "early bird" vs. "night owl", a character type, such as "fighter", which may be referred to as a first character type, "academic", which may be referred to as a second character type, and "social", which may be referred to as a third character type, etc. Thereby, the first character type may indicate a patient preferring fast and efficient action and responding best to instructions delivered in a short and compact manner. Specifically, a suitable written communication style may be a set of bullet points and verbal style a series of orders which just have to be followed. The second character type may, for example, indicate a patient having a craving to understand why they are being asked to follow an instruction. As such a suitable written or verbal communication style may be an explanation of why the instruction is given attached to the instruction itself. The third character type may, for example, indicate a patient having a craving to feel connected to other patients in a similar situation. As such a suitable written or verbal communication style will be an illustration of how somebody similar to specific patient has already undergone the procedure before the instruction is given. One or more of these parameters may be obtained from a questionnaire, which may be provided in paper form and/or electronic form, measurements made to the patient, a behavior analysis based on images, for which images of the patient (shortly) before examination can be taken, either remotely or on site, and evaluated, etc. Thus, the operation of the medical imaging device may be adapted to psychological parameters of the specific patient. For example, one or more of the examination schedule, the human (patient)-machine<!-- EPO <DP n="5"> --> communication, the scan protocol, the staff engagement, etc. may be, optionally dynamically, adapted to the psychological parameters of the specific patient.</p>
<p id="p0019" num="0019">Optionally, the physiological patient parameter may comprise one or more of heart rate, a blood pressure, breathing pattern, ability to hold breath. One or more of these parameters may be obtained from one or more of a questionnaire, which may be provided remotely and/or on site in paper form and/or electronic form, or from measurements made to the patient on site. For example, these data may be measured by a mobile device or other wearable devices (e.g. health band) that comprises, for example, one or more sensors to detect a heart rate, stress level, etc. The measured data may be provided to the medical image system and/or the medical imaging facility via a communication network, or the like. The day, may also be fetched from the data store location (device cloud data) using e-consent. Additionally or alternatively, the data may be measured on-site, which means within the environment of the medical imaging system. Thus, the operation of the medical imaging device may be adapted to physiological parameters of the specific patient. For example, one or more of the human (patient)-machine communication, the imaging schedule, the scan protocol, the level of staff engagement, etc. may be adapted to the physiological parameters of the specific patient.</p>
<p id="p0020" num="0020">In an embodiment, the time-invariant patient information may at least be partly remotely obtained in an electronic manner from a computer application to be operated by the specific patient.</p>
<p id="p0021" num="0021">Optionally, the computer application can be stored and/or processed on a mobile device, such as a smartphone etc., a personal computer, a cloud computing environment, or the like. The computer application may use one or more of a questionnaire, sensor data processing, etc. to reveal the time-invariant patient information from the specific patient. The computer application may also be adapted to provide the time-invariant patient information electronically to the medical imaging system or a related system, such as a clinical patient information system. Further, the computer application may be adapted to provide a notification to the patient to remind the patient to an upcoming examination. The computer application may also be adapted to provide a user prompt to the patient along with or triggered by the notification. Thus, these data can at least partly be obtained prior to the examination on site at the medical imaging system, without requiring the patient to be on site.</p>
<p id="p0022" num="0022">Additionally or alternatively, the time-invariant patient information may in part or completely obtained from e.g. insurance information, from electronic patient records,<!-- EPO <DP n="6"> --> or the like. These data may comprise, for example, a presence and/or type of an implant, compatibility with imaging modalities etc.</p>
<p id="p0023" num="0023">According to an embodiment, the predicted patient-specific operation workflow may comprise one or more of:
<ul id="ul0003" list-style="dash" compact="compact">
<li>a schedule for examining the specific patient,</li>
<li>a scan protocol based on which imaging for examining the specific patient is controlled, the scan protocol comprising at least an image acquisition parameter,</li>
<li>a level of staff engagement for examining the specific patient, the level of staff engagement affecting a level of an autonomous operating mode of the medical imaging system,</li>
<li>a guidance for staff for examining the specific patient, the guidance comprising one or more of a visualization output, a traffic light system, and an audio output, to be presented to the staff, and</li>
<li>a type of human-machine communication between the medical imaging system and the specific patient, the type of human-machine communication adapted to the patient profile.</li>
</ul></p>
<p id="p0024" num="0024">Optionally, predicting the schedule for examining the specific patient may comprise predicting a suitable or optimized time slot for examination.</p>
<p id="p0025" num="0025">For example, from the patient profile, an optimal time slot can be advised, e.g. morning sessions for cooperative and not impaired patients and early bird-type patients that present a low probability to delay the workflow while anxious patients may be scanned in later time slots of day as extra time is required to calm them down or even give drugs. Because performance of staff members typically varies over their working time, mostly declining towards the end their shift, exams with difficult patients or scans may be scheduled early on but not first in working shifts. Thus, scheduling may be adapted based or dependent on the predicted patient-specific operation workflow.</p>
<p id="p0026" num="0026">Optionally, the scan protocol may be selected from a scan protocol pool. The scan protocol pool may comprise a number of scan protocols previously used for examination of patients having an at least similar patient profile compared with the specific patient. Further, the scan protocol may be adapted, predicted etc. by computationally analyzing an imaging log file, such as a MRI log file etc. For example, parameters such as timing, order, polarity and repetition frequency of RF pulse, applied magnetic field gradients, or the like may be derived from such imaging log file and may be used to predict, adapt etc. the scan protocol.<!-- EPO <DP n="7"> --></p>
<p id="p0027" num="0027">For example, MRI protocols are the combination of various MRI sequences which can optimally asses a particular region of the body. There is a protocol pool to choose for a particular type of scan. Extracting information from the MRI log file may be used to identify the correct combination. Spin echo sequence can have an adapted field of view, number of slices and sequence of operations with 90 and 180 degree RF pulse, which are captured from the log file. There may be different possibilities to generate the sequence of certain contrast even with pre-defined protocols. The log files may be extracted to identify timing, order, polarity and repetition frequency of RF pulse and applied magnetic field gradients. The extracted log information from similar patients of one particular scan can identify the previous workflow issues and customization of the sequence of operations there by protocols.</p>
<p id="p0028" num="0028">Optionally, the level of staff engagement for examining the specific patient may vary between 0 and 1, where 0 means no staff engagement or fully-autonomous operating mode, respectively, and 1 means fully staff supported. Staff engagement level values in between mean a semi-autonomous operating mode.</p>
<p id="p0029" num="0029">Optionally, the level of staff engagement may comprise dedicating staff for specific examinations or parts of it, based on one or more of the individual experience or expert level, availability, medical or psychological quality, a type of interaction with patients, etc.</p>
<p id="p0030" num="0030">For example, a patient that need complex examination, e.g. cardiac MRI, or patients in a critical current state, such as having a high heart rate, high blood pressure, being nervous, etc., may require specifically experienced operators to handle the workflow timely. Dedicated personal to handle anxious patients can be available during certain time slots. Trainees or unexperienced operators may be advised to perform simple examinations.</p>
<p id="p0031" num="0031">Optionally, the type of human-machine communication may be an autonomous communication provided between the medical imaging system and the specific patient, and may comprise e.g. verbal communication, such as verbal instructions during preparation or scanning phases, written communication, e.g. by use of a display, user prompt etc., or the like.</p>
<p id="p0032" num="0032">In an embodiment, the historical patient-specific clinical workflow data comprises log file data relating to previous medical imaging exams of the specific patient. These data may comprise log files of the medical imaging system or of a similar system, and may be used to identify previous workflow issues of the specific patient, such as a delay, scan abort, unexpected or scan-disruptive events, or the like.<!-- EPO <DP n="8"> --></p>
<p id="p0033" num="0033">Thus, the patient profile may be generated on the basis of experience.</p>
<p id="p0034" num="0034">According to an embodiment, the historical patient-specific clinical workflow data may comprise log file data relating to previous medical imaging exams of a patient determined, by the data processing unit, based on the generated patient profile to have an at least similar patient profile compared to the specific patient.</p>
<p id="p0035" num="0035">Optionally, the generated patient profile may be classified, e.g. by use of pattern recognition. For example, a classifier may be used for this purpose, which is a mathematical function, implemented by a classification algorithm that maps input data to a category.</p>
<p id="p0036" num="0036">Thus, even if historical data for the specific patient are not yet available, such data from comparable patients may be considered.</p>
<p id="p0037" num="0037">In an embodiment, a scan protocol may be at least partly extracted from the log file data, the scan protocol comprising one or more of an image acquisition timing, an order, a polarity, a repetition frequency of RF pulse, and applied magnetic field gradients.</p>
<p id="p0038" num="0038">Thus, a suitable scan protocol may be determined at least partly based on historical data. This can be performed autonomously.</p>
<p id="p0039" num="0039">According to an embodiment, the method may further comprise:
<ul id="ul0004" list-style="dash" compact="compact">
<li>obtaining, by the computational prediction model, a current patient state, wherein the current patient state refers to a state in the presence of the patient in the environment of the medical imaging system;</li>
<li>wherein predicting the patient-specific operation workflow is further based on the obtained current patient state.</li>
</ul></p>
<p id="p0040" num="0040">For example, the current patient state may be measured by parameters as current blood pressure and heart rate, time elapsed since last meal, e.g. indicating the patient to be sleepy, hungry, restless etc., current medication, e.g. if affecting attentiveness, current mood etc. These data may be obtained by suitable questionnaire performed when patient arrives at the imaging facility, by taking and processing images of the patient, by measurements, etc.</p>
<p id="p0041" num="0041">Thus, the workflow may be adapted more precisely.</p>
<p id="p0042" num="0042">In an embodiment, predicting the patient-specific operation workflow is further based on staff feedback data comprising one or more of: a staff expert-level, a staff availability, and a preferred type of interaction with the patient and/or the medical imaging system.<!-- EPO <DP n="9"> --></p>
<p id="p0043" num="0043">The staff feedback data may be obtained e.g. via a input data interface, and may be mapped to the patient and/or the examination procedure. The staff feedback may comprise one or more of an expert level, availability, a preferred type of interaction with patients etc.</p>
<p id="p0044" num="0044">According to a second aspect, there is provided a method for training a computational model, the model to be trained for at least partly operating a medical imaging system, the method comprising:
<ul id="ul0005" list-style="dash" compact="compact">
<li>obtaining, by a training data processing module, a patient profile parametrized based on at least time-invariant patient information and a current patient state,</li>
<li>obtaining, by the training data processing module, log data assigned to the medical imaging system based on the obtained patient profile to identify log data directly assigned to the specific patient or to identify log data of a patient having at least a similar patient profile,</li>
<li>generating, by the training data processing module, training data by correlating the obtained patient profile with the obtained log data, the training data having at least one label indicating the correlation between the obtained patient profile with the obtained log data, and</li>
<li>providing the generated training data to the model.</li>
</ul></p>
<p id="p0045" num="0045">The method may use one or more suitable learning algorithms, which may particularly suitable for supervised learning. The training data may be labelled to be machine-readable.</p>
<p id="p0046" num="0046">According to a third aspect, a medical imaging system is provided. The medical imaging system comprises at least a data processing unit, the data processing unit adapted to compute a model adapted to operate at least parts of the medical imaging system, the processing unit configured to:
<ul id="ul0006" list-style="dash" compact="compact">
<li>obtain time-invariant patient information,<br/>
generate a patient profile parametrized based on at least the obtained time-invariant patient information,</li>
<li>obtain at least one current clinical workflow parameter, and</li>
<li>provide a prediction comprising at least a patient-specific operation workflow based on at least correlating the generated patient profile with the obtained current clinical workflow parameter, the predicted patient-specific operation workflow to be used for operating the medical imaging system.</li>
</ul></p>
<p id="p0047" num="0047">Optionally, the medical imaging system comprises an imaging device.<!-- EPO <DP n="10"> --></p>
<p id="p0048" num="0048">According to a fourth aspect, a computer program element for operating a medical imaging system is provided, which, when being executed by a data processing unit, is adapted to perform the method according to the first aspect and/or the second aspect.</p>
<p id="p0049" num="0049">According to a fifth aspect, there is provided a computer readable medium having stored the computer program element of the fourth aspect.</p>
<p id="p0050" num="0050">These and other aspects of the present invention will become apparent from and elucidated with reference to the embodiments described hereinafter.</p>
<heading id="h0004">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p0051" num="0051">Exemplary embodiments of the invention will be described in the following drawings.
<ul id="ul0007" list-style="none" compact="compact">
<li><figref idref="f0001">Fig. 1</figref> illustrates a medical imaging system according to an embodiment of the present invention.</li>
<li><figref idref="f0001">Fig. 2</figref> illustrates in a block diagram predicting and/or providing a patient-specific operation workflow according to an embodiment of the present invention.</li>
<li><figref idref="f0002">Fig. 3</figref> illustrates in a block diagram training of a computational prediction model according to an embodiment of the present invention.</li>
<li><figref idref="f0002">Fig. 4</figref> illustrates in a flow diagram of a method for operating a medical imaging system according to an embodiment of the present invention.</li>
</ul></p>
<heading id="h0005">DETAILED DESCRIPTION OF EMBODIMENTS</heading>
<p id="p0052" num="0052"><figref idref="f0001">Fig. 1</figref> illustrates a medical imaging system 100, preferably located in a medical imaging facility, wherein medical imaging system 100 may, for example, be adapted to provide magnetic resonance imaging (MRI), computed tomography (CT) imaging, X-ray imaging, or the like, of a patient P to be examined, which is in the following also referred to as the specific patient. For this purpose, medical imaging system 100 comprises a medical imaging device 110, which may be adapted for medical imaging using at least one of the above imaging techniques. Further, medical imaging system 100 comprises a controller 120, which may be a suitable type of computer, adapted to control medical imaging system 100 and/or interrelated systems. In particular, controller 120 may be adapted to process a computational prediction model as described in more detail further below, and to operate medical imaging system 100 based on the processed computational prediction model. Controller 120, which may be referred to as a data processing unit, may comprise one or more of an input data interface, an output data interface, a communication interface to<!-- EPO <DP n="11"> --> interrelated systems, devices etc., such as a clinical information system, a computer application, processed by e.g. a personal computer to be operated by patient P, a mobile device to be carried and/or operated by patient P, etc. In <figref idref="f0001">Fig. 1</figref>, a computer adapted to process the above computer application is designated with reference sign 130, wherein computer 130 is, by way of example, provided as a mobile device, wherein the computer application may also be processed on a desktop computer, or the like. Computer 130 may be coupled to medical imaging system 100, and particularly to controller 120, by a communication interface, a communication network, such as the internet, or the like. It is noted that computer 130, in at least some embodiments, may comprise or may interact with one or more sensors (not shown) adapted to measure a heart rate, a blood pressure, a stress level, sleeping behavior, or the like, of patient P. Further, medical imaging system 100 may comprise one or more sensors 140, such as a camera, a heart rate monitor, a blood pressure monitor, or the like, adapted to collect corresponding patient data on site at medical imaging system 100. In at least some embodiments, one or more of sensors 140 may be arranged within a bore of medical imaging device 110 or next to it.</p>
<p id="p0053" num="0053">Further, medical imaging system 100 may be embedded in or may interact with a clinical information system, which is designated here with reference sign 1000. Such a clinical information system 1000 may be adapted to, e.g. by use of a database and/or data interface to medical imaging system 100, collect and/or provide patient data, such as medical patient records, insurance data, historical patient-specific clinical workflow data, a health status of a patient, etc. There may be at least one data interface adapted to allow data transfer between medical imaging system 100 and clinical information system 1000.</p>
<p id="p0054" num="0054">In addition, medical imaging system 100 may be adapted to be operated at least partly autonomously, wherein three operation modes may be distinguished - fully-autonomous, semi-autonomous, and fully-staff supported. In the fully-autonomous operating mode, one or more of examination scheduling, patient communication, scan protocol selection and/or adaptation, and the imaging procedure may be carried out without human intervention, i.e. staff intervention. In the semi-autonomous operating mode, some parts of the examination may be carried out autonomously without human intervention, while other part of the examination may be carried out by staff. In the fully-staff supported operating mode, at least most relevant or all parts of the examination may carried out by staff. An individual patient-specific operation workflow may be assigned to each of these operating modes.<!-- EPO <DP n="12"> --></p>
<p id="p0055" num="0055"><figref idref="f0001">Fig.2</figref> illustrates in a block diagram predicting and/or providing a patient-specific operation workflow. According to <figref idref="f0001">Fig. 2</figref>, blocks 150<sub>1</sub>, 150<sub>2</sub>, 150<sub>3</sub>, 150<sub>4</sub> represent input data or the collection of input data for the above computational prediction model, wherein the input data represented by blocks 150<sub>1</sub>, 150<sub>2</sub>, 150<sub>3</sub>, 150<sub>4</sub> may be referred to as time-invariant patient information data. The time-invariant patient information data comprises one or more of at least one psychological patient parameter (see block 150<sub>1</sub>), at least one physiological patient parameter (see block 150<sub>2</sub>), a patient health status (see block 150<sub>3</sub>), and historical patient-specific clinical workflow data (see block 150<sub>4</sub>). In a block 150<sub>5</sub>, the time-invariant patient information is processed to a parametrized patient profile assigned to patient P, which may be referred to as intermediate output data.</p>
<p id="p0056" num="0056">Block 150<sub>5</sub> may be referred to as a processing block, wherein a dashed line surrounding this block indicates that the block forms at least part of the above computational prediction model, which is processed by controller 120.</p>
<p id="p0057" num="0057">Further, blocks 150<sub>6</sub>, 150<sub>7</sub> represent further input data for the above computational prediction model, which input data is different to the above time-invariant patient information data. In particular, block 150<sub>6</sub> represents current clinical workflow parameter comprising one or more of current delays in each procedure step of examinations carried out in the medical imaging facility, a number of re-scans required in the medical imaging facility, etc. Block 150<sub>7</sub> represents staff feedback data comprising one or more of a staff expert-level, a staff availability, and a preferred type of interaction with the patient and/or medical imaging system 100. Optionally, further input data may be formed by a current patient state, wherein the current patient state refers to a state in the presence of patient P in the environment of medical imaging system 100.</p>
<p id="p0058" num="0058">A block 150<sub>8</sub> represents the above computational prediction model or its processing, respectively. Block 150<sub>8</sub> may also be referred to as a processing block wherein a dashed line surrounding this block indicates that the block forms at least part of the above computational prediction model, which is processed by controller 120. Blocks 150<sub>9</sub>, 150<sub>10</sub>, 150<sub>11</sub>, 150<sub>12</sub> represent output data of the above computational prediction model. These output data may also be referred to as a patient-specific operation workflow. In other words, a part or all of these output data may be combined and/or further processed to the patient-specific operation workflow, as indicated by a block 150<sub>13</sub>.</p>
<p id="p0059" num="0059">In more detail, block 150<sub>1</sub> represents psychological parameter of patient P, wherein these psychological patient parameter may comprise one or more of or may be indicative for one or more of a certain behavioral pattern, a proneness to anxiety, a risk for<!-- EPO <DP n="13"> --> unexpected claustrophobia etc., a type of biorhythm, such as "early bird" vs. "night owl", a character type, such as "fighter", which may be referred to as a first character type, "academic", which may be referred to as a second character type, and "social", which may be referred to as a third character type, etc. As indicated in <figref idref="f0001">Fig. 2</figref>, these data may, for example, be obtained from patient P prior to the examination or the date of examination, respectively. In particular, these data may be derived from measurements of computer 130 or from the computer application that runs on computer 130, by a questionnaire provided by the computer application or in paper form, etc. Additionally or alternatively, at least a part of the psychological patient parameter may be obtained from the one or more sensors 140 at site of medical imaging system 100.</p>
<p id="p0060" num="0060">Block 150<sub>2</sub> represents physiological patient parameter of patient P, wherein these physiological patient parameter may comprise one or more of a heart rate, a blood pressure, breathing pattern, ability to hold breath, etc. As indicated in <figref idref="f0001">Fig. 2</figref>, these data may, for example, be obtained from patient P prior to the examination or the date of examination, respectively. In particular, these data may be derived from measurements of computer 130 or from the computer application that runs on computer 130, by a questionnaire provided by the computer application or in paper form, etc. Additionally or alternatively, at least a part of the physiological patient parameter may be obtained from the one or more sensors 140 at site of medical imaging system 100.</p>
<p id="p0061" num="0061">Block 150<sub>3</sub> represents other patient information and/or condition, such as weight, height, BMI, disabilities, motion impairment, implants carried in the body, allergies, etc. of patient P. As indicated in <figref idref="f0001">Fig. 2</figref>, these data may, for example, be obtained from patient P prior to the examination or the date of examination, respectively. In particular, these data may be derived from measurements of computer 130 or from the computer application that runs on computer 130, by a questionnaire provided by the computer application or in paper form, etc. Additionally or alternatively, at least a part of the psychological patient parameter may be obtained from the one or more sensors 140 at site of medical imaging system 100. Optionally, at least a part of the other patient information and/or condition of patient P may be obtained from an electronic patient record, insurance information, or the like, collected and/or provided, for example, by clinical information system 1000.</p>
<p id="p0062" num="0062">Block 150<sub>4</sub> represents historical patient-specific clinical workflow data of patient P or, alternatively, of another patient having an at least similar patient profile. These data comprises previous log file data relating to previous medical imaging exams of patient P<!-- EPO <DP n="14"> --> or a patient having a similar patient profile. Further, these data may be indicative for delays caused by or with the patient, or other unexpected events.</p>
<p id="p0063" num="0063">Block 150<sub>5</sub> represents a processing block, which may be processed by use of the above computational prediction model or another suitable processing module.</p>
<p id="p0064" num="0064">In at least some embodiments, block 150<sub>9</sub> represents a predicted and/or proposed patient engagement regarding patient P, comprising e.g. special preparation of patient P, such as breath hold, delivering dedicated information regarding the examination procedure, addressing anxiety, etc.</p>
<p id="p0065" num="0065">In at least some embodiments, block 150<sub>10</sub> represents a predicted and/or proposed patient experience which can be understood as how experienced the patient is in this type of examination. These data may comprise predicting and/or proposing of e.g. staff assignment depending on patient P's individual needs, selecting or composing a suitable scan protocol based on an expected level of patient cooperation, etc.</p>
<p id="p0066" num="0066">In at least some embodiments, block 150<sub>11</sub> represents a predicted and/or proposed staff engagement, such as e.g. staff assignment depending on certain examination procedures according to an individual expert-level and/or training status of the individual staff, staff assignment depending on a desired type of interaction, etc.</p>
<p id="p0067" num="0067">In at least some embodiments, block 150<sub>12</sub> represents a predicted and/or proposed workflow optimization, such as selecting or composing an imaging scan protocol for certain examinations according to patient P's abilities, such as e.g. free breathing, breath hold, etc., or assignment of qualified staff qualified for e.g. sensor placement, contrast agent delivery, etc.</p>
<p id="p0068" num="0068">Block 150<sub>13</sub> represents further processing of the above data to the patient-specific operation workflow. The latter may comprise the predicted patient-specific operation workflow comprises one or more of a schedule for examining the patient P, a scan protocol based on which imaging for examining patient P is controlled, the scan protocol comprising at least an image acquisition parameter, a level of staff engagement for examining patient P, the level of staff engagement affecting a level of the autonomous operating mode of medical imaging system 100, a guidance for staff for examining patient P, the guidance comprising one or more of a visualization output, a traffic light system, and an audio output, to be presented to the staff, and a type of human-machine communication between the medical imaging system and patient P, the type of human-machine communication adapted to the patient profile.<!-- EPO <DP n="15"> --></p>
<p id="p0069" num="0069">In at least some embodiments, one or more of blocks 150<sub>5</sub>, 150<sub>8</sub>, and 150<sub>13</sub> are adapted to determine a risk level of patient P, wherein the risk level is assigned to a specific one of the operational modes of medical imaging system 100. On this basis, medical imaging system 100 may be operated based on the specific of the operational modes that is selected depending from the determined risk level. Further, in at least some embodiments, the operational mode is selected depending on whether the determined patient-specific risk level matches an assigned threshold value or an assigned threshold range.</p>
<p id="p0070" num="0070">In the following, application examples of one or more of the above embodiments will be described.</p>
<p id="p0071" num="0071">In at least some embodiments, patient P may be scheduled for a brain MRI. Prior to the examination, patient P is reminded of the examination via the above computer application, e.g. by use of a personal computer, a mobile device, or the like. Additionally, patient P is presented a questionnaire to be filled upfront. For example, a question may be: "do you have metal implants? Are you anxious in small and narrow rooms?" etc. Optionally, other patient information, such as weight, allergies etc. may be asked. The answers may be sent to the medical imaging facility for further processing. For example, in a database of the medical imaging facility, patient P is already present and known from an initial MRI exam in the past. At that time, for example, patient P presented anxious and had problems to stay in medical imaging device 110 for more than 20 minutes. The above computational prediction model may be adapted to correlate such information, e.g. via a neural network, and predicts and/or proposes several options for the scheduling of patient P. For example, the scan protocol may be chosen and/or adapted in such a way that only fast imaging sequences are applied and the whole exam does not exceed the 20 minutes. Moreover, the staff may be advised to spend more time in talking to patient P in order to calm him down. Thus, the time slot for this patient may be extended or planned at the end of the work day.</p>
<p id="p0072" num="0072">In at least some embodiments, patient P may be scanned for a cardiac MR exam. Such exams critically depend on the heart rate of the patient. A lower heart rate may result in better image quality and a lower probability of scan interruption. Overall scan time also depends on the heart rate and its variability in a non-linear way. Cardiac scans also benefit from breath holds by the patient, improving image quality and reducing scan time. It is known that the maximal duration of breath holds (MDB) depends on the current physiological and psychological state of the patient. A high heart rate indicates a high metabolic rate which increases oxygen consumption and lowers MDB. Similarly, a meal that was just taken may result in considerably shorter MDB because lung volume is decreased and<!-- EPO <DP n="16"> --> metabolic rate increased due to digestion. Any psychological deviation form a calm state shortens MDB and increases HR. Above and further relevant input parameters, such as hear rate, breathing rate, blood pressure in comparison to average blood pressure at home, time elapsed after last meal, moisture of palms of hands indicating nervousness, current medication, further suitable parameters, may indicate the current state of patient P and may be measured when patient P arrives at the medical imaging facility and ideally again at the beginning of the cardiac exam. The computational prediction model may use a correlation of these parameters to critical intermediate quantities as MDB to predict those. Alternatively, the computational prediction model may directly propose certain MR protocols and their variants to adapt to the particular current MDB and HR. Scheduling may be changed as well on the fly if a patient is still particularly nervous, giving him some time and appropriate help to calm down. Overall scan time may be predicted to optimize scheduling for patient P and other patients.</p>
<p id="p0073" num="0073">In at least some embodiments, patient P may be scheduled for a brain examination with contrast. The patient has never been scanned before. However, based on the psychological parameters acquired through the above computer application and/or the type of examination scheduled, the computational prediction model predicts that patient P will most likely become afraid of the situation and may refuse to be examined when shown the MRI scanner, i.e. medical imaging device 110. The computational prediction model proposes that technologist A should handle this patient, because from historical data and/or staff feedback data it is known that technologist A has often been successful in handling patients of this type and in communicating in such a way that the patient feels less anxious.</p>
<p id="p0074" num="0074">In at least some embodiments, patient P may be scheduled for a spin echo MRI. MRI protocols are the combination of various MRI sequences which can optimally asses a particular region of the body. There may be a protocol pool to choose for a particular type of scan. Spin echo sequence may require one or more of adapting the field of view, the number of slices and sequence of operations with 90 and 180 degree RF pulse, which are captured from the log file. There may be different possibilities to generate the sequence of certain contrast even with pre-defined protocols. The log files may be extracted to identify timing, order, polarity and repetition frequency of RF pulse and applied magnetic field gradients. The extracted log information from similar patients, which may be identified by classification using the computational prediction model, of one particular scan can identify previous workflow issues and customization of the sequence of operations there by protocols.<!-- EPO <DP n="17"> --></p>
<p id="p0075" num="0075">In at least some embodiments, in one of the autonomous imaging operation modes of medical imaging system 100, an autonomous communication with patient P may be needed. Such a communication, which may comprise written and/or verbal communication, the style of communication may be adapted to the patient profile of patient P, by the computational prediction model. For example, a patient P having the profile of a Fighter probably prefers a rather fast and efficient action and respond best to instructions delivered in a short and compact manner. Specifically, the best written communication style will be a set of bullet points and verbal style a series of orders which just have to be followed. A patient P having an academic profile probably prefers having a craving to understand why they are being asked to follow an instruction. As such, a preferred written or verbal communication style will be an explanation of why the instruction is given attached to the instruction itself. A patient P having a social profile probably has a craving to feel connected to other patients in a similar situation. As such, a preferred written or verbal communication style may be an illustration of how somebody similar to them has already undergone the procedure before the instruction is given.</p>
<p id="p0076" num="0076">In at least some embodiments, different patient profiles will guide staff to approach patient P with a certain behavior, e.g. patients who are very knowledgeable may require staff willing and able to provide a lot of clinical and technical background. Anxious patients, for example, may require staff who are willing to take care of and calm down the patient, and who are motivated by patient satisfaction. According to the generated patient profile, the staff can be informed before seeing the patient on how to approach the patient best. For some patients, dedicated staff members may even be selected to approach and talk to the patient. Optionally, this can be indicated in the scheduling board and presented to the staff, e.g. with a traffic light system, wherein green color may be assigned to cases where no dedicated staff is required, yellow may be assigned to cases where patient P requires much information about the examination, and red color may be assigned to an anxious patient that requires extra care by the staff.</p>
<p id="p0077" num="0077"><figref idref="f0002">Fig. 3</figref> illustrates in a block diagram a method for training the above computational prediction model that is to be trained for at least partly operating medical imaging system 100. Blocks 160<sub>1</sub>, 160<sub>2</sub>, 160<sub>3</sub> represent input data and/or data sources and may comprise one or more patient metrics, log files of medical imaging system 100, and historical clinical workflow data. These input data may be collected in a central repository 160<sub>4</sub>, which may comprise e.g. a database. The computational prediction model, which in <figref idref="f0002">Fig. 3</figref> is represented by block 160<sub>5</sub>, accesses or obtains the data from central repository 160<sub>4</sub>.<!-- EPO <DP n="18"> --> In block 160<sub>6</sub>, output data of the computational prediction model are applied to medical imaging system 100, preferably in real-time, wherein block 160<sub>7</sub> represents the above patient-specific operation workflow. In particular, the method comprises obtaining, by a training data processing module, a patient profile parametrized based on at least time-invariant patient information and a current patient state, obtaining, by the training data processing module, log data assigned to the medical imaging system based on the obtained patient profile to identify log data directly assigned to the specific patient or to identify log data of a patient having at least a similar patient profile, generating, by the training data processing module, training data by correlating the obtained patient profile with the obtained log data, the training data having at least one label indicating the correlation between the obtained patient profile with the obtained log data, and providing the generated training data to the model. In other words, there is provided a method for training a computational model, the model to be trained for at least partly operating a medical imaging system. The method comprises obtaining, by a training data processing module, a patient profile parametrized based on at least time-invariant patient information and a current patient state. The method further comprises obtaining, by the training data processing module, log data assigned to the medical imaging system based on the obtained patient profile to identify log data directly assigned to the specific patient or to identify log data of a patient having at least a similar patient profile. Further, the method comprises generating, by the training data processing module, training data by correlating the obtained patient profile with the obtained log data, the training data having at least one label indicating the correlation between the obtained patient profile with the obtained log data, and providing the generated training data to the computational prediction model.</p>
<p id="p0078" num="0078"><figref idref="f0002">Fig. 4</figref> illustrates in a flow diagram a method for operating medical imaging system 100. The method is at least partly carried out by a data processing unit, which here is the controller 120. In a step S1, the above time-invariant patient information is obtained by the above computational prediction model. In a step S2, the computational prediction model generates the above patient profile parametrized based on at least the obtained time-invariant patient information. In a step S3, the computational prediction model obtains at least one current clinical workflow parameter. In a step S4, the computational prediction model provides a prediction comprising at least a patient-specific operation workflow based on at least correlating the generated patient profile with the obtained current clinical workflow parameter, the predicted patient-specific operation workflow to be used for operating the medical imaging system.<!-- EPO <DP n="19"> --></p>
<p id="p0079" num="0079">It should to be noted that embodiments of the invention are described with reference to different subject-matter. In particular, some embodiments are described with reference to method-type claims, whereas other embodiments are described with reference to device-type claims. However, a person skilled in the art will gather from the above, and the following description that, unless otherwise notified, in addition to any combination of features belonging to one type of subject-matter, also other combinations between features relating to different subject-matters is considered to be disclosed with this application.</p>
<p id="p0080" num="0080">All features can be combined to provide a synergetic effect that is more than the simple summation of the features.</p>
<p id="p0081" num="0081">While the invention has been illustrated and described in detail in the drawings and foregoing description, such illustration and description are to be considered illustrative or exemplary, and not restrictive. The invention is not limited to the disclosed embodiments.</p>
<p id="p0082" num="0082">Other variations to the disclosed embodiments can be understood, and effected by those skilled in the art in practicing the claimed invention, from a study of the drawings, the disclosure, and the dependent claims.</p>
<p id="p0083" num="0083">In the claims, the word "comprising" does not exclude other elements or steps, and the indefinite article "a" or "an" does not exclude a plurality. A single processor, or other unit, may fulfil the functions of several items recited in the claims. The mere fact that certain measures are recited in mutually different dependent claims does not indicate that a combination of these measures cannot be used to advantage. Any reference signs in the claims should not be construed as limiting the scope.<!-- EPO <DP n="20"> --></p>
<heading id="h0006">LIST OF REFERENCE SIGNS:</heading>
<p id="p0084" num="0084">
<dl id="dl0001" compact="compact">
<dt>1000</dt><dd>clinical information system</dd>
<dt>100</dt><dd>medical imaging system</dd>
<dt>110</dt><dd>medical imaging device</dd>
<dt>120</dt><dd>controller</dd>
<dt>130</dt><dd>computer</dd>
<dt>140</dt><dd>sensor</dd>
<dt>150</dt><dd>block (e.g. functional module, software module, etc.)</dd>
<dt>160</dt><dd>block (e.g. functional module, software module, etc.)</dd>
</dl></p>
</description>
<claims id="claims01" lang="en"><!-- EPO <DP n="21"> -->
<claim id="c-en-0001" num="0001">
<claim-text>A method for operating a medical imaging system (100), the method carried out by use of a data processing unit (120), the method comprising:
<claim-text>- obtaining (S1), by a computational prediction model, time-invariant patient information,</claim-text>
<claim-text>- generating (S2), by the computational prediction model, a patient profile parametrized based on at least the obtained time-invariant patient information,</claim-text>
<claim-text>- obtaining (S3), by the computational prediction model, at least one current clinical workflow parameter, and</claim-text>
<claim-text>- providing (S4), by the computational prediction model, a prediction comprising at least a patient-specific operation workflow based on at least correlating the generated patient profile with the obtained current clinical workflow parameter, the predicted patient-specific operation workflow to be used for operating the medical imaging system (100).</claim-text></claim-text></claim>
<claim id="c-en-0002" num="0002">
<claim-text>The method according to claim 1, further comprising:
<claim-text>- determining, by the computational prediction model, a patient-specific risk level assigned to a specific one of a selection of operational modes of the medical imaging system, and</claim-text>
<claim-text>- operating the medical imaging system based on the specific one of the selection of operational modes that is selected depending from the determined risk level.</claim-text></claim-text></claim>
<claim id="c-en-0003" num="0003">
<claim-text>The method according to claim 2, wherein the operational mode is selected depending on whether the determined patient-specific risk level matches an assigned threshold value or an assigned threshold range.</claim-text></claim>
<claim id="c-en-0004" num="0004">
<claim-text>The method according to claim 2 or 3, wherein the selection of operational modes comprises a fully-autonomous operation mode, a semi-autonomous operation mode, and a fully-staff supported operation mode.<!-- EPO <DP n="22"> --></claim-text></claim>
<claim id="c-en-0005" num="0005">
<claim-text>The method according to any one of the preceding claims, wherein the time-invariant patient information comprises one or more of at least one psychological patient parameter, at least one physiological patient parameter, a patient health status, and historical patient-specific clinical workflow data.</claim-text></claim>
<claim id="c-en-0006" num="0006">
<claim-text>The method according to any one of the preceding claims, wherein the time-invariant patient information is at least partly remotely obtained in an electronic manner from a computer application to be operated by the specific patient.</claim-text></claim>
<claim id="c-en-0007" num="0007">
<claim-text>The method according to any one of the preceding claims, wherein the predicted patient-specific operation workflow comprises one or more of:
<claim-text>- a schedule for examining the specific patient,</claim-text>
<claim-text>- a scan protocol based on which imaging for examining the specific patient is controlled, the scan protocol comprising at least an image acquisition parameter,</claim-text>
<claim-text>- a level of staff engagement for examining the specific patient, the level of staff engagement affects a level of an autonomous operating mode of the medical imaging system,</claim-text>
<claim-text>- a guidance for staff for examining the specific patient, the guidance comprising one or more of a visualization output, a traffic light system, and an audio output, to be presented to the staff, and</claim-text>
<claim-text>- a type of human-machine communication between the medical imaging system and the specific patient, the type of human-machine communication adapted to the patient profile.</claim-text></claim-text></claim>
<claim id="c-en-0008" num="0008">
<claim-text>The method according to any one of the preceding claims, wherein the historical patient-specific clinical workflow data comprises log file data relating to previous medical imaging exams of the specific patient.</claim-text></claim>
<claim id="c-en-0009" num="0009">
<claim-text>The method according to any one of claims 1 to 7, wherein the historical patient-specific clinical workflow data comprises log file data relating to previous medical imaging exams of a patient determined, by the data processing unit, based on the generated patient profile to have an at least similar patient profile compared to the specific patient.</claim-text></claim>
<claim id="c-en-0010" num="0010">
<claim-text>The method according to claim 8 or 9, wherein, a scan protocol is extracted from the log file data, the scan protocol comprising one or more of an image acquisition<!-- EPO <DP n="23"> --> timing, an order, a polarity, a repetition frequency of RF pulse, and applied magnetic field gradients.</claim-text></claim>
<claim id="c-en-0011" num="0011">
<claim-text>The method according to any one of the preceding claims, further comprising:
<claim-text>- obtaining, by the computational prediction model, a current patient state, wherein the current patient state refers to a state in the presence of the patient in the environment of the medical imaging system,</claim-text>
<claim-text>- wherein predicting the patient-specific operation workflow is further based on the obtained current patient state.</claim-text></claim-text></claim>
<claim id="c-en-0012" num="0012">
<claim-text>The method according to any one of the preceding claims, wherein predicting the patient-specific operation workflow is further based on staff feedback data comprising one or more of: a staff expert-level, a staff availability, and a preferred type of interaction with the patient and/or the medical imaging system.</claim-text></claim>
<claim id="c-en-0013" num="0013">
<claim-text>A medical imaging system (100), comprising a data processing unit (120), the data processing unit (120) adapted to compute a prediction model adapted to operate at least parts of the medical imaging system, the processing unit configured to:
<claim-text>- obtain time-invariant patient information,</claim-text>
<claim-text>- generate a patient profile parametrized based on at least the obtained time-invariant patient information,</claim-text>
<claim-text>- obtain at least one current clinical workflow parameter, and</claim-text>
<claim-text>- provide a prediction comprising at least a patient-specific operation workflow based on at least correlating the generated patient profile with the obtained current clinical workflow parameter, the predicted patient-specific operation workflow to be used for operating the medical imaging system.</claim-text></claim-text></claim>
<claim id="c-en-0014" num="0014">
<claim-text>A computer program element for operating a medical imaging system, which, when being executed by a data processing unit, is adapted to perform the method according to any one of claims 1 to 12 or the method according to claim 13.</claim-text></claim>
<claim id="c-en-0015" num="0015">
<claim-text>A computer readable medium, having stored the computer program element of claim 14.</claim-text></claim>
</claims>
<drawings id="draw" lang="en"><!-- EPO <DP n="24"> -->
<figure id="f0001" num="1,2"><img id="if0001" file="imgf0001.tif" wi="147" he="221" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="25"> -->
<figure id="f0002" num="3,4"><img id="if0002" file="imgf0002.tif" wi="148" he="220" img-content="drawing" img-format="tif"/></figure>
</drawings>
<search-report-data id="srep" lang="en" srep-office="EP" date-produced=""><doc-page id="srep0001" file="srep0001.tif" wi="151" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="151" he="233" type="tif"/><doc-page id="srep0003" file="srep0003.tif" wi="155" he="233" type="tif"/></search-report-data><search-report-data date-produced="20200817" id="srepxml" lang="en" srep-office="EP" srep-type="ep-sr" status="n"><!--
 The search report data in XML is provided for the users' convenience only. It might differ from the search report of the PDF document, which contains the officially published data. The EPO disclaims any liability for incorrect or incomplete data in the XML for search reports.
 -->

<srep-info><file-reference-id>2019P01021EP</file-reference-id><application-reference><document-id><country>EP</country><doc-number>20167653.3</doc-number></document-id></application-reference><applicant-name><name>Koninklijke Philips N.V.</name></applicant-name><srep-established srep-established="yes"/><srep-invention-title title-approval="yes"/><srep-abstract abs-approval="yes"/><srep-figure-to-publish figinfo="by-applicant"><figure-to-publish><fig-number>1</fig-number></figure-to-publish></srep-figure-to-publish><srep-info-admin><srep-office><addressbook><text>MN</text></addressbook></srep-office><date-search-report-mailed><date>20200825</date></date-search-report-mailed></srep-info-admin></srep-info><srep-for-pub><srep-fields-searched><minimum-documentation><classifications-ipcr><classification-ipcr><text>G16H</text></classification-ipcr><classification-ipcr><text>G06Q</text></classification-ipcr></classifications-ipcr></minimum-documentation></srep-fields-searched><srep-citations><citation id="sr-cit0001"><patcit dnum="US2012190962A1" id="sr-pcit0001" url="http://v3.espacenet.com/textdoc?DB=EPODOC&amp;IDX=US2012190962&amp;CY=ep"><document-id><country>US</country><doc-number>2012190962</doc-number><kind>A1</kind><name>GLASER-SEIDNITZER KARLHEINZ [DE] ET AL</name><date>20120726</date></document-id></patcit><category>X</category><rel-claims>1-15</rel-claims><rel-passage><passage>* The whole document, in particular:Paragraphs [0013] - [0018], [0031], [0032], [0035] - [0045]; Tables 1, 2. *</passage></rel-passage></citation><citation id="sr-cit0002"><patcit dnum="US2019074083A1" id="sr-pcit0002" url="http://v3.espacenet.com/textdoc?DB=EPODOC&amp;IDX=US2019074083&amp;CY=ep"><document-id><country>US</country><doc-number>2019074083</doc-number><kind>A1</kind><name>JUNG DOROTHEE [DE] ET AL</name><date>20190307</date></document-id></patcit><category>X</category><rel-claims>1-15</rel-claims><rel-passage><passage>* The whole document, in particular:Paragraphs [0006], [0021], [0089] - [0123], [0173] - [0175]. *</passage></rel-passage></citation><citation id="sr-cit0003"><patcit dnum="US2013090946A1" id="sr-pcit0003" url="http://v3.espacenet.com/textdoc?DB=EPODOC&amp;IDX=US2013090946&amp;CY=ep"><document-id><country>US</country><doc-number>2013090946</doc-number><kind>A1</kind><name>FOO THOMAS KWOK-FAH [US] ET AL</name><date>20130411</date></document-id></patcit><category>X</category><rel-claims>1-15</rel-claims><rel-passage><passage>* The whole document, in particular:Paragraphs [0005] - [0007], [0024] - [0029], [0047], [0061] - [0065]. *</passage></rel-passage></citation><citation id="sr-cit0004"><patcit dnum="US2018137248A1" id="sr-pcit0004" url="http://v3.espacenet.com/textdoc?DB=EPODOC&amp;IDX=US2018137248&amp;CY=ep"><document-id><country>US</country><doc-number>2018137248</doc-number><kind>A1</kind><name>GOERTLER GEORG [DE] ET AL</name><date>20180517</date></document-id></patcit><category>X</category><rel-claims>1-15</rel-claims><rel-passage><passage>* The whole document, in particular:Paragraphs [0002], [0006], [0007], [0011], [0014], [0015], [0018], [0029] - [0032]. *</passage></rel-passage></citation><citation id="sr-cit0005"><patcit dnum="WO2019243400A1" id="sr-pcit0005" url="http://v3.espacenet.com/textdoc?DB=EPODOC&amp;IDX=WO2019243400&amp;CY=ep"><document-id><country>WO</country><doc-number>2019243400</doc-number><kind>A1</kind><name>KONINKLIJKE PHILIPS NV [NL]</name><date>20191226</date></document-id></patcit><category>X</category><rel-claims>1-15</rel-claims><rel-passage><passage>* The whole document, in particular:Pages 1 - 4, 11, 12; Figures 2, 3A, 3B. *</passage></rel-passage></citation><citation id="sr-cit0006"><nplcit id="sr-ncit0001" npl-type="s"><article><author><name>PIRASTEH ALI ET AL</name></author><atl>Implementation of an Online Screening and Check-In Process to Optimize Patient Workflow Before Outpatient MRI Studies</atl><serial><sertitle>JOURNAL OF THE AMERICAN COLLEGE OF RADIOLOGY, ELSEVIER, AMSTERDAM, NL</sertitle><pubdate>20160116</pubdate><vid>13</vid><ino>8</ino><doi>10.1016/J.JACR.2015.10.036</doi><issn>1546-1440</issn></serial><location><pp>page 956</pp></location><refno>XP029669317</refno></article></nplcit><category>A</category><rel-claims>6</rel-claims><rel-passage><passage>* The whole document, in particular:Section "Implementation of a solution"; Figures 1, 4. *</passage></rel-passage></citation></srep-citations><srep-admin><examiners><primary-examiner><name>Nagele, Stefan</name></primary-examiner></examiners><srep-office><addressbook><text>Munich</text></addressbook></srep-office><date-search-completed><date>20200817</date></date-search-completed></srep-admin><!--							The annex lists the patent family members relating to the patent documents cited in the above mentioned European search report.							The members are as contained in the European Patent Office EDP file on							The European Patent Office is in no way liable for these particulars which are merely given for the purpose of information.							For more details about this annex : see Official Journal of the European Patent Office, No 12/82						--><srep-patent-family><patent-family><priority-application><document-id><country>US</country><doc-number>2012190962</doc-number><kind>A1</kind><date>20120726</date></document-id></priority-application><family-member><document-id><country>DE</country><doc-number>102011002928</doc-number><kind>A1</kind><date>20120726</date></document-id></family-member><family-member><document-id><country>US</country><doc-number>2012190962</doc-number><kind>A1</kind><date>20120726</date></document-id></family-member></patent-family><patent-family><priority-application><document-id><country>US</country><doc-number>2019074083</doc-number><kind>A1</kind><date>20190307</date></document-id></priority-application><family-member><document-id><country>CN</country><doc-number>109464199</doc-number><kind>A</kind><date>20190315</date></document-id></family-member><family-member><document-id><country>DE</country><doc-number>102017215829</doc-number><kind>A1</kind><date>20181206</date></document-id></family-member><family-member><document-id><country>US</country><doc-number>2019074083</doc-number><kind>A1</kind><date>20190307</date></document-id></family-member></patent-family><patent-family><priority-application><document-id><country>US</country><doc-number>2013090946</doc-number><kind>A1</kind><date>20130411</date></document-id></priority-application><text>NONE</text></patent-family><patent-family><priority-application><document-id><country>US</country><doc-number>2018137248</doc-number><kind>A1</kind><date>20180517</date></document-id></priority-application><family-member><document-id><country>DE</country><doc-number>102016222524</doc-number><kind>A1</kind><date>20180517</date></document-id></family-member><family-member><document-id><country>US</country><doc-number>2018137248</doc-number><kind>A1</kind><date>20180517</date></document-id></family-member></patent-family><patent-family><priority-application><document-id><country>WO</country><doc-number>2019243400</doc-number><kind>A1</kind><date>20191226</date></document-id></priority-application><family-member><document-id><country>CN</country><doc-number>112292732</doc-number><kind>A</kind><date>20210129</date></document-id></family-member><family-member><document-id><country>DE</country><doc-number>112019003151</doc-number><kind>T5</kind><date>20210401</date></document-id></family-member><family-member><document-id><country>US</country><doc-number>2021118554</doc-number><kind>A1</kind><date>20210422</date></document-id></family-member><family-member><document-id><country>WO</country><doc-number>2019243400</doc-number><kind>A1</kind><date>20191226</date></document-id></family-member></patent-family></srep-patent-family></srep-for-pub></search-report-data>
</ep-patent-document>
