<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE ep-patent-document PUBLIC "-//EPO//EP PATENT DOCUMENT 1.5.1//EN" "ep-patent-document-v1-5-1.dtd">
<!-- This XML data has been generated under the supervision of the European Patent Office -->
<ep-patent-document id="EP19890890A1" file="EP19890890NWA1.xml" lang="en" country="EP" doc-number="3889898" kind="A1" date-publ="20211006" status="n" dtd-version="ep-patent-document-v1-5-1">
<SDOBI lang="en"><B000><eptags><B001EP>ATBECHDEDKESFRGBGRITLILUNLSEMCPTIESILTLVFIROMKCYALTRBGCZEEHUPLSKBAHRIS..MTNORSMESMMAKHTNMD..........</B001EP><B005EP>J</B005EP><B007EP>BDM Ver 2.0.12 (4th of August) -  1100000/0</B007EP></eptags></B000><B100><B110>3889898</B110><B120><B121>EUROPEAN PATENT APPLICATION</B121><B121EP>published in accordance with Art. 153(4) EPC</B121EP></B120><B130>A1</B130><B140><date>20211006</date></B140><B190>EP</B190></B100><B200><B210>19890890.7</B210><B220><date>20191121</date></B220><B240><B241><date>20210526</date></B241></B240><B250>ja</B250><B251EP>en</B251EP><B260>en</B260></B200><B300><B310>2018221374</B310><B320><date>20181127</date></B320><B330><ctry>JP</ctry></B330><B310>2019115598</B310><B320><date>20190621</date></B320><B330><ctry>JP</ctry></B330></B300><B400><B405><date>20211006</date><bnum>202140</bnum></B405><B430><date>20211006</date><bnum>202140</bnum></B430></B400><B500><B510EP><classification-ipcr sequence="1"><text>G06T   7/20        20170101AFI20200605BHEP        </text></classification-ipcr><classification-ipcr sequence="2"><text>G08B  13/196       20060101ALI20200605BHEP        </text></classification-ipcr><classification-ipcr sequence="3"><text>G08B  25/00        20060101ALI20200605BHEP        </text></classification-ipcr><classification-ipcr sequence="4"><text>G08B  25/04        20060101ALI20200605BHEP        </text></classification-ipcr><classification-ipcr sequence="5"><text>H04N   5/232       20060101ALI20200605BHEP        </text></classification-ipcr></B510EP><B520EP><classifications-cpc><classification-cpc sequence="1"><text>G08B  25/00        20130101 LI20200626BCEP        </text></classification-cpc><classification-cpc sequence="2"><text>G06T   7/20        20130101 LI20200626BCEP        </text></classification-cpc><classification-cpc sequence="3"><text>G08B  25/08        20130101 LI20200626BCEP        </text></classification-cpc><classification-cpc sequence="4"><text>G08B  25/04        20130101 LI20200626BCEP        </text></classification-cpc><classification-cpc sequence="5"><text>G08B  13/196       20130101 LI20200626BCEP        </text></classification-cpc><classification-cpc sequence="6"><text>H04N   5/232       20130101 LI20200626BCEP        </text></classification-cpc></classifications-cpc></B520EP><B540><B541>de</B541><B542>DETEKTOR VON VERDÄCHTIGEN UND ANORMALEN OBJEKTEN</B542><B541>en</B541><B542>SUSPICIOUS AND ABNORMAL OBJECT DETECTOR</B542><B541>fr</B541><B542>DÉTECTEUR D'OBJET SUSPECT ET ANORMAL</B542></B540><B590><B598>3</B598></B590></B500><B700><B710><B711><snm>Asilla, Inc.</snm><iid>101901262</iid><irf>236 799 a/scho</irf><adr><str>1-4-2 Nakamachi 
Machida-shi</str><city>Tokyo 194-0021</city><ctry>JP</ctry></adr></B711></B710><B720><B721><snm>KIMURA Daisuke</snm><adr><str>C/O Asilla, Inc. 1-4-2 Nakamachi</str><city>Machida-shi Tokyo 194-0021</city><ctry>JP</ctry></adr></B721></B720><B740><B741><snm>Hoffmann Eitle</snm><iid>100061036</iid><adr><str>Patent- und Rechtsanwälte PartmbB 
Arabellastraße 30</str><city>81925 München</city><ctry>DE</ctry></adr></B741></B740></B700><B800><B840><ctry>AL</ctry><ctry>AT</ctry><ctry>BE</ctry><ctry>BG</ctry><ctry>CH</ctry><ctry>CY</ctry><ctry>CZ</ctry><ctry>DE</ctry><ctry>DK</ctry><ctry>EE</ctry><ctry>ES</ctry><ctry>FI</ctry><ctry>FR</ctry><ctry>GB</ctry><ctry>GR</ctry><ctry>HR</ctry><ctry>HU</ctry><ctry>IE</ctry><ctry>IS</ctry><ctry>IT</ctry><ctry>LI</ctry><ctry>LT</ctry><ctry>LU</ctry><ctry>LV</ctry><ctry>MC</ctry><ctry>MK</ctry><ctry>MT</ctry><ctry>NL</ctry><ctry>NO</ctry><ctry>PL</ctry><ctry>PT</ctry><ctry>RO</ctry><ctry>RS</ctry><ctry>SE</ctry><ctry>SI</ctry><ctry>SK</ctry><ctry>SM</ctry><ctry>TR</ctry></B840><B844EP><B845EP><ctry>BA</ctry></B845EP><B845EP><ctry>ME</ctry></B845EP></B844EP><B848EP><B849EP><ctry>KH</ctry></B849EP><B849EP><ctry>MA</ctry></B849EP><B849EP><ctry>MD</ctry></B849EP><B849EP><ctry>TN</ctry></B849EP></B848EP><B860><B861><dnum><anum>JP2019045563</anum></dnum><date>20191121</date></B861><B862>ja</B862></B860><B870><B871><dnum><pnum>WO2020110879</pnum></dnum><date>20200604</date><bnum>202023</bnum></B871></B870></B800></SDOBI>
<abstract id="abst" lang="en">
<p id="pa01" num="0001">To provide a suspicious or abnormal subject detecting device for detecting a suspicious or abnormal subject appeared in time-series images.</p>
<p id="pa02" num="0002">[Solution]</p>
<p id="pa03" num="0003">An accumulating device 2 includes a first detecting unit 23 for detecting movement of a plurality of articulations includes in an action subject Z appeared in a plurality of first time-series images Y1 obtained by photographing a predetermined point; and a determining unit 24 for determining one or more of normal actions at the predetermined point based on a large number of movement of the plurality of articulations detected by the first detecting unit 23. The detecting device 3 includes a second detecting unit 33 for detecting movement of a plurality of articulations includes in an action subject Z appeared in a plurality of second time-series images Y2 obtained by photographing the predetermined point; and an extracting unit 34 for extracting, when the movement of a plurality of articulations detected by the second detecting unit 33 is different from the normal action determined by the determining unit 24,the action subject Z which has performed the action different from the normal action from among the plurality of second time-series images Y2.<img id="iaf01" file="imgaf001.tif" wi="57" he="118" img-content="drawing" img-format="tif"/></p>
</abstract>
<description id="desc" lang="en"><!-- EPO <DP n="1"> -->
<heading id="h0001">[TECHNICAL FIELD of THE INVENTION]</heading>
<p id="p0001" num="0001">The present invention relates to a suspicious or abnormal subject detecting device for detecting a suspicious or abnormal subject appeared in time-series images.</p>
<heading id="h0002">[BACKGROUND OF THE INVENTION]</heading>
<p id="p0002" num="0002">Conventionally, a technique for analyzing the movement or action of a person appeared in image data and detecting a suspicious person based on whether or not the person has performed a pre-registered pattern of movement or action has been known (see, for example, Patent Document 1).</p>
<heading id="h0003">[Prior art]</heading>
<p id="p0003" num="0003">Patent Document 1: <patcit id="pcit0001" dnum="JP2017068394A"><text>Japanese Patent Application publication No. 2017-068394</text></patcit></p>
<heading id="h0004">[SUMMARY OF INVENTION]</heading>
<heading id="h0005">[Problem to Be Solved by the Invention]</heading>
<p id="p0004" num="0004">However, in the above-described technique, since it is necessary to register the movement or action pattern in advance, it takes labor to perform the registration work, and in addition, there is a possibility that the registered movement or action pattern is not appropriate.</p>
<p id="p0005" num="0005">In view of the foregoing, it is an object of the invention to provide a suspicious or abnormal subject detecting device capable of easily and high-accurately detecting a suspicious or abnormal subject.<!-- EPO <DP n="2"> --></p>
<heading id="h0006">[Means for Solving the Problem]</heading>
<p id="p0006" num="0006">The present invention provides a suspicious or abnormal subject detecting device includes: an accumulating device; and a detecting device. The accumulating device includes: a first obtaining unit configured to obtain a plurality of first time-series images obtained by photographing a predetermined point; a first detecting unit configured to detect movement of a plurality of articulations included in an action subject appeared in the plurality of first time-series images; and a determining unit configured to determine one or more of normal actions at the predetermined point based on a large number of the movement of a plurality of articulations detected by the first detecting unit. The detecting device includes: a second obtaining unit configured to obtain a plurality of second time-series images obtained by photographing the predetermined point; a second detecting unit configured to detect movement of a plurality of articulations included in an action subject appeared in the plurality of second time-series images; and an extracting unit configured to extract, when the movement of a plurality of articulations detected by the second detecting unit is different from the normal action determined by the determining unit, an action subject which has performed an action different from the normal action from among the plurality of second time-series images.</p>
<p id="p0007" num="0007">With this configuration, it becomes possible to easily and high-accurately detect a suspicious or abnormal subject simply by detecting an "unusual action" without registering suspicious action in advance or identifying the type of detected action.</p>
<p id="p0008" num="0008">It is preferable that the first detecting unit detects a plurality of articulations corresponding to articulation identification criteria for identifying a plurality of<!-- EPO <DP n="3"> --> articulations of an action subject, specifies an action subject appeared in the plurality of first time-series images by specifying a plurality of articulations included in one action subject referring action subject specific criteria indicating basic postures of many variations of an action subject, ranges of movement of each articulation, and distances between each articulation in one action subject, and detects movement of the plurality of articulations included in the specified action subject. The determining unit determines one or more of normal actions at the predetermined point based on the large number of the movement of the plurality of articulations detected by the first detecting unit. The second detecting unit detects a plurality of articulations corresponding to articulation identification criteria for identifying a plurality of articulations of an action subject, in the plurality of second time-series images, specifies an action subject appeared in the plurality of second time-series images by specifying a plurality of articulations included in one action subject referring action subject specific criteria indicating basic postures of many variations of an action subject, ranges of movement of each articulation, and distances between each articulation in one action subject, and detects movement of the plurality of articulations included in the specified action subject. The extracting unit extracts, when the movement of a plurality of articulations detected by the second detecting unit is different from the normal action determined by the determining unit, an action subject which has performed an action different from the normal action from among the plurality of second time-series images.</p>
<p id="p0009" num="0009">With this configuration, it becomes possible to more easily and high-accurately detect a suspicious or abnormal subject.</p>
<p id="p0010" num="0010">It is preferable that the suspicious or abnormal subject<!-- EPO <DP n="4"> --> detecting device further includes a producing unit configured to produce individual identifying information for the extracted action subject based on at least one second time-series image.</p>
<p id="p0011" num="0011">With this configuration, it becomes possible to confirm whether or not the extracted action subject has actually executed a suspicious or abnormal action, and to concretely grasp the characteristics of the extracted action subject.</p>
<p id="p0012" num="0012">It is preferable that the suspicious or abnormal subject detecting device further includes a transmitting unit configured to automatically transmit the individual identification information produced by the producing unit to a registered information terminal.</p>
<p id="p0013" num="0013">With this configuration, since it is possible to immediately notify an emergency or a danger to the outside, it becomes possible to quickly deal with it, attributing to a crime prevention.</p>
<p id="p0014" num="0014">Another aspect of this invention provides a suspicious or abnormal subject detecting program installed on a computer. The program includes: a step for obtaining a plurality of first time-series images obtained by photographing a predetermined point; a step for detecting movement of a plurality of articulations included in an action subject appeared in the plurality of first time-series images; a step for determining one or more of normal actions at the predetermined point based on a large number of the detected movement of a plurality of articulations;<br/>
a step for obtaining a plurality of second time-series images obtained by photographing the predetermined point; a step for detecting movement of a plurality of articulations included in an<!-- EPO <DP n="5"> --> action subject appeared in the plurality of second time-series images; and a step for extracting, when the movement of a plurality of articulations detected with respect to the plurality of second time-series images is different from the determined normal action, an action subject which has performed an action different from the normal action from among the plurality of second time-series images.</p>
<p id="p0015" num="0015">It is preferable that the step for detecting in the plurality of first time-series images includes: a step for detecting a plurality of articulations corresponding to articulation identification criteria for identifying a plurality of articulations of an action subject; a step for specifying an action subject appeared in the plurality of first time-series images by specifying a plurality of articulations included in one action subject referring action subject specific criteria indicating basic postures of many variations of an action subject, ranges of movement of each articulation, and distances between each articulation in one action subject; and a step for detecting movement of the plurality of articulations included in the specified action subject. The step for determining determines one or more of normal actions at the predetermined point based on the detected large number of the movement of the plurality of articulations. The step for detecting in the plurality of second time-series images includes: a step for detecting a plurality of articulations corresponding to articulation identification criteria for identifying a plurality of articulations of an action subject, in the plurality of second time-series images; a step for specifying an action subject appeared in the plurality of second time-series images by specifying a plurality of articulations included in one action subject referring action subject specific criteria indicating basic postures of many variations of an action subject, ranges of movement of each articulation, and distances between each articulation in one action subject; and a step for detecting movement of the plurality of articulations included in<!-- EPO <DP n="6"> --> the specified action subject. The step for extracting extracts, when the movement of a plurality of articulations detected with respect to the second time-series images is different from the determined normal action, an action subject which has performed an action different from the normal action from among the plurality of second time-series images.</p>
<p id="p0016" num="0016">It is preferable that the suspicious or abnormal subject detecting program further includes a step for producing individual identifying information for the extracted action subject based on at least one second time-series image.</p>
<p id="p0017" num="0017">It is preferable that the suspicious or abnormal subject detecting program further includes a step for automatically transmitting the produced individual identification information to a registered information terminal.</p>
<heading id="h0007">[Effects of the Invention]</heading>
<p id="p0018" num="0018">According to the suspicious or abnormal subject detecting device of the present invention, it is possible to easily detect the suspicious or abnormal subject with high accuracy.</p>
<heading id="h0008">[Brief Description of the Drawings]</heading>
<p id="p0019" num="0019">
<ul id="ul0001" list-style="none">
<li><figref idref="f0001">Fig. 1</figref> is an explanatory view of a state of use of a suspicious or abnormal subject detecting device according to an embodiment of the present invention.</li>
<li><figref idref="f0001">Fig. 2</figref> is a block diagram of the suspicious or abnormal subject detecting device according to the embodiment of the present invention.</li>
<li><figref idref="f0002">Fig. 3</figref> is a flowchart of the suspicious or abnormal subject detecting device according to the embodiment of the present<!-- EPO <DP n="7"> --> invention.</li>
</ul></p>
<heading id="h0009">[PREFERRED EMBODIMENTS]</heading>
<p id="p0020" num="0020">A suspicious or abnormal subject detecting device 1 according to an embodiment of the present invention will be described below with reference to <figref idref="f0001 f0002">Figs. 1 to 3</figref>.</p>
<p id="p0021" num="0021">As shown in <figref idref="f0001">Fig. 1</figref>, the suspicious or abnormal subject detecting device 1 is for detecting a suspicious or abnormal subject from among action-subjects Z appeared in a plurality of time-series images Y (each frame constituting a moving image) photographed by a photographing means X. In the present embodiment, a human is adopted as the action subject Z, and the action subject Z is simply displayed only by the skeleton for easy understanding.</p>
<p id="p0022" num="0022">As shown in <figref idref="f0001">Fig. 2</figref>, the suspicious or abnormal subject detecting device 1 includes an accumulating device 2 and a detecting device 3. The detecting device 3 detects the suspicious or abnormal subject by referring to the data accumulated by the accumulating device 2.</p>
<p id="p0023" num="0023">The accumulating device 2 includes a first storing unit 21, a first obtaining unit 22, a first detecting unit 23, and a determining unit 24.</p>
<p id="p0024" num="0024">The first storing unit 21 stores the "articulation identification criteria" and the "action subject specific criteria."</p>
<p id="p0025" num="0025">The "articulation identification criteria" indicates the<!-- EPO <DP n="8"> --> shape, direction, size, etc. for each articulation A to identify a plurality of articulations A (neck, right elbow, left elbow, waist, right knee, left knee in <figref idref="f0001">Fig. 1</figref>) of the action subject Z.</p>
<p id="p0026" num="0026">The "action subject specific criteria" indicates the "basic posture" of many variations of the action subject Z ("walking", "standing", etc.), the "range of movement of each articulation A", and the "distance between each articulation A in one action subject Z."</p>
<p id="p0027" num="0027">The first obtaining unit 22 obtains a plurality of first time-series images Y1 obtained by photographing a predetermined point. Preferably, the predetermined point is a point at which one or more predetermined actions are mainly performed.</p>
<p id="p0028" num="0028">As the predetermined action, for example, when the predetermined point is "in front of the merchandise shelf of the shop", "picking up the merchandise", "putting the merchandise into the shopping basket", and the like can be considered. Further, for example, when the predetermined point is "in a service counter of a store", "receive merchandise", "receive money", "open a cash register", "give change", "give merchandise", and the like can be considered.</p>
<p id="p0029" num="0029">The first detecting unit 23 specifies the action subject Z appeared in the plurality of first time-series images Y1, and detects the action of the specified action subject Z.</p>
<p id="p0030" num="0030">Although a known method can be used to specify the action subject Z, in this embodiment, a plurality of articulations A corresponding to the "articulation identification criteria" stored in the first storing unit 21 are detected, and then the plurality<!-- EPO <DP n="9"> --> of articulations A included in one action subject Z are specified by referring to the "action subject specific criteria." In the example of <figref idref="f0001">Fig. 1</figref>, articulations A1 to A6 are specified as articulations A included in one action subject Z, whereas articulations A7 to A12 are specified as articulations A included in another action subject Z, and two action subjects Z are specified as being existed there.</p>
<p id="p0031" num="0031">With respect to the action detection, each articulation's movement during the predetermined action preformed may be stored in the first storing unit 21, and if the corresponding movement of each articulation is detected, it may be detected that the predetermined action is performed. Otherwise, the movement of the entire articulation A, the movement of the hip articulation A, or the movement of the center of gravity (moving speed in the XYZ direction) etc., may be simply detected.</p>
<p id="p0032" num="0032">The determining unit 24 determines one or more of "normal actions (normal movement of a plurality of articulations)" at the predetermined point based on a large number of actions (movement of the plurality of articulations) detected by the first detecting unit 23.</p>
<p id="p0033" num="0033">The "normal action" can be determined on various criteria. For example, from among entire detected actions, the action that occurred at a predetermined percentage or more may be determined as "normal action." In the example of the movement of the hip articulation A, the movement of the hip articulation A whose speed is in the XYZ direction within a predetermined range can be determined as the "normal action."</p>
<p id="p0034" num="0034">The "normal action" determined by the determining unit 24 is<!-- EPO <DP n="10"> --> stored in the first storing unit 21.</p>
<p id="p0035" num="0035">The detecting device 3 includes a second storing unit 31, a second obtaining unit 32, a second detecting unit 33, an extracting unit 34, a producing unit 35, and a transmitting unit 36.</p>
<p id="p0036" num="0036">Similar to the first storing unit 21, the second storing unit 31 stores "articulation identification criteria" and the "action subject specific criteria."</p>
<p id="p0037" num="0037">The second obtaining unit 32 obtains a plurality of second time-series images Y2 obtained by photographing the predetermined point. The plurality of second time-series images Y2 is preferably photographed by the photographing means X at substantially the same angle of view and magnification as that of the first obtaining unit 22.</p>
<p id="p0038" num="0038">The second detecting unit 33 specifies the action subject Z appeared in the plurality of second time-series images Y2, and detects the action of the specified action subject Z. The specification of the action subject Z and the detection of the action can be performed in the same manner as in the first detecting unit 23.</p>
<p id="p0039" num="0039">When the action detected by the second detecting unit 33 is different from the "normal action" determined by the determining unit 24, the extracting unit 34 extracts the action subject Z, which has performed the action different from the "normal action", from among the plurality of second time-series images Y2.</p>
<p id="p0040" num="0040"><!-- EPO <DP n="11"> --> As actions different from "normal action", actions that are not appropriate for a predetermined point (types of action, traveling directions, traveling speeds, abnormal walking, and abnormal action (falling, collapsing, sitting down, circling action, etc.)) can be extracted.</p>
<p id="p0041" num="0041">The producing unit 35 produces individual identifying information for the extracted action subject Z based on at least one second time-series image Y2.</p>
<p id="p0042" num="0042">Although various types of individual identifying information can be considered, in the present embodiment, a focus mark is attached to the extracted action subject. Further, information on clothing, personal belongings, traveling direction, time, etc. are also attached as additional information.</p>
<p id="p0043" num="0043">The transmitting unit 36 automatically transmits the individual identification information produced by the producing unit 35 to the registered information terminal (information terminal of the security company, individual portable information terminal, etc.).</p>
<p id="p0044" num="0044">Next, detection of a suspicious or abnormal subject by the suspicious or abnormal subject detecting device 1 will be described with reference to the flowchart of <figref idref="f0002">Fig. 3</figref>.</p>
<p id="p0045" num="0045">The detection of suspicious or abnormal subjects is carried out in two steps such as "accumulating step" and "detecting step."</p>
<heading id="h0010">(1) Accumulating step</heading>
<p id="p0046" num="0046"><!-- EPO <DP n="12"> --> In the accumulating step, firstly, when a plurality of first time-series images Y1 is obtained (S1), the action subject Z appeared in the plurality of first time-series images Y1 is specified, and the action of the specified action subject Z is detected (S2). It is preferable that S1 and S2 are performed for a plurality of different first time-series images Y1, and a large number of actions are detected.</p>
<p id="p0047" num="0047">Subsequently, one or more "normal actions" at a predetermined point are determined based on the plurality of actions detected in S2 (S3).</p>
<heading id="h0011">(2) Detecting step</heading>
<p id="p0048" num="0048">In the detecting step, firstly, a plurality of second time-series images Y2 is obtained (S4), then, the action subject Z appeared in the plurality of second time-series images Y2 is specified, and the action of the specified action subject Z is detected (S5).</p>
<p id="p0049" num="0049">Subsequently, when the action detected in S5 is different from the "normal action" determined in S3 (S6: YES), the action subject Z having performed the action different from the "normal action" is extracted from among the plurality of second time-series images Y2 (S7).</p>
<p id="p0050" num="0050">Subsequently, individual identifying information for the extracted action subject Z is produced based on at least one second time-series image Y2 (S8).</p>
<p id="p0051" num="0051">Finally, the individual identifying information produced in<!-- EPO <DP n="13"> --> S8 is transmitted to the registered portable information terminal or the like (S9).</p>
<p id="p0052" num="0052">The suspicious or abnormal subject detecting device 1 having such a configuration can be used for various applications such as crime prevention and nursing care.</p>
<p id="p0053" num="0053">For example, by using the suspicious or abnormal subject detecting device 1 with respect to the time-series image Y obtained by photographing "in front of the merchandise shelf of the shop", it is possible to extract the action subject Z which has performed an action different from the "normal action" such as "putting the merchandise into the bag". Further, by using the suspicious or abnormal subject detecting device 1 with respect to the time-series image obtained by photographing "in front of the service counter of the store" or "inside the service counter of the store", it is possible to extract the action subject Z having performed an action different from "normal action" such as "taking out a blade".</p>
<p id="p0054" num="0054">In the case of the "road in front of the house", only family members and visitors usually visit the house, and many passers-by are to pass through the house. Therefore, by using the suspicious or abnormal subject detecting device 1 with respect to the time-series image Y obtained by photographing the "road in front of the house", it is possible to extract those persons other than the family members and the visitors among the action subjects Z having performed the "unusual action" such as "approaching the house."</p>
<p id="p0055" num="0055">Further, by using the suspicious or abnormal subject detecting device 1 with respect to the time-series image Y obtained by photographing "a private room in a hospital" or "a<!-- EPO <DP n="14"> --> house of an elderly person living alone", it is possible to extract the action different from "normal action" (abnormal action) such as "falling". In the same way, it is possible to extract a drunk on a station platform, a lost child, a pickpocket or a fight in commercial facilities or the like.</p>
<p id="p0056" num="0056">It should be noted that the above-described types of action such as "putting merchandise into a bag" can be recognized by the individual identification information after the action subject Z having the possibility to be a suspicious or abnormal subject is found and extracted by detecting the "unusual action."</p>
<p id="p0057" num="0057">As described above, in the suspicious or abnormal subject detecting device 1 according to the present embodiment, when the action (movement of a plurality of articulations) detected by the second detecting unit 33 is different from the "normal action" determined by the determining unit 24, the action subject Z having performed the action different from the "normal action (normal movement of a plurality of articulations)" is extracted from among the plurality of second time-series images Y2.</p>
<p id="p0058" num="0058">With this configuration, it becomes possible to easily and high-accurately detect a suspicious or abnormal subject simply by detecting an "unusual action" without registering suspicious action in advance or identifying the type of detected action.</p>
<p id="p0059" num="0059">The suspicious or abnormal subject detecting device 1 according to the present embodiment produces individual identifying information for the extracted action subject Z based on at least one second time-series image Y2.</p>
<p id="p0060" num="0060">With this configuration, it becomes possible to confirm<!-- EPO <DP n="15"> --> whether or not the extracted action subject Z has actually executed a suspicious or abnormal action, and to concretely grasp the characteristics of the extracted action subject Z.</p>
<p id="p0061" num="0061">In the suspicious or abnormal subject detecting device 1 according to the present embodiment, the individual identifying information produced by the producing unit 35 is automatically transmitted to the registered information terminal.</p>
<p id="p0062" num="0062">With this configuration, since it is possible to immediately notify an emergency or a danger to the outside, it becomes possible to quickly deal with it, attributing to a crime prevention.</p>
<p id="p0063" num="0063">While the suspicious or abnormal subject detecting device of the invention has been described in detail with reference to the preferred embodiment thereof, it would be apparent to those skilled in the art that many modifications and variations may be made therein without departing from the spirit of the invention, the scope of which is defined by the attached claims.</p>
<p id="p0064" num="0064">For example, in the above-described embodiment, the first storing unit 21 and the second storing unit 31, the first obtaining unit 22 and the second obtaining unit 32, and, the first detecting unit 23 and the second detecting unit 33 are provided in the accumulating device 2 and the detecting device 3, respectively. However, they may be commonly used, and such a case is also included in the scope of the present invention. Further, in the case of common use, the producing unit 35 and the transmitting unit 36 may be provided on the accumulating device 2 side.</p>
<p id="p0065" num="0065">It is also possible to activate only the detecting device 3<!-- EPO <DP n="16"> --> after data (a large number of actions) have been accumulated to some extent in the accumulating device 2. However, since lager amounts of data are preferable in order to increase the accuracy of detection of a suspicious or abnormal subject, it is preferable that the data-accumulation is continued by the accumulating device 2 in parallel with the operation of the detecting device 3 even after the data have been accumulated to some extent.</p>
<p id="p0066" num="0066">Although it is effective to perform the detection of the suspicious or abnormal subject in real time for the plurality of second time-series images Y2 according to the present embodiment, the detection of the suspicious or abnormal subject may be performed later for the recorded plurality of second time-series images Y2, depending on the purpose of use of the suspicious or abnormal subject detecting devise 1.</p>
<p id="p0067" num="0067">In the above-described embodiment, a human is used as an example of the action subject Z, but it is also possible to use an animal or a robot, instead. For example, in the case of a work robot, when it performs an action different from the preset action, it is detected as an abnormal action, so that a problem such as "a defect in the movable range" can be found.</p>
<p id="p0068" num="0068">In the above-described embodiment, "movements of the plurality of articulations included in the action subject appeared in the plurality of first time-series images" are detected with reference to the "articulation identification criteria" and the "action subject specific criteria." However, other methods for the detection can also be employed.</p>
<p id="p0069" num="0069">The present invention is also applied to a program that conducts the process of the suspicious or abnormal subject<!-- EPO <DP n="17"> --> detecting devise 1, or to a record media accommodating the content of the program. In the case of record media, the program should be installed on the computer or the like. The record media storing the program may be reusable and not one-time use only. As reusable record media, for example, CD-ROM may be employed, but the record media is not limited to this.</p>
<heading id="h0012">[Description of the Reference Number]</heading>
<p id="p0070" num="0070">
<dl id="dl0001" compact="compact">
<dt>1</dt><dd>suspicious or abnormal subject detecting device</dd>
<dt>2</dt><dd>accumulating device</dd>
<dt>3</dt><dd>detecting device</dd>
<dt>21</dt><dd>first storing unit</dd>
<dt>22</dt><dd>first obtaining unit</dd>
<dt>23</dt><dd>first detecting unit</dd>
<dt>24</dt><dd>determining unit</dd>
<dt>31</dt><dd>second storing unit</dd>
<dt>32</dt><dd>second obtaining unit</dd>
<dt>33</dt><dd>second detecting unit</dd>
<dt>34</dt><dd>extracting unit</dd>
<dt>35</dt><dd>producing unit</dd>
<dt>36</dt><dd>transmitting unit</dd>
<dt>X</dt><dd>photographing means</dd>
<dt>Y</dt><dd>time-series images</dd>
<dt>Z</dt><dd>action subject</dd>
</dl></p>
</description>
<claims id="claims01" lang="en"><!-- EPO <DP n="18"> -->
<claim id="c-en-0001" num="0001">
<claim-text>A suspicious or abnormal subject detecting device comprising:
<claim-text>an accumulating device; and</claim-text>
<claim-text>a detecting device,</claim-text>
<claim-text>wherein the accumulating device includes:
<claim-text>a first obtaining unit configured to obtain a plurality of first time-series images obtained by photographing a predetermined point;</claim-text>
<claim-text>a first detecting unit configured to detect movement of a plurality of articulations included in an action subject appeared in the plurality of first time-series images; and</claim-text>
<claim-text>a determining unit configured to determine one or more of normal actions at the predetermined point based on a large number of the movement of a plurality of articulations detected by the first detecting unit,</claim-text>
<claim-text>wherein the detecting device includes:
<claim-text>a second obtaining unit configured to obtain a plurality of second time-series images obtained by photographing the predetermined point;</claim-text>
<claim-text>a second detecting unit configured to detect movement of a plurality of articulations included in an action subject appeared in the plurality of second time-series images; and</claim-text>
<claim-text>an extracting unit configured to extract, when the movement of a plurality of articulations detected by the second detecting unit is different from the normal action determined by the determining unit, an action subject which has performed an action different from the normal action from among the plurality of second time-series images.</claim-text></claim-text></claim-text></claim-text></claim>
<claim id="c-en-0002" num="0002">
<claim-text>The suspicious or abnormal subject detecting device<!-- EPO <DP n="19"> --> according to claim 1, wherein the first detecting unit detects a plurality of articulations corresponding to articulation identification criteria for identifying a plurality of articulations of an action subject, specifies an action subject appeared in the plurality of first time-series images by specifying a plurality of articulations included in one action subject referring action subject specific criteria indicating basic postures of many variations of an action subject, ranges of movement of each articulation, and distances between each articulation in one action subject, and detects movement of the plurality of articulations included in the specified action subject,
<claim-text>wherein the determining unit determines one or more of normal actions at the predetermined point based on the large number of the movement of the plurality of articulations detected by the first detecting unit,</claim-text>
<claim-text>wherein the second detecting unit detects a plurality of articulations corresponding to articulation identification criteria for identifying a plurality of articulations of an action subject, in the plurality of second time-series images, specifies an action subject appeared in the plurality of second time-series images by specifying a plurality of articulations included in one action subject referring action subject specific criteria indicating basic postures of many variations of an action subject, ranges of movement of each articulation, and distances between each articulation in one action subject, and detects movement of the plurality of articulations included in the specified action subject, and</claim-text>
<claim-text>wherein the extracting unit extracts, when the movement of a plurality of articulations detected by the second detecting unit is different from the normal action determined by the determining unit, an action subject which has performed an action different from the normal action from among the plurality of second time-series images.</claim-text><!-- EPO <DP n="20"> --></claim-text></claim>
<claim id="c-en-0003" num="0003">
<claim-text>The suspicious or abnormal subject detecting device according to claim 1 or 2, further comprising a producing unit configured to produce individual identifying information for the extracted action subject based on at least one second time-series image.</claim-text></claim>
<claim id="c-en-0004" num="0004">
<claim-text>The suspicious or abnormal subject detecting device according to claim 3, further comprising a transmitting unit configured to automatically transmit the individual identification information produced by the producing unit to a registered information terminal.</claim-text></claim>
<claim id="c-en-0005" num="0005">
<claim-text>A suspicious or abnormal subject detecting program installed on a computer, the program comprising:
<claim-text>a step for obtaining a plurality of first time-series images obtained by photographing a predetermined point;</claim-text>
<claim-text>a step for detecting movement of a plurality of articulations included in an action subject appeared in the plurality of first time-series images;</claim-text>
<claim-text>a step for determining one or more of normal actions at the predetermined point based on a large number of the detected movement of a plurality of articulations;</claim-text>
<claim-text>a step for obtaining a plurality of second time-series images obtained by photographing the predetermined point;</claim-text>
<claim-text>a step for detecting movement of a plurality of articulations included in an action subject appeared in the plurality of second time-series images; and</claim-text>
<claim-text>a step for extracting, when the movement of a plurality of articulations detected with respect to the plurality of second time-series images is different from the determined normal action, an action subject which has performed an action different from the normal action from among the plurality of second time-series images.</claim-text></claim-text></claim>
<claim id="c-en-0006" num="0006">
<claim-text>The suspicious or abnormal subject detecting program<!-- EPO <DP n="21"> --> according to claim 5, wherein the step for detecting in the plurality of first time-series images includes:
<claim-text>a step for detecting a plurality of articulations corresponding to articulation identification criteria for identifying a plurality of articulations of an action subject;</claim-text>
<claim-text>a step for specifying an action subject appeared in the plurality of first time-series images by specifying a plurality of articulations included in one action subject referring action subject specific criteria indicating basic postures of many variations of an action subject, ranges of movement of each articulation, and distances between each articulation in one action subject; and</claim-text>
<claim-text>a step for detecting movement of the plurality of articulations included in the specified action subject,</claim-text>
<claim-text>wherein the step for determining determines one or more of normal actions at the predetermined point based on the detected large number of the movement of the plurality of articulations,</claim-text>
<claim-text>wherein the step for detecting in the plurality of second time-series images includes:
<claim-text>a step for detecting a plurality of articulations corresponding to articulation identification criteria for identifying a plurality of articulations of an action subject, in the plurality of second time-series images;</claim-text>
<claim-text>a step for specifying an action subject appeared in the plurality of second time-series images by specifying a plurality of articulations included in one action subject referring action subject specific criteria indicating basic postures of many variations of an action subject, ranges of movement of each articulation, and distances between each articulation in one action subject; and</claim-text>
<claim-text>a step for detecting movement of the plurality of articulations included in the specified action subject, and<!-- EPO <DP n="22"> --></claim-text>
<claim-text>wherein the step for extracting extracts, when the movement of a plurality of articulations detected with respect to the second time-series images is different from the determined normal action, an action subject which has performed an action different from the normal action from among the plurality of second time-series images.</claim-text></claim-text></claim-text></claim>
<claim id="c-en-0007" num="0007">
<claim-text>The suspicious or abnormal subject detecting program according to claim 5 or 6, further comprising a step for producing individual identifying information for the extracted action subject based on at least one second time-series image.</claim-text></claim>
<claim id="c-en-0008" num="0008">
<claim-text>The suspicious or abnormal subject detecting program according to claim 7, further comprising a step for automatically transmitting the produced individual identification information to a registered information terminal.</claim-text></claim>
</claims>
<amended-claims id="aclaims" lang="en" amend-claim-type="PCT"><!-- EPO <DP n="23"> -->
<heading id="h0013">Amended claims under Art. 19.1 PCT</heading>
<claim id="ac-en-0001" num="0001">
<claim-text>(Amended) A suspicious or abnormal subject detecting device comprising:
<claim-text>an accumulating device; and</claim-text>
<claim-text>a detecting device,</claim-text>
<claim-text>wherein the accumulating device includes:
<claim-text>a first obtaining unit configured to obtain a plurality of first time-series images obtained by photographing a predetermined point;</claim-text>
<claim-text>a first detecting unit configured to detect movement of a plurality of articulations included in an action subject appeared in the plurality of first time-series images; and</claim-text>
<claim-text>a determining unit configured to determine one or more of normal actions at the predetermined point based on a large number of the movement of a plurality of articulations detected by the first detecting unit,</claim-text>
<claim-text>wherein the detecting device includes:
<claim-text>a second obtaining unit configured to obtain a plurality of second time-series images obtained by photographing the predetermined point;</claim-text>
<claim-text>a second detecting unit configured to detect movement of a plurality of articulations included in an action subject appeared in the plurality of second time-series images; and</claim-text>
<claim-text>an extracting unit configured to extract, when the movement of a plurality of articulations detected by the second detecting unit is different from the normal action determined by the determining unit, an action subject which has performed an action different from the normal action from among the plurality of second time-series images,<!-- EPO <DP n="24"> --></claim-text>
<claim-text>wherein the first detecting unit detects a plurality of articulations corresponding to articulation identification criteria for identifying a plurality of articulations of an action subject, specifies an action subject appeared in the plurality of first time-series images by specifying a plurality of articulations included in one action subject referring action subject specific criteria indicating basic postures of many variations of an action subject, ranges of movement of each articulation, and distances between each articulation in one action subject, and detects movement of the plurality of articulations included in the specified action subject,</claim-text>
<claim-text>wherein the determining unit determines one or more of normal actions at the predetermined point based on the large number of the movement of the plurality of articulations detected by the first detecting unit,</claim-text>
<claim-text>wherein the second detecting unit detects a plurality of articulations corresponding to articulation identification criteria for identifying a plurality of articulations of an action subject, in the plurality of second time-series images, specifies an action subject appeared in the plurality of second time-series images by specifying a plurality of articulations included in one action subject referring action subject specific criteria indicating basic postures of many variations of an action subject, ranges of movement of each articulation, and distances between each articulation in one action subject, and detects movement of the plurality of articulations included in the specified action subject, and</claim-text>
<claim-text>wherein the extracting unit extracts, when the movement of a plurality of articulations detected by the second detecting unit is different from the normal action determined by the determining unit, an action subject which has performed an action different from the normal action from among the plurality of second time-series images.</claim-text></claim-text></claim-text><!-- EPO <DP n="25"> --></claim-text></claim>
<claim id="ac-en-0002" num="0002">
<claim-text>(Cancelled)</claim-text></claim>
<claim id="ac-en-0003" num="0003">
<claim-text>(Amended) The suspicious or abnormal subject detecting device according to claim 1, further comprising a producing unit configured to produce individual identifying information for the extracted action subject based on at least one second time-series image.</claim-text></claim>
<claim id="ac-en-0004" num="0004">
<claim-text>The suspicious or abnormal subject detecting device according to claim 3, further comprising a transmitting unit configured to automatically transmit the individual identification information produced by the producing unit to a registered information terminal.</claim-text></claim>
<claim id="ac-en-0005" num="0005">
<claim-text>(Amended) A suspicious or abnormal subject detecting program installed on a computer, the program comprising:
<claim-text>a step for obtaining a plurality of first time-series images obtained by photographing a predetermined point;</claim-text>
<claim-text>a step for detecting movement of a plurality of articulations included in an action subject appeared in the plurality of first time-series images;</claim-text>
<claim-text>a step for determining or more of normal actions at the predetermined point based on a large number of the movement of a plurality of articulations detected by the first detecting unit;</claim-text>
<claim-text>a step for obtaining a plurality of second time-series images obtained by photographing the predetermined point;</claim-text>
<claim-text>a step for detecting movement of a plurality of articulations included in an action subject appeared in the plurality of second time-series images; and</claim-text>
<claim-text>a step for extracting, when the movement of a plurality of articulations detected with respect to the plurality of second time-series images is different from the determined normal action, an action subject which has performed an action different from the normal action from among the plurality of second time-series<!-- EPO <DP n="26"> --> images,</claim-text>
<claim-text>wherein the step for detecting in the plurality of first time-series images includes:
<claim-text>a step for detecting a plurality of articulations corresponding to articulation identification criteria for identifying a plurality of articulations of an action subject;</claim-text>
<claim-text>a step for specifying an action subject appeared in the plurality of first time-series images by specifying a plurality of articulations included in one action subject referring action subject specific criteria indicating basic postures of many variations of an action subject, ranges of movement of each articulation, and distances between each articulation in one action subject; and</claim-text>
<claim-text>a step for detecting movement of the plurality of articulations included in the specified action subject,</claim-text>
<claim-text>wherein the step for determining determines one or more of normal actions at the predetermined point based on the detected large number of the movement of the plurality of articulations,</claim-text>
<claim-text>wherein the step for detecting in the plurality of second time-series images includes:
<claim-text>a step for detecting a plurality of articulations corresponding to articulation identification criteria for identifying a plurality of articulations of an action subject, in the plurality of second time-series images;</claim-text>
<claim-text>a step for specifying an action subject appeared in the plurality of second time-series images by specifying a plurality of articulations included in one action subject referring action subject specific criteria indicating basic postures of many variations of an action subject, ranges of movement of each articulation, and distances between each articulation in one action subject; and<!-- EPO <DP n="27"> --></claim-text>
<claim-text>a step for detecting movement of the plurality of articulations included in the specified action subject, and</claim-text>
<claim-text>wherein the step for extracting extracts, when the movement of a plurality of articulations detected with respect to the second time-series images is different from the determined normal action, an action subject which has performed an action different from the normal action from among the plurality of second time-series images.</claim-text></claim-text></claim-text></claim-text></claim>
<claim id="ac-en-0006" num="0006">
<claim-text>(Cancelled)</claim-text></claim>
<claim id="ac-en-0007" num="0007">
<claim-text>(Amended) The suspicious or abnormal subject detecting program according to claim 5 or 6, further comprising a step for producing individual identifying information for the extracted action subject based on at least one second time-series image.</claim-text></claim>
<claim id="ac-en-0008" num="0008">
<claim-text>The suspicious or abnormal subject detecting program according to claim 7, further comprising a step for transmitting automatically transmit the produced individual identification information to a registered information terminal.</claim-text></claim></amended-claims>
<drawings id="draw" lang="en"><!-- EPO <DP n="28"> -->
<figure id="f0001" num="1,2"><img id="if0001" file="imgf0001.tif" wi="165" he="214" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="29"> -->
<figure id="f0002" num="3"><img id="if0002" file="imgf0002.tif" wi="109" he="233" img-content="drawing" img-format="tif"/></figure>
</drawings>
<search-report-data id="srep" lang="en" srep-office="EP" date-produced=""><doc-page id="srep0001" file="srep0001.tif" wi="165" he="230" type="tif"/></search-report-data>
<ep-reference-list id="ref-list">
<heading id="ref-h0001"><b>REFERENCES CITED IN THE DESCRIPTION</b></heading>
<p id="ref-p0001" num=""><i>This list of references cited by the applicant is for the reader's convenience only. It does not form part of the European patent document. Even though great care has been taken in compiling the references, errors or omissions cannot be excluded and the EPO disclaims all liability in this regard.</i></p>
<heading id="ref-h0002"><b>Patent documents cited in the description</b></heading>
<p id="ref-p0002" num="">
<ul id="ref-ul0001" list-style="bullet">
<li><patcit id="ref-pcit0001" dnum="JP2017068394A"><document-id><country>JP</country><doc-number>2017068394</doc-number><kind>A</kind></document-id></patcit><crossref idref="pcit0001">[0003]</crossref></li>
</ul></p>
</ep-reference-list>
</ep-patent-document>
