<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE ep-patent-document PUBLIC "-//EPO//EP PATENT DOCUMENT 1.5.1//EN" "ep-patent-document-v1-5-1.dtd">
<!-- This XML data has been generated under the supervision of the European Patent Office -->
<ep-patent-document id="EP19905331A1" file="EP19905331NWA1.xml" lang="en" country="EP" doc-number="3889561" kind="A1" date-publ="20211006" status="n" dtd-version="ep-patent-document-v1-5-1">
<SDOBI lang="en"><B000><eptags><B001EP>ATBECHDEDKESFRGBGRITLILUNLSEMCPTIESILTLVFIROMKCYALTRBGCZEEHUPLSKBAHRIS..MTNORSMESMMAKHTNMD..........</B001EP><B005EP>J</B005EP><B007EP>BDM Ver 2.0.12 (4th of August) -  1100000/0</B007EP></eptags></B000><B100><B110>3889561</B110><B120><B121>EUROPEAN PATENT APPLICATION</B121><B121EP>published in accordance with Art. 153(4) EPC</B121EP></B120><B130>A1</B130><B140><date>20211006</date></B140><B190>EP</B190></B100><B200><B210>19905331.5</B210><B220><date>20191225</date></B220><B240><B241><date>20210628</date></B241></B240><B250>ja</B250><B251EP>en</B251EP><B260>en</B260></B200><B300><B310>201811635297</B310><B320><date>20181229</date></B320><B330><ctry>CN</ctry></B330></B300><B400><B405><date>20211006</date><bnum>202140</bnum></B405><B430><date>20211006</date><bnum>202140</bnum></B430></B400><B500><B510EP><classification-ipcr sequence="1"><text>G01H   9/00        20060101AFI20200703BHEP        </text></classification-ipcr></B510EP><B540><B541>de</B541><B542>VERFAHREN UND SYSTEM ZUR BESTIMMUNG VON ZEIT-RAUM UND ZUR ERKENNUNG UND IDENTIFIZIERUNG VON VIBRATIONEN AUF DER BASIS EINER GLASFASERSIGNALFUNKTION</B542><B541>en</B541><B542>METHOD AND SYSTEM FOR SPECIFYING TIME-SPACE, AND FOR DETECTING AND IDENTIFYING VIBRATION ON BASIS OF OPTICAL FIBER SIGNAL FEATURE</B542><B541>fr</B541><B542>PROCÉDÉ ET SYSTÈME POUR SPÉCIFIER UN ESPACE-TEMPS ET POUR DÉTECTER ET IDENTIFIER UNE VIBRATION SUR LA BASE D'UNE CARACTÉRISTIQUE DE SIGNAL DE FIBRE OPTIQUE</B542></B540><B590><B598>1</B598></B590></B500><B700><B710><B711><snm>Neubrex Co., Ltd.</snm><iid>101713700</iid><irf>N 5055EU - ds / lre</irf><adr><str>1-24, Sakaemachidori 1-chome 
Chuo-ku</str><city>Kobe-shi, Hyogo 650-0023</city><ctry>JP</ctry></adr></B711></B710><B720><B721><snm>XIE, Feng</snm><adr><city>Wuxi City</city><ctry>CN</ctry></adr></B721><B721><snm>CONG, Hongliang</snm><adr><city>Wuxi City</city><ctry>CN</ctry></adr></B721><B721><snm>LI, Guidong</snm><adr><city>Wuxi City</city><ctry>CN</ctry></adr></B721><B721><snm>HU, Xiaohui</snm><adr><city>Wuxi City</city><ctry>CN</ctry></adr></B721><B721><snm>XU, Longhai</snm><adr><city>Wuxi City</city><ctry>CN</ctry></adr></B721></B720><B740><B741><snm>Müller-Boré &amp; Partner 
Patentanwälte PartG mbB</snm><iid>100060440</iid><adr><str>Friedenheimer Brücke 21</str><city>80639 München</city><ctry>DE</ctry></adr></B741></B740></B700><B800><B840><ctry>AL</ctry><ctry>AT</ctry><ctry>BE</ctry><ctry>BG</ctry><ctry>CH</ctry><ctry>CY</ctry><ctry>CZ</ctry><ctry>DE</ctry><ctry>DK</ctry><ctry>EE</ctry><ctry>ES</ctry><ctry>FI</ctry><ctry>FR</ctry><ctry>GB</ctry><ctry>GR</ctry><ctry>HR</ctry><ctry>HU</ctry><ctry>IE</ctry><ctry>IS</ctry><ctry>IT</ctry><ctry>LI</ctry><ctry>LT</ctry><ctry>LU</ctry><ctry>LV</ctry><ctry>MC</ctry><ctry>MK</ctry><ctry>MT</ctry><ctry>NL</ctry><ctry>NO</ctry><ctry>PL</ctry><ctry>PT</ctry><ctry>RO</ctry><ctry>RS</ctry><ctry>SE</ctry><ctry>SI</ctry><ctry>SK</ctry><ctry>SM</ctry><ctry>TR</ctry></B840><B844EP><B845EP><ctry>BA</ctry></B845EP><B845EP><ctry>ME</ctry></B845EP></B844EP><B848EP><B849EP><ctry>KH</ctry></B849EP><B849EP><ctry>MA</ctry></B849EP><B849EP><ctry>MD</ctry></B849EP><B849EP><ctry>TN</ctry></B849EP></B848EP><B860><B861><dnum><anum>JP2019050799</anum></dnum><date>20191225</date></B861><B862>ja</B862></B860><B870><B871><dnum><pnum>WO2020138154</pnum></dnum><date>20200702</date><bnum>202027</bnum></B871></B870></B800></SDOBI>
<abstract id="abst" lang="en">
<p id="pa01" num="0001">A method for detecting and specifying a vibration on the basis of a feature of a fiber-optic signal to determine a time and a spatial location of the present invention includes: Step 1 of acquiring a feature-expanded function vector and C-number of vibration categories by expanding a feature of initial data of a vibration signal from a distributed fiber-optic sensor; Step 2 of calculating a dimensionality reduction matrix based on the feature-expanded function vector; Step 3 of acquiring a dimensionality-reduced feature function by operating the dimensionality reduction matrix to the initial data and the feature-expanded function vector; Step 4 of acquiring a primary classification result of the vibration signal by performing a classification with reference to primary classification parameter acquired from a parameter database; and Step 5 of acquiring and outputting a secondary classification result of the vibration signal by performing removal of a wrong detection result and correction of a wrong classification result of the primary classification result.<img id="iaf01" file="imgaf001.tif" wi="39" he="97" img-content="drawing" img-format="tif"/></p>
</abstract>
<description id="desc" lang="en"><!-- EPO <DP n="1"> -->
<heading id="h0001"><b>Technical Field</b></heading>
<p id="p0001" num="0001">The present invention belongs to the field of fiber-optic signal processing, and specifically, relates to a method and a system for detecting and specifying a vibration on the basis of a feature of a fiber-optic signal to determine a time and a spatial location.</p>
<heading id="h0002"><b>Background Art</b></heading>
<p id="p0002" num="0002">Systems for detecting vibrations by use of a distributed fiber-optic sensor have been employed in the field of facility surveillance, area security, environmental measurement, and the like since they are easy to install, have a wide detection range, and an excellent detection sensitivity. However, a physical property of the distributed fiber-optic sensor causes to be difficult to associate a signal waveform acquired by the distributed fiber-optic sensor with a mechanical vibration received by the distributed fiber-optic sensor by a simple equation. Further, in the case of detecting a vibration by use of the distributed fiber-optic sensor, since there are a variety of interferences and noises in the signal of the distributed fiber-optic sensor, it is difficult to accurately detect and specify a category of the vibration to thereby determine a time and a spatial location of the vibration.</p>
<p id="p0003" num="0003">In conventional vibration detection technique using a distributed fiber-optic sensor, a vibration is detected mainly on the basis of a fluctuation amplitude of a signal of the distributed fiber-optic sensor within a predetermined time window to roughly determine a time and a spatial location. However, the vibration detection technique has not satisfied the daily increasing<!-- EPO <DP n="2"> --> application demands because it has a high detection error rate, an inferiority in the specification performance of vibrations belonging to different categories, and an inferiority in the determination performance of a time and a spatial location of the vibration.</p>
<p id="p0004" num="0004">Besides, a conventional algorithm detecting and specifying a vibration on the basis of a fiber-optic signal to determine a time and a spatial location detects a fluctuation amplitude of a signal of a distributed fiber-optic sensor mainly on the basis of predetermined time window and frequency range. The algorithm determines the presence or absence of a vibration by comparing a fluctuation amplitude of a signal with a predetermined threshold value. However, since the threshold value is set on the basis of an experience of a measurer, a limitation exists in the distinction of complicated vibrations to categories based on the simple threshold, and it is difficult to maintain a balance between a wrong detection rate and a detection failure rate. Due to the problems described above, there is a limitation in applying the algorithm detecting and specifying a vibration on the basis of a fiber-optic sensor to determine a time and a spatial location to a field which requires high reliability and accuracy.</p>
<p id="p0005" num="0005">As another technique for detecting and specifying a vibration on the basis of a fiber-optic signal, there is a way comprising establishing an equation based on a logical model concerning a relationship between a signal waveform acquired by a distributed fiber-optic sensor and a mechanical vibration received by the distributed fiber-optic sensor, and acquiring a signal feature and a reference threshold value which are necessary to be extracted to detect a vibration. However, a plurality of nonlinear conversions is made in the process from a mechanical vibration to a fiber-optic sensor signal. Therefore, the logical analysis can be applied only to a predetermined simple vibration. Additionally, the logical model uses a large number of approximations, which results in omission of various distortions of the signal feature which occur in an actual process to the fiber-optic sensor signal. Accordingly, the logical model involves large errors, and is disadvantageous in the detection and specification.<!-- EPO <DP n="3"> --></p>
<heading id="h0003"><b>Summary of Invention</b></heading>
<p id="p0006" num="0006">The present invention has been made in view of the above circumstances, and an object thereof is to provide a method and a system for detecting and specifying a vibration on the basis of a feature of a fiber-optic signal to determine a time and a spatial location which can improve an accuracy in detecting and specifying the vibration.</p>
<p id="p0007" num="0007">According to an aspect of the present invention, a method for detecting and specifying a vibration on the basis of a feature of a fiber-optic signal to determine a time and a spatial location comprises: Step 1 of acquiring a feature-expanded function vector and C-number of vibration categories by expanding a feature of initial data of a vibration signal from a distributed fiber-optic sensor; Step 2 of calculating a dimensionality reduction matrix based on the feature-expanded function vector; Step 3 of acquiring a dimensionality-reduced feature function by operating the dimensionality reduction matrix to the initial data and the feature-expanded function vector; Step 4 of acquiring a primary classification result of the vibration signal by performing a classification with reference to a primary classification parameter acquired from a parameter database; and Step 5 of acquiring and outputting a secondary classification result of the vibration signal by performing removal of a wrong detection result and correction of a wrong classification result of the primary classification result.</p>
<p id="p0008" num="0008">According to another aspect of the present invention, a system for detecting and specifying a vibration on the basis of a feature of a fiber-optic signal to determine a time and a spatial location comprises: a feature expansion unit for acquiring a feature-expanded function vector and C-number of vibration categories by expanding a feature of initial data of a vibration signal from a distributed fiber-optic sensor; a dimensionality reduction matrix calculation unit for calculating a dimensionality reduction matrix based on the feature-expanded function vector; a linear dimensionality reduction unit for acquiring a dimensionality-reduced feature function by operating the dimensionality reduction matrix to the initial data and the feature-expanded function vector; a primary classification unit for acquiring a primary classification result of the vibration<!-- EPO <DP n="4"> --> signal by performing a classification with reference to a primary classification parameter acquired from a parameter database; and a secondary classification unit for acquiring and outputting a secondary classification result of the vibration signal by performing removal of a wrong detection result and correction of a wrong classification result of the primary classification result.</p>
<p id="p0009" num="0009">The objects, features, aspects, and advantages of the present invention will be more apparent from the following detailed description and drawings.</p>
<heading id="h0004"><b>Brief Description of Drawings</b></heading>
<p id="p0010" num="0010">
<ul id="ul0001" list-style="none" compact="compact">
<li><figref idref="f0001">FIG. 1</figref> is a flowchart of a method according to an embodiment of the present invention.</li>
<li><figref idref="f0002">FIG.2</figref> is a block diagram of a system according to an embodiment of the present invention.</li>
<li><figref idref="f0003">FIG. 3</figref> is a diagram showing a vibration signal occurring in a case of climbing a fence in an Example.</li>
<li><figref idref="f0004">FIG. 4</figref> is a diagram showing a vibration signal occurring in a case of striking a fence in the Example.</li>
<li><figref idref="f0005">FIG. 5</figref> is a diagram showing a vibration signal occurring in a case of intersecting an optical fiber in the Example.</li>
</ul></p>
<heading id="h0005"><b>Description of Embodiments</b></heading>
<p id="p0011" num="0011">All the terms (including technical terms and scientific terms) recited in the present specification convey the same meanings as what are generally understood by a person skilled in the art unless they are separately defined in the present specification. Further, the terms defined in a dictionary versatilely used convey the same meanings as what are used in the prior art, and should not be interpreted in an idealized meaning or an excessively formal meaning unless they are specifically defined in the present specification.</p>
<p id="p0012" num="0012">The present invention provides a novel algorithm configuration which can solve problems pertaining to conventional algorithms for detecting and specifying a vibration on the basis of a<!-- EPO <DP n="5"> --> fiber-optic signal to determine a time and a spatial location. The configuration includes a training part and a detecting-specifying part. The training part executes a statistical analysis to initial fiber-optic signals collected through experiments, acquires a feature to detect and specify a vibration, and extracts it as an algorithm parameter. The detecting-specifying part detects a vibration on the basis of the parameter acquired by the training part according to a predetermined signal processing sequence, specifies a category of the vibration, and completes determination of a time and a spatial location of the vibration.</p>
<p id="p0013" num="0013">The algorithm configuration provided according to the present invention is based on a statistical parameter of fiber-optic signal data collected through experiments. This enables the algorithm to accurately treat interferences and/or noises encountered in detecting and specifying a vibration, and also avoid the problem of model error occurring in the method for detecting and specifying a vibration on the basis of a logical model.</p>
<p id="p0014" num="0014">A vibration detected and specified according to the present invention is, for example, an environmental vibration caused by a pedestrian, an automobile, a train, wind, rain, snow, or the like. Further, a field to which the present invention is applied is: for example, excavation prevention, theft prevention, and/or leakage prevention in a petrol/gas pipeline; leakage prevention in a petrol/gas well; water-flow disturbance detection and/or geophysical exploration; intrusion prevention in public facilities such as a train, an airport, and a museum; security protection and security measures in a governmental/national buildings such as a city hall, a prison, and a military base; or intrusion prevention along a border and prevention of illegal border transgression.</p>
<p id="p0015" num="0015">Hereinafter, preferable embodiments of the present invention will be described in detail with reference to the drawings. However, the present invention is not limited to the embodiments.</p>
<p id="p0016" num="0016"><figref idref="f0001">FIG. 1</figref> is a flowchart showing a method according to an embodiment of the present invention. As shown in <figref idref="f0001">FIG. 1</figref>, the method includes Step 1 (feature expansion step), Step 2 (dimensionality reduction matrix calculation step), Step 3 (linear dimensionality reduction step), Step 4 (primary classification step), and Step 5 (secondary classification step).<!-- EPO <DP n="6"> --></p>
<heading id="h0006">[Step 1 (Feature Expansion Step)]</heading>
<p id="p0017" num="0017">In Step 1, a feature-expanded function vector is acquired by expanding a feature of initial data of a vibration signal from a distributed fiber-optic sensor. The vibration signal, which is an input data acquired by the distributed fiber-optic sensor, is interpreted as a quadratic function f (t, d) concerning a relationship between a time t and a spatial location d. In this step, the vibration signal f (t, d), which is an input data, is converted into a plurality of feature-expanded functions by a nonlinear conversion. The following functions (1) to (8) can be raised as specific examples of the feature-expanded functions.</p>
<p id="p0018" num="0018">
<ol id="ol0001" compact="compact" ol-style="">
<li>(1) Translation of the initial signal with respect to time,<br/>
for example, <i>g</i><sub>1</sub>(<i>t,d</i>) = <i>f</i>(<i>t</i> ― <i>T,d</i>);</li>
<li>(2) Translation of the initial signal with respect to space,<br/>
for example, <i>g</i><sub>2</sub>(<i>t,d</i>) = <i>f</i>(<i>t,d</i> ― <i>D</i>);</li>
<li>(3) Exponent of the initial signal,<br/>
for example, <i>g</i><sub>3</sub>(<i>t,d</i>) = [<i>f</i>(<i>t,d</i>)]<i><sup>r</sup></i>;</li>
<li>(4) Component of the initial signal in a frequency band F<sub>0</sub>,<br/>
for example, <i>g</i><sub>4</sub>(<i>t,d</i>) = LPF{<i>f</i>(<i>t</i>,<i>d</i>)cos (2<i>πF</i><sub>0</sub><i>t</i>)};</li>
<li>(5) Product of the feature-expanded functions,<br/>
for example, <i>g</i><sub>5</sub>(<i>t,d</i>) = <i>g</i><sub>1</sub>(<i>t,d</i>)<i>g<sub>2</sub></i>(<i>t,</i>d);</li>
<li>(6) Product of a feature-expanded function and the initial signal,<br/>
for example, <i>g</i><sub>6</sub>(<i>t,d</i>) = <i>g</i><sub>4</sub>(<i>t,d</i>)<i>f</i>(<i>t,d</i>);</li>
<li>(7) Partial average values of a time and a spatial location of the initial signal,<br/>
for example, <maths id="math0001" num=""><math display="inline"><msub><mi>g</mi><mn>7</mn></msub><mfenced><mi>t</mi><mi>d</mi></mfenced><mo>=</mo><mfrac><mn>1</mn><mrow><mfenced separators=""><mn>2</mn><mi>N</mi><mo>+</mo><mn>1</mn></mfenced><mfenced separators=""><mn>2</mn><mi>M</mi><mo>+</mo><mn>1</mn></mfenced></mrow></mfrac><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mo>−</mo><mi>N</mi></mrow><mi>N</mi></msubsup><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mo>−</mo><mi>M</mi></mrow><mi>M</mi></msubsup><mrow><mi>f</mi><mfenced separators=""><mi>t</mi><mo>−</mo><mi>n</mi><mo>,</mo><mi>d</mi><mo>−</mo><mi>m</mi></mfenced></mrow></mstyle></mstyle></math><img id="ib0001" file="imgb0001.tif" wi="95" he="9" img-content="math" img-format="tif" inline="yes"/></maths> where, in the equation, N denotes a maximum value in a time domain, and M denotes a maximum value in a spatial location; and</li>
<li>(8) Partial covariance of the initial signal with respect to space,<!-- EPO <DP n="7"> --> for example, <maths id="math0002" num=""><math display="inline"><msub><mi>g</mi><mn>8</mn></msub><mfenced><mi>t</mi><mi>d</mi></mfenced><mo>=</mo><mfrac><mn>1</mn><mrow><mfenced separators=""><mn>2</mn><mi>N</mi><mo>+</mo><mn>1</mn></mfenced><mfenced separators=""><mn>2</mn><mi>M</mi><mo>+</mo><mn>1</mn></mfenced></mrow></mfrac><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mo>−</mo><mi>N</mi></mrow><mi>N</mi></msubsup><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mo>−</mo><mi>M</mi></mrow><mi>M</mi></msubsup><mrow><msup><mi>f</mi><mn>2</mn></msup><mfenced separators=""><mi>t</mi><mo>−</mo><mi>n</mi><mo>,</mo><mi>d</mi><mo>−</mo><mi>m</mi></mfenced><mo>−</mo><msubsup><mi>g</mi><mn>7</mn><mn>2</mn></msubsup><mfenced><mi>t</mi><mi>d</mi></mfenced></mrow></mstyle></mstyle></math><img id="ib0002" file="imgb0002.tif" wi="116" he="9" img-content="math" img-format="tif" inline="yes"/></maths><i>.</i></li>
</ol></p>
<p id="p0019" num="0019">Among the feature-expanded functions (1) to (8), for example, a nonlinearity can be introduced in the initial data by the function g<sub>3</sub> (t, d) or g<sub>6</sub> (t, d). On the other hand, for example, data within predetermined time window and space window can be associated with each other by the function g<sub>1</sub> (t, d), g<sub>2</sub> (t, d), g<sub>5</sub> (t, d), g<sub>7</sub> (t, d), or g<sub>8</sub> (t, d). As a result, the accuracy in detecting and specifying a vibration can be improved. The functions (1) to (8) are nothing more than examples of feature-expanded functions. Further, in Step 1, a feature-expanded function vector g (t, d) is formed by combining the feature-expanded functions.</p>
<heading id="h0007">[Step 2 (Dimensionality Reduction Matrix Calculation Step)]</heading>
<p id="p0020" num="0020">In the step subsequent to Step 1, a calculation of dimensionality reduction matrix is required to reduce the dimensionality of the feature function vector. Accordingly, in Step 2, the dimensionality reduction matrix W is calculated by executing the statistical analysis to the feature on the basis of the feature-expanded function vector g (t, d). The calculation way is in accordance with Fisher's linear discriminant, which is a linear dimensionality reduction algorithm. Sub-steps 21 to 23, which are specific examples, are described below.</p>
<heading id="h0008">(Sub-step 21)</heading>
<p id="p0021" num="0021">First, K<sub>c</sub>-number of training sample sets represented by the following equations are collected for each vibration mode c regarding a vibration (including non-vibration) in the category C to be classified. The training sample set is acquired from a value of a feature-expanded function vector g (t, d) representing a relationship between a time t and a spatial location d corresponding to the vibration category c.</p>
<p id="p0022" num="0022">Training Sample Set: <maths id="math0003" num=""><math display="inline"><mfenced open="{" close="}" separators=""><msubsup><mi mathvariant="bold">g</mi><mn>1</mn><mfenced><mi>c</mi></mfenced></msubsup><mo>,</mo><msubsup><mi mathvariant="bold">g</mi><mn>2</mn><mfenced><mi>c</mi></mfenced></msubsup><mo>,</mo><mo>…</mo><mo>,</mo><msubsup><mi mathvariant="bold">g</mi><msub><mi>K</mi><mi>c</mi></msub><mfenced><mi>c</mi></mfenced></msubsup></mfenced></math><img id="ib0003" file="imgb0003.tif" wi="34" he="9" img-content="math" img-format="tif" inline="yes"/></maths> Wherein <maths id="math0004" num=""><math display="inline"><msubsup><mi mathvariant="bold">g</mi><mi>k</mi><mfenced><mi>c</mi></mfenced></msubsup></math><img id="ib0004" file="imgb0004.tif" wi="8" he="7" img-content="math" img-format="tif" inline="yes"/></maths> denotes a <b>k</b><sup>-th</sup> training sample in vibration category c.</p>
<heading id="h0009">(Sub-step 22)</heading>
<p id="p0023" num="0023">Second, the following statistical amounts are calculated for each vibration category.<!-- EPO <DP n="8"> --></p>
<p id="p0024" num="0024">
<ul id="ul0002" list-style="none" compact="compact">
<li>Center of a cluster: <maths id="math0005" num=""><math display="inline"><msup><mover accent="true"><mi mathvariant="bold">g</mi><mo>‾</mo></mover><mfenced><mi>c</mi></mfenced></msup><mo>=</mo><mfrac><mn>1</mn><msub><mi>K</mi><mi>c</mi></msub></mfrac><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>K</mi><mi>c</mi></msub></msubsup><msubsup><mi mathvariant="bold">g</mi><mi>k</mi><mfenced><mi>c</mi></mfenced></msubsup></mstyle></math><img id="ib0005" file="imgb0005.tif" wi="33" he="9" img-content="math" img-format="tif" inline="yes"/></maths></li>
<li>Variance within the cluster: <maths id="math0006" num=""><math display="inline"><msup><mi mathvariant="bold">S</mi><mfenced><mi>c</mi></mfenced></msup><mo>=</mo><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>K</mi><mi>c</mi></msub></msubsup><mrow><mfenced separators=""><msubsup><mi mathvariant="bold">g</mi><mi>k</mi><mfenced><mi>c</mi></mfenced></msubsup><mo>−</mo><msup><mover accent="true"><mi mathvariant="bold">g</mi><mo>‾</mo></mover><mfenced><mi>c</mi></mfenced></msup></mfenced><msup><mfenced separators=""><msubsup><mi mathvariant="bold">g</mi><mi>k</mi><mfenced><mi>c</mi></mfenced></msubsup><mo>−</mo><msup><mover accent="true"><mi mathvariant="bold">g</mi><mo>‾</mo></mover><mfenced><mi>c</mi></mfenced></msup></mfenced><mi>T</mi></msup></mrow></mstyle></math><img id="ib0006" file="imgb0006.tif" wi="69" he="10" img-content="math" img-format="tif" inline="yes"/></maths></li>
<li>Sum of variances within clusters: <maths id="math0007" num=""><math display="inline"><msub><mi mathvariant="bold-italic">S</mi><mi mathvariant="normal">Σ</mi></msub><mo>=</mo><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></msubsup><msup><mi mathvariant="bold">S</mi><mfenced><mi>c</mi></mfenced></msup></mstyle></math><img id="ib0007" file="imgb0007.tif" wi="26" he="7" img-content="math" img-format="tif" inline="yes"/></maths></li>
<li>Center of all the data: <maths id="math0008" num=""><math display="inline"><mover accent="true"><mi mathvariant="bold">g</mi><mo>‾</mo></mover><mo>=</mo><mfrac><mn>1</mn><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></msubsup><msub><mi>K</mi><mi>c</mi></msub></mstyle></mfrac><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></msubsup><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>K</mi><mi>c</mi></msub></msubsup><msubsup><mi mathvariant="bold">g</mi><mi>k</mi><mfenced><mi>c</mi></mfenced></msubsup></mstyle></mstyle></math><img id="ib0008" file="imgb0008.tif" wi="43" he="10" img-content="math" img-format="tif" inline="yes"/></maths></li>
<li>Variance between clusters: <maths id="math0009" num=""><math display="inline"><mi mathvariant="bold-italic">S</mi><mo>=</mo><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></msubsup><mrow><msub><mi>K</mi><mi>c</mi></msub><mfenced separators=""><mover accent="true"><mi mathvariant="bold">g</mi><mo>‾</mo></mover><mo>−</mo><msup><mover accent="true"><mi mathvariant="bold">g</mi><mo>‾</mo></mover><mfenced><mi>c</mi></mfenced></msup></mfenced><msup><mfenced separators=""><mover accent="true"><mi mathvariant="bold">g</mi><mo>‾</mo></mover><mo>−</mo><msup><mover accent="true"><mi mathvariant="bold">g</mi><mo>‾</mo></mover><mfenced><mi>c</mi></mfenced></msup></mfenced><mi>T</mi></msup></mrow></mstyle></math><img id="ib0009" file="imgb0009.tif" wi="59" he="8" img-content="math" img-format="tif" inline="yes"/></maths></li>
</ul></p>
<heading id="h0010">(Sub-step 23)</heading>
<p id="p0025" num="0025">Third, the feature values of the matrix represented by the following equation are calculated and decomposed. Subsequently, a feature vector corresponding to Q-number of maximum feature values is acquired. Columns in the dimensionality reduction matrix W are constituted by feature vectors.</p>
<p id="p0026" num="0026">Matrix: <maths id="math0010" num=""><math display="inline"><msubsup><mi mathvariant="bold-italic">S</mi><mi mathvariant="normal">Σ</mi><mrow><mo>−</mo><mn>1</mn></mrow></msubsup><mi mathvariant="bold-italic">S</mi></math><img id="ib0010" file="imgb0010.tif" wi="10" he="7" img-content="math" img-format="tif" inline="yes"/></maths></p>
<p id="p0027" num="0027">The algorithm is an example for achieving a linear dimensionality reduction matrix. In a method according to the embodiment of the present invention, the other linear dimensionality reduction algorithms such as Principal Component Analysis (PCA) and Independent Component Analysis (ICA) may be used in place of the aforementioned algorithms.</p>
<heading id="h0011">[Step 3 (Linear Dimensionality Reduction Step)]</heading>
<p id="p0028" num="0028">In Step 3, the initial data of the vibration signal and the previously acquired feature-expanded functions {f (t, d), g<sub>1</sub> (t, d), g<sub>2</sub> (t, d), g<sub>3</sub> (t, d), ... g<sub>P-1</sub> (t, d)} are linearly combined and compressed, and a predetermined number of dimensionality-reduced feature functions {h<sub>1</sub> (t, d), h<sub>2</sub> (t, d), h<sub>3</sub> (t, d), ... h<sub>Q</sub> (t, d)} is acquired. The dimensionality reduction result can be acquired from a matrix equation represented by the following equation.<maths id="math0011" num=""><math display="block"><msup><mi mathvariant="bold">W</mi><mi>T</mi></msup><mi mathvariant="bold">g</mi><mfenced><mi>t</mi><mi>d</mi></mfenced><mo>=</mo><mi mathvariant="bold">h</mi><mfenced><mi>t</mi><mi>d</mi></mfenced></math><img id="ib0011" file="imgb0011.tif" wi="38" he="6" img-content="math" img-format="tif"/></maths> Wherein <b>g</b>(<i>t</i>, <i>d</i>) is a function column vector of a size P × 1, <maths id="math0012" num=""><math display="block"><mi mathvariant="bold">g</mi><mfenced><mi>t</mi><mi>d</mi></mfenced><mo>=</mo><msup><mfenced open="[" close="]" separators=""><mi>f</mi><mfenced><mi>t</mi><mi>d</mi></mfenced><msub><mi>g</mi><mn>1</mn></msub><mfenced><mi>t</mi><mi>d</mi></mfenced><msub><mi>g</mi><mn>2</mn></msub><mfenced><mi>t</mi><mi>d</mi></mfenced><msub><mi>g</mi><mn>3</mn></msub><mfenced><mi>t</mi><mi>d</mi></mfenced><mo>…</mo><msub><mi>g</mi><mrow><mi>P</mi><mo>−</mo><mn>1</mn></mrow></msub><mfenced><mi>t</mi><mi>d</mi></mfenced></mfenced><mi>T</mi></msup><mo>,</mo></math><img id="ib0012" file="imgb0012.tif" wi="105" he="6" img-content="math" img-format="tif"/></maths> <b>h</b>(<i>t</i>, <i>d</i>) is a function vector of a size Q × 1,<!-- EPO <DP n="9"> --> <maths id="math0013" num=""><math display="block"><mi mathvariant="bold">h</mi><mfenced><mi>t</mi><mi>d</mi></mfenced><mo>=</mo><msup><mfenced open="[" close="]" separators=""><msub><mi>h</mi><mn>1</mn></msub><mfenced><mi>t</mi><mi>d</mi></mfenced><msub><mi>h</mi><mn>2</mn></msub><mfenced><mi>t</mi><mi>d</mi></mfenced><msub><mi>h</mi><mn>3</mn></msub><mfenced><mi>t</mi><mi>d</mi></mfenced><mo>…</mo><msub><mi>h</mi><mi>Q</mi></msub><mfenced><mi>t</mi><mi>d</mi></mfenced></mfenced><mi>T</mi></msup><mo>,</mo></math><img id="ib0013" file="imgb0013.tif" wi="88" he="8" img-content="math" img-format="tif"/></maths> the dimensionality reduction matrix W is a numerical matrix of a size P × Q,<br/>
the vector <b>h</b>(t, d) has a size smaller than <b>g</b>(t, d), and Q &lt; P.</p>
<heading id="h0012">[Step 4 (Primary Classification Step)]</heading>
<p id="p0029" num="0029">In Step 4, the feature vector h (t, d) having been subjected to the dimensionality reduction is input in a classifier (hereinafter, also referred to as "primary classifier") which has been subjected to the training and contains a control parameter, and a vibration category c is output. The value of the vibration category c may be set as c = 1, 2, ..., C, and the category c = 1 means no vibration. A decision tree classifier may be used as the classifier. However, a classifier containing a neural network or a support vector machine (SVM) may be used. Since a variety of trainers are described in the machine learning theory, no further description is made here. The control parameter of the classifier is acquired through the training. In the training of parameter, a training sample set {(hi, c<sub>1</sub>), (h2, c<sub>2</sub>), (h<sub>3</sub>, c<sub>3</sub>), ...} of the vibration in category C to be classified is input. Here, (h<sub>k</sub>, c<sub>k</sub>) represents a training sample in a vibration category c<sub>k</sub>, and h<sub>k</sub> denotes a value in a feature function vector h (t, d) which corresponds to an occurrence time t and a spatial location d of the vibration in the current category and has been subjected to the dimensionality reduction. The specific algorithm configuration corresponds to the primary classifier, for example, a decide tree trainer, a neural network trainer, and a support vector machine trainer.</p>
<p id="p0030" num="0030">Step 4 is performed to achieve the primary classification. An error which is contained in the output in Step 4 is removed in the secondary classification in the subsequent Step.</p>
<heading id="h0013">[Step 5 (Secondary Classification Step)]</heading>
<p id="p0031" num="0031">In Step 5, the primary classification result e (t, d) acquired in Step 4 is improved. The improvement includes removal of a wrongly detected vibration and/or correction of a wrongly classified vibration. In an actual processing, the vibration continuing time and/or the concerning spatial area is large depending on a category difference, and liable to exceed the area covered by the feature-expanded function. Therefore, it is required to execute a secondary analysis by use<!-- EPO <DP n="10"> --> of a classification result in a broader time and spatial ranges from a higher dimensionality. Sub-steps 51 to 53, which are specific examples, are described below.</p>
<heading id="h0014">(Sub-step 51)</heading>
<p id="p0032" num="0032">First, the primary classification result e (t, d) acquired in Step 4 is converted into a logical variable represented by the following equation. The logical variable is a single sequence variable consisting of the values of 0 and 1.</p>
<p id="p0033" num="0033">Logical variable: <maths id="math0014" num=""><math display="inline"><msubsup><mi>L</mi><mrow><mi>m</mi><mo>,</mo><mi>n</mi></mrow><mfenced><mi>i</mi></mfenced></msubsup><mo>=</mo><mrow><mo>{</mo><mtable><mtr><mtd><mrow><mn>1</mn><mspace width="1ex"/><mi mathvariant="italic">if</mi><mspace width="1ex"/><mi>e</mi><mfenced separators=""><mi>t</mi><mo>−</mo><mi>m</mi><mo>,</mo><mi>d</mi><mo>−</mo><mi>n</mi></mfenced><mo>=</mo><mo>=</mo><mi>i</mi></mrow></mtd></mtr><mtr><mtd><mtable><mtr><mtd><mn>0</mn></mtd><mtd><mi mathvariant="italic">otherwise</mi></mtd></mtr></mtable></mtd></mtr></mtable></mrow></math><img id="ib0014" file="imgb0014.tif" wi="55" he="9" img-content="math" img-format="tif" inline="yes"/></maths><br/>
Wherein <maths id="math0015" num=""><math display="inline"><msubsup><mi>L</mi><mrow><mi>m</mi><mo>,</mo><mi>n</mi></mrow><mfenced><mi>i</mi></mfenced></msubsup></math><img id="ib0015" file="imgb0015.tif" wi="8" he="6" img-content="math" img-format="tif" inline="yes"/></maths> denotes a logical variable when a fiber-optic signal at a time (t - m) and a location (d - n) is determined to be a vibration of category i by the primary classifier.</p>
<heading id="h0015">(Sub-step 52)</heading>
<p id="p0034" num="0034">Second, a score is calculated for each vibration category on the basis of a logical rule in a logical rule base.</p>
<p id="p0035" num="0035">Here, each logical rule includes the following definitions (a) and (b).</p>
<p id="p0036" num="0036">
<ol id="ol0002" compact="compact" ol-style="">
<li>(a) A logical equation is represented by J<sub>b</sub> (L), wherein the input L is the entirety of the logical variable <maths id="math0016" num=""><math display="inline"><msubsup><mi>L</mi><mrow><mi>m</mi><mo>,</mo><mi>n</mi></mrow><mfenced><mi>i</mi></mfenced></msubsup></math><img id="ib0016" file="imgb0016.tif" wi="9" he="7" img-content="math" img-format="tif" inline="yes"/></maths>, and the subscript b denotes the b<sup>-th</sup> logical equation.</li>
<li>(b) When the logical equation J<sub>b</sub> (L) is established, a contribution degree to a score of each vibration category is <maths id="math0017" num=""><math display="inline"><msubsup><mi>s</mi><mi>b</mi><mfenced><mi>c</mi></mfenced></msubsup></math><img id="ib0017" file="imgb0017.tif" wi="8" he="7" img-content="math" img-format="tif" inline="yes"/></maths>. Namely, <maths id="math0018" num=""><math display="inline"><msubsup><mi>s</mi><mi>b</mi><mfenced><mi>c</mi></mfenced></msubsup></math><img id="ib0018" file="imgb0018.tif" wi="7" he="8" img-content="math" img-format="tif" inline="yes"/></maths> denotes a contribution degree to a score of a vibration in category c when the b<sup>-th</sup> logical equation is established.</li>
</ol>
With respect to B-number of whole logical equations {J<sub>1</sub> (L), J<sub>2</sub> (L), ..., J<sub>B</sub> (L)}, a score <i>s</i><sup>(<i>c</i>)</sup> when the current vibration signal belongs to category c is calculated in the equation <i>s</i><sup>(<i>c</i>)</sup> = <maths id="math0019" num=""><math display="inline"><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>b</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></msubsup><mrow><msub><mi>J</mi><mi>b</mi></msub><mfenced><mi mathvariant="bold">L</mi></mfenced><msubsup><mi>s</mi><mi>b</mi><mfenced><mi>c</mi></mfenced></msubsup></mrow></mstyle></math><img id="ib0019" file="imgb0019.tif" wi="25" he="7" img-content="math" img-format="tif" inline="yes"/></maths>.</p>
<heading id="h0016">(Sub-step 53)</heading>
<p id="p0037" num="0037">Third, the vibration category corresponding to a highest score represented by the following equation is output.<maths id="math0020" num=""><math display="block"><mi>e</mi><mo>*</mo><mfenced><mi>t</mi><mi>d</mi></mfenced><mo>=</mo><msub><mi>argmax</mi><mi>c</mi></msub><mspace width="1ex"/><msup><mi>s</mi><mfenced><mi>c</mi></mfenced></msup></math><img id="ib0020" file="imgb0020.tif" wi="39" he="9" img-content="math" img-format="tif"/></maths><!-- EPO <DP n="11"> --></p>
<p id="p0038" num="0038">Here, two specific examples J<sub>1</sub> (L) and J<sub>2</sub> (L) are shown in order to describe a specific formation of this logical equation.<maths id="math0021" num=""><math display="block"><msub><mi>J</mi><mn>1</mn></msub><mfenced><mi mathvariant="bold">L</mi></mfenced><mo>=</mo><msubsup><mi>L</mi><mn>0,0</mn><mfenced><mn>1</mn></mfenced></msubsup><mspace width="1ex"/><mi mathvariant="italic">and</mi><mfenced separators=""><msubsup><mi>L</mi><mn>1,0</mn><mfenced><mn>1</mn></mfenced></msubsup><mspace width="1ex"/><mi mathvariant="italic">or</mi><mspace width="1ex"/><msubsup><mi>L</mi><mn>2,0</mn><mfenced><mn>1</mn></mfenced></msubsup></mfenced></math><img id="ib0021" file="imgb0021.tif" wi="50" he="8" img-content="math" img-format="tif"/></maths> <maths id="math0022" num=""><math display="block"><msub><mi>J</mi><mn>2</mn></msub><mfenced><mi mathvariant="bold">L</mi></mfenced><mo>=</mo><msubsup><mi>L</mi><mn>0,0</mn><mfenced><mn>5</mn></mfenced></msubsup><mspace width="1ex"/><mi mathvariant="italic">and</mi><mspace width="1ex"/><msubsup><mi>L</mi><mn>0,1</mn><mfenced><mn>5</mn></mfenced></msubsup><mspace width="1ex"/><mi mathvariant="italic">and</mi><mspace width="1ex"/><msubsup><mi>L</mi><mrow><mn>0</mn><mo>,</mo><mo>−</mo><mn>1</mn></mrow><mfenced><mn>5</mn></mfenced></msubsup></math><img id="ib0022" file="imgb0022.tif" wi="51" he="7" img-content="math" img-format="tif"/></maths></p>
<p id="p0039" num="0039">J<sub>1</sub> (L) represents a logical event when a vibration in category 1 is detected by the first classifier at a current time, a preceding time or a time preceding the preceding time.</p>
<p id="p0040" num="0040">J<sub>2</sub> (L) represents a logical event when a vibration in category 5 is detected by the first classifier at a current location and adjacent locations in front of and behind the current location.</p>
<p id="p0041" num="0041"><figref idref="f0002">FIG.2</figref> is a block diagram (a schematic diagram of a function module) of a system according to an embodiment of the present invention. The system corresponds to the method described in the embodiment. Specifically, a system according to the embodiment of the present invention is for detecting and specifying a vibration on the basis of a feature of a fiber-optic signal to determine a time and a spatial location, and comprises: a feature expansion unit for acquiring a feature-expanded function vector and C-number of vibration categories by expanding a feature of initial data of a vibration signal from a distributed fiber-optic sensor; a dimensionality reduction matrix calculation unit for calculating a dimensionality reduction matrix based on the feature-expanded function vector; a linear dimensionality reduction unit for acquiring a dimensionality-reduced feature function by operating the dimensionality reduction matrix to the initial data and the feature-expanded function vector; a primary classification unit for acquiring a primary classification result of the vibration signal by performing a classification with reference to a primary classification parameter acquired from a parameter database; and a secondary classification unit for acquiring and outputting a secondary classification result of the vibration signal by performing removal of a wrong detection result and correction of a wrong classification result of the primary classification result.</p>
<p id="p0042" num="0042">The system may further comprise a parameter database. The parameter database is used<!-- EPO <DP n="12"> --> to accumulate at least one of the dimensionality reduction matrix, a classifier parameter, and a logical rule base.</p>
<p id="p0043" num="0043">As described above, one aspect of the present invention is directed to a method for detecting and specifying vibrations on the basis of a feature of a fiber-optic signal to determine a time and a spatial location comprising: Step 1 (feature expansion step) of acquiring a feature-expanded function vector and C-number of vibration categories by expanding a feature of initial data of a vibration signal from a distributed fiber-optic sensor; Step 2 (dimensionality reduction matrix calculation step) of calculating a dimensionality reduction matrix based on the feature-expanded function vector; Step 3 (linear dimensionality reduction step) of acquiring a dimensionality-reduced feature function by operating the dimensionality reduction matrix to the initial data and the feature-expanded function vector; Step 4 (primary classification step) of acquiring a primary classification result of the vibration signal by performing a classification with reference to a primary classification parameter acquired from a parameter database; and Step 5 (secondary classification step) of acquiring and outputting a secondary classification result of the vibration signal by performing removal of a wrong detection result and correction of a wrong classification result of the primary classification result.</p>
<p id="p0044" num="0044">In the method described above, Step 2 preferably includes: Sub-step 21 of collecting a training sample set represented by the following Equation 1 for vibration category c; Sub-step 22 of calculating, for each vibration category, a center of a cluster represented by the following Equation 2, a variance within the cluster represented by the following Equation 3, a sum of variances within clusters represented by the following Equation 4, a center of all the data represented by the following Equation 5, and a variance between clusters represented by the following Equation 6; and Sub-step 23 of calculating a feature value of a matrix represented by the following Equation 7, decomposing the matrix, acquiring Q-number of maximum feature values and corresponding feature vectors, and composing the dimensionality reduction matrix by using columns of the feature vectors.<!-- EPO <DP n="13"> --></p>
<p id="p0045" num="0045">Training sample set: <maths id="math0023" num="(Equation 1)"><math display="block"><mfenced open="{" close="}" separators=""><msubsup><mi mathvariant="bold">g</mi><mn>1</mn><mfenced><mi>c</mi></mfenced></msubsup><mo>,</mo><msubsup><mi mathvariant="bold">g</mi><mn>2</mn><mfenced><mi>c</mi></mfenced></msubsup><mo>,</mo><mo>…</mo><mo>,</mo><msubsup><mi mathvariant="bold">g</mi><msub><mi>K</mi><mi>c</mi></msub><mfenced><mi>c</mi></mfenced></msubsup></mfenced></math><img id="ib0023" file="imgb0023.tif" wi="110" he="9" img-content="math" img-format="tif"/></maths></p>
<p id="p0046" num="0046">In Equation 1, <maths id="math0024" num=""><math display="inline"><msubsup><mi mathvariant="bold">g</mi><mi>k</mi><mfenced><mi>c</mi></mfenced></msubsup></math><img id="ib0024" file="imgb0024.tif" wi="8" he="7" img-content="math" img-format="tif" inline="yes"/></maths> denotes a k-<sup>th</sup> training sample in vibration category c.</p>
<p id="p0047" num="0047">Center of a cluster: <maths id="math0025" num="(Equation 2)"><math display="block"><msup><mover accent="true"><mi mathvariant="bold">g</mi><mo>‾</mo></mover><mfenced><mi>c</mi></mfenced></msup><mo>=</mo><mfrac><mn>1</mn><msub><mi>K</mi><mi>c</mi></msub></mfrac><msubsup><mi mathvariant="normal">Σ</mi><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>K</mi><mi>c</mi></msub></msubsup><msubsup><mi mathvariant="bold">g</mi><mi>k</mi><mfenced><mi>c</mi></mfenced></msubsup></math><img id="ib0025" file="imgb0025.tif" wi="112" he="9" img-content="math" img-format="tif"/></maths></p>
<p id="p0048" num="0048">In Equation 2, Kc denotes the number of training samples in the category c.</p>
<p id="p0049" num="0049">Variance within a cluster: <maths id="math0026" num="(Equation 3)"><math display="block"><msup><mi mathvariant="bold">S</mi><mfenced><mi>c</mi></mfenced></msup><mo>=</mo><msubsup><mi mathvariant="normal">Σ</mi><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>K</mi><mi>c</mi></msub></msubsup><mfenced separators=""><msubsup><mi mathvariant="bold">g</mi><mi>k</mi><mfenced><mi>c</mi></mfenced></msubsup><mo>−</mo><msup><mover accent="true"><mi mathvariant="bold">g</mi><mo>‾</mo></mover><mfenced><mi>c</mi></mfenced></msup></mfenced><msup><mfenced separators=""><msubsup><mi mathvariant="bold">g</mi><mi>k</mi><mfenced><mi>c</mi></mfenced></msubsup><mo>−</mo><msup><mover accent="true"><mi mathvariant="bold">g</mi><mo>‾</mo></mover><mfenced><mi>c</mi></mfenced></msup></mfenced><mi>T</mi></msup></math><img id="ib0026" file="imgb0026.tif" wi="100" he="9" img-content="math" img-format="tif"/></maths></p>
<p id="p0050" num="0050">Sum of variances within clusters: <maths id="math0027" num="(Equation 4)"><math display="block"><msub><mi mathvariant="bold-italic">S</mi><mi mathvariant="normal">Σ</mi></msub><mo>=</mo><msubsup><mi mathvariant="normal">Σ</mi><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></msubsup><msup><mi mathvariant="bold">S</mi><mfenced><mi>c</mi></mfenced></msup></math><img id="ib0027" file="imgb0027.tif" wi="88" he="6" img-content="math" img-format="tif"/></maths></p>
<p id="p0051" num="0051">In Equation 4, C denotes the total number of vibration categories.</p>
<p id="p0052" num="0052">Center of all the data: <maths id="math0028" num="(Equation 5)"><math display="block"><mover accent="true"><mi mathvariant="bold">g</mi><mo>‾</mo></mover><mo>=</mo><mfrac><mn>1</mn><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></msubsup><msub><mi>K</mi><mi>c</mi></msub></mstyle></mfrac><msubsup><mi mathvariant="normal">Σ</mi><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></msubsup><msubsup><mi mathvariant="normal">Σ</mi><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>K</mi><mi>c</mi></msub></msubsup><msubsup><mi mathvariant="bold">g</mi><mi>k</mi><mfenced><mi>c</mi></mfenced></msubsup></math><img id="ib0028" file="imgb0028.tif" wi="108" he="9" img-content="math" img-format="tif"/></maths></p>
<p id="p0053" num="0053">Variance between clusters: <maths id="math0029" num="(Equation 6)"><math display="block"><mi mathvariant="bold-italic">S</mi><mo>=</mo><msubsup><mi mathvariant="normal">Σ</mi><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></msubsup><msub><mi>K</mi><mi>c</mi></msub><mfenced separators=""><mover accent="true"><mi mathvariant="bold">g</mi><mo>‾</mo></mover><mo>−</mo><msup><mover accent="true"><mi mathvariant="bold">g</mi><mo>‾</mo></mover><mfenced><mi>c</mi></mfenced></msup></mfenced><msup><mfenced separators=""><mover accent="true"><mi mathvariant="bold">g</mi><mo>‾</mo></mover><mo>−</mo><msup><mover accent="true"><mi mathvariant="bold">g</mi><mo>‾</mo></mover><mfenced><mi>c</mi></mfenced></msup></mfenced><mi>T</mi></msup></math><img id="ib0029" file="imgb0029.tif" wi="99" he="8" img-content="math" img-format="tif"/></maths></p>
<p id="p0054" num="0054">Matrix: <maths id="math0030" num="(Equation 7)"><math display="block"><msubsup><mi mathvariant="bold-italic">S</mi><mi mathvariant="normal">Σ</mi><mrow><mo>−</mo><mn>1</mn></mrow></msubsup><mi mathvariant="bold-italic">S</mi></math><img id="ib0030" file="imgb0030.tif" wi="132" he="7" img-content="math" img-format="tif"/></maths></p>
<p id="p0055" num="0055">In the method described above, in Step 2, the dimensionality reduction matrix is preferably acquired by Principal Component Analysis or Independent Component Analysis.</p>
<p id="p0056" num="0056">In the method described above, Step 5 preferably includes: Sub-step 51 of converting the primary classification result represented by the following Equation 8 to a logical variable represented by the following Equation 9; Sub-step 52 of calculating, for each vibration category, a score of B-number of whole logical equations {J<sub>1</sub> (L), J<sub>2</sub> (L), ..., J<sub>B</sub> (L)} in a logical rule base on the basis of a calculation equation represented by the following Equation 10; and Sub-step 53 of outputting a vibration category corresponding to a highest score represented by the following Equation 11 as an output of a secondary classifier.</p>
<p id="p0057" num="0057">Primary Classification Result: <maths id="math0031" num="(Equation 8)"><math display="block"><mi>e</mi><mfenced><mi>t</mi><mi>d</mi></mfenced></math><img id="ib0031" file="imgb0031.tif" wi="93" he="6" img-content="math" img-format="tif"/></maths></p>
<p id="p0058" num="0058">Logical Variable: <maths id="math0032" num="(Equation 9)"><math display="block"><msubsup><mi>L</mi><mrow><mi>m</mi><mo>,</mo><mi>n</mi></mrow><mfenced><mi>i</mi></mfenced></msubsup><mo>=</mo><mrow><mo>{</mo><mtable><mtr><mtd><mrow><mn>1</mn><mspace width="1ex"/><mi mathvariant="italic">if</mi><mspace width="1ex"/><mi>e</mi><mfenced separators=""><mi>t</mi><mo>−</mo><mi>m</mi><mo>,</mo><mi>d</mi><mo>−</mo><mi>n</mi></mfenced><mo>=</mo><mo>=</mo><mi>i</mi></mrow></mtd></mtr><mtr><mtd><mtable><mtr><mtd><mn>0</mn></mtd><mtd><mi mathvariant="italic">otherwise</mi></mtd></mtr></mtable></mtd></mtr></mtable></mrow></math><img id="ib0032" file="imgb0032.tif" wi="114" he="10" img-content="math" img-format="tif"/></maths></p>
<p id="p0059" num="0059">In Equation 9, <maths id="math0033" num=""><math display="inline"><msubsup><mi>L</mi><mrow><mi>m</mi><mo>,</mo><mi>n</mi></mrow><mfenced><mi>i</mi></mfenced></msubsup></math><img id="ib0033" file="imgb0033.tif" wi="9" he="8" img-content="math" img-format="tif" inline="yes"/></maths>denotes a logical variable when a fiber-optic signal at a time (t - m) and a location (d - n) is determined to be a vibration of category i in Step 4.</p>
<p id="p0060" num="0060">Calculation Equation: <maths id="math0034" num="(Equation 10)"><math display="block"><msup><mi>s</mi><mfenced><mi>c</mi></mfenced></msup><mo>=</mo><msubsup><mi mathvariant="normal">Σ</mi><mrow><mi>b</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></msubsup><msub><mi>J</mi><mi>b</mi></msub><mfenced><mi mathvariant="bold">L</mi></mfenced><msubsup><mi>s</mi><mi>b</mi><mfenced><mi>c</mi></mfenced></msubsup></math><img id="ib0034" file="imgb0034.tif" wi="109" he="7" img-content="math" img-format="tif"/></maths><!-- EPO <DP n="14"> --></p>
<p id="p0061" num="0061">In Equation 10, s<sup>(c)</sup> denotes a score on the basis of the whole logical equations in the logical rule base when the current vibration belongs to category c, wherein the input L in (L) configures all the logical variables <maths id="math0035" num=""><math display="inline"><msubsup><mi>L</mi><mrow><mi>m</mi><mo>,</mo><mi>n</mi></mrow><mfenced><mi>i</mi></mfenced></msubsup></math><img id="ib0035" file="imgb0035.tif" wi="9" he="7" img-content="math" img-format="tif" inline="yes"/></maths>, the subscript b denotes the b<sup>-th</sup> logical equation, and <maths id="math0036" num=""><math display="inline"><msubsup><mi>s</mi><mi>b</mi><mfenced><mi>c</mi></mfenced></msubsup></math><img id="ib0036" file="imgb0036.tif" wi="8" he="7" img-content="math" img-format="tif" inline="yes"/></maths> denotes a contribution degree to a score in each vibration category when the logical equation (L) is established.<br/>
Vibration category corresponding to a highest score: <maths id="math0037" num="(Equation 11)"><math display="block"><mi>e</mi><mo>*</mo><mfenced><mi>t</mi><mi>d</mi></mfenced><mo>=</mo><msub><mi>argmax</mi><mi>c</mi></msub><mspace width="1ex"/><msup><mi>s</mi><mfenced><mi>c</mi></mfenced></msup></math><img id="ib0037" file="imgb0037.tif" wi="70" he="9" img-content="math" img-format="tif"/></maths></p>
<p id="p0062" num="0062">Another aspect of the present invention is directed to a system for detecting and specifying a vibration on the basis of a feature of a fiber-optic signal to determine a time and a spatial location comprising: a feature expansion unit for acquiring a feature-expanded function vector and C-number of vibration categories by expanding a feature of initial data of a vibration signal from a distributed fiber-optic sensor; a dimensionality reduction matrix calculation unit for calculating a dimensionality reduction matrix based on the feature-expanded function vector; a linear dimensionality reduction unit for acquiring a dimensionality-reduced feature function by operating the dimensionality reduction matrix to the initial data and the feature-expanded function vector; a primary classification unit for acquiring a primary classification result of the vibration signal by performing a classification with reference to a primary classification parameter acquired from a parameter database; and a secondary classification unit for acquiring and outputting a secondary classification result of the vibration signal by performing removal of a wrong detection result and correction of a wrong classification result of the primary classification result.</p>
<p id="p0063" num="0063">In the system, the parameter database is preferably used to accumulate at least one of the dimensionality reduction matrix, a classifier parameter, and a logical rule base.</p>
<p id="p0064" num="0064">The present invention has the following technical advantageous effects.</p>
<p id="p0065" num="0065">The present invention introduces a nonlinearity in the initial data by nonlinearly expanding a feature in the time, space, and frequency band, and associates data within<!-- EPO <DP n="15"> --> predetermined time window and space window with each other. Consequently, a vibration signal in a single field of time and space is not analyzed as a single point by a classifier, but is analyzed and classified in combination in the subsequent processing. As a result, the feature expansion improves the accuracy in detecting a vibration in the present invention.</p>
<p id="p0066" num="0066">Besides, the present invention adopts a two-stage specification way in specifying a vibration category. In the first stage, a primary classification of a vibration category is performed by use of an expanded feature data. In the second stage, the result of the primary classification is improved in accordance with a logical rule. Specifically, vibration detection results within relatively broad time and spatial ranges are associated with each other in accordance with a predetermined logical rule to thereby eliminate a specification error caused by an occasional interference and a wrong specification. This improves the accuracy in specifying a vibration in the present invention.</p>
<p id="p0067" num="0067">Further, in the present invention, statistical classification technologies and classification experiences in the field of fiber-optic signal detection are effectively combined in the two-stage specification-classification way. This secures the accuracy of a specification algorithm in the present invention.</p>
<p id="p0068" num="0068">According to the present invention, for example, when detecting and specifying an environmental vibration on a railroad by use of a four-tiered decision tree classifier, the high reliability and accuracy were made that the space specification rate was ± 10m; the response time to a vibration was three seconds or less; the wrong detection in a week occurred one or less a day; and the detection failure in a week occurred zero. In contrast, when detecting and specifying an environmental vibration on a railroad by an artificial intelligence (AI), the poor reliability and accuracy were made that the wrong detection in a week occurred twelve or more a day. As it can be seen, the present invention can relatively promptly and also accurately detect and specify a vibration and determine a time and a spatial location in a smaller amount of training data than AI.</p>
<p id="p0069" num="0069">Hereinafter, the present invention will be further specifically described by way of<!-- EPO <DP n="16"> --> Examples. However, the scope of the present invention is not limited to the Examples.</p>
<heading id="h0017"><b>Examples</b></heading>
<p id="p0070" num="0070">The present invention was applied to an area security system to distinguish vibrations caused by three types of intrusive actions (namely, fence climbing, fence striking, and optical fiber intersection) defined in the area security system. Detection signals in the three types of invasive actions are shown in <figref idref="f0003 f0004 f0005">FIGS. 3 to 5</figref>. More specifically, <figref idref="f0003">FIG. 3</figref> is a diagram showing a vibration signal occurring in the case of climbing a fence in this Example. <figref idref="f0004">FIG. 4</figref> is a diagram showing a vibration signal occurring in the case of striking a fence in this Example. <figref idref="f0005">FIG. 5</figref> is a diagram showing a vibration signal occurring in the case of intersecting an optical fiber in this Example. In these drawings, the X axis represents a location on the optical fiber, the Y axis represents a vibration frequency, and the Z axis represents a vibration intensity.</p>
<p id="p0071" num="0071">As shown in <figref idref="f0003 f0004 f0005">FIGS. 3 to 5</figref>, quite remarkable differences were observed between feature vectors corresponding to motions of the different intrusive actions. Specifically, in the case of climbing a fence, the energy distribution is mainly concentrated in a low frequency band in the frequency range. However, in the case of striking a fence, the energy distribution is relatively shifted to a high frequency side compared with the case of climbing the fence. Additionally, in the case of intersecting an optical fiber, the energy distribution is mainly in a high frequency band. The feature vectors corresponding to the motions of the three types of intrusive actions have the significant differences from one another. Thus, these differences could be seen to be usable as an effective training for a feature vector.</p>
<p id="p0072" num="0072">Accordingly, a great number of experiments on the three types of intrusive actions was conducted, and the collected fiber-optic sensing data were used as training data. Specifically, sequentially arrayed 19991 pieces of csv data (100 columns) were collected in a given time, and were composited into a csv file with 19991 rows × 100 columns to thereby obtain an initial feature data file "feature.csv" of the events. Subsequently, a csv file "target.csv" with the same number<!-- EPO <DP n="17"> --> of rows and columns as the file "feature.csv" was produced. All the data in the file "target.csv" was allotted with "0" at the initial place, and the twelfth channel was used as an experimental event occurrence channel based on experimental records and data comparison. The twelfth column of the file "target.csv" was allotted with event data. Specifically, as an event data, "1" was allotted to the case of climbing a fence, "2" to the case of striking a fence, and "3" to the case of intersecting an optical fiber, respectively. When extracting a result on the basis of the feature, the following feature expansion equations were used.</p>
<p id="p0073" num="0073">
<ul id="ul0003" list-style="none" compact="compact">
<li>F1 = input('C:/work/Fiber/dt_tree/data/feature.csv')</li>
<li>F2 = F1.time_shift(1)</li>
<li>F3 = F1.time_shift(2)</li>
<li>F4 = F1.time_shift(3)</li>
<li>F5 = F1.time_shift(-2)</li>
<li>F6 = F1.time_shift(-4)</li>
<li>F7 = F1.time_shift(-8)</li>
<li>F8 = F1.channel_shift(4)</li>
<li>F9 = F1.channel_shift(5)</li>
<li>F10= F1.channel_shift(6)</li>
<li>F11= F1.channel_shift(-1)</li>
<li>F12= F1.channel_shift(-2)</li>
<li>F13= F1.channel_shift(-3)</li>
</ul></p>
<p id="p0074" num="0074">After having executed the algorithm program, the generated decide tree was applied to the area security system, and numerous detection tests were conducted. The results are shown below.</p>
<p id="p0075" num="0075">First, in detection test of 2000 fence climbings, 11 detection failures and 21 wrong detections occurred. The wrong detections included 6 detections as fence striking action and 15 detections as optical fiber intersecting action.<!-- EPO <DP n="18"> --></p>
<p id="p0076" num="0076">Next, in detection tests of 2000 fence strikings, 5 detection failures and 13 wrong detections occurred. The wrong detections included 3 detections as fence climbing action and 10 detections as optical fiber intersecting action.</p>
<p id="p0077" num="0077">Further, in detection tests of 2000 optical fiber intersections, 3 detection failures and 31 wrong detections occurred. The wrong detections included 26 detections as fence climbing action and 5 detections as fence striking action.</p>
<p id="p0078" num="0078">The whole error rate is: ((11 + 21) + (5 + 13) + (3 + 31)) / (2000 + 2000 + 2000) × 100 = 1.4%. Consequently, the category classification of the three types of intrusive actions that is required for an area security system was confirmed to be established.</p>
<p id="p0079" num="0079">The present application is based on <patcit id="pcit0001" dnum="CN201811635297" dnum-type="L"><text>Chinese Patent Application No. 201811635297.3 filed on December 29, 2018</text></patcit>, and the contents of which are incorporated in the present application.</p>
<p id="p0080" num="0080">The present invention was suitably and fully described above by means of embodiments in order to express the present invention. However, it should be recognized that a person skilled in the art would be able to easily modify and/or improve the embodiments described above. Accordingly, a modified embodiment or an improved embodiment achieved by the person skilled in the art are construed to be comprehended in the protection scope of Claims as long as the modified embodiment or the improved embodiment do not deviate from the protection scope of Claims.</p>
</description>
<claims id="claims01" lang="en"><!-- EPO <DP n="19"> -->
<claim id="c-en-0001" num="0001">
<claim-text>A method for detecting and specifying a vibration on the basis of a feature of a fiber-optic signal to determine a time and a spatial location, comprising:
<claim-text>Step 1 of acquiring a feature-expanded function vector and C-number of vibration categories by expanding a feature of initial data of a vibration signal from a distributed fiber-optic sensor;</claim-text>
<claim-text>Step 2 of calculating a dimensionality reduction matrix based on the feature-expanded function vector;</claim-text>
<claim-text>Step 3 of acquiring a dimensionality-reduced feature function by operating the dimensionality reduction matrix to the initial data and the feature-expanded function vector;</claim-text>
<claim-text>Step 4 of acquiring a primary classification result of the vibration signal by performing a classification with reference to a primary classification parameter acquired from a parameter database; and</claim-text>
<claim-text>Step 5 of acquiring and outputting a secondary classification result of the vibration signal by performing removal of a wrong detection result and correction of a wrong classification result of the primary classification result.</claim-text></claim-text></claim>
<claim id="c-en-0002" num="0002">
<claim-text>The method for detecting and specifying a vibration on the basis of a feature of a fiber-optic signal to determine a time and a spatial location according to claim 1, wherein
<claim-text>Step 2 includes:
<claim-text>Sub-step 21 of collecting a training sample set represented by the following Equation 1 for vibration category c;</claim-text>
<claim-text>Sub-step 22 of calculating, for each vibration category, a center of a cluster represented by the following Equation 2, a variance within the cluster represented by the following Equation 3, a sum of variances within clusters represented by the following Equation 4, a center<!-- EPO <DP n="20"> --> of all the data represented by the following Equation 5, and a variance between clusters represented by the following Equation 6; and</claim-text>
<claim-text>Sub-step 23 of calculating a feature value of a matrix represented by the following Equation 7, decomposing the matrix, acquiring Q-number of maximum feature values and corresponding feature vectors, and composing the dimensionality reduction matrix by using columns of the feature vectors,</claim-text></claim-text>
<claim-text>Training sample set: <maths id="math0038" num="(Equation 1),"><math display="block"><mfenced open="{" close="}" separators=""><msubsup><mi mathvariant="bold">g</mi><mn>1</mn><mfenced><mi>c</mi></mfenced></msubsup><mo>,</mo><msubsup><mi mathvariant="bold">g</mi><mn>2</mn><mfenced><mi>c</mi></mfenced></msubsup><mo>,</mo><mo>…</mo><mo>,</mo><msubsup><mi mathvariant="bold">g</mi><msub><mi>K</mi><mi>c</mi></msub><mfenced><mi>c</mi></mfenced></msubsup></mfenced></math><img id="ib0038" file="imgb0038.tif" wi="111" he="9" img-content="math" img-format="tif"/></maths> where, in Equation 1, <maths id="math0039" num=""><math display="inline"><msubsup><mi mathvariant="bold">g</mi><mi>k</mi><mfenced><mi>c</mi></mfenced></msubsup></math><img id="ib0039" file="imgb0039.tif" wi="8" he="7" img-content="math" img-format="tif" inline="yes"/></maths> denotes a k-<sup>th</sup> training sample in vibration category c,</claim-text>
<claim-text>Center of a cluster: <maths id="math0040" num="(Equation 2),"><math display="block"><msup><mover accent="true"><mi mathvariant="bold">g</mi><mo>‾</mo></mover><mfenced><mi>c</mi></mfenced></msup><mo>=</mo><mfrac><mn>1</mn><msub><mi>K</mi><mi>c</mi></msub></mfrac><msubsup><mi mathvariant="normal">Σ</mi><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>K</mi><mi>c</mi></msub></msubsup><msubsup><mi mathvariant="bold">g</mi><mi>k</mi><mfenced><mi>c</mi></mfenced></msubsup></math><img id="ib0040" file="imgb0040.tif" wi="112" he="9" img-content="math" img-format="tif"/></maths> where, in Equation 2, Kc denotes the number of training samples in the category c,</claim-text>
<claim-text>Variance within the cluster: <maths id="math0041" num="(Equation 3),"><math display="block"><msup><mi mathvariant="bold">S</mi><mfenced><mi>c</mi></mfenced></msup><mo>=</mo><msubsup><mi mathvariant="normal">Σ</mi><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>K</mi><mi>c</mi></msub></msubsup><mfenced separators=""><msubsup><mi mathvariant="bold">g</mi><mi>k</mi><mfenced><mi>c</mi></mfenced></msubsup><mo>−</mo><msup><mover accent="true"><mi mathvariant="bold">g</mi><mo>‾</mo></mover><mfenced><mi>c</mi></mfenced></msup></mfenced><msup><mfenced separators=""><msubsup><mi mathvariant="bold">g</mi><mi>k</mi><mfenced><mi>c</mi></mfenced></msubsup><mo>−</mo><msup><mover accent="true"><mi mathvariant="bold">g</mi><mo>‾</mo></mover><mfenced><mi>c</mi></mfenced></msup></mfenced><mi>T</mi></msup></math><img id="ib0041" file="imgb0041.tif" wi="99" he="9" img-content="math" img-format="tif"/></maths></claim-text>
<claim-text>Sum of variances within clusters: <maths id="math0042" num="(Equation 4),"><math display="block"><msub><mi mathvariant="bold-italic">S</mi><mi mathvariant="normal">Σ</mi></msub><mo>=</mo><msubsup><mi mathvariant="normal">Σ</mi><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></msubsup><msup><mi mathvariant="bold">S</mi><mfenced><mi>c</mi></mfenced></msup></math><img id="ib0042" file="imgb0042.tif" wi="89" he="7" img-content="math" img-format="tif"/></maths> where, in Equation 4, C denotes the total number of vibration categories,</claim-text>
<claim-text>Center of all the data: <maths id="math0043" num="(Equation 5),"><math display="block"><mover accent="true"><mi mathvariant="bold">g</mi><mo>‾</mo></mover><mo>=</mo><mfrac><mn>1</mn><mrow><msubsup><mi mathvariant="normal">Σ</mi><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></msubsup><msub><mi>K</mi><mi>c</mi></msub></mrow></mfrac><msubsup><mi mathvariant="normal">Σ</mi><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></msubsup><msubsup><mi mathvariant="normal">Σ</mi><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>K</mi><mi>c</mi></msub></msubsup><msubsup><mi mathvariant="bold">g</mi><mi>k</mi><mfenced><mi>c</mi></mfenced></msubsup></math><img id="ib0043" file="imgb0043.tif" wi="107" he="9" img-content="math" img-format="tif"/></maths></claim-text>
<claim-text>Variance between clusters: <maths id="math0044" num="(Equation 6),"><math display="block"><mi mathvariant="bold-italic">S</mi><mo>=</mo><msubsup><mi mathvariant="normal">Σ</mi><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></msubsup><msub><mi>K</mi><mi>c</mi></msub><mfenced separators=""><mover accent="true"><mi mathvariant="bold">g</mi><mo>‾</mo></mover><mo>−</mo><msup><mover accent="true"><mi mathvariant="bold">g</mi><mo>‾</mo></mover><mfenced><mi>c</mi></mfenced></msup></mfenced><msup><mfenced separators=""><mover accent="true"><mi mathvariant="bold">g</mi><mo>‾</mo></mover><mo>−</mo><msup><mover accent="true"><mi mathvariant="bold">g</mi><mo>‾</mo></mover><mfenced><mi>c</mi></mfenced></msup></mfenced><mi>T</mi></msup></math><img id="ib0044" file="imgb0044.tif" wi="100" he="8" img-content="math" img-format="tif"/></maths></claim-text>
<claim-text>Matrix: <maths id="math0045" num="(Equation 7)."><math display="block"><msubsup><mi mathvariant="bold-italic">S</mi><mi mathvariant="normal">Σ</mi><mrow><mo>−</mo><mn>1</mn></mrow></msubsup><mi mathvariant="bold-italic">S</mi></math><img id="ib0045" file="imgb0045.tif" wi="132" he="7" img-content="math" img-format="tif"/></maths></claim-text></claim-text></claim>
<claim id="c-en-0003" num="0003">
<claim-text>The method for detecting and specifying a vibration on the basis of a feature of a fiber-optic signal to determine a time and a spatial location according to claim 1, wherein<br/>
in Step 2, the dimensionality reduction matrix is acquired by Principal Component Analysis or Independent Component Analysis.</claim-text></claim>
<claim id="c-en-0004" num="0004">
<claim-text>The method for detecting and specifying a vibration on the basis of a feature of a fiber-optic signal to determine a time and a spatial location according to claim 1, wherein<!-- EPO <DP n="21"> -->
<claim-text>Step 5 includes:
<claim-text>Sub-step 51 of converting the primary classification result represented by the following Equation 8 to a logical variable represented by the following Equation 9;</claim-text>
<claim-text>Sub-step 52 of calculating, for each vibration category, a score of B-number of whole logical equations {J<sub>1</sub> (L), J<sub>2</sub> (L), ..., J<sub>B</sub> (L)} in a logical rule base on the basis of a calculation equation represented by the following Equation 10; and</claim-text>
<claim-text>Sub-step 53 of outputting a vibration category corresponding to a highest score represented by the following Equation 11 as an output of a secondary classifier,</claim-text></claim-text>
<claim-text>Primary Classification Result: <maths id="math0046" num="(Equation 8),"><math display="block"><mi>e</mi><mfenced><mi>t</mi><mi>d</mi></mfenced></math><img id="ib0046" file="imgb0046.tif" wi="94" he="6" img-content="math" img-format="tif"/></maths></claim-text>
<claim-text>Logical Variable: <maths id="math0047" num="(Equation 9),"><math display="block"><msubsup><mi>L</mi><mrow><mi>m</mi><mo>,</mo><mi>n</mi></mrow><mfenced><mi>i</mi></mfenced></msubsup><mo>=</mo><mrow><mo>{</mo><mtable><mtr><mtd><mrow><mn>1</mn><mspace width="1ex"/><mi mathvariant="italic">if</mi><mspace width="1ex"/><mi>e</mi><mfenced separators=""><mi>t</mi><mo>−</mo><mi>m</mi><mo>,</mo><mi>d</mi><mo>−</mo><mi>n</mi></mfenced><mo>=</mo><mo>=</mo><mi>i</mi></mrow></mtd></mtr><mtr><mtd><mtable><mtr><mtd><mn>0</mn></mtd><mtd><mi mathvariant="italic">otherwise</mi></mtd></mtr></mtable></mtd></mtr></mtable></mrow></math><img id="ib0047" file="imgb0047.tif" wi="116" he="10" img-content="math" img-format="tif"/></maths> where, in Equation 9, <maths id="math0048" num=""><math display="inline"><msubsup><mi>L</mi><mrow><mi>m</mi><mo>,</mo><mi>n</mi></mrow><mfenced><mi>i</mi></mfenced></msubsup></math><img id="ib0048" file="imgb0048.tif" wi="8" he="6" img-content="math" img-format="tif" inline="yes"/></maths> denotes a logical variable when a fiber-optic signal at a time (t - m) and a location (d - n) is determined to be a vibration of category i in Step 4,</claim-text>
<claim-text>Calculation Equation: <maths id="math0049" num="(Equation 10),"><math display="block"><msup><mi>s</mi><mfenced><mi>c</mi></mfenced></msup><mo>=</mo><msubsup><mi mathvariant="normal">Σ</mi><mrow><mi>b</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></msubsup><msub><mi>J</mi><mi>b</mi></msub><mfenced><mi mathvariant="bold">L</mi></mfenced><msubsup><mi>s</mi><mi>b</mi><mfenced><mi>c</mi></mfenced></msubsup></math><img id="ib0049" file="imgb0049.tif" wi="111" he="10" img-content="math" img-format="tif"/></maths> where, in Equation 10, s<sup>(c)</sup> denotes a score on the basis of the whole logical equations in the logical rule base when the current vibration belongs to category c, the input L in (L) configures all the logical variables <maths id="math0050" num=""><math display="inline"><msubsup><mi>L</mi><mrow><mi>m</mi><mo>,</mo><mi>n</mi></mrow><mfenced><mi>i</mi></mfenced></msubsup></math><img id="ib0050" file="imgb0050.tif" wi="9" he="7" img-content="math" img-format="tif" inline="yes"/></maths>, the subscript b denotes the b<sup>-th</sup> logical equation, and <maths id="math0051" num=""><math display="inline"><msubsup><mi>s</mi><mi>b</mi><mfenced><mi>c</mi></mfenced></msubsup></math><img id="ib0051" file="imgb0051.tif" wi="8" he="8" img-content="math" img-format="tif" inline="yes"/></maths> denotes a contribution degree to a score in each vibration category when the logical equation (L) is established,<br/>
Vibration category corresponding to a highest score: <maths id="math0052" num="(Equation 11)."><math display="block"><mi>e</mi><mo>*</mo><mfenced><mi>t</mi><mi>d</mi></mfenced><mo>=</mo><msub><mi>argmax</mi><mi>c</mi></msub><mspace width="1ex"/><msup><mi>s</mi><mfenced><mi>c</mi></mfenced></msup></math><img id="ib0052" file="imgb0052.tif" wi="69" he="9" img-content="math" img-format="tif"/></maths></claim-text></claim-text></claim>
<claim id="c-en-0005" num="0005">
<claim-text>A system for detecting and specifying a vibration on the basis of a feature of a fiber-optic signal to determine a time and a spatial location, comprising:
<claim-text>a feature expansion unit for acquiring a feature-expanded function vector and C-number of vibration categories by expanding a feature of initial data of a vibration signal from a distributed<!-- EPO <DP n="22"> --> fiber-optic sensor;</claim-text>
<claim-text>a dimensionality reduction matrix calculation unit for calculating a dimensionality reduction matrix based on the feature-expanded function vector;</claim-text>
<claim-text>a linear dimensionality reduction unit for acquiring a dimensionality-reduced feature function by operating the dimensionality reduction matrix to the initial data and the feature-expanded function vector;</claim-text>
<claim-text>a primary classification unit for acquiring a primary classification result of the vibration signal by performing a classification with reference to a primary classification parameter acquired from a parameter database; and</claim-text>
<claim-text>a secondary classification unit for acquiring and outputting a secondary classification result of the vibration signal by performing removal of a wrong detection result and correction of a wrong classification result of the primary classification result.</claim-text></claim-text></claim>
<claim id="c-en-0006" num="0006">
<claim-text>The system for detecting and specifying a vibration on the basis of a feature of a fiber-optic signal to determine a time and a spatial location according to claim 5, wherein<br/>
the parameter database is used to accumulate at least one of the dimensionality reduction matrix, a classifier parameter, and a logical rule base.</claim-text></claim>
</claims>
<drawings id="draw" lang="en"><!-- EPO <DP n="23"> -->
<figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="54" he="144" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="24"> -->
<figure id="f0002" num="2"><img id="if0002" file="imgf0002.tif" wi="130" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="25"> -->
<figure id="f0003" num="3"><img id="if0003" file="imgf0003.tif" wi="126" he="219" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="26"> -->
<figure id="f0004" num="4"><img id="if0004" file="imgf0004.tif" wi="130" he="219" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="27"> -->
<figure id="f0005" num="5"><img id="if0005" file="imgf0005.tif" wi="129" he="221" img-content="drawing" img-format="tif"/></figure>
</drawings>
<search-report-data id="srep" lang="en" srep-office="EP" date-produced=""><doc-page id="srep0001" file="srep0001.tif" wi="164" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="164" he="233" type="tif"/></search-report-data>
<ep-reference-list id="ref-list">
<heading id="ref-h0001"><b>REFERENCES CITED IN THE DESCRIPTION</b></heading>
<p id="ref-p0001" num=""><i>This list of references cited by the applicant is for the reader's convenience only. It does not form part of the European patent document. Even though great care has been taken in compiling the references, errors or omissions cannot be excluded and the EPO disclaims all liability in this regard.</i></p>
<heading id="ref-h0002"><b>Patent documents cited in the description</b></heading>
<p id="ref-p0002" num="">
<ul id="ref-ul0001" list-style="bullet">
<li><patcit id="ref-pcit0001" dnum="CN201811635297" dnum-type="L"><document-id><country>CN</country><doc-number>201811635297</doc-number><date>20181229</date></document-id></patcit><crossref idref="pcit0001">[0079]</crossref></li>
</ul></p>
</ep-reference-list>
</ep-patent-document>
