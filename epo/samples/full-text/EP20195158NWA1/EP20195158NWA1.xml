<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE ep-patent-document PUBLIC "-//EPO//EP PATENT DOCUMENT 1.5.1//EN" "ep-patent-document-v1-5-1.dtd">
<!-- This XML data has been generated under the supervision of the European Patent Office -->
<ep-patent-document id="EP20195158A1" file="EP20195158NWA1.xml" lang="en" country="EP" doc-number="3889883" kind="A1" date-publ="20211006" status="n" dtd-version="ep-patent-document-v1-5-1">
<SDOBI lang="en"><B000><eptags><B001EP>ATBECHDEDKESFRGBGRITLILUNLSEMCPTIESILTLVFIROMKCYALTRBGCZEEHUPLSKBAHRIS..MTNORSMESMMAKHTNMD..........</B001EP><B005EP>J</B005EP><B007EP>BDM Ver 2.0.12 (4th of August) -  1100000/0</B007EP></eptags></B000><B100><B110>3889883</B110><B120><B121>EUROPEAN PATENT APPLICATION</B121></B120><B130>A1</B130><B140><date>20211006</date></B140><B190>EP</B190></B100><B200><B210>20195158.9</B210><B220><date>20200908</date></B220><B250>en</B250><B251EP>en</B251EP><B260>en</B260></B200><B300><B310>202010243546</B310><B320><date>20200331</date></B320><B330><ctry>CN</ctry></B330></B300><B400><B405><date>20211006</date><bnum>202140</bnum></B405><B430><date>20211006</date><bnum>202140</bnum></B430></B400><B500><B510EP><classification-ipcr sequence="1"><text>G06T   5/00        20060101AFI20210222BHEP        </text></classification-ipcr><classification-ipcr sequence="2"><text>H04N   5/235       20060101ALI20210222BHEP        </text></classification-ipcr></B510EP><B520EP><classifications-cpc><classification-cpc sequence="1"><text>H04N   9/64        20130101 LI20210831BHEP        </text></classification-cpc><classification-cpc sequence="2"><text>G06T   5/008       20130101 FI20210217BHEP        </text></classification-cpc><classification-cpc sequence="3"><text>G06T2207/20208     20130101 LA20210217BHEP        </text></classification-cpc><classification-cpc sequence="4"><text>G06T2207/10004     20130101 LA20210217BHEP        </text></classification-cpc><classification-cpc sequence="5"><text>G06T2207/10024     20130101 LA20210217BHEP        </text></classification-cpc><classification-cpc sequence="6"><text>G06T2207/20012     20130101 LA20210217BHEP        </text></classification-cpc></classifications-cpc></B520EP><B540><B541>de</B541><B542>BILDVERARBEITUNGSVERFAHREN UND -VORRICHTUNG, MOBILES ENDGERÄT UND SPEICHERMEDIUM</B542><B541>en</B541><B542>IMAGE PROCESSING METHOD AND DEVICE, MOBILE TERMINAL, AND STORAGE MEDIUM</B542><B541>fr</B541><B542>PROCÉDÉ ET DISPOSITIF DE TRAITEMENT D'IMAGES, TERMINAL MOBILE ET SUPPORT D'ENREGISTREMENT</B542></B540><B590><B598>1</B598></B590></B500><B700><B710><B711><snm>Beijing Xiaomi Mobile Software Co., Ltd.</snm><iid>101766513</iid><irf>53.DG150907</irf><adr><str>No. 018, Floor 8, Building 6, Yard 33 
Middle Xierqi Road 
Haidian District</str><city>Beijing 100085</city><ctry>CN</ctry></adr></B711></B710><B720><B721><snm>XU, Jing</snm><adr><str>BEIJING XIAOMI MOBILE SOFTWARE CO., LTD.
No. 018, Floor 8, Building 6, Yard 33, Middle
Xierqi Road, Haidian District</str><city>Beijing, Beijing 100085</city><ctry>CN</ctry></adr></B721></B720><B740><B741><snm>Hughes, Andrea Michelle</snm><sfx>et al</sfx><iid>101522860</iid><adr><str>Dehns Germany 
Theresienstraße 6-8</str><city>80333 München</city><ctry>DE</ctry></adr></B741></B740></B700><B800><B840><ctry>AL</ctry><ctry>AT</ctry><ctry>BE</ctry><ctry>BG</ctry><ctry>CH</ctry><ctry>CY</ctry><ctry>CZ</ctry><ctry>DE</ctry><ctry>DK</ctry><ctry>EE</ctry><ctry>ES</ctry><ctry>FI</ctry><ctry>FR</ctry><ctry>GB</ctry><ctry>GR</ctry><ctry>HR</ctry><ctry>HU</ctry><ctry>IE</ctry><ctry>IS</ctry><ctry>IT</ctry><ctry>LI</ctry><ctry>LT</ctry><ctry>LU</ctry><ctry>LV</ctry><ctry>MC</ctry><ctry>MK</ctry><ctry>MT</ctry><ctry>NL</ctry><ctry>NO</ctry><ctry>PL</ctry><ctry>PT</ctry><ctry>RO</ctry><ctry>RS</ctry><ctry>SE</ctry><ctry>SI</ctry><ctry>SK</ctry><ctry>SM</ctry><ctry>TR</ctry></B840><B844EP><B845EP><ctry>BA</ctry></B845EP><B845EP><ctry>ME</ctry></B845EP></B844EP><B848EP><B849EP><ctry>KH</ctry></B849EP><B849EP><ctry>MA</ctry></B849EP><B849EP><ctry>MD</ctry></B849EP><B849EP><ctry>TN</ctry></B849EP></B848EP></B800></SDOBI>
<abstract id="abst" lang="en">
<p id="pa01" num="0001">Provided are an image processing method and device, a mobile terminal, and a storage medium. The method includes: acquiring a first image output by an image sensor; responsive to a first signal value of the first image after being processed exceeding a saturation value of a first bit width at a preset image processing stage, recording the first signal value of the processed first image with a second bit width, the second bit width being greater than the first bit width; and mapping the second signal value recorded with the second bit width to a third signal value recorded with the first bit width to obtain a second image. Through the method, an operation of increasing a bit width can be used to retain more information of an image and improve the quality of the image, and an implementation is simple and effective.
<img id="iaf01" file="imgaf001.tif" wi="125" he="103" img-content="drawing" img-format="tif"/></p>
</abstract>
<description id="desc" lang="en"><!-- EPO <DP n="1"> -->
<heading id="h0001"><b>TECHNICAL FIELD</b></heading>
<p id="p0001" num="0001">The present disclosure generally relates to the technical field of image processing, and more particularly, to an image processing method and device, a mobile terminal, and a storage medium.</p>
<heading id="h0002"><b>BACKGROUND</b></heading>
<p id="p0002" num="0002">In the field of computer vision and pattern recognition, the highlight of an image brings difficulties and challenges to implementation effects of many applications. Highlight is actually a very common phenomenon in real scenes, which is the change of the color and brightness of an object surface caused by the change of illumination at different viewing angles and reflects the optical reflection characteristics of the object surface. In digital images, highlights in each pixel often have high brightness, and thus cover the color, contour or texture of the object surface. Saturated highlight directly leads to the loss of local area information, so highlight is usually regarded as a defect in the image.</p>
<heading id="h0003"><b>SUMMARY</b></heading>
<p id="p0003" num="0003">The present disclosure provides an image processing method and device, a mobile terminal, and a storage medium. According to a first aspect of the present disclosure, an image processing method is provided. The method may be applied to a mobile terminal, and may include:
<ul id="ul0001" list-style="none" compact="compact">
<li>acquiring a first image output by an image sensor;</li>
<li>responsive to a first signal value of the first image after being processed exceeding a saturation value of a first bit width at a preset image processing stage, recording the first signal value of the processed first image with a second bit width, the second bit width being greater than the first bit width; and<!-- EPO <DP n="2"> --></li>
<li>mapping the second signal value recorded with the second bit width to a third signal value recorded with the first bit width to obtain a second image.</li>
</ul></p>
<p id="p0004" num="0004">Optionally, the operation of mapping the second signal value recorded with the second bit width to a third signal value recorded with the first bit width to obtain a second image may include:
<ul id="ul0002" list-style="none" compact="compact">
<li>mapping the second signal value recorded with the second bit width to the third signal value recorded with the first bit width according to a maximum signal value of different color components of each pixel of an image recorded with the first bit width after image processing to obtain a third image;</li>
<li>mapping different color sub-signal values of each pixel recorded with the second bit width to the third signal value recorded with the first bit width based on the first image before image processing to obtain a fourth image; and</li>
<li>obtaining the second image based on the third image and the fourth image.</li>
</ul></p>
<p id="p0005" num="0005">Optionally, the operation of mapping the second signal value recorded with the second bit width to the third signal value recorded with the first bit width according to a maximum signal value of different color components of each pixel of an image recorded with the first bit width after image processing to obtain a third image may include:
<ul id="ul0003" list-style="none" compact="compact">
<li>mapping a first part, greater than a preset threshold, of the maximum signal value of different color components of each pixel recorded with the second bit width to a range between the preset threshold and the saturation value of the first bit width; and</li>
<li>mapping a second part, less than or equal to the preset threshold, of the maximum signal value of different color components of each pixel recorded with the second bit width to match with a part, less than or equal to the preset threshold, of the maximum signal value of different color components of each pixel of the image recorded with the first bit width after image processing to obtain the third image.</li>
</ul></p>
<p id="p0006" num="0006">Optionally, the method may further include:<br/>
obtaining a smooth-curve-type mapping relationship based on the mapping of the first part to the range between the preset threshold and the saturation value of the first bit width and the mapping of the second part to the part, less than or equal to the preset threshold, of the maximum signal value of different color components of each pixel of the image recorded<!-- EPO <DP n="3"> --> with the first bit width after image processing.</p>
<p id="p0007" num="0007">The operation of mapping the second signal value recorded with the second bit width to the third signal value recorded with the first bit width according to a maximum signal value of different color components of each pixel of an image recorded with the first bit width after image processing to obtain a third image may include:<br/>
mapping a maximum signal value of different color components of each pixel recorded with the second bit width to the third signal value recorded with the first bit width according to the smooth-curve-type mapping relationship to obtain the third image.</p>
<p id="p0008" num="0008">Optionally, the operation of mapping different color sub-signal values of each pixel recorded with the second bit width to the third signal value recorded with the first bit width based on the first image before image processing to obtain a fourth image may include:
<ul id="ul0004" list-style="none" compact="compact">
<li>determining a first pixel having different color sub-signal values all less than the saturation value of the first bit width among each pixel of the first image;</li>
<li>determining a second pixel corresponding to the first pixel among each pixel recorded with the second bit width;</li>
<li>determining a third part having a color sub-signal value greater than the saturation value of the first bit width from the second pixel; and</li>
<li>mapping different color sub-signal values of each pixel recorded with the second bit width to the third signal value recorded with the first bit width based on the third part to obtain the fourth image.</li>
</ul></p>
<p id="p0009" num="0009">Optionally, the operation of mapping different color sub-signal values of each pixel recorded with the second bit width to the third signal value recorded with the first bit width based on the third part to obtain the fourth image may include:
<ul id="ul0005" list-style="none" compact="compact">
<li>compressing different color sub-signal values of each pixel of the third part proportionally to a range not exceeding the saturation value of the first bit width; and</li>
<li>mapping color sub-signal values of pixels, other than the third part, recorded with the second bit width, which are greater than a color sub-signal value of the saturation value of the first bit width, to the saturation value of the first bit width to obtain the fourth image.</li>
</ul></p>
<p id="p0010" num="0010">Optionally, both the third image and the fourth image may be images of an RGB<!-- EPO <DP n="4"> --> space.</p>
<p id="p0011" num="0011">The operation of obtaining the second image based on the third image and the fourth image may include:
<ul id="ul0006" list-style="none" compact="compact">
<li>converting the third image to an HSV space to obtain a first HSV space image;</li>
<li>converting the fourth image to the HSV space to obtain a second HSV space image; and</li>
<li>acquiring corresponding values in the RGB space according to a value of a value V channel in the first HSV space image, and a value of a hue H channel and a value of a saturation S channel in the second HSV space image, and the second image is obtained.</li>
</ul></p>
<p id="p0012" num="0012">Optionally, the image processing may include at least one of:
<ul id="ul0007" list-style="none" compact="compact">
<li>lens shading correction; and</li>
<li>white balance correction.</li>
</ul></p>
<p id="p0013" num="0013">According to a second aspect of the present disclosure, an image collection device is provided. The device may be applied to a mobile terminal, and may include:
<ul id="ul0008" list-style="none" compact="compact">
<li>an acquisition module, configured to acquire a first image output by an image sensor, responsive to a first signal value of the first image after being processed exceeding a saturation value of a first bit width at a preset image processing stage, record the first signal value of the processed first image with a second bit width, the second bit width being greater than the first bit width; and</li>
<li>a mapping module, configured to map the second signal value recorded with the second bit width to a third signal value recorded with the first bit width to obtain a second image.</li>
</ul></p>
<p id="p0014" num="0014">Optionally, the mapping module may include a first mapping module, a second mapping module, and an obtaining module.</p>
<p id="p0015" num="0015">The first mapping module may be configured to map, according to a maximum signal value of different color components of each pixel of an image recorded with the first bit width after image processing, the second signal value recorded with the second bit width to the third signal value recorded with the first bit width to obtain a third image.</p>
<p id="p0016" num="0016">The second mapping module may be configured to map, based on the first image before image processing, different color sub-signal values of each pixel recorded with the<!-- EPO <DP n="5"> --> second bit width to the third signal value recorded with the first bit width to obtain a fourth image.</p>
<p id="p0017" num="0017">The obtaining module may be configured to obtain the second image based on the third image and the fourth image.</p>
<p id="p0018" num="0018">Optionally, the first mapping module may be specifically configured to map a first part, greater than a preset threshold, of the maximum signal value of different color components of each pixel recorded with the second bit width to a range between the preset threshold and the saturation value of the first bit width; and map a second part, less than or equal to the preset threshold, of the maximum signal value of different color components of each pixel recorded with the second bit width to match with a part, less than or equal to the preset threshold, of the maximum signal value of different color components of each pixel of the image recorded with the first bit width after image processing to obtain the third image.</p>
<p id="p0019" num="0019">Optionally, the device may further include:<br/>
a smoothing module, configured to obtain a smooth-curve-type mapping relationship based on the mapping of the first part to the range between the preset threshold and the saturation value of the first bit width and the mapping of the second part to the part, less than or equal to the preset threshold, of the maximum signal value of different color components of each pixel of the image recorded with the first bit width after image processing.</p>
<p id="p0020" num="0020">The first mapping module may be specifically configured to map, according to the smooth-curve-type mapping relationship, a maximum signal value of different color components of each pixel recorded with the second bit width to the third signal value recorded with the first bit width to obtain the third image.</p>
<p id="p0021" num="0021">Optionally, the second mapping module may be specifically configured to determine, among each pixel of the first image, a first pixel having different color sub-signal values all less than the saturation value of the first bit width; determine, among each pixel recorded with the second bit width, a second pixel corresponding to the first pixel; determine, from the second pixel, a third part having a color sub-signal value greater than the saturation value of the first bit width; and map, based on the third part, different color sub-signal values of each pixel recorded with the second bit width to the third signal value recorded with the first bit width to obtain the fourth image.<!-- EPO <DP n="6"> --></p>
<p id="p0022" num="0022">Optionally, the second mapping module may be specifically configured to proportionally compress different color sub-signal values of each pixel of the third part to a range not exceeding the saturation value of the first bit width; and map color sub-signal values of pixels, other than the third part, recorded with the second bit width, which are greater than a color sub-signal value of the saturation value of the first bit width, to the saturation value of the first bit width to obtain the fourth image.</p>
<p id="p0023" num="0023">Optionally, the obtaining module may be specifically configured to convert the third image to an HSV space to obtain a first HSV space image; convert the fourth image to the HSV space to obtain a second HSV space image; and acquire corresponding values in the RGB space according to a value of a value V channel in the first HSV space image, and a value of a hue H channel and a value of a saturation S channel in the second HSV space image, and obtain the second image.</p>
<p id="p0024" num="0024">Optionally, the image processing may include at least one of:
<ul id="ul0009" list-style="none" compact="compact">
<li>lens shading correction; and</li>
<li>white balance correction.</li>
</ul></p>
<p id="p0025" num="0025">According to a third aspect of the present disclosure, a mobile terminal is provided. The mobile terminal may include:
<ul id="ul0010" list-style="none" compact="compact">
<li>a processor; and</li>
<li>a memory configured to store instructions executable by the processor.</li>
</ul></p>
<p id="p0026" num="0026">The processor may be configured to implement the image processing method as described in the first aspect.</p>
<p id="p0027" num="0027">According to a fourth aspect of the present disclosure, a storage medium is provided.</p>
<p id="p0028" num="0028">When instructions in the storage medium are executed by a processor of a mobile terminal, the mobile terminal can be caused to implement the image processing method as described in the first aspect.</p>
<p id="p0029" num="0029">The technical solutions provided by the embodiments of the present disclosure may include the following beneficial effects.</p>
<p id="p0030" num="0030">In the embodiments of the present disclosure, during image processing of a first image output by a sensor, when a first signal value of the first image after being processed<!-- EPO <DP n="7"> --> exceeds a saturation value of a first bit width, the first signal value of the first image may be recorded with a second bit width, that is, information that may be lost can be recorded with a simple bit width increasing operation, and the original first bit width can be mapped back for subsequent operations while more information is retained. On the one hand, there is no need for a mobile terminal to collect multiple frames of images and perform processing based on the multiple frames of images to restore the information that may be lost, thus lowering the power consumption of the mobile terminal and reducing the occurrence of bad restoration effect caused by alignment processing or interpolation processing on the multiple frames of images. On the other hand, a mode of increasing a bit width is not limited by an image scene. Compared with a mode of performing intrinsic image decomposition by use of a light reflection model for highlight repair, the solutions of the present disclosure are more universal.</p>
<p id="p0031" num="0031">It is to be understood that the above general descriptions and detailed descriptions below are only exemplary and explanatory and not intended to limit the present disclosure.</p>
<heading id="h0004"><b>BRIEF DESCRIPTION OF THE DRAWINGS</b></heading>
<p id="p0032" num="0032">The accompanying drawings, which are incorporated in and constitute a part of this specification, illustrate embodiments consistent with the present disclosure and, together with the specification, serve to explain the principles of the present disclosure.
<ul id="ul0011" list-style="none" compact="compact">
<li><figref idref="f0001">FIG. 1</figref> is a flowchart showing an image processing method according to an embodiment of the present disclosure.</li>
<li><figref idref="f0001">FIG. 2</figref> is a first example diagram of a mapping relationship in an embodiment of the present disclosure.</li>
<li><figref idref="f0002">FIG. 3</figref> is a second example diagram of a mapping relationship in an embodiment of the present disclosure.</li>
<li><figref idref="f0002">FIG. 4</figref> is a diagram illustrating an image processing device according to an exemplary embodiment.</li>
<li><figref idref="f0003">FIG. 5</figref> is a block diagram illustrating a mobile terminal according to an embodiment of the present disclosure.</li>
</ul><!-- EPO <DP n="8"> --></p>
<heading id="h0005"><b>DETAILED DESCRIPTION</b></heading>
<p id="p0033" num="0033">Reference will now be made in detail to exemplary embodiments, examples of which are illustrated in the accompanying drawings. The following description refers to the accompanying drawings in which the same numbers in different drawings represent the same or similar elements unless otherwise represented. The implementations set forth in the following description of exemplary embodiments do not represent all implementations consistent with the present disclosure. Instead, they are merely examples of devices and methods consistent with aspects related to the present disclosure as recited in the appended claims.</p>
<p id="p0034" num="0034"><figref idref="f0001">FIG. 1</figref> is a flowchart showing an image processing method according to an embodiment of the present disclosure. As shown in <figref idref="f0001">FIG. 1</figref>, an image processing method applied to a mobile terminal includes the following operations.</p>
<p id="p0035" num="0035">In S11, a first image output by an image sensor is acquired. The first image may include first image signal values with a first bit width. The first image signal values may be raw image signals.</p>
<p id="p0036" num="0036">In S12, responsive to a signal value of the first image after being processed exceeding a saturation value of a first bit width at a preset image processing stage, the signal value of the processed first image is recorded with a second bit width. The second bit width is greater than the first bit width.</p>
<p id="p0037" num="0037">Specifically, responsive to a first signal value of the first image after being processed exceeding a saturation value of a first bit width at a preset image processing stage, the first signal value of the processed first image is recorded with a second bit width. The second bit width is greater than the first bit width.</p>
<p id="p0038" num="0038">In S13, the signal value recorded with the second bit width is mapped to a signal value recorded with the first bit width to obtain a second image.</p>
<p id="p0039" num="0039">Specifically, the second signal value recorded with the second bit width is mapped to a third signal value recorded with the first bit width to obtain a second image.</p>
<p id="p0040" num="0040">In the embodiments of the present disclosure, the mobile terminal can be a mobile phone, a tablet computer, a camera, a smart wearable device, or the like. The mobile terminal may include an image collection module, such as a front camera or a rear camera in a<!-- EPO <DP n="9"> --> mobile phone, which may perform image collection.</p>
<p id="p0041" num="0041">In operation S11, the first image is an image output by a sensor. For example, the first image may be an image output by a sensor in the image collection module. During the output, the sensor has a fixed bit width, which may be understood as a first bit width, such as 8 bits. A supported dynamic range is 0 to 255. Due to the limitation of a dynamic range of the sensor itself, a brightness value exceeding the dynamic range may be truncated to a saturation value of 255.</p>
<p id="p0042" num="0042">Generally, the image output by the sensor needs to be subjected to preset image processing. The preset image processing is also called Image Signal Processing (ISP). The ISP can complete the effect processing of digital images through a series of digital image processing algorithms, including black level correction, white balance correction, lens shading correction, demosaicing, color space conversion, denoising, global tone mapping, local tone mapping, brightening, sharpening, and other operations. Due to the limitation of a data bit width, a signal that is not saturated at the output of the image sensor may also exceed the saturation value after the ISP.</p>
<p id="p0043" num="0043">The lens shading correction is taken as an example. When the lens shading correction is performed, the center of an image is taken as an origin, a distance between each pixel and the center of the image is taken as a radius, and the pixel is multiplied by a corresponding gain to offset the uneven brightness caused by the optical characteristics of a lens. The gain value of the center of the image is 1, and the gain values of other positions are greater than 1. Based on the introduction of a gain in the lens shading correction, the unsaturated signal may exceed the saturation value after correction processing.</p>
<p id="p0044" num="0044">The white balance correction is taken as an example. In the white balance correction, a green channel is taken as a reference, and a red channel and a blue channel may be multiplied by corresponding gains to achieve uniform brightness of the three color channels. The gain of the green channel is 1, and the gains of the red channel and the blue channel are greater than 1. It can be seen that, based on the introduction of a gain in the white balance correction, the unsaturated signal may exceed the saturation value after correction processing.</p>
<p id="p0045" num="0045">In this regard, in operation S12 of the present disclosure, when the first signal value of the processed first image exceeds the saturation value of the first bit width, the first<!-- EPO <DP n="10"> --> signal value of the processed first image may be recorded with a second bit width that is greater than the first bit width. That is, when image processing is performed on the first image, if the signal value exceeds the saturation value of the first bit width, truncation processing may be not performed, but the bit width may be increased to the second bit width for output to retain a truncated signal.</p>
<p id="p0046" num="0046">For example, the first bit width may be 8 bits, the second bit width may be 9 bits, and the supported dynamic range can be 0 to 511. After image processing is performed on the first image, if the signal value exceeds 255, the second bit width may be used for recording. It should be noted that the second bit width is not limited to 9 bits, and the appropriate second bit width may be formulated according to a data storage capacity of the mobile terminal itself, so that signals exceeding the saturation value of the first bit width may be recorded without truncation.</p>
<p id="p0047" num="0047">In an embodiment, the image processing may include at least one of:
<ul id="ul0012" list-style="none" compact="compact">
<li>lens shading correction; and</li>
<li>white balance correction.</li>
</ul></p>
<p id="p0048" num="0048">In this embodiment, as described above, due to image processing modes such as lens shading correction and white balance correction, the unsaturated signal may exceed the saturation value after correction processing. However, it should be noted that the image processing modes in which the unsaturated signal exceeds the saturation value due to image processing are not limited to lens shading correction and white balance correction, and include, for example, brightness increasing processing and the like.</p>
<p id="p0049" num="0049">It should be noted that, generally, a larger signal value of an image indicates larger brightness, and a large-brightness area is called a highlight area or a high-brightness area. Therefore, a part of the signal value of the first image after image processing, which exceeds the saturation value of the first bit width, also belongs to the highlight area. The highlight area part is likely to lose original detail information of an object (such as color, contour or texture), and the saturation value of the highlight area directly loses local area information. Therefore, in the present disclosure, in order to retain information belonging to the highlight area, a part of the saturation value that exceeds the first bit width after image processing is recorded with the second bit width.<!-- EPO <DP n="11"> --></p>
<p id="p0050" num="0050">However, considering the operations of subsequent processing modules, for example, the display of images in the mobile terminal, etc., the signal value after being increased to the second bit width is needed to be compressed to the original first bit width (that is, bit width compression). Therefore, in operation S13 of the embodiments of the present disclosure, the second signal value recorded with the second bit width may be mapped to the third signal value recorded with the first bit width to obtain a second image that retains the information of the highlight area (that is, highlight restoration).</p>
<p id="p0051" num="0051">There are two main technologies for performing highlight restoration on images. The first technology is multi-frame processing. By controlling the exposure time of different frames, different exposure images of the same area can be acquired. For highlight areas under normal exposure (such as the sky and neon lights), highlight recovery can be achieved by fusing color and detail information of corresponding areas under underexposure conditions (such as underexposure thumbnail images). The second technology is single-frame processing. Intrinsic image decomposition may be performed on a light reflective area by estimating a light reflection model of the highlight area, and diffuse reflection components and intrinsic reflection information may be separated by integrating local area features to achieve the purpose of repairing the highlight area.</p>
<p id="p0052" num="0052">However, with respect to the first solution, first, since the reference is an underexposed thumbnail, the thumbnail needs to be interpolated to have the same size as a normally exposed image. However, the interpolation process may bring errors, which may further cause information recovery errors, thereby affecting the recovery effect of the highlight area. Second, the processing of multi-frame images may have a problem of image alignment. Without image alignment, the global position of two frames of images may be offset, and if there are moving objects in the images, local alignment cannot be guaranteed. Third, since the mobile terminal needs to collect multiple frames of images and process the multiple frames of images, the data processing load of the mobile terminal may be relatively heavy, making the mobile terminal consume more power.</p>
<p id="p0053" num="0053">In addition, with respect to the second solution, since the light reflection model only deals with a phenomenon of an image that smooth objects reflect light, all the highlight areas, such as the sky and neon lights, cannot be processed, so the restoration effect is limited.<!-- EPO <DP n="12"> --></p>
<p id="p0054" num="0054">In the present disclosure, at an image processing stage, information that may be lost can be recorded with a simple operation of increasing a bit width, and the original first bit width can be mapped back for subsequent operations while more information is retained. On the one hand, there is no need for a mobile terminal to collect multiple frames of images and perform processing based on the multiple frames of images, thus lowering the power consumption of the mobile terminal and reducing the occurrence of bad restoration effect caused by alignment processing or interpolation processing on the multiple frames of images. On the other hand, a mode of increasing a bit width is not limited by an image scene. Compared with a mode of using a light reflection model to perform intrinsic image decomposition, the solutions of the present disclosure are more universal.</p>
<p id="p0055" num="0055">In an embodiment, operation S12 may include that:
<ul id="ul0013" list-style="none" compact="compact">
<li>the second signal value recorded with the second bit width is mapped to the third signal value recorded with the first bit width according to a maximum signal value of different color components of each pixel of an image recorded with the first bit width after image processing to obtain a third image;</li>
<li>different color sub-signal values of each pixel recorded with the second bit width are mapped to the third signal value recorded with the first bit width based on the first image before image processing to obtain a fourth image; and</li>
<li>the second image is obtained based on the third image and the fourth image.</li>
</ul></p>
<p id="p0056" num="0056">In this embodiment, mapping may be performed according to the maximum signal value of different color components of each pixel of the image recorded with the first bit width after image processing. Since a maximum signal value of different color components reflects the brightness of images, for example, in an HSV space, a value (V) of an image refers to a maximum value of red pixels (R), green pixels (G), and blue pixels (B) in the image, it can be understood that when mapping is performed according to the maximum signal value of different color components of each pixel of the image recorded with the first bit width after image processing, the recovery of brightness during image correction can be achieved. The restoration of brightness may reflect the contour and/or texture of the image, so detailed information may be restored based on the recovery of brightness.</p>
<p id="p0057" num="0057">In this embodiment, based on the first image before image processing, different<!-- EPO <DP n="13"> --> color sub-signal values of each pixel recorded with the second bit width can be mapped to the signal value recorded with the first bit width. The first image is an image output by the sensor, that is, a collected original image. For example, a three-channel ratio value that has not reached the saturation value in the collected original image can truly reflect a color, so the color can be restored based on the first image.</p>
<p id="p0058" num="0058">According to the third image that recovers the details and the fourth image that restores the color, the second image that recovers both the details and the color may be obtained, so the quality of the obtained image is better.</p>
<p id="p0059" num="0059">In an embodiment, both the third image and the fourth image may be images of an RGB space. The operation that the second image is obtained based on the third image and the fourth image may include that:
<ul id="ul0014" list-style="none" compact="compact">
<li>the third image is converted to an HSV space to obtain a first HSV space image;</li>
<li>the fourth image is converted to the HSV space to obtain a second HSV space image; and</li>
<li>corresponding values in the RGB space are acquired according to a value of a value V channel in the first HSV space image, and a value of a hue H channel and a value of a saturation S channel in the second HSV space image, and the second image is obtained.</li>
</ul></p>
<p id="p0060" num="0060">In this embodiment, in order to obtain the second image that recovers both the details and the color, brightness information of the third image and color-related information in the fourth image are used. In the HSV space, the value of the value (V) channel reflects brightness, so the third image is converted to the first HSV space to obtain the value of the V channel. Hue (H) in the HSV space reflects hue, and saturation (S) reflects the saturation of a color in a hue space, which is the information of the reflected color, so the fourth image is converted to the second HSV space to obtain the values of the H channel and the V channel.</p>
<p id="p0061" num="0061">According to the value of the V channel obtained from the third image, the values of the H channel and the S channel obtained from the fourth image may be inversely transformed into the RGB space to obtain a second image with both brightness and color restored.</p>
<p id="p0062" num="0062">It can be understood that, in this embodiment, based on the recovery of the brightness and the restoration of the color separately, a full range of recovery can be achieved.<!-- EPO <DP n="14"> --></p>
<p id="p0063" num="0063">In an embodiment, the operation that the second signal value recorded with the second bit width is mapped to the third signal value recorded with the first bit width according to a maximum signal value of different color components of each pixel of an image recorded with the first bit width after image processing to obtain a third image may include that:
<ul id="ul0015" list-style="none" compact="compact">
<li>a first part, greater than a preset threshold, of the maximum signal value of different color components of each pixel recorded with the second bit width is mapped to a range between the preset threshold and the saturation value of the first bit width; and</li>
<li>a second part, less than or equal to the preset threshold, of the maximum signal value of different color components of each pixel recorded with the second bit width is mapped to match with a part, less than or equal to the preset threshold, of the maximum signal value of different color components of each pixel of the image recorded with the first bit width after image processing to obtain the third image.</li>
</ul></p>
<p id="p0064" num="0064">In this embodiment, after image processing is performed on the first image, the image recorded with the first bit width refers to an image after a signal exceeding the saturation value of the first bit width is truncated with the saturation value of the first bit width, for example, recorded as SrcC. When the first signal value of the processed first image exceeds the saturation value of the first bit width, the image recorded with the second bit width is recorded as SrcU.</p>
<p id="p0065" num="0065">In the present disclosure, when mapping is performed according to the image recorded with the first bit width after image processing, it can be understood that, in a part less than or equal to the saturation value of the first bit width, different color component signal values of the each pixel of SrcC and SrcU are consistent, and differ only in a part greater than the saturation value of the first bit width. Therefore, when mapping is performed on the basis of the maximum signal value of different color components of each pixel to obtain a brightness-recovered third image, before the mapping, in the part less than or equal to the saturation value of the first bit width, the maximum signal value of different color components of each pixel is consistent, while the maximum signal value of different color components of each pixel is different in the part greater than the saturation value of the first bit width.</p>
<p id="p0066" num="0066">For example, the first bit width may be 8 bits and the second bit width may be 9 bits. <figref idref="f0001">FIG. 2</figref> is a first example diagram of a mapping relationship in an embodiment of the<!-- EPO <DP n="15"> --> present disclosure. As shown in <figref idref="f0001">FIG. 2</figref>, the ordinate represents a maximum value of different color components of each pixel point of SrcC, and the abscissa represents a maximum value of different color components of each pixel point of SrcU. In <figref idref="f0001">FIG. 2</figref>, before the mapping processing of SrcU in the present disclosure is performed, a curve of a mapping relationship between SrcU and SrcC is recorded as L1. As can be seen from <figref idref="f0001">FIG. 2</figref>, in a part less than or equal to 255, the maximum value of different color components of each pixel point of SrcC is consistent, the mapping relationship is linear, and the slope is 1. For SrcC, since the part that exceeds the saturation value is truncated by 255, the mapping relationship is expressed as a straight line with a value of255 in a part with the maximum value of different color components of each pixel point of SrcU exceeding 255.</p>
<p id="p0067" num="0067">In the present disclosure, in order to recover the detailed information of the highlighted area, L1 needs to be modified. In this regard, a brightness threshold Thresh to be recovered is set in the present disclosure, that is, a preset threshold. The preset threshold represents the set brightness area that needs to be recovered. For example, if the Thresh value is 240, the set highlight area to be recovered is 241 to 255, so that a part exceeding 240 of the maximum signal value of different color components of each pixel recorded with the second bit width may be mapped to a range between 241 and 255.</p>
<p id="p0068" num="0068">Exemplarily, as shown in <figref idref="f0001">FIG. 2</figref>, L2 is an example curve of mapping. In L2, the part (second part) less than or equal to the preset threshold (240) of the maximum signal value of different color components of each pixel of SrcU is consistent with the part less than or equal to 240 of the maximum signal value of different color components of each pixel of SrcC. The part (first part) greater than 240 of the maximum signal value of different color components of each pixel of SrcU is mapped to a range between 241 and 255, and the slope of the brightness mapping curve of this part is tan((255-Thresh) / (511 -Thresh)).</p>
<p id="p0069" num="0069">It should be noted that when the first part, greater than the preset threshold, of the maximum signal value of different color components of each pixel recorded with the second bit width is mapped to a range between the preset threshold and the saturation value of the first bit width, the slope of the mapping curve is not limited to: a ratio between the value of the saturation value of the first bit width minus the preset threshold and the value of the saturation value of the second bit width minus the preset threshold. For example, a non-linear mapping<!-- EPO <DP n="16"> --> mode may also be used. However, it can be understood that, by adopting the slope linear mapping mode, the gradient of the brightness value recorded with the second bit width can be used to maintain the recovery of the brightness gradient, thereby making the brightness recovery effect more realistic.</p>
<p id="p0070" num="0070">It can be understood that when the second signal value recorded with the second bit width is mapped to the third signal value recorded with the first bit width according to a maximum signal value of different color components of each pixel of an image recorded with the first bit width after image processing to obtain a third image, the above mode of the present disclosure is adopted. On the one hand, the second part is kept consistent with the first image, and it can be ensured that the operation of mapping from the second bit width to the first bit width (bit width compression) cannot change the brightness of the processed image. On the other hand, the brightness recovery of the highlight area is more controllable and smarter based on the control of the preset threshold.</p>
<p id="p0071" num="0071">In an embodiment, the method may further include that:<br/>
a smooth-curve-shape mapping relationship is obtained based on the mapping of the first part between the preset threshold and the saturation value of the first bit width and the mapping of the second part to the part, less than or equal to the preset threshold, of the maximum signal value of different color components of each pixel of the image recorded with the first bit width after image processing.</p>
<p id="p0072" num="0072">The operation that the second signal value recorded with the second bit width is mapped to the third signal value recorded with the first bit width according to a maximum signal value of different color components of each pixel of an image recorded with the first bit width after image processing to obtain a third image may include that:<br/>
a maximum signal value of different color components of each pixel recorded with the second bit width is mapped to the third signal value recorded with the first bit width according to the smooth-curve-shape mapping relationship to obtain the third image.</p>
<p id="p0073" num="0073">In this embodiment, in order to avoid the phenomenon that the changed brightness mapping curve causes an unnatural transition in the image, fitting may be performed based on the mapping of the first part and the mapping of the second part to obtain a smooth-curve-shape mapping relationship. For example, the fitting mode may use polynomial fitting,<!-- EPO <DP n="17"> --> least square fitting, etc. The embodiments of the present disclosure do not limit the fitting method for obtaining the smooth-curve-shape mapping relationship.</p>
<p id="p0074" num="0074">In the present disclosure, after performing fitting, a maximum signal value of different color components of each pixel recorded with the second bit width may be mapped to the third signal value recorded with the first bit width according to the fitted smooth-curve-shape mapping relationship to obtain a third image that is excessively natural after brightness recovery.</p>
<p id="p0075" num="0075">In an embodiment, the operation that different color sub-signal values of each pixel recorded with the second bit width are mapped to the third signal value recorded with the first bit width based on the first image before image processing to obtain a fourth image may include that:
<ul id="ul0016" list-style="none" compact="compact">
<li>a first pixel having different color sub-signal values all less than the saturation value of the first bit width is determined among each pixel of the first image;</li>
<li>a second pixel corresponding to the first pixel is determined among each pixel recorded with the second bit width;</li>
<li>a third part having a color sub-signal value greater than the saturation value of the first bit width is determined from the second pixel; and</li>
<li>different color sub-signal values of each pixel recorded with the second bit width are mapped to the third signal value recorded with the first bit width based on the third part to obtain the fourth image.</li>
</ul></p>
<p id="p0076" num="0076">In this embodiment, the first image before image processing is an image originally output by the image sensor. As mentioned above, in the signals output by the image sensor, the three-channel ratio of an output signal that has not reached the saturation value can truly reflect the color, and when the signal output by the image sensor reaches saturation, the three-channel ratio of the output signal cannot reflect the true color. Therefore, in the embodiments of the present disclosure, the first image (for example, recorded as SrcS) may be used to map different color sub-signal values of each pixel of the second signal value recorded with the second bit width to the third signal value recorded with the first bit width to obtain a color-recovered fourth image. An image corresponding to the second signal value recorded with the second bit width is recorded as SrcU, for example.<!-- EPO <DP n="18"> --></p>
<p id="p0077" num="0077">Specifically, a first pixel having different color sub-signal values all less than the saturation value of the first bit width can be first determined among each pixel of the first image (SrcS). In this operation, different color sub-signal values of each pixel in SrcS may be scanned point by point, and whether different color sub-signal values are all less than the saturation value of the first bit width (for example, 255) can be determined.</p>
<p id="p0078" num="0078">For example, assuming that different color sub-signal values of each pixel of the signal (SrcS) output by the image sensor are R0, G0, and B0, the maximum value of R0, G0, and B0 may be first acquired as maxRGB0, and whether maxRGB0 is less than 255 may be determined.</p>
<p id="p0079" num="0079">Further, a second pixel corresponding to the first pixel needs to be determined among the pixels (SrcU) recorded with the second bit width, and a third part (belonging to the highlight area) having a color sub-signal value greater than the saturation value of the first bit width needs to be determined from the second pixel to map, based on the third part, different color sub-signal values of each pixel recorded with the second bit width to the third signal value recorded with the first bit width to obtain a fourth image for recovering the color of the highlight area.</p>
<p id="p0080" num="0080">For example, it is assumed that different color sub-signal values of each pixel point of the image (SrcU) that is subjected to image processing and recorded with the second bit width are R, G, and B. In the second pixel corresponding to the first pixel, the maximum value of R, G, and B may be first acquired as maxRGB, it may be determined whether maxRGB is greater than 255, and the second pixel having maxRGB greater than 255 is recorded as the third part.</p>
<p id="p0081" num="0081">It can be understood that the first pixel may be determined from the pixels of the first image, the third part for color recovery may be divided from the signal values recorded with the second bit width according to the first pixel, and then different color sub-signal values of each pixel recorded with the second bit width may be mapped to the signal value recorded with the first bit width based on the third part to obtain a color-recovered fourth image. The accuracy of color recovery can be improved.</p>
<p id="p0082" num="0082">It should be noted that when bit width compression mapping is performed based on the third part, the pixels belonging to the third part and the pixels other than the third part<!-- EPO <DP n="19"> --> among the pixels recorded with the second bit width need to be mapped in different ways.</p>
<p id="p0083" num="0083">In an embodiment, the operation that different color sub-signal values of each pixel recorded with the second bit width are mapped to the third signal value recorded with the first bit width based on the third part to obtain the fourth image may include that:
<ul id="ul0017" list-style="none" compact="compact">
<li>different color sub-signal values of each pixel of the third part are compressed proportionally to a range not exceeding the saturation value of the first bit width; and</li>
<li>color sub-signal values of pixels, other than the third part, recorded with the second bit width, which are greater than a color sub-signal value of the saturation value of the first bit width, are mapped to the saturation value of the first bit width to obtain the fourth image.</li>
</ul></p>
<p id="p0084" num="0084">In this embodiment, since the third part belongs to a part capable of color recovery, different color sub-signal values of each pixel of the third part may be compressed proportionally to a range not exceeding the saturation value of the first bit width to retain the true color. By way of example, when the third part is compressed proportionally by color, the code is as follows:
<pre listing-type="program-listing">              if maxRGB0 &lt; Sat
                if maxRGB &gt; Sat
                    d = Sat / maxRGB;
                    R = R * (1-a) + R * d * a;
                    G = G * (1-a) + G * d * a;
                    B = B * (1-a) + B * d * a;</pre></p>
<p id="p0085" num="0085">In this part, Sat is the saturation value of the first bit width, d and a are compression coefficients, the value of d is less than 1, and the value of a is less than or equal to 1. d is the ratio of the saturation value of the first bit width to the maximum value of a current pixel in the third part, and a may be an S-shaped mapping curve. By means of the above mapping, different color sub-signal values of each pixel of the third part can be compressed proportionally to a range not exceeding the saturation value of the first bit width.</p>
<p id="p0086" num="0086"><figref idref="f0002">FIG. 3</figref> is a second example diagram of a mapping relationship in an embodiment of the present disclosure. The mapping relationship diagram is a value mapping diagram of a. As shown in <figref idref="f0002">FIG. 3</figref>, the ordinate is the value of a, the abscissa diff refers to a difference between<!-- EPO <DP n="20"> --> the saturation value (Sat) of the first bit width and the maximum value maxRGB0 of different color sub-signal values of each pixel point of the first image, the value of a is related to the value of diff, and the value of a changes dynamically.</p>
<p id="p0087" num="0087">It can be understood that, when the proportional compression mapping is performed for different color sub-signal values of each pixel of the third part, the above dynamic proportional compression mode according to the present pixel situation can improve the accuracy of color recovery of the highlight area. In addition, in this embodiment, color sub-signal values, greater than the saturation value of the first bit width, in different color sub-signal values of each of the pixels other than the third part can be directly mapped to the saturation value of the first bit width. The mapping mode is also relatively simple.</p>
<p id="p0088" num="0088">It should be noted that, in this embodiment, color sub-signal values, less than or equal to the saturation value of the first bit width, in different color sub-signal values of each of the pixels other than the third part may be kept unchanged.</p>
<p id="p0089" num="0089"><figref idref="f0002">FIG. 4</figref> is a diagram illustrating an image processing device according to an exemplary embodiment. Referring to <figref idref="f0002">FIG. 4</figref>, the image collection device includes:
<ul id="ul0018" list-style="none" compact="compact">
<li>an acquisition module 101, configured to acquire a first image output by an image sensor;</li>
<li>a bit width increasing module 102, configured to, responsive to that a first signal value of the first image after being processed exceeds a saturation value of a first bit width at a preset image processing stage, record the first signal value of the processed first image with a second bit width, the second bit width being greater than the first bit width; and</li>
<li>a mapping module 103, configured to map the second signal value recorded with the second bit width to a third signal value recorded with the first bit width to obtain a second image.</li>
</ul></p>
<p id="p0090" num="0090">Optionally, the mapping module 103 may include a first mapping module 103A, a second mapping module 103B, and an obtaining module 103C.</p>
<p id="p0091" num="0091">The first mapping module 103A is configured to, according to a maximum signal value of different color components of each pixel of an image recorded with the first bit width after image processing, map the second signal value recorded with the second bit width to the third signal value recorded with the first bit width to obtain a third image.<!-- EPO <DP n="21"> --></p>
<p id="p0092" num="0092">The second mapping module 103B is configured to, based on the first image before image processing, map different color sub-signal values of each pixel recorded with the second bit width to the third signal value recorded with the first bit width to obtain a fourth image.</p>
<p id="p0093" num="0093">The obtaining module 103C is configured to obtain the second image based on the third image and the fourth image.</p>
<p id="p0094" num="0094">Optionally, the first mapping module 102A is specifically configured to map a first part, greater than a preset threshold, of the maximum signal value of different color components of each pixel recorded with the second bit width between the preset threshold and the saturation value of the first bit width; and map a second part, less than or equal to the preset threshold, of the maximum signal value of different color components of each pixel recorded with the second bit width to match with a part, less than or equal to the preset threshold, of the maximum signal value of different color components of each pixel of the image recorded with the first bit width after image processing to obtain the third image.</p>
<p id="p0095" num="0095">Optionally, the device may further include:<br/>
a smoothing module 104, configured to obtain a smooth-curve-shape mapping relationship based on the mapping of the first part between the preset threshold and the saturation value of the first bit width and the mapping of the second part to the part, less than or equal to the preset threshold, of the maximum signal value of different color components of each pixel of the image recorded with the first bit width after image processing.</p>
<p id="p0096" num="0096">The first mapping module 103A is specifically configured to, according to the smooth-curve-shape mapping relationship, map a maximum signal value of different color components of each pixel recorded with the second bit width to the third signal value recorded with the first bit width to obtain the third image.</p>
<p id="p0097" num="0097">Optionally, the second mapping module 103B is specifically configured to determine, among each pixel of the first image, a first pixel having different color sub-signal values all less than the saturation value of the first bit width; determine, among each pixel recorded with the second bit width, a second pixel corresponding to the first pixel; determine, from the second pixel, a third part having a color sub-signal value greater than the saturation value of the first bit width; and map, based on the third part, different color sub-signal values<!-- EPO <DP n="22"> --> of each pixel recorded with the second bit width to the third signal value recorded with the first bit width to obtain the fourth image.</p>
<p id="p0098" num="0098">Optionally, the second mapping module 103B is specifically configured to proportionally compress different color sub-signal values of each pixel of the third part to a range not exceeding the saturation value of the first bit width; and map color sub-signal values of pixels, other than the third part, recorded with the second bit width, which are greater than a color sub-signal value of the saturation value of the first bit width, to the saturation value of the first bit width to obtain the fourth image.</p>
<p id="p0099" num="0099">Optionally, the obtaining module 103C is specifically configured to convert the third image to an HSV space to obtain a first HSV space image; convert the fourth image to the HSV space to obtain a second HSV space image; and acquire corresponding values in the RGB space according to a value of a value V channel in the first HSV space image, and a value of a hue H channel and a value of a saturation S channel in the second HSV space image, and obtain the second image.</p>
<p id="p0100" num="0100">Optionally, the image processing may include at least one of:
<ul id="ul0019" list-style="none" compact="compact">
<li>lens shading correction; and</li>
<li>white balance correction.</li>
</ul></p>
<p id="p0101" num="0101">With respect to the devices in the above embodiments, the specific manners for performing operations for individual modules therein have been described in detail in the embodiments regarding the methods, which will not be elaborated herein.</p>
<p id="p0102" num="0102"><figref idref="f0003">FIG. 5</figref> is a block diagram illustrating a mobile terminal device 800 according to an exemplary embodiment. For example, the device 800 may be a mobile phone, a camera, etc.</p>
<p id="p0103" num="0103">Referring to <figref idref="f0003">FIG. 5</figref>, the device 800 may include one or more of the following components: a processing component 802, a memory 804, a power component 806, a multimedia component 808, an audio component 810, an Input/Output (I/O) interface 812, a sensor component 814, and a communication component 816.</p>
<p id="p0104" num="0104">The processing component 802 typically controls overall operations of the device 800, such as operations associated with display, telephone calls, data communications, camera operations, and recording operations. The processing component 802 may include one or more processors 820 for executing instructions to complete all or part of the operations in<!-- EPO <DP n="23"> --> the described methods. Moreover, the processing component 802 may include one or more modules which facilitate the interaction between the processing component 802 and other components. For example, the processing component 802 may include a multimedia module to facilitate the interaction between the multimedia component 808 and the processing component 802.</p>
<p id="p0105" num="0105">The memory 804 is configured to store various types of data to support operations at the device 800. Examples of such data include instructions for any applications or methods operated on the device 800, contact data, phonebook data, messages, pictures, video, etc. The memory 804 may be implemented using any type of volatile or non-volatile memory devices, or a combination thereof, such as a Static Random Access Memory (SRAM), an Electrically Erasable Programmable Read-Only Memory (EEPROM), an Erasable Programmable Read-Only Memory (EPROM), a Programmable Read-Only Memory (PROM), a Read-Only Memory (ROM), a magnetic memory, a flash memory, a magnetic disk or an optical disk.</p>
<p id="p0106" num="0106">The power component 806 provides power to various components of the device 800. The power component 806 may include: a power management system, one or more power sources, and any other components associated with the generation, management and distribution of power in the device 800.</p>
<p id="p0107" num="0107">The multimedia component 808 includes a screen providing an output interface between the device 800 and the user. In some embodiments, the screen may include a Liquid Crystal Display (LCD) and a Touch Panel (TP). If the screen includes the TP, the screen may be implemented as a touch screen to receive an input signal from the user. The TP includes one or more touch sensors to sense touches, swipes and gestures on the TP. The touch sensors may not only sense a boundary of a touch or swipe action but also detect a duration and pressure associated with the touch or swipe action. In some embodiments, the multimedia component 808 includes a front camera and/or a rear camera. The front camera and/or the rear camera may receive an external multimedia datum while the device 800 is in an operation mode, such as a photographing mode or a video mode. Each of the front camera and the rear camera may be a fixed optical lens system or may have focusing and optical zooming capabilities.</p>
<p id="p0108" num="0108">The audio component 810 is configured to output and/or input audio signals.<!-- EPO <DP n="24"> --> For example, the audio component 810 includes a Microphone (MIC) configured to receive an external audio signal when the device 800 is in an operation mode, such as a call mode, a recording mode, and a voice recognition mode. The received audio signal may be further stored in the memory 804 or transmitted via the communication component 816. In some embodiments, the audio component 810 further includes a speaker for outputting the audio signal.</p>
<p id="p0109" num="0109">The I/O interface 812 provides an interface between the processing component 802 and peripheral interface modules, such as a keyboard, a click wheel, or buttons. The buttons may include, but are not limited to, a home button, a volume button, a starting button, and a locking button.</p>
<p id="p0110" num="0110">The sensor component 814 includes one or more sensors to provide status assessments of various aspects of the device 800. For example, the sensor component 814 may detect an open/closed status of the device 800, and relative positioning of components. For example, the component is the display and the keypad of the device 800. The sensor component 814 may also detect a change in position of the device 800 or a component of the device 800, a presence or absence of user contact with the device 800, an orientation or an acceleration/deceleration of the device 800, and a change in temperature of the device 800. The sensor component 814 may include a proximity sensor configured to detect the presence of nearby objects without any physical contact. The sensor component 814 may also include a light sensor, such as a Complementary Metal Oxide Semiconductor (CMOS) or Charge Coupled Device (CCD) image sensor, configured for use in an imaging application. In some embodiments, the sensor component 814 may also include an acceleration sensor, a gyroscope sensor, a magnetic sensor, a pressure sensor, or a temperature sensor.</p>
<p id="p0111" num="0111">The communication component 816 is configured to facilitate communication, wired or wirelessly, between the device 800 and other devices. The device 800 may access a wireless network based on a communication standard, such as Wi-Fi, 2G or 3G, or a combination thereof. In one exemplary embodiment, the communication component 816 receives a broadcast signal or broadcast associated information from an external broadcast management system via a broadcast channel. In an exemplary embodiment, the communication component 816 further includes a Near Field Communication (NFC) module to facilitate short-range<!-- EPO <DP n="25"> --> communications. For example, the NFC module may be implemented based on a Radio Frequency Identification (RFID) technology, an Infrared Data Association (IrDA) technology, an Ultra-Wideband (UWB) technology, a Bluetooth (BT) technology, and other technologies.</p>
<p id="p0112" num="0112">In exemplary embodiments, the device 800 may be implemented with one or more Application Specific Integrated Circuits (ASICs), Digital Signal Processors (DSPs), Digital Signal Processing Devices (DSPDs), Programmable Logic Devices (PLDs), Field Programmable Gate Arrays (FPGAs), controllers, micro-controllers, microprocessors, or other electronic elements, for performing the above described methods.</p>
<p id="p0113" num="0113">In exemplary embodiments, there is also provided a non-transitory computer-readable storage medium including instructions, such as included in the memory 804, executable by the processor 820 of the device 800 to complete the above described method. For example, the non-transitory computer-readable storage medium may be a ROM, a Random Access Memory (RAM), a Compact Disc Read-Only Memory (CD-ROM), a magnetic tape, a floppy disc, an optical data storage device and the like.</p>
<p id="p0114" num="0114">A non-transitory computer-readable storage medium is provided. When instructions in the storage medium are executed by a processor of a mobile terminal, the mobile terminal is caused to perform a control method. The method include:
<ul id="ul0020" list-style="none" compact="compact">
<li>acquiring a first image output by an image sensor;</li>
<li>responsive to a first signal value of the first image after being processed exceeding a saturation value of a first bit width at a preset image processing stage, recording the first signal value of the processed first image as a second signal value with a second bit width, the second bit width being greater than the first bit width; and</li>
</ul></p>
<p id="p0115" num="0115">mapping the second signal value recorded with the second bit width to a third signal value recorded with the first bit width to obtain a second image.</p>
<p id="p0116" num="0116">It may further be understood that "a plurality of' in the present disclosure refers to more or more than two, and other quantifiers are the same. The "and/or" is an association relationship for describing associated objects and represents that three relationships may exist. For example, A and/or B may represent the following three cases: only A exists, both A and B exist, and only B exists. The character "/" generally indicates that the related objects are in an "or" relationship. "A/an", "said" and "the" in a singular form are also intended to include a<!-- EPO <DP n="26"> --> plural form, unless other meanings are clearly denoted throughout the present disclosure.</p>
<p id="p0117" num="0117">It is further to be understood that, although terms "first", "second" and the like may be adopted to describe various information, the information should not be limited to these terms. These terms are only adopted to distinguish the information of the same type rather than represent a special sequence or an importance. As a matter of fact, the terms "first", "second" and the like may be interchangeable completely. For example, without departing from the scope of the present disclosure, first information may also be called second information and, similarly, second information may also be called first information.</p>
<p id="p0118" num="0118">In the description of the present disclosure, the terms "one embodiment," "some embodiments," "example," "specific example," or "some examples,' and the like can indicate a specific feature described in connection with the embodiment or example, a structure, a material or feature included in at least one embodiment or example. In the present disclosure, the schematic representation of the above terms is not necessarily directed to the same embodiment or example.</p>
<p id="p0119" num="0119">Other embodiments of the present disclosure will be apparent to those skilled in the art from consideration of the specification and practice of the present disclosure disclosed here. The present disclosure is intended to cover any variations, uses, or adaptations of the present disclosure following the general principles thereof and including such departures from the present disclosure as come within known or customary practice in the art. It is intended that the specification and examples be considered as exemplary only, with the scope of the invention being defined by the following claims.</p>
</description>
<claims id="claims01" lang="en"><!-- EPO <DP n="27"> -->
<claim id="c-en-0001" num="0001">
<claim-text>A method for image processing, applied to a mobile terminal, the method comprising:
<claim-text>acquiring (S11) a first image output by an image sensor;</claim-text>
<claim-text>responsive to (S12) a first signal value of the first image after being processed exceeding a saturation value of a first bit width at a preset image processing stage, recording the first signal value of the processed first image as a second signal value with a second bit width, wherein the second bit width is greater than the first bit width; and</claim-text>
<claim-text>mapping (S13) the second signal value recorded with the second bit width to a third signal value recorded with the first bit width to obtain a second image.</claim-text></claim-text></claim>
<claim id="c-en-0002" num="0002">
<claim-text>The method according to claim 1, wherein the mapping the second signal value recorded with the second bit width to a third signal value recorded with the first bit width to obtain a second image comprises:
<claim-text>mapping, according to a maximum signal value of different color components of each pixel of an image recorded with the first bit width after image processing, the second signal value recorded with the second bit width to the third signal value recorded with the first bit width to obtain a third image;</claim-text>
<claim-text>mapping, based on the first image before image processing, different color sub-signal values of each pixel recorded with the second bit width to the third signal value recorded with the first bit width to obtain a fourth image; and</claim-text>
<claim-text>obtaining the second image based on the third image and the fourth image.</claim-text></claim-text></claim>
<claim id="c-en-0003" num="0003">
<claim-text>The method according to claim 2, wherein the mapping, according to a maximum signal value of different color components of each pixel of an image recorded with the first bit width after image processing, the second signal value recorded with the second bit width to the third signal value recorded with the first bit width to obtain a third image comprises:
<claim-text>mapping a first part, greater than a preset threshold, of the maximum signal value of different color components of each pixel recorded with the second bit width to a range between the preset threshold and the saturation value of the first bit width; and<!-- EPO <DP n="28"> --></claim-text>
<claim-text>mapping a second part, less than or equal to the preset threshold, of the maximum signal value of different color components of each pixel recorded with the second bit width to match with a part, less than or equal to the preset threshold, of the maximum signal value of different color components of each pixel of the image recorded with the first bit width after image processing to obtain the third image.</claim-text></claim-text></claim>
<claim id="c-en-0004" num="0004">
<claim-text>The method according to claim 3, further comprising:
<claim-text>obtaining a smooth-curve-shape mapping relationship based on the mapping of the first part to the range between the preset threshold and the saturation value of the first bit width and the mapping of the second part to the part, less than or equal to the preset threshold, of the maximum signal value of different color components of each pixel of the image recorded with the first bit width after image processing,</claim-text>
<claim-text>wherein the mapping, according to a maximum signal value of different color components of each pixel of an image recorded with the first bit width after image processing, the second signal value recorded with the second bit width to the third signal value recorded with the first bit width to obtain a third image comprises:<br/>
mapping, according to the smooth-curve-shape mapping relationship, the maximum signal value of different color components of each pixel recorded with the second bit width to the third signal value recorded with the first bit width to obtain the third image.</claim-text></claim-text></claim>
<claim id="c-en-0005" num="0005">
<claim-text>The method according to claim 2, wherein the mapping, based on the first image before image processing, different color sub-signal values of each pixel recorded with the second bit width to the third signal value recorded with the first bit width to obtain a fourth image comprises:
<claim-text>determining, among each pixel of the first image, a first pixel having different color sub-signal values all less than the saturation value of the first bit width;</claim-text>
<claim-text>determining, among each pixel recorded with the second bit width, a second pixel corresponding to the first pixel;</claim-text>
<claim-text>determining, from the second pixel, a third part having a color sub-signal value greater than the saturation value of the first bit width; and<!-- EPO <DP n="29"> --></claim-text>
<claim-text>mapping, based on the third part, different color sub-signal values of each pixel recorded with the second bit width to the third signal value recorded with the first bit width to obtain the fourth image.</claim-text></claim-text></claim>
<claim id="c-en-0006" num="0006">
<claim-text>The method according to claim 5, wherein the mapping, based on the third part, different color sub-signal values of each pixel recorded with the second bit width to the third signal value recorded with the first bit width to obtain the fourth image comprises:
<claim-text>proportionally compressing different color sub-signal values of each pixel of the third part to a range not exceeding the saturation value of the first bit width; and</claim-text>
<claim-text>mapping color sub-signal values of pixels, other than the third part, recorded with the second bit width, which are greater than a color sub-signal value of the saturation value of the first bit width, to the saturation value of the first bit width to obtain the fourth image.</claim-text></claim-text></claim>
<claim id="c-en-0007" num="0007">
<claim-text>The method according to claim 2 or any claim dependent thereon, wherein both the third image and the fourth image are images of a red green blue (RGB) space;<br/>
obtaining the second image based on the third image and the fourth image comprises:
<claim-text>converting the third image to an HSV space to obtain a first HSV space image;</claim-text>
<claim-text>converting the fourth image to the HSV space to obtain a second HSV space image; and</claim-text>
<claim-text>acquiring corresponding values in the RGB space according to a value of a value V channel in the first HSV space image, and a value of a hue H channel and a value of a saturation S channel in the second HSV space image, and obtaining the second image.</claim-text></claim-text></claim>
<claim id="c-en-0008" num="0008">
<claim-text>The method according to any preceding claim, wherein the image processing comprises at least one of:
<claim-text>lens shading correction; and</claim-text>
<claim-text>white balance correction.</claim-text></claim-text></claim>
<claim id="c-en-0009" num="0009">
<claim-text>A device for image processing, applied to a mobile terminal, the device comprising:
<claim-text>an acquisition module (101), configured to acquire a first image output by an image sensor;<!-- EPO <DP n="30"> --></claim-text>
<claim-text>a bit width increasing module (102), configured to, responsive to a first signal value of the first image after being processed exceeding a saturation value of a first bit width at a preset image processing stage, record the first signal value of the processed first image with a second bit width, the second bit width being greater than the first bit width; and</claim-text>
<claim-text>a mapping module (103), configured to map the second signal value recorded with the second bit width to a third signal value recorded with the first bit width to obtain a second image.</claim-text></claim-text></claim>
<claim id="c-en-0010" num="0010">
<claim-text>The device according to claim 9, wherein the mapping module comprises a first mapping module, a second mapping module, and an obtaining module;<br/>
the first mapping module is configured to map, according to a maximum signal value of different color components of each pixel of an image recorded with the first bit width after image processing, the second signal value recorded with the second bit width to the third signal value recorded with the first bit width to obtain a third image;<br/>
the second mapping module is configured to map, based on the first image before image processing, different color sub-signal values of each pixel recorded with the second bit width to the third signal value recorded with the first bit width to obtain a fourth image; and<br/>
the obtaining module is configured to obtain the second image based on the third image and the fourth image.</claim-text></claim>
<claim id="c-en-0011" num="0011">
<claim-text>The device according to claim 10, wherein<br/>
the first mapping module is specifically configured to map a first part, greater than a preset threshold, of the maximum signal value of different color components of each pixel recorded with the second bit width to a range between the preset threshold and the saturation value of the first bit width; and map a second part, less than or equal to the preset threshold, of the maximum signal value of different color components of each pixel recorded with the second bit width to match with a part, less than or equal to the preset threshold, of the maximum signal value of different color components of each pixel of the image recorded with the first bit width after image processing to obtain the third image.<!-- EPO <DP n="31"> --></claim-text></claim>
<claim id="c-en-0012" num="0012">
<claim-text>The device according to claim 10 or 11, further comprising:
<claim-text>a smoothing module, configured to obtain a smooth-curve-shape mapping relationship based on the mapping of the first part to the range between the preset threshold and the saturation value of the first bit width and the mapping of the second part to the part, less than or equal to the preset threshold, of the maximum signal value of different color components of each pixel of the image recorded with the first bit width after image processing,</claim-text>
<claim-text>wherein the first mapping module is specifically configured to map, according to the smooth-curve-shape mapping relationship, a maximum signal value of different color components of each pixel recorded with the second bit width to the third signal value recorded with the first bit width to obtain the third image.</claim-text></claim-text></claim>
<claim id="c-en-0013" num="0013">
<claim-text>The device according to claim 10, 11 or 12 wherein the second mapping module is specifically configured to:
<claim-text>determine, among each pixel of the first image, a first pixel having different color sub-signal values all less than the saturation value of the first bit width;</claim-text>
<claim-text>determine, among each pixel recorded with the second bit width, a second pixel corresponding to the first pixel;</claim-text>
<claim-text>determine, from the second pixel, a third part having a color sub-signal value greater than the saturation value of the first bit width; and</claim-text>
<claim-text>map, based on the third part, different color sub-signal values of each pixel recorded with the second bit width to the third signal value recorded with the first bit width to obtain the fourth image.</claim-text></claim-text></claim>
<claim id="c-en-0014" num="0014">
<claim-text>The device according to claim 13, wherein the second mapping module is specifically configured to:
<claim-text>proportionally compress different color sub-signal values of each pixel of the third part to a range not exceeding the saturation value of the first bit width; and</claim-text>
<claim-text>map color sub-signal values of pixels, other than the third part, recorded with the second bit width, which are greater than a color sub-signal value of the saturation value of the first bit width, to the saturation value of the first bit width to obtain the fourth image.</claim-text><!-- EPO <DP n="32"> --></claim-text></claim>
<claim id="c-en-0015" num="0015">
<claim-text>Anon-transitory computer-readable storage medium, having stored instructions therein that, when executed by a processor of a mobile terminal, cause the mobile terminal to implement the image processing method according to any one of claims 1 to 8.</claim-text></claim>
</claims>
<drawings id="draw" lang="en"><!-- EPO <DP n="33"> -->
<figure id="f0001" num="1,2"><img id="if0001" file="imgf0001.tif" wi="128" he="209" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="34"> -->
<figure id="f0002" num="3,4"><img id="if0002" file="imgf0002.tif" wi="93" he="161" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="35"> -->
<figure id="f0003" num="5"><img id="if0003" file="imgf0003.tif" wi="157" he="169" img-content="drawing" img-format="tif"/></figure>
</drawings>
<search-report-data id="srep" lang="en" srep-office="EP" date-produced=""><doc-page id="srep0001" file="srep0001.tif" wi="157" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="155" he="233" type="tif"/></search-report-data><search-report-data date-produced="20210217" id="srepxml" lang="en" srep-office="EP" srep-type="ep-sr" status="n"><!--
 The search report data in XML is provided for the users' convenience only. It might differ from the search report of the PDF document, which contains the officially published data. The EPO disclaims any liability for incorrect or incomplete data in the XML for search reports.
 -->

<srep-info><file-reference-id>53.DG150907</file-reference-id><application-reference><document-id><country>EP</country><doc-number>20195158.9</doc-number></document-id></application-reference><applicant-name><name>Beijing Xiaomi Mobile Software Co., Ltd.</name></applicant-name><srep-established srep-established="yes"/><srep-invention-title title-approval="yes"/><srep-abstract abs-approval="yes"/><srep-figure-to-publish figinfo="by-applicant"><figure-to-publish><fig-number>1</fig-number></figure-to-publish></srep-figure-to-publish><srep-info-admin><srep-office><addressbook><text>MN</text></addressbook></srep-office><date-search-report-mailed><date>20210226</date></date-search-report-mailed></srep-info-admin></srep-info><srep-for-pub><srep-fields-searched><minimum-documentation><classifications-ipcr><classification-ipcr><text>G06T</text></classification-ipcr><classification-ipcr><text>H04N</text></classification-ipcr></classifications-ipcr></minimum-documentation></srep-fields-searched><srep-citations><citation id="sr-cit0001"><patcit dnum="CN110365949A" id="sr-pcit0001" url="http://v3.espacenet.com/textdoc?DB=EPODOC&amp;IDX=CN110365949&amp;CY=ep"><document-id><country>CN</country><doc-number>110365949</doc-number><kind>A</kind><name>SPREADTRUM COMMUNICATIONS TIANJIN CO LTD</name><date>20191022</date></document-id></patcit><category>X</category><rel-claims>1-6,8-15</rel-claims><category>Y</category><rel-claims>7</rel-claims><rel-passage><passage>* paragraphs [0004] - [0006],  [0011] - [0016] *</passage></rel-passage><rel-passage><passage>* paragraphs [0054],  [0067] *</passage><passage>* paragraphs [0070] - [0073],  [0082] *</passage><passage>* paragraphs [0095],  [0100] - [0102] *</passage></rel-passage></citation><citation id="sr-cit0002"><nplcit id="sr-ncit0001" npl-type="s"><article><author><name>ARORA SHAVETA ET AL</name></author><atl>Enhancement of overexposed color images</atl><serial><sertitle>2015 3RD INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (ICOICT), IEEE</sertitle><pubdate>20150527</pubdate><doi>10.1109/ICOICT.2015.7231423</doi></serial><location><pp><ppf>207</ppf><ppl>211</ppl></pp></location><refno>XP033215142</refno></article></nplcit><category>Y</category><rel-claims>7</rel-claims><rel-passage><passage>* abstract *</passage><passage>* page 208, paragraph 1 *</passage></rel-passage></citation><citation id="sr-cit0003"><patcit dnum="US2018007332A1" id="sr-pcit0002" url="http://v3.espacenet.com/textdoc?DB=EPODOC&amp;IDX=US2018007332&amp;CY=ep"><document-id><country>US</country><doc-number>2018007332</doc-number><kind>A1</kind><name>LIM SUK HWAN [US] ET AL</name><date>20180104</date></document-id></patcit><category>A</category><rel-claims>1-15</rel-claims><rel-passage><passage>* abstract *</passage><passage>* paragraphs [0001] - [0014] *</passage><passage>* paragraphs [0062],  [0065] *</passage></rel-passage></citation><citation id="sr-cit0004"><nplcit id="sr-ncit0002" npl-type="s"><article><author><name>GUPTA SUNIT ET AL</name></author><atl>Effective restoration of clipped pixels in LDR images</atl><serial><sertitle>2013 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING, IEEE</sertitle><pubdate>20130403</pubdate><doi>10.1109/ICCSP.2013.6577185</doi><isbn>978-1-4673-4865-2</isbn></serial><location><pp><ppf>893</ppf><ppl>896</ppl></pp></location><refno>XP032474807</refno></article></nplcit><category>A</category><rel-claims>1-15</rel-claims><rel-passage><passage>* abstract *</passage></rel-passage></citation></srep-citations><srep-admin><examiners><primary-examiner><name>Klemencic, Ales</name></primary-examiner></examiners><srep-office><addressbook><text>Munich</text></addressbook></srep-office><date-search-completed><date>20210217</date></date-search-completed></srep-admin><!--							The annex lists the patent family members relating to the patent documents cited in the above mentioned European search report.							The members are as contained in the European Patent Office EDP file on							The European Patent Office is in no way liable for these particulars which are merely given for the purpose of information.							For more details about this annex : see Official Journal of the European Patent Office, No 12/82						--><srep-patent-family><patent-family><priority-application><document-id><country>CN</country><doc-number>110365949</doc-number><kind>A</kind><date>20191022</date></document-id></priority-application><text>NONE</text></patent-family><patent-family><priority-application><document-id><country>US</country><doc-number>2018007332</doc-number><kind>A1</kind><date>20180104</date></document-id></priority-application><text>NONE</text></patent-family></srep-patent-family></srep-for-pub></search-report-data>
</ep-patent-document>
