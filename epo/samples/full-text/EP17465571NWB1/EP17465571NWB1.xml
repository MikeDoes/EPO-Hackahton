<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE ep-patent-document PUBLIC "-//EPO//EP PATENT DOCUMENT 1.5.1//EN" "ep-patent-document-v1-5-1.dtd">
<!-- This XML data has been generated under the supervision of the European Patent Office -->
<ep-patent-document id="EP17465571B1" file="EP17465571NWB1.xml" lang="en" country="EP" doc-number="3483781" kind="B1" date-publ="20211006" status="n" dtd-version="ep-patent-document-v1-5-1">
<SDOBI lang="en"><B000><eptags><B001EP>ATBECHDEDKESFRGBGRITLILUNLSEMCPTIESILTLVFIROMKCYALTRBGCZEEHUPLSK..HRIS..MTNORS..SM..................</B001EP><B005EP>J</B005EP><B007EP>BDM Ver 2.0.12 (4th of August) -  2100000/0</B007EP></eptags></B000><B100><B110>3483781</B110><B120><B121>EUROPEAN PATENT SPECIFICATION</B121></B120><B130>B1</B130><B140><date>20211006</date></B140><B190>EP</B190></B100><B200><B210>17465571.2</B210><B220><date>20171113</date></B220><B240><B241><date>20191115</date></B241></B240><B250>en</B250><B251EP>en</B251EP><B260>en</B260></B200><B400><B405><date>20211006</date><bnum>202140</bnum></B405><B430><date>20190515</date><bnum>201920</bnum></B430><B450><date>20211006</date><bnum>202140</bnum></B450><B452EP><date>20210601</date></B452EP></B400><B500><B510EP><classification-ipcr sequence="1"><text>G06K   9/00        20060101AFI20180508BHEP        </text></classification-ipcr><classification-ipcr sequence="2"><text>G06K   9/46        20060101ALI20180508BHEP        </text></classification-ipcr></B510EP><B520EP><classifications-cpc><classification-cpc sequence="1"><text>G06K   9/00791     20130101 FI20180430BHEP        </text></classification-cpc><classification-cpc sequence="2"><text>G06K   9/4647      20130101 LI20180430BHEP        </text></classification-cpc></classifications-cpc></B520EP><B540><B541>de</B541><B542>VORRICHTUNG ZUR ERKENNUNG EINER SICHTBEHINDERUNG IM BEREICH EINER WINDSCHUTZSCHEIBE</B542><B541>en</B541><B542>DEVICE FOR DETECTING WINDSHIELD BLOCKAGE</B542><B541>fr</B541><B542>DISPOSITIF POUR DÉTECTER UN BLOCAGE DE PARE-BRISE</B542></B540><B560><B561><text>EP-A1- 2 879 370</text></B561><B561><text>EP-A1- 3 070 928</text></B561><B561><text>US-B2- 9 319 637</text></B561><B562><text>Anonymous: "Summed area table", Wikipedia, the free encyclopedia , 2 May 2016 (2016-05-02), XP55269859, Retrieved from the Internet: URL:https://en.wikipedia.org/wiki/Summed_a rea_table [retrieved on 2016-05-02]</text></B562></B560></B500><B700><B720><B721><snm>Radu, Petru</snm><adr><str>Intrarea Saturn, no. 4</str><city>300692 Timisoara</city><ctry>RO</ctry></adr></B721></B720><B730><B731><snm>Continental Automotive GmbH</snm><iid>101676895</iid><irf>2017P02927EP (NU)</irf><adr><str>Vahrenwalder Straße 9</str><city>30165 Hannover</city><ctry>DE</ctry></adr></B731></B730><B740><B741><snm>Continental Corporation</snm><iid>101882523</iid><adr><str>c/o Conti Temic microelectronic GmbH 
Intellectual Property 
Sieboldstraße 19</str><city>90411 Nürnberg</city><ctry>DE</ctry></adr></B741></B740></B700><B800><B840><ctry>AL</ctry><ctry>AT</ctry><ctry>BE</ctry><ctry>BG</ctry><ctry>CH</ctry><ctry>CY</ctry><ctry>CZ</ctry><ctry>DE</ctry><ctry>DK</ctry><ctry>EE</ctry><ctry>ES</ctry><ctry>FI</ctry><ctry>FR</ctry><ctry>GB</ctry><ctry>GR</ctry><ctry>HR</ctry><ctry>HU</ctry><ctry>IE</ctry><ctry>IS</ctry><ctry>IT</ctry><ctry>LI</ctry><ctry>LT</ctry><ctry>LU</ctry><ctry>LV</ctry><ctry>MC</ctry><ctry>MK</ctry><ctry>MT</ctry><ctry>NL</ctry><ctry>NO</ctry><ctry>PL</ctry><ctry>PT</ctry><ctry>RO</ctry><ctry>RS</ctry><ctry>SE</ctry><ctry>SI</ctry><ctry>SK</ctry><ctry>SM</ctry><ctry>TR</ctry></B840></B800></SDOBI>
<description id="desc" lang="en"><!-- EPO <DP n="1"> -->
<heading id="h0001">FIELD OF THE INVENTION</heading>
<p id="p0001" num="0001">The present invention relates to a device for detecting windshield blockage of a vehicle, to a system for detecting windshield blockage for a vehicle, to a method for detecting windshield blockage for a vehicle, as well as to a computer program element and a computer readable medium.</p>
<heading id="h0002">BACKGROUND OF THE INVENTION</heading>
<p id="p0002" num="0002">The general background of this invention is the field of driving systems that determine if a windscreen and/or windshield of a vehicle is suffering from a blockage.</p>
<p id="p0003" num="0003"><patcit id="pcit0001" dnum="US9319637A1"><text>US9319637A1</text></patcit> describes that a vision system for a vehicle includes a camera and a processor operable to process image data captured by the camera. When the vehicle is moving, the processor at least one of (a) reads a selected set of imager register values and compare a contrast of auto exposure control zones, and wherein, responsive to a determination that a range of contrast levels is less than a threshold level, the processor determines that there are contaminants at the lens or cover of the camera, and (b) monitors outputs of photosensing elements of the camera and, when the outputs fit a Gaussian distribution, the processor classifies the photosensing elements as blocked elements and, responsive to a determination that a number of the blocked photosensing elements is greater than a threshold level, the processor determines that there are contaminants at the lens or cover of the camera. <patcit id="pcit0002" dnum="US9319637A1"><text>US9319637A1</text></patcit> relies on a sequence of frames for an initial training that is required every time the algorithm starts. It counts the pixels that do not change from one frame to another,r and by employing a heuristic thresholding value representing the percentage of non-changing pixels, blockage is identified. However, changing illumination changing environments are problematic, for example if the obstruction is semi-transparent, when the car goes from shade to sun-light the intensities of the pixels change.</p>
<p id="p0004" num="0004">There is a need to provide an improved technique for blockage of a windshield or windscreen of a vehicle.<!-- EPO <DP n="2"> --></p>
<heading id="h0003">SUMMARY OF THE INVENTION</heading>
<p id="p0005" num="0005">The object of the present invention is solved with the subject matter of the independent claims, wherein further embodiments are incorporated in the dependent claims. It should be noted that the following described aspects and examples of the invention apply also for the device for detecting windshield blockage of a vehicle, the system for detecting windshield blockage of a vehicle, the method for detecting windshield blockage of a vehicle, and for the computer program element and computer readable medium.</p>
<p id="p0006" num="0006">According to a first aspect, there is provided a device for detecting windshield blockage of a vehicle, comprising:
<ul id="ul0001" list-style="dash" compact="compact">
<li>an input unit;</li>
<li>a processing unit; and</li>
<li>an output unit.</li>
</ul></p>
<p id="p0007" num="0007">The input unit is configured to provide the processing unit with at least one initial image, the at least one initial image relating to a scene external to a vehicle viewed through a windshield of the vehicle. The processing unit is configured to transform each initial image of the at least one initial image into an integral image. The processing unit is configured also to calculate summed pixel values for each of a plurality of areas in the at least one integral image. The processing unit is configured also to detect windshield blockage on the basis of a plurality of differences between the summed pixel values for all the available adjacent pairs of at least a subset of the plurality of areas. The output unit is configured to output information that at least a part of the windshield has a blockage.</p>
<p id="p0008" num="0008">In other words, the device utilizes the benefits of image processing an integral image, and detecting blockage on a windshield/windscreen by revealing the strength of the spatial relationship of different regions of the image. A weak spatial relationship between regions can be used to indicate the presence of a blockage, while a strong relationship between the regions can be used to indicate a clear field of view. The pixel values in one area in the integral image are summed and the pixel values in another area in the integral image are summed, and then the difference between these summed values is calculated.</p>
<p id="p0009" num="0009">In this way, an indication can be provided that a windscreen (windshield) is blocked and this information can be provided to other Advanced Drive Assistance ADAS algorithms that could be corrupted or mislead due to the windscreen being blocked or partially blocked.<!-- EPO <DP n="3"> --></p>
<p id="p0010" num="0010">In an example, a value at a position x, y, in the integral image is calculated as the sum of all the pixels values above and to the left in the initial image including the pixel value at position x, y, in the initial image.</p>
<p id="p0011" num="0011">In an example, the plurality of areas each contain the same number of pixels. The plurality of areas are situated along at least two lines that are angled one to the other. The windshield blockage is detected on the basis of a plurality of differences between the summed pixels values for all the available adjacent pairs of the subset of the plurality of areas.</p>
<p id="p0012" num="0012">In other words, if there are n areas situated along at least one line, then the pixels in the nth area are summed and the pixels in the n-1th are summed, and the difference calculated. Also, a difference between the summed pixel values for the n-1th and the n-2th areas is calculated, and difference between the summed pixels values for the n-2th and n-3 areas is calculated. Thus, for n areas n-1 differences are calculated for the summed pixels values.</p>
<p id="p0013" num="0013">In an example, at least one image segment is formed between at least parts of the plurality of lines, and for a segment that is bounded on two sides by a part of one line and by a part of a second line, the at least one subset of the plurality of areas comprises the plurality of areas on the part of the first line and on the part of the second line.</p>
<p id="p0014" num="0014">In other words, the processing unit is configured to detect a windshield blockage for a segment formed between a part of a first line and a part of a second line of on the basis of the differences between the summed pixels values for the plurality of areas on the part of the first line and on the part of the second line.<!-- EPO <DP n="4"> --></p>
<p id="p0015" num="0015">The processing unit is configured to detect windshield blockage on the basis of a variation in at least a subset of the plurality of differences.</p>
<p id="p0016" num="0016">In an example, detection of windshield blockage comprises utilisation of a training data set.</p>
<p id="p0017" num="0017">According to a second aspect, there is provided a system for detecting windshield blockage for a vehicle, comprising:
<ul id="ul0002" list-style="dash" compact="compact">
<li>at least one camera;</li>
<li>a device for detecting windshield blockage of a vehicle according to the first aspect and any associated example.</li>
</ul></p>
<p id="p0018" num="0018">The at least one camera is configured to be located within a vehicle and the at least one camera is configured to acquire the at least one image relating to a scene external to the vehicle viewed through a windshield of the vehicle. The device is located within the vehicle.</p>
<p id="p0019" num="0019">According to a third aspect, there is provided a method as defined by claim 6.</p>
<p id="p0020" num="0020">According to another aspect, there is provided a computer program element controlling apparatus as previously described which, when the computer program element is executed by a processing unit, is adapted to perform the method steps as previously described.<!-- EPO <DP n="5"> --></p>
<p id="p0021" num="0021">According to another aspect, there is also provided a computer readable medium having stored the computer element as previously described.</p>
<p id="p0022" num="0022">Advantageously, the benefits provided by any of the above aspects equally apply to all of the other aspects and vice versa.</p>
<p id="p0023" num="0023">The above aspects and examples will become apparent from and be elucidated with reference to the embodiments described hereinafter.</p>
<heading id="h0004">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p0024" num="0024">Exemplary embodiments will be described in the following with reference to the following drawings:
<ul id="ul0003" list-style="none" compact="compact">
<li><figref idref="f0001">Fig. 1</figref> shows a schematic set up of an example of a device for detecting windshield blockage of a vehicle;</li>
<li><figref idref="f0001">Fig. 2</figref> shows a schematic set up of an example of a system for detecting windshield blockage of a vehicle;</li>
<li><figref idref="f0002">Fig. 3</figref> shows a method for detecting windshield blockage of a vehicle;</li>
<li><figref idref="f0002">Fig. 4</figref> shows an example of the positioning of a plurality of areas in a field of view of a camera;</li>
<li><figref idref="f0003">Fig. 5</figref> shows an example of one of the plurality of areas in an integral image formed from the image shown in <figref idref="f0002">Fig. 4</figref>; and</li>
<li><figref idref="f0003">Fig. 6</figref> shows a detailed logic flow for the blockage detection algorithm utilized for detailed examples of the device, system and method for detecting windshield blockage of a vehicle.</li>
</ul></p>
<heading id="h0005">DETAILED DESCRIPTION OF EMBODIMENTS</heading>
<p id="p0025" num="0025"><figref idref="f0001">Fig. 1</figref> shows an example of a device 10 for detecting windshield blockage of a vehicle. The device 10 comprises an input unit 20, a processing unit 30 and an output unit 40. The input unit 20 is configured to provide the processing unit 30 with at least one initial image, the at least one initial image relating to a scene external to a vehicle viewed through a windshield of the vehicle. The processing unit 30 is configured to transform each initial image of the at least one initial image into an integral image. The processing unit 30 is configured also to calculate summed pixel values for each of a plurality of areas in the at least one integral image. The processing unit 30 is configured to detect windshield blockage on the basis of a plurality of differences between the summed pixel values for all the available adjacent pairs of at least a subset<!-- EPO <DP n="6"> --> of the plurality of areas. The output unit 40 is configured to output information that at least a part of the windshield has a blockage.</p>
<p id="p0026" num="0026">In an example, the at least one image was acquired by at least one camera that was not focussed on the windscreen of the vehicle.</p>
<p id="p0027" num="0027">Thus in this manner, standard vehicle cameras that are viewing scenes external to the vehicle as part of navigation and/or safety systems, or as part of automatic driving systems can also be utilised to determine if a part or portion(s) of a vehicle's windscreen is blocked or partially blocked, where that part or portion is the portion of the windscreen associated with the field of view(s) of the camera(s) viewing the scene through the windscreen.</p>
<p id="p0028" num="0028">According to an example, a value at a position x, y, in the integral image is calculated as the sum of all the pixels values above and to the left in the initial image including the pixel value at position x, y, in the initial image.</p>
<p id="p0029" num="0029">According to an example, the plurality of areas each contain the same number of pixels.</p>
<p id="p0030" num="0030">In an example, each area is 16x16 pixels in dimension. The plurality of areas are situated along at least two lines that are angled one to the other.</p>
<p id="p0031" num="0031">In an example, the plurality of areas are situated along at least three lines that are angled one to the other.</p>
<p id="p0032" num="0032">In an example, the at least one line bisects the centre of the integral image.</p>
<p id="p0033" num="0033">In an example, each of the at least one lines bisects the centre of the integral image.</p>
<p id="p0034" num="0034">In an example, one of the at least one lines is a horizontal line and the at least three lines intersect in the centre of the horizontal line. In an example, the horizontal line can move up and down in the image from one image to the next. In other words, the three lines can intersect at the centre of a horizontal line that can move up and down whilst driving.</p>
<p id="p0035" num="0035">In an example, one of the at least one lines is horizontally orientated in the at least one image.<!-- EPO <DP n="7"> --></p>
<p id="p0036" num="0036">The windshield blockage is detected on the basis of a plurality of differences between the summed pixel values for all the available adjacent pairs of at least a subset of the plurality of areas.</p>
<p id="p0037" num="0037">The at least two lines are angled one to the other. According to an example, at least one image segment is formed between at least parts of the plurality of lines. For a segment that is bounded on two sides by a part of one line and by a part of a second line, the at least one subset of the plurality of areas comprises the plurality of areas on the part of the first line and on the part of the second line.</p>
<p id="p0038" num="0038">In an example, for each of the segments bounded by parts of lines, the processing unit is configured to similarly detect a windshield blockage for each of those segments on the basis of the differences between the summed pixel values for the plurality of areas on the parts of the lines that border each of those segments.</p>
<p id="p0039" num="0039">According to an example, the processing unit is configured to detect windshield blockage on the basis of a variation in at least a subset of the plurality of differences.</p>
<p id="p0040" num="0040">In an example, the processing unit is configured to detect windshield blockage on the basis of a variation the plurality of differences.</p>
<p id="p0041" num="0041">According to an example, detection of windshield blockage comprises utilisation of a training data set.</p>
<p id="p0042" num="0042">In an example, the training data set comprises image data that exhibits windshield blockage. In an example, the training data set comprises image data that does not exhibit windshield blockage. This training data can be used to adjust the parameters of a classification algorithm, which decides based on the trained parameters if a new set of differences belongs to blocked/non-blocked regions.</p>
<p id="p0043" num="0043">In an example, a plurality of cameras can be utilised to have different fields of view through a vehicle's windscreen, thereby covering more area of the windscreen.</p>
<p id="p0044" num="0044"><figref idref="f0001">Fig. 2</figref> shows an example of a system 100 for detecting windshield blockage for a vehicle. The system comprises at least one camera 110 and a device 10 for detecting<!-- EPO <DP n="8"> --> windshield blockage of a vehicle as described above with respect to any of the examples of <figref idref="f0001">Fig. 1</figref>. The at least one camera 110 is configured to be located within a vehicle 120 and the at least one camera 110 is configured to acquire the at least one image relating to a scene external to the vehicle 120 viewed through a windshield 130 of the vehicle. The device is located on or within the vehicle.</p>
<p id="p0045" num="0045">In an example, the at least one camera 110 is the input unit 20.</p>
<p id="p0046" num="0046"><figref idref="f0002">Fig. 3</figref> shows a method 200 for detecting windshield blockage of a vehicle in its basic steps. The method 200 comprises:
<ul id="ul0004" list-style="none" compact="compact">
<li>in a providing step 210, also referred to as step a), providing a processing unit (30) with at least one initial image, the at least one initial image relating to a scene external to a vehicle viewed through a windshield of the vehicle;</li>
<li>in a transforming step 220, also referred to as step b), transforming by the processing unit each initial image of the at least one initial image into an integral image;</li>
<li>in a calculating step 230, also referred to as step c), calculating by the processing unit summed pixel values for each of a plurality of areas in the at least one integral image;</li>
<li>in a detecting step 240, also referred to as step d), detecting by the processing unit windshield blockage on the basis of at least one difference between the summed pixel values for at least a subset of the plurality of areas; and</li>
<li>in an outputting step 250, also referred to as step e), outputting with an output unit (40) output information that the at least a part of the windshield has a blockage.</li>
</ul></p>
<p id="p0047" num="0047">In an example, a value at a position x, y, in the integral image is calculated as the sum of all the pixels values above and to the left in the initial image including the pixel value at position x, y, in the initial image.</p>
<p id="p0048" num="0048">In an example, the plurality of areas each contain the same number of pixels.</p>
<p id="p0049" num="0049">The plurality of areas are situated along at least two lines that are angled one to the other. In step d) the windshield blockage is detected on the basis of a plurality of differences between the summed pixels values for at least some of the adjacent pairs of the subset of the plurality of areas.<!-- EPO <DP n="9"> --></p>
<p id="p0050" num="0050">The differences are calculated for all the available adjacent pairs of the subset of the plurality of areas.</p>
<p id="p0051" num="0051">In an example, at least one image segment is formed between at least parts of the plurality of lines, and for a segment that is bounded on two sides by a part of one line and by a part of a second line, the at least one subset of the plurality of areas comprises the plurality of areas on the part of the first line and on the part of the second line.</p>
<p id="p0052" num="0052">In an example, the processing unit is configured to detect windshield blockage on the basis of a variation in at least a subset of the plurality of differences.</p>
<p id="p0053" num="0053">In an example, detection of windshield blockage comprises utilisation of a classifier.</p>
<p id="p0054" num="0054">In an example, detection of windshield blockage comprises utilisation of a training data set.</p>
<p id="p0055" num="0055">The device, system and method are now described in further detail with respect to <figref idref="f0002 f0003">Figs. 4-6</figref>.</p>
<p id="p0056" num="0056">The device, system and method described here enables the detection of detect blockage / partial blockage events occuring on the windscreen in front of the field of view of a camera-based driver assistance system. The design provides robustness of the blockage detection to external factors, such as illumination changes and partial obstructions. By utilizing the benefits of the image processing concept of the integral image, the present blockage detection algorithm reveals the strength of the spatial relationship of adiacent regions of the image. A weak spatial relationship between the regions can be used to indicate the presence of a blockage event, while a strong relationship between the regions can be used to indicate a clear field of view.</p>
<p id="p0057" num="0057">Thus, as described above the algorithm uses the concept of the integral image. When a new (or initial) image I is processed by the detector, an integral image I' is first computed. When computing an integral image, a Summed Area Table (SAT) is created with the same size as the initial image I. The table is the integral image I'. In this table, at any point (x,y) the value is represented by the sum of all the pixel values above, to the left and including the original pixel value of (x,y) itself.</p>
<p id="p0058" num="0058">The value in the SAT at (x,y) is simply calculated by:<!-- EPO <DP n="10"> --> <maths id="math0001" num=""><math display="block"><mi>I</mi><mo>'</mo><mfenced><mi>x</mi><mi>y</mi></mfenced><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mtable columnalign="left"><mtr><mtd><mrow><mi>x</mi><mo>'</mo><mo>≤</mo><mi>x</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>y</mi><mo>'</mo><mo>≤</mo><mi>y</mi></mrow></mtd></mtr></mtable></munder><mrow><mi>I</mi><mfenced separators=""><mi>x</mi><mo>'</mo><mo>,</mo><mi>y</mi><mo>'</mo></mfenced></mrow></mstyle></math><img id="ib0001" file="imgb0001.tif" wi="44" he="14" img-content="math" img-format="tif"/></maths></p>
<p id="p0059" num="0059">The SAT can be computed efficiently in a single pass over the image I, as the value in the SAT at (x,y) is <maths id="math0002" num=""><math display="block"><mi>I'</mi><mfenced><mi mathvariant="normal">x</mi><mi mathvariant="normal">y</mi></mfenced><mo>=</mo><mi mathvariant="normal">I</mi><mfenced><mi mathvariant="normal">x</mi><mi mathvariant="normal">y</mi></mfenced><mo>+</mo><mi>I'</mi><mfenced separators=""><mi mathvariant="normal">x</mi><mo>−</mo><mn>1</mn><mo>,</mo><mi mathvariant="normal">y</mi></mfenced><mo>+</mo><mi>I'</mi><mfenced separators=""><mi mathvariant="normal">x</mi><mo>,</mo><mi mathvariant="normal">y</mi><mo>−</mo><mn>1</mn></mfenced><mo>−</mo><mi>I'</mi><mfenced separators=""><mi mathvariant="normal">x</mi><mo>−</mo><mn>1</mn><mo>,</mo><mi mathvariant="normal">y</mi><mo>−</mo><mn>1</mn></mfenced></math><img id="ib0002" file="imgb0002.tif" wi="82" he="5" img-content="math" img-format="tif"/></maths></p>
<p id="p0060" num="0060">The algorithm relies on the difference of sums of adjacent rectangles placed along 3 lines on the field of view of the camera. The rectangles for the ADAS blockage detector have a size of 16 by 16 pixels, but other dimensions can be used, depending on the application scenario. The rectangles are situated on 3 lines intersected at the center of the horizon line, as shown in <figref idref="f0002">Fig. 4</figref>.</p>
<p id="p0061" num="0061">Initially, the sum for all the 16 by 16 pixel blocks is computed by employing the integral image as discussed above. The windshield obstruction algorithm then computes the differences between sums of adjacent blocks of pixels and observes how much variation there is in a subset of differences.</p>
<p id="p0062" num="0062"><figref idref="f0003">Fig. 5</figref> shows an area of 16 pixels in the integral image. Thus, once the above equation has been used to calculate and fill up the SAT, that is generate an integral image, the task of calculating the sum of pixels in any rectangle, which is a subset of the original image, is carried out. To compute the sum of a rectangle from the original image, 4 values from the SAT can be used. Only using only these 4 values, the sum S of the pixels within a region defined by 4 points, A(x,y), B(x,y), C(x,y) and D(x,y) is computed by using the following equation: <maths id="math0003" num=""><math display="block"><mi mathvariant="normal">S</mi><mo>=</mo><mi>I'</mi><mfenced><mi mathvariant="normal">A</mi></mfenced><mo>+</mo><mi>I'</mi><mfenced><mi mathvariant="normal">D</mi></mfenced><mo>+</mo><mi>I'</mi><mfenced><mi mathvariant="normal">B</mi></mfenced><mo>−</mo><mi>I'</mi><mfenced><mi mathvariant="normal">C</mi></mfenced></math><img id="ib0003" file="imgb0003.tif" wi="52" he="5" img-content="math" img-format="tif"/></maths></p>
<p id="p0063" num="0063">Thus, although an integral image is calculated for the complete image, actually only integral image values need to be calculated for the rectangles shown in <figref idref="f0002">Fig. 4</figref>.</p>
<p id="p0064" num="0064">Returning to <figref idref="f0002">Fig. 4</figref>, the blocks of pixels (areas) are situated on 3 lines: one line is represented by the horizon line and the other two are symmetric to the first line, as observed in <figref idref="f0002">Fig. 4</figref>. The 3 lines form 6 segments, 2 from their intersection point to the left and right on the horizon line, 2 towards the top side and 2 towards the bottom side of the image. Thus one segment is bounded by part of one line of blocks of pixels at approx. 1 o' clock and by another part of one line of blocks at approx. 3 o' clock (30 degrees). A second segment is<!-- EPO <DP n="11"> --> bounded by part of one line of blocks of pixels at approx. 3 o' clock and by another part of one line of blocks at approx. 4 o' clock (120 degrees). A third segment is bounded by part of one line of blocks of pixels at approx. 4 o' clock and by another part of one line of blocks at approx. 8 o' clock (240 degrees). A fourth segment is bounded by part of one line of blocks of pixels at approx. 8 o' clock and by another part of one line of blocks at approx. 9 o' clock (270 degrees). A fifth segment is bounded by part of one line of blocks of pixels at approx. 9 o' clock and by another part of one line of blocks at approx. 11 o' clock (330 degrees). And the sixth segment is bounded by part of one line of blocks of pixels at approx. 11 o' clock and by another part of one line of blocks at approx. 1 o' clock (30 degrees). The lines of blocks of pixels can be angled differently to that shown in <figref idref="f0002">Fig. 4</figref>, which is just an example. Also, there can be other numbers of lines of blocks of pixels (area) angled to one another as required, and as such there can be other numbers of segments bounded on both sides by blocks of pixels.</p>
<p id="p0065" num="0065">For each of the 6 segments, a set of differences between the sum of pixels between adjacent blocks is computed. If a segment has n blocks, n-1 differences will be generated. Thus, referring to the segment bounded by part of one line of segments at approx. 1 o' clock and by part of one line of segments at approx. 3 o' clock the n segments are those situated along both parts of those lines including the centre block of pixels. Thus the calculation of the differences between the summed values if adjacent blocks of pixels can be considered to start at one end of part of one line, progress to the centre pixel and then progress back out along the other part of the line that bounds a segment.</p>
<p id="p0066" num="0066">Large or small values of the differences for each of the 6 segments are a measure of the strength of the spatial relationship between the different regions of the initial image. Six training sets are formed by extracting the 6 sets of values from positive and negative examples of camera blockage events from multiple images and 6 training sets. Using the training sets, a number of 6 "2-class" generic classifiers (e.g. logistic regression) are trained. After the training of the 2-class classifiers is conducted, when a new image is acquired by the camera and processed as discussed above, the 6 classifiers can be used to output a set of 6 probabilities between 0 and 1. The output from each of the 6 classifiers represents the likelihood of the corresponding region of the image being obstructed.</p>
<p id="p0067" num="0067">Subsequently, for each line segment, a segment analyzer is used as a customizable algorithm to analyze the output of the 2-class classifiers. Each segment analyzer process a vector of outputs generated by one of the 2-class classifiers on a sequence<!-- EPO <DP n="12"> --> of N frames. The segment analyzer performs a non-trainable mathematical operation, such as mean or median. The size of the vector N is variable and application specific. For a fast decision on a line segment, a small N can be chosen, while for an increased stability of the detector, a large value of N can be chosen.</p>
<p id="p0068" num="0068">The output of the segment analyzers is integrated into a decision module. In the decision module, thresholding of the output of the segment analyzers with empirically determined thresholds takes place, for different areas of the image and for day/night driving. The thresholding operation outputs binary 0 or 1 values. If the segment analyzers corresponding to line segments below the horizon line produce values below the threshold, this indicates that there is a bottom partial blockage.</p>
<p id="p0069" num="0069">As a vehicle (e.g. car) moves and a new frame is acquired, the 6 "2-class" classifiers produce their output and the corresponding segment analyzers update their vectors of probabilities. In this way, no abrupt changes occur in the output of the final detector, as only one of N components of the segment analyzers changes.</p>
<p id="p0070" num="0070">The confidence of the detector is represented by the equation below: <maths id="math0004" num=""><math display="block"><mi mathvariant="italic">Conf</mi><mo>=</mo><mrow><mo>{</mo><mtable><mtr><mtd><mrow><mfrac bevelled="true"><mn>1</mn><mn>6</mn></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mn>6</mn></munderover><mrow><mi mathvariant="italic">segment</mi><mspace width="1ex"/><mi mathvariant="italic">analizer</mi><mspace width="1ex"/><mi>i</mi><mo>,</mo><mspace width="1ex"/><mi>if</mi><mspace width="1ex"/><mi>no</mi><mspace width="1ex"/><mi>blockage</mi><mspace width="1ex"/><mi>detected</mi></mrow></mstyle></mrow></mtd></mtr><mtr><mtd><mrow><mfrac bevelled="true"><mn>1</mn><mi>p</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>p</mi></munderover><mrow><mi mathvariant="italic">segment</mi><mspace width="1ex"/><mi mathvariant="italic">analizer</mi><mspace width="1ex"/><mi>i</mi><mspace width="1ex"/><mi mathvariant="italic">with</mi><mspace width="1ex"/><mi mathvariant="italic">output</mi><mo>&gt;</mo><mi mathvariant="italic">threshold</mi><mspace width="1ex"/><mi>i</mi><mo>,</mo><mspace width="1ex"/><mi>if</mi><mspace width="1ex"/><mi>blockage</mi><mspace width="1ex"/><mi>detected</mi></mrow></mstyle></mrow></mtd></mtr></mtable></mrow></math><img id="ib0004" file="imgb0004.tif" wi="137" he="30" img-content="math" img-format="tif"/></maths></p>
<p id="p0071" num="0071"><figref idref="f0003">Fig. 6</figref> shows a detailed example of the logic flow of the blockage detection algorithm. The following steps are undertaken:
<ol id="ol0001" compact="compact" ol-style="">
<li>a) The image is received by the algorithm. An image can be seen as a matrix, with rows and columns.</li>
<li>b) The integral image is computed, thus obtaining a new matrix.</li>
<li>c) From the new matrix, the 6 sets of sums are computed.</li>
<li>d) Then, the 6 sets of differences are computed</li>
<li>e) The 6 sets of differences serve as input in the testing phase to a 2-class classifier. The classifier outputs a value between 0 and 1 representing the degree of confidence that a segment is part of a "blocked" region of the image (matrix).</li>
<li>f) 6 segment analyzers process the output of the 2-class classifiers. Each segment analyzer process a vector of outputs generated by one of the 2-class classifiers on a sequence of N<!-- EPO <DP n="13"> --> frames. The segment analyzer will typically perform a non-trainable mathematical operation, such as mean or median.</li>
<li>g) In the decision module, thresholding of the output of the segment analyzers with empirically determined thresholds takes place.</li>
</ol></p>
<heading id="h0006"><u>Classification Task</u></heading>
<p id="p0072" num="0072">Here, more detail relating to the classification task is presented. The classification task is part of the pattern recognition or (machine learning) field. A 2-class classification algorithm has as output a set of 2 numbers, showing the "probability" of the input belonging to a class, and the other value is "1- the probability". The above described classification algorithm receives as input numbers (named features) and utilizes a "training" phase, during which it adjusts a set of parameters to best fit a separation hyperplane between the 2 classes. The testing phase uses a set of "training features", which are input values with known output value (class belonging). After fitting, the hyperplane is tuned according to the training examples. In the "testing" phase the classifier simply outputs the probability of the given input belonging to one of the 2 classes.</p>
<p id="p0073" num="0073">The choice of the 2 class classification algorithm is application dependent: one could use naive Bayes classifier, or neural networks, or simple k-Nearest Neighbor. "Application dependent" here refers to hardware resources and desired level of accuracy, in other words to the specific application being considered.</p>
<p id="p0074" num="0074">In another exemplary embodiment, a computer program or computer program element is provided that is characterized by being configured to execute the method steps of the method according to one of the preceding embodiments, on an appropriate system.</p>
<p id="p0075" num="0075">The computer program element might therefore be stored on a computer unit, which might also be part of an embodiment. This computing unit may be configured to perform or induce performing of the steps of the method described above. Moreover, it may be configured to operate the components of the above described apparatus and/or system. The computing unit can be configured to operate automatically and/or to execute the orders of a user. A computer program may be loaded into a working memory of a data processor. The data processor may thus be equipped to carry out the method according to one of the preceding embodiments.<!-- EPO <DP n="14"> --></p>
<p id="p0076" num="0076">According to a further exemplary embodiment of the present invention, a computer readable medium, such as a CD-ROM, is presented wherein the computer readable medium has a computer program element stored on it which computer program element is described by the preceding section.</p>
<p id="p0077" num="0077">It has to be noted that embodiments of the invention are described with reference to different subject matters. In particular, some embodiments are described with reference to method type claims whereas other embodiments are described with reference to the device type claims. However, a person skilled in the art will gather from the above and the following description that, unless otherwise notified, in addition to any combination of features belonging to one type of subject matter also any combination between features relating to different subject matters is considered to be disclosed with this application. However, all features can be combined providing synergetic effects that are more than the simple summation of the features.</p>
<p id="p0078" num="0078">While the invention has been illustrated and described in detail in the drawings and foregoing description, such illustration and description are to be considered illustrative or exemplary and not restrictive.</p>
<p id="p0079" num="0079">In the claims, the word "comprising" does not exclude other elements or steps, and the indefinite article "a" or "an" does not exclude a plurality. A single processor or other unit may fulfill the functions of several items re-cited in the claims. The mere fact that certain measures are re-cited in mutually different dependent claims does not indicate that a combination of these measures cannot be used to advantage. Any reference signs in the claims should not be construed as limiting the scope.</p>
</description>
<claims id="claims01" lang="en"><!-- EPO <DP n="15"> -->
<claim id="c-en-01-0001" num="0001">
<claim-text>A device (10) for detecting windshield blockage of a vehicle (120), the device (10) comprising:
<claim-text>- an input unit (20, 110);</claim-text>
<claim-text>- a processing unit (30); and</claim-text>
<claim-text>- an output unit (40); wherein the input unit (20, 110) is configured to provide (210) the processing unit (30) with at least one initial image, the at least one initial image relating to a scene external to a vehicle viewed through a windshield (130) of the vehicle (120); wherein the processing unit (30) is configured to calculate (230) summed pixel values for each of a plurality of areas, wherein the plurality of areas are situated along at least two lines that are angled one to the other; wherein the processing unit (30) is configured to detect (240) windshield blockage on the basis of a plurality of differences between the summed pixel values for at least a subset of the plurality of areas; and wherein, the output unit is configured to output (250) information that at least a part of the windshield (130) has a blockage, <b>characterised in that</b> the processing unit (30) is configured to transform (220) each initial image of the at least one initial image into an integral image and to calculate (230) the summed pixel values in the at least one integral image,<br/>
said plurality of differences being a plurality of differences between the summed pixel values for all the available adjacent pairs of the subset of the plurality of areas.</claim-text><!-- EPO <DP n="16"> --></claim-text></claim>
<claim id="c-en-01-0002" num="0002">
<claim-text>Device according to claim 1, wherein the plurality of areas each contain the same number of pixels.</claim-text></claim>
<claim id="c-en-01-0003" num="0003">
<claim-text>Device according to claim 1, wherein at least one image segment is formed between at least parts of the at least two lines, and wherein for a segment that is bounded on two sides by a part of one line and by a part of a second line, the at least one subset of the plurality of areas comprises the plurality of areas on the part of the first line and on the part of the second line.<!-- EPO <DP n="17"> --></claim-text></claim>
<claim id="c-en-01-0004" num="0004">
<claim-text>Device according to any of claims 1-3, detection of windshield blockage comprises utilisation of a training data set.</claim-text></claim>
<claim id="c-en-01-0005" num="0005">
<claim-text>A system (100) for detecting windshield blockage for a vehicle, comprising:
<claim-text>- at least one camera (110);</claim-text>
<claim-text>- a device (10) for detecting windshield blockage of a vehicle according to any of claims 1-4;
<claim-text>wherein, the at least one camera is configured to be located within a vehicle (120) and the at least one camera is configured to acquire the at least one image relating to a scene external to the vehicle viewed through a windshield (130) of the vehicle; and</claim-text>
<claim-text>wherein, the device (10) is configured to be located within the vehicle.</claim-text></claim-text></claim-text></claim>
<claim id="c-en-01-0006" num="0006">
<claim-text>A method (200) for detecting windshield blockage of a vehicle, comprising:
<claim-text>(a) providing (210) a processing unit (30) with at least one initial image, the at least one initial image relating to a scene external to a vehicle viewed through a windshield of the vehicle;</claim-text>
<claim-text>(b) transforming (220) by the processing unit each initial image of the at least one initial image into an integral image;</claim-text>
<claim-text>(c) calculating (230) by the processing unit summed pixel values for each of a plurality of areas in the at least one integral image, wherein the plurality of areas are situated along at least two lines that are angled one to the other;</claim-text>
<claim-text>(d) detecting (240) by the processing unit windshield blockage on the basis of plurality of differences between the summed pixels values for all the available adjacent pairs of at least a subset of the plurality of areas; and</claim-text>
<claim-text>(e) outputting (250) with an output unit (40) output information that the at least a part of the windshield has a blockage.</claim-text><!-- EPO <DP n="18"> --></claim-text></claim>
<claim id="c-en-01-0007" num="0007">
<claim-text>A computer program element for controlling a device according to any one of claims 1 to 4 and/or a system according to claim 5, which when executed by a processor is configured to carry out the method of claim 6.</claim-text></claim>
<claim id="c-en-01-0008" num="0008">
<claim-text>A computer readable medium having stored the computer program element of claim 7.</claim-text></claim>
</claims>
<claims id="claims02" lang="de"><!-- EPO <DP n="19"> -->
<claim id="c-de-01-0001" num="0001">
<claim-text>Vorrichtung (10) zum Detektieren einer Windschutzscheibenblockade eines Fahrzeugs (120), wobei die Vorrichtung (10) Folgendes umfasst:
<claim-text>- eine Eingabeeinheit (20, 110);</claim-text>
<claim-text>- eine Verarbeitungseinheit (30); und</claim-text>
<claim-text>- eine Ausgabeeinheit (40);
<claim-text>wobei die Eingabeeinheit (20, 110) konfiguriert ist, die Verarbeitungseinheit (30) mit wenigstens einem Startbild zu versorgen (210), wobei sich das wenigstens eine Startbild auf eine Stelle außerhalb eines Fahrzeugs bezieht, die durch eine Windschutzscheibe (130) des Fahrzeugs (120) gesehen wird; wobei</claim-text>
<claim-text>die Verarbeitungseinheit (30) konfiguriert ist, aufsummierte Pixelwerte für jeden von mehreren Bereichen zu berechnen (230), wobei die mehreren Bereiche längs wenigstens zweier Linien angeordnet sind, die in einem Winkel zueinander verlaufen;</claim-text>
<claim-text>wobei die Verarbeitungseinheit (30) konfiguriert ist, eine Windschutzscheibenblockade auf der Basis von mehreren Differenzen zwischen den aufsummierten Pixelwerten für wenigstens eine Teilgruppe der mehreren Bereiche zu detektieren (240); und</claim-text>
<claim-text>wobei die Ausgabeeinheit konfiguriert ist, Informationen auszugeben (250), dass wenigstens ein Teil der Windschutzscheibe (130) eine Blockade hat, <b>dadurch gekennzeichnet, dass</b><!-- EPO <DP n="20"> --></claim-text>
<claim-text>die Verarbeitungseinheit (30) konfiguriert ist, jedes Startbild des wenigstens einen Startbilds zu einem Gesamtbild zu transformieren (220) und die aufsummierten Pixelwerte in dem wenigstens einen Gesamtbild zu berechnen (230),</claim-text>
<claim-text>wobei mehrere Differenzen mehrere Differenzen zwischen den aufsummierten Pixelwerten für alle verfügbaren benachbarten Paare der Teilgruppe der mehreren Bereiche sind.</claim-text></claim-text></claim-text></claim>
<claim id="c-de-01-0002" num="0002">
<claim-text>Vorrichtung nach Anspruch 1, wobei die mehreren Bereiche jeweils die gleiche Anzahl an Pixeln enthalten.</claim-text></claim>
<claim id="c-de-01-0003" num="0003">
<claim-text>Vorrichtung nach Anspruch 1, wobei wenigstens ein Bildsegment wenigstens zwischen Teilen der wenigstens zwei Linien gebildet wird, und wobei für ein Segment, das auf zwei Seiten durch einen Teil einer Linie und durch einen Teil einer zweiten Linie begrenzt ist, die wenigstens eine Teilgruppe der mehreren Bereiche die mehreren Bereiche an dem Teil der ersten Linie und an dem Teil der zweiten Linie umfasst.</claim-text></claim>
<claim id="c-de-01-0004" num="0004">
<claim-text>Vorrichtung nach einem der Ansprüche 1-3, wobei die Detektion einer Windschutzscheibenblockade die Nutzung eines Trainingsdatensatzes umfasst.</claim-text></claim>
<claim id="c-de-01-0005" num="0005">
<claim-text>System (100) zum Detektieren einer Windschutzscheibenblockade für ein Fahrzeug, wobei das System Folgendes umfasst:
<claim-text>- wenigstens eine Kamera (110);</claim-text>
<claim-text>- eine Vorrichtung (10) zum Detektieren einer Windschutzscheibenblockade eines Fahrzeugs nach einem der Ansprüche 1-4;
<claim-text>wobei die wenigstens eine Kamera so konfiguriert ist, dass sie sich in einem Fahrzeug (120) befindet, und wobei die wenigstens eine Kamera konfiguriert ist, das wenigstens eine Bild zu erfassen, das sich auf eine Stelle außerhalb des Fahrzeugs bezieht, die durch eine Windschutzscheibe (130) des Fahrzeugs gesehen wird; und<!-- EPO <DP n="21"> --></claim-text>
<claim-text>wobei die Vorrichtung (10) so konfiguriert ist, dass sie sich im Fahrzeug befindet.</claim-text></claim-text></claim-text></claim>
<claim id="c-de-01-0006" num="0006">
<claim-text>Verfahren (200) zum Detektieren einer Windschutzscheibenblockade eines Fahrzeugs, wobei das Verfahren die folgenden Schritte umfasst:
<claim-text>(a) Versorgen (210) einer Verarbeitungseinheit (30) mit wenigstens einem Startbild, wobei sich das wenigstens eine Startbild auf eine Stelle außerhalb eines Fahrzeugs bezieht, die durch eine Windschutzscheibe des Fahrzeugs gesehen wird;</claim-text>
<claim-text>(b) Transformieren (220) jedes Startbilds des wenigstens einen Startbilds durch die Verarbeitungseinheit zu einem Gesamtbild;</claim-text>
<claim-text>(c) Berechnen (230) von aufsummierten Pixelwerten für jeden der mehreren Bereiche in dem wenigstens einen Gesamtbild durch die Verarbeitungseinheit, wobei die mehreren Bereiche entlang wenigstens zweier Linien angeordnet sind, die in einem Winkel zueinander verlaufen;</claim-text>
<claim-text>(d) Detektieren (240) einer Windschutzscheibenblockade durch die Verarbeitungseinheit auf der Basis von mehreren Differenzen zwischen den aufsummierten Pixelwerten für alle verfügbaren benachbarten Paare von wenigstens einer Teilgruppe der mehreren Bereiche; und</claim-text>
<claim-text>(e) Ausgeben (250) von Ausgabeinformationen mit einer Ausgabeeinheit (40), dass wenigstens ein Teil der Windschutzscheibe eine Blockade hat.</claim-text></claim-text></claim>
<claim id="c-de-01-0007" num="0007">
<claim-text>Computerprogrammelement zum Steuern einer Vorrichtung nach einem der Ansprüche 1 bis 4 und/oder eines Systems nach Anspruch 5, das dann, wenn es durch einen Prozessor ausgeführt wird, konfiguriert ist, das Verfahren nach Anspruch 6 auszuführen.</claim-text></claim>
<claim id="c-de-01-0008" num="0008">
<claim-text>Computerlesbares Medium, auf dem das Computerprogrammelement nach Anspruch 7 gespeichert ist.</claim-text></claim>
</claims>
<claims id="claims03" lang="fr"><!-- EPO <DP n="22"> -->
<claim id="c-fr-01-0001" num="0001">
<claim-text>Dispositif (10) de détection d'une obstruction de pare-brise d'un véhicule (120), le dispositif (10) comprenant :
<claim-text>- une unité d'entrée (20, 110) ;</claim-text>
<claim-text>- une unité de traitement (30) ; et</claim-text>
<claim-text>- une unité de sortie (40) ;
<claim-text>l'unité d'entrée (20, 110) étant configurée pour fournir (210) à l'unité de traitement (30) au moins une image initiale, l'au moins une image initiale étant relative à une scène à l'extérieur d'un véhicule observée à travers un pare-brise (130) du véhicule (120) ;</claim-text>
<claim-text>l'unité de traitement (30) étant configurée pour calculer (230) des valeurs de pixels sommées pour chacune d'une pluralité de zones, la pluralité de zones étant situées le long d'au moins deux lignes formant un angle entre elles ;</claim-text>
<claim-text>l'unité de traitement (30) étant configurée pour détecter (240) une obstruction de pare-brise sur la base d'une pluralité de différences entre les valeurs de pixels sommées pour au moins un sous-ensemble de la pluralité de zones ; et</claim-text>
<claim-text>l'unité de sortie étant configurée pour fournir en sortie (250) des informations indiquant qu'au moins une partie du pare-brise (130) présente une obstruction,</claim-text>
<b>caractérisé en ce que</b> l'unité de traitement (30) est configurée pour transformer (220) chaque image initiale de l'au moins une image initiale en une image intégrale<!-- EPO <DP n="23"> --> et pour calculer (230) les valeurs de pixels sommées dans l'au moins une image intégrale, ladite pluralité de différences étant une pluralité de différences entre les valeurs de pixels sommées pour toutes les paires adjacentes disponibles du sous-ensemble de la pluralité de zones.</claim-text></claim-text></claim>
<claim id="c-fr-01-0002" num="0002">
<claim-text>Dispositif selon la revendication 1, dans lequel la pluralité de zones contiennent chacune le même nombre de pixels.</claim-text></claim>
<claim id="c-fr-01-0003" num="0003">
<claim-text>Dispositif selon la revendication 1, dans lequel au moins un segment d'image est formé entre au moins des parties des au moins deux lignes, et dans lequel, pour un segment qui est borné des deux côtés par une partie d'une ligne et par une partie d'une deuxième ligne, l'au moins un sous-ensemble de la pluralité de zones comprend la pluralité de zones sur la partie de la première ligne et sur la partie de la deuxième ligne.</claim-text></claim>
<claim id="c-fr-01-0004" num="0004">
<claim-text>Dispositif selon l'une quelconque des revendications 1 à 3, dans lequel la détection d'une obstruction de pare-brise comprend l'utilisation d'un ensemble de données d'apprentissage.</claim-text></claim>
<claim id="c-fr-01-0005" num="0005">
<claim-text>Système (100) de détection d'une obstruction de pare-brise pour un véhicule, comprenant :
<claim-text>- au moins une caméra (110) ;</claim-text>
<claim-text>- un dispositif (10) de détection d'une obstruction de pare-brise d'un véhicule selon l'une quelconque des revendications 1 à 4 ;
<claim-text>l'au moins une caméra étant configurée pour être positionnée à l'intérieur d'un véhicule (120) et l'au moins une caméra étant configurée pour acquérir l'au moins une image relative à une scène à l'extérieur du véhicule observée à travers un pare-brise (130) du véhicule ; et</claim-text>
<claim-text>le dispositif (10) étant configuré pour être positionné à l'intérieur du véhicule.</claim-text></claim-text><!-- EPO <DP n="24"> --></claim-text></claim>
<claim id="c-fr-01-0006" num="0006">
<claim-text>Procédé (200) de détection d'une obstruction de pare-brise d'un véhicule, comprenant :
<claim-text>(a) la fourniture (210) à une unité de traitement (30) d'au moins une image initiale, l'au moins une image initiale étant relative à une scène à l'extérieur d'un véhicule observée à travers un pare-brise du véhicule ;</claim-text>
<claim-text>(b) la transformation (220), par l'unité de traitement, de chaque image initiale de l'au moins une image initiale en une image intégrale ;</claim-text>
<claim-text>(c) le calcul (230), par l'unité de traitement, de valeurs de pixels sommées pour chacune d'une pluralité de zones dans l'au moins une image intégrale, la pluralité de zones étant situées le long d'au moins deux lignes formant un angle entre elles ;</claim-text>
<claim-text>(d) la détection (240), par l'unité de traitement, d'une obstruction de pare-brise sur la base d'une pluralité de différences entre les valeurs de pixels sommées pour toutes les paires adjacentes disponibles d'au moins un sous-ensemble de la pluralité de zones ; et</claim-text>
<claim-text>(e) la fourniture en sortie (250), au moyen d'une unité de sortie (40), d'informations de sortie indiquant que l'au moins une partie du pare-brise présente une obstruction.</claim-text></claim-text></claim>
<claim id="c-fr-01-0007" num="0007">
<claim-text>Élément de programme d'ordinateur pour commander un dispositif selon l'une quelconque des revendications 1 à 4 et/ou un système selon la revendication 5, qui, lorsqu'il est exécuté par un processeur, est configuré pour réaliser le procédé selon la revendication 6.</claim-text></claim>
<claim id="c-fr-01-0008" num="0008">
<claim-text>Support lisible par ordinateur sur lequel est enregistré l'élément de programme d'ordinateur selon la revendication 7.</claim-text></claim>
</claims>
<drawings id="draw" lang="en"><!-- EPO <DP n="25"> -->
<figure id="f0001" num="1,2"><img id="if0001" file="imgf0001.tif" wi="134" he="220" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="26"> -->
<figure id="f0002" num="3a,3b,3c,3d,3e,4"><img id="if0002" file="imgf0002.tif" wi="155" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="27"> -->
<figure id="f0003" num="5,6"><img id="if0003" file="imgf0003.tif" wi="151" he="233" img-content="drawing" img-format="tif"/></figure>
</drawings>
<ep-reference-list id="ref-list">
<heading id="ref-h0001"><b>REFERENCES CITED IN THE DESCRIPTION</b></heading>
<p id="ref-p0001" num=""><i>This list of references cited by the applicant is for the reader's convenience only. It does not form part of the European patent document. Even though great care has been taken in compiling the references, errors or omissions cannot be excluded and the EPO disclaims all liability in this regard.</i></p>
<heading id="ref-h0002"><b>Patent documents cited in the description</b></heading>
<p id="ref-p0002" num="">
<ul id="ref-ul0001" list-style="bullet">
<li><patcit id="ref-pcit0001" dnum="US9319637A1"><document-id><country>US</country><doc-number>9319637</doc-number><kind>A1</kind></document-id></patcit><crossref idref="pcit0001">[0003]</crossref><crossref idref="pcit0002">[0003]</crossref></li>
</ul></p>
</ep-reference-list>
</ep-patent-document>
