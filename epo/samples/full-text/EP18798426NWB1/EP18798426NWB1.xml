<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE ep-patent-document PUBLIC "-//EPO//EP PATENT DOCUMENT 1.5.1//EN" "ep-patent-document-v1-5-1.dtd">
<!-- This XML data has been generated under the supervision of the European Patent Office -->
<ep-patent-document id="EP18798426B1" file="EP18798426NWB1.xml" lang="en" country="EP" doc-number="3545389" kind="B1" date-publ="20211006" status="n" dtd-version="ep-patent-document-v1-5-1">
<SDOBI lang="en"><B000><eptags><B001EP>ATBECHDEDKESFRGBGRITLILUNLSEMCPTIESILTLVFIROMKCYALTRBGCZEEHUPLSK..HRIS..MTNORS..SM..................</B001EP><B003EP>*</B003EP><B005EP>J</B005EP><B007EP>BDM Ver 2.0.12 (4th of August) -  2100000/0</B007EP></eptags></B000><B100><B110>3545389</B110><B120><B121>EUROPEAN PATENT SPECIFICATION</B121></B120><B130>B1</B130><B140><date>20211006</date></B140><B190>EP</B190></B100><B200><B210>18798426.5</B210><B220><date>20180502</date></B220><B240><B241><date>20190627</date></B241></B240><B250>en</B250><B251EP>en</B251EP><B260>en</B260></B200><B300><B310>201741016333</B310><B320><date>20170509</date></B320><B330><ctry>IN</ctry></B330></B300><B400><B405><date>20211006</date><bnum>202140</bnum></B405><B430><date>20191002</date><bnum>201940</bnum></B430><B450><date>20211006</date><bnum>202140</bnum></B450><B452EP><date>20210415</date></B452EP></B400><B500><B510EP><classification-ipcr sequence="1"><text>G06F   3/01        20060101AFI20210222BHEP        </text></classification-ipcr><classification-ipcr sequence="2"><text>H04W   4/02        20180101ALI20210222BHEP        </text></classification-ipcr><classification-ipcr sequence="3"><text>H04M   1/72412     20210101ALI20210222BHEP        </text></classification-ipcr><classification-ipcr sequence="4"><text>H04M   1/72454     20210101ALI20210222BHEP        </text></classification-ipcr></B510EP><B520EP><classifications-cpc><classification-cpc sequence="1"><text>H04M   1/72454     20210101 LI20210101RHEP        </text></classification-cpc><classification-cpc sequence="2"><text>H04M2250/12        20130101 LA20181220BHEP        </text></classification-cpc><classification-cpc sequence="3"><text>G06F   3/017       20130101 LI20191024BHEP        </text></classification-cpc><classification-cpc sequence="4"><text>G06F   3/014       20130101 LI20191024BHEP        </text></classification-cpc><classification-cpc sequence="5"><text>H04W   4/023       20130101 FI20181115BHEP        </text></classification-cpc><classification-cpc sequence="6"><text>H04M   1/72412     20210101 LI20210101RHEP        </text></classification-cpc></classifications-cpc></B520EP><B540><B541>de</B541><B542>VERFAHREN UND VORRICHTUNG ZUR DURCHFÜHRUNG VON MINDESTENS EINER OPERATION AUF BASIS VON EINRICHTUNGSKONTEXT</B542><B541>en</B541><B542>METHOD AND APPARATUS FOR PERFORMING AT LEAST ONE OPERATION BASED ON DEVICES CONTEXT</B542><B541>fr</B541><B542>PROCÉDÉ ET APPAREIL DE RÉALISATION D'AU MOINS UNE OPÉRATION D'APRÈS UN CONTEXTE DE DISPOSITIFS</B542></B540><B560><B561><text>EP-A1- 3 010 212</text></B561><B561><text>WO-A1-2016/077035</text></B561><B561><text>US-A1- 2015 022 438</text></B561><B561><text>US-A1- 2016 098 091</text></B561><B561><text>US-A1- 2016 198 322</text></B561><B561><text>US-A1- 2016 262 116</text></B561><B561><text>US-A1- 2016 277 891</text></B561><B561><text>US-A1- 2017 010 674</text></B561><B565EP><date>20191113</date></B565EP></B560></B500><B700><B720><B721><snm>AVASTHI, Prakhar</snm><adr><str>Plot No. C 28-29
Tower D
Logix Cyber Park
Overseas Lane
C Block, Sector 62</str><city>Noida
Uttar Pradesh 201301</city><ctry>IN</ctry></adr></B721><B721><snm>VERMA, Ranjesh</snm><adr><str>Plot No. C 28-29
Tower D
Logix Cyber Park
Overseas Lane
C Block, Sector 62</str><city>Noida
Uttar Pradesh 201301</city><ctry>IN</ctry></adr></B721><B721><snm>TIWARY, Sumit Kumar</snm><adr><str>Plot No. C 28-29
Tower D
Logix Cyber Park
Overseas Lane
C Block, Sector 62</str><city>Noida
Uttar Pradesh 201301</city><ctry>IN</ctry></adr></B721></B720><B730><B731><snm>Samsung Electronics Co., Ltd.</snm><iid>101604699</iid><irf>SET/92200EP1</irf><adr><str>129, Samsung-ro 
Yeongtong-gu</str><city>Suwon-si, Gyeonggi-do 16677</city><ctry>KR</ctry></adr></B731></B730><B740><B741><snm>Taor, Simon Edward William</snm><sfx>et al</sfx><iid>101319945</iid><adr><str>Venner Shipley LLP 
200 Aldersgate</str><city>London EC1A 4HD</city><ctry>GB</ctry></adr></B741></B740></B700><B800><B840><ctry>AL</ctry><ctry>AT</ctry><ctry>BE</ctry><ctry>BG</ctry><ctry>CH</ctry><ctry>CY</ctry><ctry>CZ</ctry><ctry>DE</ctry><ctry>DK</ctry><ctry>EE</ctry><ctry>ES</ctry><ctry>FI</ctry><ctry>FR</ctry><ctry>GB</ctry><ctry>GR</ctry><ctry>HR</ctry><ctry>HU</ctry><ctry>IE</ctry><ctry>IS</ctry><ctry>IT</ctry><ctry>LI</ctry><ctry>LT</ctry><ctry>LU</ctry><ctry>LV</ctry><ctry>MC</ctry><ctry>MK</ctry><ctry>MT</ctry><ctry>NL</ctry><ctry>NO</ctry><ctry>PL</ctry><ctry>PT</ctry><ctry>RO</ctry><ctry>RS</ctry><ctry>SE</ctry><ctry>SI</ctry><ctry>SK</ctry><ctry>SM</ctry><ctry>TR</ctry></B840><B860><B861><dnum><anum>KR2018005091</anum></dnum><date>20180502</date></B861><B862>en</B862></B860><B870><B871><dnum><pnum>WO2018208041</pnum></dnum><date>20181115</date><bnum>201846</bnum></B871></B870></B800></SDOBI>
<description id="desc" lang="en"><!-- EPO <DP n="1"> -->
<heading id="h0001"><b>Technical Field</b></heading>
<p id="p0001" num="0001">The disclosure relates to an electronic device. More particularly, the disclosure relates to a method and an apparatus for performing at least one operation based on a devices context.</p>
<heading id="h0002"><b>Background Art</b></heading>
<p id="p0002" num="0002">A wearable device using a wireless technology is configured to maintain a wireless communication connection with an electronic device (e.g., a smart phone, or the like) either through establishing the connection on-demand or establishing an always-on connection. <patcit id="pcit0001" dnum="US2016098091A1"><text>US 2016/098091 A1</text></patcit> describes providing a user with a user interface using a relative relationship between postures or motions of two or more devices, by acquiring information on postures or motions of a first device and a second device, sensing an input event specified on the basis of a relative relationship between the posture or motion of the first device and that of the second device, and in response to the occurrence of the input event, causing at least some of contents and functions provided on the first device to be provided on the second device, or causing at least some of contents and functions provided on the second device to be provided on the first device.</p>
<p id="p0003" num="0003"><patcit id="pcit0002" dnum="US20150022438A1"><text>US 2015/0022438 A1</text></patcit> discloses a watch type mobile terminal. In embodiments, the watch type mobile terminal is synchronized with an external terminal. In an embodiment, a user's arm having the watch type mobile terminal is opposite to a hand holding the external terminal and a screen displayed on a display of the watch type mobile terminal is a screen in a right hand mode and a screen displayed on a display of the external terminal is in a left hand mode. In another embodiment, the same screen is displayed on the watch type mobile terminal and the external terminal when an arm having the watch type mobile terminal and a hand holding the external terminal are positioned in the same direction.</p>
<heading id="h0003"><b>Disclosure of Invention</b></heading>
<heading id="h0004"><b>Technical Problem</b></heading>
<p id="p0004" num="0004">The simultaneous operation between the wearable device and the electronic device may not be possible in certain scenarios like below.</p>
<p id="p0005" num="0005">In an example, assume that the user holds and operates the smart watch and smart phone in same hand. If the user receives an incoming call then the incoming call restricts the use of smart watch. In another example, assume that the user holds and operates the smart watch and smart phone in same hand. If the smart watch receives a notification message, then the notification event may cause the user to switch the smart phone from one hand to another hand unnecessarily for a short duration.</p>
<p id="p0006" num="0006">Thus, it is desired to address the above-mentioned disadvantages or other shortcomings or at least provide a useful alternative.<!-- EPO <DP n="2"> --></p>
<heading id="h0005"><b>Solution to Problem</b></heading>
<p id="p0007" num="0007">Aspects of the disclosure are to address at least the above-mentioned problems and/or disadvantages and to provide at least the advantages described below. Specifically, the present invention relates to a method and an apparatus for performing at least one operation based on a devices context according to the independent claims. The dependent claims define further embodiments of the invention.<!-- EPO <DP n="3"> --></p>
<heading id="h0006"><b>Brief Description of Drawings</b></heading>
<p id="p0008" num="0008">The above and other aspects, features, and advantages of certain embodiments of the disclosure will be apparent from the following description taken in conjunction with accompanying drawings, in which:
<ul id="ul0001" list-style="none" compact="compact">
<li><figref idref="f0001">FIGS. 1A and 1B</figref> illustrate an overview of a system for managing an operation based on a devices context according to various embodiments of the disclosure;</li>
<li><figref idref="f0002">FIG. 2</figref> is a block diagram of various hardware elements of a system for managing an operation based on devices context according to an embodiment of the disclosure;</li>
<li><figref idref="f0003">FIG. 3A</figref> is a flow diagram illustrating a method for managing an operation based on devices context according to an embodiment of the disclosure;</li>
<li><figref idref="f0004">FIG. 3B</figref> is a flow diagram illustrating a method for determining devices context based on an input data of a first electronic device and an input data of a second electronic device according to an embodiment of the disclosure;</li>
<li><figref idref="f0005">FIG. 3C</figref> is a flow diagram illustrating a method for determining devices context based on proximity and motion comparison according to an embodiment of the disclosure;</li>
<li><figref idref="f0006">FIG. 4</figref> illustrates an operation being performed based on devices context according to an embodiment of the disclosure;</li>
<li><figref idref="f0007">FIG. 5</figref> illustrates a first electronic device sending a request to regulate a playback rate of a media file played on a second electronic device, when a first electronic device receives an incoming call, and a first electronic device and the second electronic device being used by a same hand of a user, according to an embodiment of the disclosure;</li>
<li><figref idref="f0008">FIG. 6</figref> illustrates a first electronic device sending a request to regulate a playback rate of a media file played on a second electronic device, when the first electronic device receives an incoming call and the first electronic device and the second electronic device being used by different hands of a user, according to an embodiment of the disclosure;<!-- EPO <DP n="4"> --></li>
<li><figref idref="f0009">FIG. 7</figref> illustrates a mobile phone sending a request to a second electronic device to enable an input over a screen off, when a first electronic device receiving an incoming call and the first electronic device and the second electronic device being used by different hands of a user, according to an embodiment of the disclosure;</li>
<li><figref idref="f0010">FIG. 8</figref> illustrates a first electronic sending a notification to a second electronic device, when the first electronic device is an ongoing call, and the first electronic device and the second electronic device being used by a same hand of a user, according to an embodiment of the disclosure;</li>
<li><figref idref="f0011">FIG. 9</figref> illustrates a first electronic device sending a request to a second electronic device to switch a navigation from an audio mode to a haptic feedback mode, when the first electronic device receives an incoming call and the first electronic device and the second electronic device being used by different hands of a user, according to an embodiment of the disclosure;</li>
<li><figref idref="f0012">FIG. 10</figref> illustrates a first electronic device receiving a notification from a second electronic device, when a display screen of the first electronic device is in an active mode, a display screen of the second electronic device is in an inactive mode, and the first electronic device and the second electronic device are used by a same hand of a user, according to an embodiment of the disclosure;</li>
<li><figref idref="f0012">FIG. 11</figref> illustrates a first electronic device sending a request to a second electronic device to switch a navigation from an audio mode to a haptic feedback mode, when the first electronic device receives an incoming call, and the first electronic device and the second electronic device are used by a same hand of a user, according to an embodiment of the disclosure;</li>
<li><figref idref="f0012">FIG. 12</figref> illustrates a second electronic device displaying a notification after a hand switch event according to an embodiment of the disclosure;</li>
<li><figref idref="f0013">FIG. 13</figref> illustrates a first electronic device sending a request to a second electronic device to enable an input over screen off, when the first electronic device receives an incoming call, and the first electronic device and the second electronic device are used by different hands of the user, according to an embodiment of the disclosure;</li>
<li><figref idref="f0014">FIG. 14</figref> illustrates a first electronic device sending a request to provide access to a private memory at a second electronic device, when the first electronic device and the second electronic device are used by different hands of the user, according to an embodiment of the disclosure; and</li>
<li><figref idref="f0014">FIG. 15</figref> illustrates a computing environment implementing a method for managing an operation based on devices context according to an embodiment of the disclosure.</li>
</ul></p>
<p id="p0009" num="0009">Throughout the drawings, like reference numerals will be understood to refer to like parts, components, and structures.<!-- EPO <DP n="5"> --></p>
<heading id="h0007"><b>Mode for the Invention</b></heading>
<p id="p0010" num="0010">The following description with reference to the accompanying drawings is provided to assist in a comprehensive understanding of various embodiments of the disclosure. It includes various specific details to assist in that understanding but these are to be regarded as merely exemplary. Accordingly, those of ordinary skill in the art will recognize that various changes and modifications of the various embodiments described herein can be made without departing from the scope of the disclosure. In addition, descriptions of well-known functions and constructions may be omitted for clarity and conciseness.</p>
<p id="p0011" num="0011">It should be apparent to those skilled in the art that the following description of various embodiments of the disclosure is provided for illustration purpose only and not for the purpose of limiting the invention as defined by the appended claims.</p>
<p id="p0012" num="0012">It is to be understood that the singular forms "a," "an," and "the" include plural referents unless the context clearly dictates otherwise. Thus, for example, reference to "a component surface" includes reference to one or more of such surfaces.</p>
<p id="p0013" num="0013">By the term "substantially" it is meant that the recited characteristic, parameter, or value need not be achieved exactly, but that deviations or variations, including for example, tolerances, measurement error, measurement accuracy limitations and other factors known to those of skill in the art, may occur in amounts that do not preclude the effect the characteristic was intended to provide.</p>
<p id="p0014" num="0014">In addition, the various embodiments described herein are not necessarily mutually exclusive, as some embodiments can be combined with one or more other embodiments to form new embodiments. The term "or" as used herein, refers to a non-exclusive or, unless otherwise indicated. The examples used herein are intended merely to facilitate an understanding of ways in which the embodiments herein can be practiced and to further enable those skilled in the art to practice the embodiments herein. Accordingly, the examples should not be construed as limiting the scope of the embodiments herein.</p>
<p id="p0015" num="0015">As is traditional in the field, embodiments may be described and illustrated in terms of blocks which carry out a described function or functions. These blocks, which may be referred to herein as units or modules, or the like, are physically implemented by analog or digital circuits, such as logic gates, integrated circuits, microprocessors, microcontrollers, memory circuits, passive electronic components, active electronic components, optical components, hardwired circuits, and the like, and may optionally<br/>
<!-- EPO <DP n="6"> -->be driven by firmware and software. The circuits may, for example, be embodied in one or more semiconductor chips, or on substrate supports, such as printed circuit boards, and the like. The circuits constituting a block may be implemented by dedicated hardware, or by a processor (e.g., one or more programmed microprocessors and associated circuitry), or by a combination of dedicated hardware to perform some functions of the block and a processor to perform other functions of the block. Each block of the embodiments may be physically separated into two or more interacting and discrete blocks without departing from the scope of the disclosure. Likewise, the blocks of the embodiments may be physically combined into more complex blocks without departing from the scope of the disclosure.</p>
<p id="p0016" num="0016">The accompanying drawings are used to help easily understand various technical features and it should be understood that the embodiments presented herein are not limited by the accompanying drawings. As such, the disclosure should be construed to extend to any alterations, equivalents and substitutes in addition to those which are particularly set out in the accompanying drawings. Although the terms first, second, and the like, may be used herein to describe various elements, these elements should not be limited by these terms. These terms are generally only used to distinguish one element from another.</p>
<p id="p0017" num="0017">The embodiments herein disclose a method for managing operations based on devices context. The method includes detecting, by a first electronic device, a first input data. Further, the method includes receiving, by the first electronic device, a second input data from a second electronic device. Further, the method includes determining, by the first electronic device, the devices context based on the first input data and the second input data. In an embodiment of the disclosure, the devices context is a same hand context. In an embodiment of the disclosure, the devices context is a different hand context. Furthermore, the method includes causing, by the first electronic device, to perform an operation based on the determined devices context.</p>
<p id="p0018" num="0018">Unlike the systems and methods of the related art, the proposed method can be used to set up the context based on that the first electronic device (e.g., a smart phone) and the second electronic device (e.g., a smart watch) are in same hand or different hands based on a motion comparison and a bluetooth proximity comparison. Based on the motion comparison and the Bluetooth proximity comparison, the proposed method can be used to define interactions between the first and second electronic devices.</p>
<p id="p0019" num="0019">The proposed method can be used to determine relative states of the first electronic device (i.e., a smart phone) with the second electronic device (e.g., a wearable device) to determine priority of the first and second devices for an event (e.g., an incoming call, a notification event, a message service, or the like). The proposed method can be used to automatically provide an input over the first and second electronic devices<!-- EPO <DP n="7"> --> along with motion of the first and second electronic devices for decision making.</p>
<p id="p0020" num="0020">The proposed method can be used to provide the devices contextual based operation based on the user holding the first electronic device and the second electronic device on same hand or different hands. This resulting in providing a seamless experience of using both first electronic device and second electronic device together.</p>
<p id="p0021" num="0021">The proposed method can be used to allow the user to define priority of the first electronic device and the second electronic device based on the first and second electronic device's display currently relevant to the user.</p>
<p id="p0022" num="0022">The proposed method can intuitively change the behavior of the first electronic device and the second electronic device based on the first and second electronic device's display which is relevant for the user at a particular instance of time. In an example, the user is attending call over a smart phone while wearing the smart watch in other hand and at the same time, the user wants to provide an input to the smart watch for performing some operation. The proposed method allows the user to perform the operation based on the first and second electronic device's display which is relevant for the user at the particular instance of time.</p>
<p id="p0023" num="0023">Further, the proposed method allows the user to define priorities of various events based on the current context of the first electronic device and the second electronic device by determining the display unit associated with one of the first electronic device and the second electronic device best suitable for the user. This way user can be able to perform operations on multiple devices with the least amount of effort.</p>
<p id="p0024" num="0024">Further, the proposed method can be used to define the context when the first electronic device and the second electronic device are used on the same hand or the first electronic device and the second electronic device are used on different hands. The context can be associated using comparison of motion of the first electronic device and the second electronic device and corresponding detection of switching of hand operation.</p>
<p id="p0025" num="0025">The proposed method doesn't need any user initiated special gesture to determine control function. Further, the proposed method can be used to automatically determine whether the first electronic device and the second electronic device are in same arm or the different arms based on proximity detection using a wireless media like a bluetooth low energy (BLE) whisper mode or a motion comparison function. The proposed method intuitively determines priority of the first electronic device and the second electronic device based on relative positioning and then apply control function based on running applications on either first electronic device or the second electronic device.</p>
<p id="p0026" num="0026">Referring now to the drawings and more particularly to <figref idref="f0001 f0002 f0003 f0004 f0005 f0006 f0007 f0008 f0009 f0010 f0011 f0012 f0013 f0014">FIGS. 1A through 15</figref>, where similar reference characters denote corresponding features consistently throughout the<!-- EPO <DP n="8"> --> figure, these are shown preferred embodiments.</p>
<p id="p0027" num="0027"><figref idref="f0001">FIGS. 1A and 1B</figref> illustrate an overview of a system for managing an operation based on devices context, according to an embodiment of the disclosure.</p>
<p id="p0028" num="0028">Referring to <figref idref="f0001">FIGS. 1A and 1B</figref>, in an embodiment of the disclosure, a system 1000 includes a first electronic device 100 and a second electronic device 200. The first electronic device 100 can be, for example but not limited to, a mobile phone, a smart phone, a laptop computer, an electronic book terminal, a personal digital assistant, a portable multimedia player (PMP), or the like. The second electronic device 200 can be, for example but not limited to, a wearable device (e.g., a smart watch, a smart band, a smart ring, or the like). In an embodiment of the disclosure, the devices context is a same hand context. In an embodiment of the disclosure, the devices context is a different hand context.</p>
<p id="p0029" num="0029">The first electronic device 100 is configured to detect a first input data and receive a second input data from the second electronic device 200. In an embodiment of the disclosure, the first input data is detected based on user gesture (e.g., a swipe gesture, a hand motion gesture, a tap event, a double tap event, a long press event, or the like). Further, the first electronic device 100 is configured to compare the first input data with the second input data. Based on the comparison of the first input data and the second input data, the first electronic device 100 is configured to detect whether motion data of the first electronic device 100 and the second electronic device 200 is one of same hand and different hands.</p>
<p id="p0030" num="0030">In an embodiment of the disclosure, the first electronic device 100 is configured to determine one of the devices context as the same hand context based on detecting that the motion data of the first electronic device 100 and the second electronic device 200 is substantially same or similar.</p>
<p id="p0031" num="0031">In an embodiment of the disclosure, the first electronic device 100 is configured to determine one of the devices context as the same hand context based on detecting that the motion data of the first electronic device 100 and the second electronic device 200 is same.</p>
<p id="p0032" num="0032">In an embodiment of the disclosure, the first electronic device 100 is configured to determine one of the devices context as the different hand context based on detecting that the motion data of the first electronic device 100 and the second electronic device 200 is different.</p>
<p id="p0033" num="0033">In an embodiment of the disclosure, the same hand context indicates that the first electronic device 100 and the second electronic device 200 are used by a same hand of a user.</p>
<p id="p0034" num="0034">In an embodiment of the disclosure, the different hand context indicates that the first electronic device 100 and the second electronic device 200 are not used by a same<!-- EPO <DP n="9"> --> hand of a user.</p>
<p id="p0035" num="0035">In an embodiment of the disclosure, the devices context is determined by comparing the first input data with the second input data, detecting whether motion data of the first electronic device 100 and the second electronic device 200 is one of similar and different based on a result of the comparison, and determining one of the devices context as the same hand context in response to detecting that the motion data of the first electronic device 100 and the second electronic device 200 is similar, and the devices context as the different hand context in response to detecting that the motion data of the first electronic device 100 and the second electronic device 200 is different.</p>
<p id="p0036" num="0036">In an embodiment of the disclosure, similarity between the motion data of the first electronic device 100 and the second electronic device 200 is determined based on motion threshold criteria.</p>
<p id="p0037" num="0037">In an embodiment of the disclosure, the motion threshold criteria includes a range having an upper limit and lower limit dynamically determined based on one of the motion data of the first electronic device 100 and the motion data of the second electronic device 200.</p>
<p id="p0038" num="0038">In an embodiment of the disclosure, the devices context is determined by comparing the first input data with the second input data, detecting whether a proximity between the first electronic device 100 and the second electronic device 200 is within a proximity threshold criteria based on the comparison, detecting whether motion data of the first electronic device 100 and the second electronic device 200 is one of similar and different based on the comparison in response to determining that the proximity between the first electronic device 100 and the second electronic device 200 is within the threshold criteria, and determining one of the devices context as the same hand context in response to detecting that the motion data of the first electronic device 100 and the second electronic device 200 is similar, and the devices context as the different hand context in response to detecting that the motion data of the first electronic device 100 and the second electronic device 200 is different.</p>
<p id="p0039" num="0039">In an embodiment of the disclosure, the proximity threshold criteria includes a range includes an upper limit and lower limit dynamically determined based on one of the input data of the first electronic device 100 and the input data of the second electronic device 200.</p>
<p id="p0040" num="0040">In an example, assume that initially the user wears the smart watch on the left hand and the smart phone on the right hand. Further, the user switches the smart phone to the left hand where the user wears the smart watch. After switching the smart phone to the left hand, the smart phone and the smart watch have similar motion as shown in the <figref idref="f0001">FIG. 1A</figref>.</p>
<p id="p0041" num="0041">In an example, assume that initially the user wears the smart watch and holds the<!-- EPO <DP n="10"> --> smart phone on the same hand (i.e., a left hand). Further, the user switches the smart phone to the right hand and the user wears the smart watch on the left hand. After switching the smart phone to the right hand, the smart phone and the smart watch have different motion as shown in the <figref idref="f0001">FIG. 1B</figref>.</p>
<p id="p0042" num="0042">In an embodiment of the disclosure, the first input data includes motion information of the first electronic device 100. In an embodiment of the disclosure, the first input data includes proximity information of the second electronic device 200. In an embodiment of the disclosure, the first input data includes combination of motion information of the first electronic device 100 and proximity information of the second electronic device 200.</p>
<p id="p0043" num="0043">In an embodiment of the disclosure, the second input data includes motion information of the second electronic device 200. In an embodiment of the disclosure, the second input data includes proximity information of the first electronic device 100. In an embodiment of the disclosure, the second input data includes combination of motion information of the second electronic device 200 and proximity information of the first electronic device 100.</p>
<p id="p0044" num="0044">In an embodiment of the disclosure, the motion information of the first electronic device 100 and the motion information of the second electronic device 200 are measured at a same time period.</p>
<p id="p0045" num="0045">Further, the first electronic device 100 is configured to perform an operation based on the determined devices context. In an embodiment of the disclosure, the operation corresponds to sending a request to regulate a playback rate of a media file on the second electronic device 200. In an embodiment of the disclosure, the operation corresponds to regulating a playback rate of a media file of the first electronic device 100.</p>
<p id="p0046" num="0046">In an embodiment of the disclosure, the operation corresponds to send the request to the second electronic device 200 to enable an input over a screen off. In an embodiment of the disclosure, the operation corresponds to enable an input dispatcher over a screen off.</p>
<p id="p0047" num="0047">In an embodiment of the disclosure, the operation corresponds to receive, an input at the first electronic device 100 and map the received input to the second electronic device 200.</p>
<p id="p0048" num="0048">In an embodiment of the disclosure, the operation corresponds to send a notification received at the first electronic device 100 to the second electronic device 200.</p>
<p id="p0049" num="0049">In an embodiment of the disclosure, the operation corresponds to send, by the first electronic device 100, a request to the second electronic device 200 to switch a navigation from an audio mode to a haptic feedback mode.</p>
<p id="p0050" num="0050">In an embodiment of the disclosure, the operation corresponds to switch, by the first electronic device 100, a navigation from the audio mode to the haptic feedback mode.<!-- EPO <DP n="11"> --></p>
<p id="p0051" num="0051">In an embodiment of the disclosure, the operation corresponds to send, by the first electronic device 100, a request to provide access to a private memory at the second electronic device 200.</p>
<p id="p0052" num="0052">In an embodiment of the disclosure, the operation corresponds to provide, by the first electronic device 100, an access to a private memory.</p>
<p id="p0053" num="0053">In an embodiment of the disclosure, the first electronic device 100 is configured to detect a hand switch event. Further, the first electronic device 100 is configured to update the determined devices context based on the hand switch event. This results in increasing the usability of the first electronic device 100 by removing the previous devices context. In an embodiment of the disclosure, the motion data of the first electronic device 100 and the second electronic device 200 is substantially same determined based on threshold criteria.</p>
<p id="p0054" num="0054">In an embodiment of the disclosure, the first electronic device 100 and the second electronic device 200 can communicate with each other. For example, the first electronic device 100 may transmit or receive data to/from the second electronic device 200 via a short-range communication. The short-range communication may be performed in wireless fidelity (Wi-Fi), near field communication (NFC), bluetooth, an infrared ray method, and ZigBee, but is not limited thereto.</p>
<p id="p0055" num="0055">In an example, assume that the smart phone and the smart watch are used by the same hand. Therefore, the smart phone in motion detects a movement similar to the smart watch.</p>
<p id="p0056" num="0056">In an embodiment of the disclosure, if the smart phone and the smart watch are used by the same hand, then the movements of the smart phone and the smart watch is similar.</p>
<p id="p0057" num="0057">In an embodiment of the disclosure, if the smart phone and the smart watch are used by the same hand, the movement of the smart phone is coherent with the movement of the smart watch.</p>
<p id="p0058" num="0058">The motion data include the acceleration toward a particular direction which represents the motion of the smart phone or the smart watch.</p>
<p id="p0059" num="0059">In an embodiment of the disclosure, the first electronic device 100 compares the first input data and the second input data by calculating a difference between the first motion data and the second motion data.</p>
<p id="p0060" num="0060">In an embodiment of the disclosure, the motion coherence between the first electronic device 100 and the second electronic device 200 may be determined by comparing the first motion data and the second motion data. If the difference between the first motion data and the second motion data is within a predetermined threshold, the motion of the first electronic device 100 and the motion the second electronic device 200 is determined to be coherent. In an embodiment of the disclosure, the predetermined<!-- EPO <DP n="12"> --> threshold may refer to an acceptable tolerance for the difference between the first motion data and the second motion data.</p>
<p id="p0061" num="0061">Further, the assignment of the devices context for same or different hand of the operation can be initiated based on comparison of the motion as well as input to any device under following circumstances:</p>
<p id="p0062" num="0062">Events based, such as accepting a call, swipe gestures, input to the first and second electronic devices, and</p>
<p id="p0063" num="0063">Switching of the first electronic device or the second electronic device from one hand to another hand.</p>
<p id="p0064" num="0064"><u>Event-based Context</u>: In the event-based context, during the occurrence of events, such as tap event over an application icon, the context is tried to setup as detailed in the table below. If the tap event occurs from the hand having the second electronic device 200, this sets up a context which can be used present a different behavior and different user experience. The device would evaluate parameters based on pressure on second electronic device 200/event on the second electronic device 200, time of the tap event on the application icon and use this information to setup the context.
<tables id="tabl0001" num="0001">
<table frame="all">
<title>[Table 1]</title>
<tgroup cols="4">
<colspec colnum="1" colname="col1" colwidth="35mm"/>
<colspec colnum="2" colname="col2" colwidth="67mm"/>
<colspec colnum="3" colname="col3" colwidth="43mm"/>
<colspec colnum="4" colname="col4" colwidth="22mm"/>
<thead>
<row>
<entry valign="top">Event over the first electronic device 100</entry>
<entry valign="top">Comparison of events in the first electronic device 100 and second electronic device 200</entry>
<entry valign="top">Deduction</entry>
<entry valign="top">Context</entry></row></thead>
<tbody>
<row>
<entry>Tap over application icon</entry>
<entry>Tap detected in the second electronic device 200 but motion different from the first electronic device 100</entry>
<entry>Input from the second electronic device 100 in different hand</entry>
<entry>Different hand</entry></row>
<row>
<entry>Receive call</entry>
<entry>Similar motion</entry>
<entry>Same hand</entry>
<entry>Same hand</entry></row>
<row>
<entry>Receive call</entry>
<entry>Different motion</entry>
<entry>Different hand</entry>
<entry>Different hand</entry></row></tbody></tgroup>
</table>
</tables></p>
<p id="p0065" num="0065"><u>Switching of device from one hand to another:</u> Based on the comparison of relative motion of the first electronic device 100 and second electronic device 200, the devices context can be determined whether the first electronic device 100 or the second electronic device 200 is being switched between the hands. Whenever there is motion of both first electronic device 100 and second electronic device 200 relative to another, the user allows the first electronic device 100 and the second electronic device 200 to<!-- EPO <DP n="13"> --> associate context of same or different hands as shown in the below Table 2:
<tables id="tabl0002" num="0002">
<table frame="all">
<title>[Table 2]</title>
<tgroup cols="3">
<colspec colnum="1" colname="col1" colwidth="64mm"/>
<colspec colnum="2" colname="col2" colwidth="71mm"/>
<colspec colnum="3" colname="col3" colwidth="32mm"/>
<thead>
<row>
<entry valign="top">Relative motion of the second electronic device 200 with respect to the first electronic device 100 initially</entry>
<entry valign="top">Relative motion of the second electronic device 200 with respect to first electronic device 100 when direction of motion changes</entry>
<entry valign="top">Switching context</entry></row></thead>
<tbody>
<row>
<entry>Different motions</entry>
<entry>Similar motions</entry>
<entry>Switching to Same Hand</entry></row>
<row>
<entry>Similar motions</entry>
<entry>Different motions</entry>
<entry>Switching to Different Hand</entry></row></tbody></tgroup>
</table>
</tables></p>
<p id="p0066" num="0066">If the user moves both the first electronic device 100 and the second electronic device 200 in different directions initially and then the motion for the first electronic device 100 and the second electronic device 200 is same for a period of time and the motion will associate that the first electronic device 100 and the second electronic device 200 are being switched to the same hand.</p>
<p id="p0067" num="0067">In an example, the user may be notified of an incoming text message via a display screen of the wearable device. The incoming text message may be viewed by simply picking up the mobile phone with the hand corresponding to the arm wearing the wearable device, then the display screen of the mobile device automatically displays the incoming message when the difference between the first motion data of the wearable device and the second motion data of the mobile device is within the predetermined threshold.</p>
<p id="p0068" num="0068"><figref idref="f0001">FIGS. 1A and 1B</figref> illustrate the limited overview of the system 1000 but, it is to be understood that other embodiments are not limited thereto. Further, the system 1000 includes any number of hardware or software components communicating with each other. By way of illustration, both an application running on a device and the device itself can be a component.</p>
<p id="p0069" num="0069"><figref idref="f0002">FIG. 2</figref> is a block diagram of various hardware elements of a system for managing an operation based on devices context according to an embodiment of the disclosure.</p>
<p id="p0070" num="0070">Referring to <figref idref="f0002">FIG. 2</figref>, in an embodiment of the disclosure, the system 1000 includes the first electronic device 100 and the second electronic device 200. In an embodiment of the disclosure, the first electronic device 100 includes an input detector 110, a context detector 120, a controller 130, a storage unit 140, an application 150 and a processor 160. In an embodiment of the disclosure, the second electronic device 200 includes an input detector 210, a context detector 220, a controller 230, a storage unit<!-- EPO <DP n="14"> --> 240, an application 250, and a processor 260.</p>
<p id="p0071" num="0071">The processor 160 is in a communication with the input detector 110, the context detector 120, the controller 130, the storage unit 140, the application 150 and a communication unit (or a transceiver)(not shown). The input detector 110 is configured to detect the first input data and receive the second input data from the second electronic device 200. After receiving the second input data, the context detector 120 is configured to compare the first input data with the second input data. Based on a result of the comparison, the context detector 120 is configured to detect whether motion data of the first electronic device 100 and the second electronic device 200 is one of same hand and different hands. Based on the devices context, the controller 130 is configured to perform the operation.</p>
<p id="p0072" num="0072">In an example, the context detector 120 can be, for example but not limited to, a motion sensor and a proximity sensor. The motion sensor is configured to detect a linear movement of the first electronic device moving in a direction. The motion sensor outputs a motion data representing the linear movement and the direction corresponding to the movement. It should be noted that the linear movement is provided for illustration purpose. The embodiment is not intended to limit the direction of the movement. In an embodiment of the disclosure, the motion sensor may be implemented by, but not limited to, a g-sensor, such as an accelerometer or a gyroscope sensor (i.e., a gyro-sensor). For example, a three-axis accelerometer would output an acceleration corresponding to an axis in response to the movement of the first electronic device 100, so that the linear movement of the first electronic device 100 can be obtained.</p>
<p id="p0073" num="0073">Further, the motion information of the first electronic device 100 may include values obtained by sensing movement of the first electronic device 100 by using a geomagnetic sensor, a location sensor, an acceleration sensor, a proximity sensor, or a gyroscope sensor, for example, a directionality value, a velocity value, or an acceleration value of the first electronic device 100, but is not limited thereto.</p>
<p id="p0074" num="0074">In an embodiment of the disclosure, the context detector 120 is configured to determine one of the devices context as the same hand context based on detecting that the motion data of the first electronic device 100 and the second electronic device 200 is substantially same or similar.</p>
<p id="p0075" num="0075">In an embodiment of the disclosure, the context detector 120 is configured to determine one of the devices context as the same hand context based on detecting that the motion data of the first electronic device 100 and the second electronic device 200 is same.</p>
<p id="p0076" num="0076">In an embodiment of the disclosure, the context detector 120 is configured to determine one of the devices context as the different hand context based on detecting<!-- EPO <DP n="15"> --> that the motion data of the first electronic device 100 and the second electronic device 200 is different.</p>
<p id="p0077" num="0077">In an embodiment of the disclosure, the same hand context indicates that the first electronic device 100 and the second electronic device 200 are used by a same hand of a user.</p>
<p id="p0078" num="0078">In an embodiment of the disclosure, the different hand context indicates that the first electronic device 100 and the second electronic device 200 are not used by the same hand of a user.</p>
<p id="p0079" num="0079">Further, the controller 130 retrieves and compares motion of the first electronic device 100 and the second electronic device 200 and the related information stored in the storage unit 140. Further, the based on the devices context, the corresponding information associated with the applications 150 is mapped into corresponding behavior for processing by the controller 130.</p>
<p id="p0080" num="0080">The communication unit is configured for communicating internally between internal units and with external devices via one or more networks. The storage unit 140 may include one or more computer-readable storage media. The storage unit 140 may include non-volatile storage elements. Examples of such non-volatile storage elements may include magnetic hard disc, optical discs, floppy discs, flash memories, or forms of electrically programmable memories (EPROM) or electrically erasable and programmable (EEPROM) memories. In addition, the storage unit 140 may, in some examples, be considered a non-transitory storage medium. The term "non-transitory" may indicate that the storage medium is not embodied in a carrier wave or a propagated signal. However, the term "non-transitory" should not be interpreted that the storage unit 208 is non-movable. In some examples, the storage unit 208 can be configured to store larger amounts of information than a memory. In certain examples, a non-transitory storage medium may store data that can, over time, change (e.g., in a random access memory (RAM) or a cache).</p>
<p id="p0081" num="0081">Certain aspects of the disclosure can also be embodied as computer readable code on a non-transitory computer readable recording medium. A non-transitory computer readable recording medium is any data storage device that can store data which can be thereafter read by a computer system. Examples of the non-transitory computer readable recording medium include a read-only memory (ROM), a RAM, compact disc-ROMs (CD-ROMs), magnetic tapes, floppy disks, and optical data storage devices. The non-transitory computer readable recording medium can also be distributed over network coupled computer systems so that the computer readable code is stored and executed in a distributed fashion. In addition, functional programs, code, and code segments for accomplishing the disclosure can be easily construed by programmers skilled in the art to which the disclosure pertains.<!-- EPO <DP n="16"> --></p>
<p id="p0082" num="0082">At this point it should be noted that the various embodiments of the disclosure as described above typically involve the processing of input data and the generation of output data to some extent. This input data processing and output data generation may be implemented in hardware or software in combination with hardware. For example, specific electronic components may be employed in a mobile device or similar or related circuitry for implementing the functions associated with the various embodiments of the disclosure as described above. Alternatively, one or more processors operating in accordance with stored instructions may implement the functions associated with the various embodiments of the disclosure as described above. If such is the case, it is within the scope of the disclosure that such instructions may be stored on one or more non-transitory processor readable mediums. Examples of the processor readable mediums include a ROM, a RAM, CD-ROMs, magnetic tapes, floppy disks, and optical data storage devices. The processor readable mediums can also be distributed over network coupled computer systems so that the instructions are stored and executed in a distributed fashion. In addition, functional computer programs, instructions, and instruction segments for accomplishing the disclosure can be easily construed by programmers skilled in the art to which the disclosure pertains.</p>
<p id="p0083" num="0083">Further, the operations and functions of the input detector 210, the context detector 220, the controller 230, the storage unit 240 and the processor 260 of the second electronic device 200 are similar to the operations and functions of the input detector 110, the context detector 120, the controller 130, the storage unit 140 and the processor 160 150 of the first electronic device 100.</p>
<p id="p0084" num="0084">Although the <figref idref="f0002">FIG. 2</figref> shows the hardware elements of the system 1000 but it is to be understood that other embodiments are not limited thereon. In other embodiments of the disclosure, the system 1000 may include less or more number of hardware elements. Further, the labels or names of the hardware elements are used only for illustrative purpose and does not limit the scope of the disclosure. One or more hardware elements may be combined together to perform same or substantially similar function to manage the operation based on the device context.</p>
<p id="p0085" num="0085"><figref idref="f0003">FIG. 3A</figref> is a flow diagram illustrating a method for managing an operation based on devices context according to an embodiment of the disclosure.</p>
<p id="p0086" num="0086">Referring to <figref idref="f0003">FIG. 3A</figref>, at operation 302, the method includes detecting the first input data of the first electronic device 100. In an embodiment of the disclosure, the method allows the input detector 110 to detect the first input data of the first electronic device 100. At operation 304, the method includes receiving the second input data from the second electronic device 200. In an embodiment of the disclosure, the method allows the input detector 110 to receive the second input data from the second electronic device 200.<!-- EPO <DP n="17"> --></p>
<p id="p0087" num="0087">At operation 306, the method includes determining the devices context as same hand context or different hand context based on the first input data and the second input data. In an embodiment of the disclosure, the method allows the context detector 120 to determine the devices context as same hand context or different hand context based on the first input data and the second input data.</p>
<p id="p0088" num="0088">If the devices context is the different hand context then, operation 308, the method includes causing to perform the operation based on the different hand context. In an embodiment of the disclosure, the method allows the controller 130 to perform the operation based on the different hand context.</p>
<p id="p0089" num="0089">If the devices context is the same hand context then, operation 310, the method includes causing to perform the operation based on the same hand context. In an embodiment of the disclosure, the method allows the controller 130 to perform the operation based on the same hand context.</p>
<p id="p0090" num="0090">At operation 312, the method includes detecting the hand switch event on the first electronic device 100. In an embodiment of the disclosure, the method allows the context detector 120 to detect the hand switch event on the first electronic device 100. If the hand switch event occurs on the first electronic device 100 then, at operation 314, the method includes updating the determined devices context (i.e., a different hand context) based on the hand switch event. In an embodiment of the disclosure, the method allows the context detector 120 to update the determined devices context (i.e., a different hand context) based on the hand switch event. If the hand switch event does not occur on the first electronic device 100 then, at operation 316, the method performs the operation as usual.</p>
<p id="p0091" num="0091">The proposed method is executed based on comparison of events and motion for the first electronic device 100 and the second electronic device 200 in the following manner.</p>
<heading id="h0008"><u>Comparison of motion event detected by the second electronic device 200 (e.g..</u> a <u>smart watch) as the tap gesture over the display screen and corresponding the tap touch event over the first electronic device 100 (e.g.. a smart phone) with same time stamps</u></heading>
<p id="p0092" num="0092">Record if the tap motion event generated on the first electronic device 100 based on motion sensor of the second electronic device 200 with a current time stamp,
<ul id="ul0002" list-style="none" compact="compact">
<li>Record if the tap touch event is generated on the first electronic device 100 based on the display sensors with current time stamp,</li>
<li>Compare both events with time stamp and determine if same,</li>
<li>Control application launch and contents associated with that application based on above observation, and</li>
<li>Store different hand context i.e., both devices are in different hands in current session.</li>
</ul><!-- EPO <DP n="18"> --></p>
<heading id="h0009"><u>Comparison of motion event detected by the second electronic device 200 (e.g.,</u> a <u>smart watch) and corresponding motion event detected over the first electronic device 100 (e.g., a smart phone) with same time stamps</u></heading>
<p id="p0093" num="0093">Record if the motion event above a threshold average motion generated on the smart phone based on motion sensors with current time stamp,
<ul id="ul0003" list-style="none" compact="compact">
<li>Record if the motion event above the threshold average motion generated on the smart watch based on motion sensors with current time stamp,</li>
<li>Compare if the events are related,</li>
<li>If both events are same, then detect for same hand,</li>
<li>If both events are different, then detect for different hand, and</li>
<li>Associate same or different hand context for current session and customize user preferences accordingly.</li>
</ul></p>
<heading id="h0010"><u>Customize notifications for same hand context</u></heading>
<p id="p0094" num="0094">If notification for the event is generated in either device, determine if both devices in same/different hand,
<ul id="ul0004" list-style="none" compact="compact">
<li>For same hand, notifications to be displayed in one device only,</li>
<li>Determine currently active device i.e., either one of the devices with display ON or with current input device,</li>
<li>Determine if notification is related to which device, and</li>
<li>Direct notification to the active device with an indication if notification related to another device.</li>
</ul></p>
<heading id="h0011"><u>Control application running in smart watch for call event:</u></heading>
<p id="p0095" num="0095">If the incoming call event is generated in either device, determine if both the smart watch and smart phone are in same hand or different hand,
<ul id="ul0005" list-style="none" compact="compact">
<li>Wait for call being picked by the user,</li>
<li>If both devices in same hand, pause any application running in the smart watch,</li>
<li>If both devices in different hands, determine if the call is received over smart phone,</li>
<li>Determine if the display of the smart watch is off during the call using proximity sensor,</li>
<li>If both conditions (d) and (e) are true and the smart watch display is ON, direct input of the smart phone to the smart watch.</li>
</ul></p>
<p id="p0096" num="0096">The various actions, acts, blocks, operations, or the like in the flow diagram <figref idref="f0003">FIG. 3A</figref> may be performed in the order presented, in a different order or simultaneously. Further, in some embodiments of the disclosure, some of the actions, acts, blocks, operations, or the like may be omitted, added, modified, skipped, or the like without departing from the scope of the disclosure.</p>
<p id="p0097" num="0097"><figref idref="f0004">FIG. 3B</figref> is a flow diagram illustrating a method for determining devices context based on an input data of a first electronic device and input data of a second electronic<!-- EPO <DP n="19"> --> device according to an embodiment of the disclosure.</p>
<p id="p0098" num="0098">Referring to <figref idref="f0004">FIG. 3B</figref>, at operation 306a1, the method includes comparing the first input data with the second input data. In an embodiment of the disclosure, the method allows the context detector 120 to compare the first input data with the second input data. At operation 306a2, the method includes detecting whether motion data of the first electronic device 100 and the second electronic device 200 is one of same and different based on the comparison. In an embodiment of the disclosure, the method allows the context detector 120 to detect whether motion data of the first electronic device 100 and the second electronic device 200 is one of same and different based on a result of the comparison.</p>
<p id="p0099" num="0099">If the motion data of the first electronic device 100 and the second electronic device 100 is similar then, at operation 306a3, the method includes determining the devices context as the same hand context. In an embodiment of the disclosure, the method allows the context detector 120 to determine the devices context as the same hand context.</p>
<p id="p0100" num="0100">In an embodiment of the disclosure, similarity between the motion data of the first electronic device 100 and the second electronic device 200 is determined based on the motion threshold criteria.</p>
<p id="p0101" num="0101">In an embodiment of the disclosure, the motion threshold criteria includes a range comprising the upper limit and the lower limit dynamically determined based on one of the motion data of the first electronic device 100 and the motion data of the second electronic device 200.</p>
<p id="p0102" num="0102">If the motion data of the first electronic device 100 and the second electronic device 100 is different then, at operation 306a4, the method includes determining the devices context as the different hand context. In an embodiment of the disclosure, the method allows the context detector 120 to determine the devices context as the different hand context in response to detecting that the motion data of the first electronic device and the second electronic device is different.</p>
<p id="p0103" num="0103">The various actions, acts, blocks, operations, or the like in the flow diagram 306 may be performed in the order presented, in a different order or simultaneously. Further, in some embodiments of the disclosure, some of the actions, acts, blocks, operations, or the like may be omitted, added, modified, skipped, or the like without departing from the scope of the disclosure.</p>
<p id="p0104" num="0104"><figref idref="f0005">FIG. 3C</figref> is a flow diagram illustrating a method for determining devices context based on proximity and motion comparison according to an embodiment of the disclosure.</p>
<p id="p0105" num="0105">Referring to <figref idref="f0005">FIG. 3C</figref>, at operation 306b1, the method includes comparing the first input data with the second input data. In an embodiment of the disclosure, the method<!-- EPO <DP n="20"> --> allows the context detector 120 to compare the first input data with the second input data. At operation 306b2, the method includes determining the comparison result corresponding to the motion or proximity. In an embodiment of the disclosure, the method allows the context detector 120 to determine the comparison result corresponding to the motion or proximity.</p>
<p id="p0106" num="0106">If the comparison result corresponding to the motion then, at operation 306b3, the method includes determining the similar motion between the first electronic device 100 and the second electronic device 200 and proximity not increasing between the first electronic device 100 and the second electronic device 200. In an embodiment of the disclosure, the method allows the context detector 120 to determine the similar motion between the first electronic device 100 and the second electronic device 200 and proximity not increasing between the first electronic device 100 and the second electronic device 200.</p>
<p id="p0107" num="0107">If the similar motion is not occurred between the first electronic device 100 and the second electronic device 200 and proximity increasing between the first electronic device 100 and the second electronic device 200 then, at operation 306b4, the method includes performing the operation with different hand context. If the similar motion is occurred between the first electronic device 100 and the second electronic device 200 and proximity not increasing between the first electronic device 100 and the second electronic device 200 then, at operation 306b5, the method includes performing the operation with same hand context.</p>
<p id="p0108" num="0108">At operation 306b6, the method includes determining whether the proximity between the first electronic device 100 and the second electronic device 200 is increasing. If the proximity between the first electronic device 100 and the second electronic device 200 is increasing then, at operation 306b1, the method includes comparing the first input data with the second input data. If the proximity between the first electronic device 100 and the second electronic device 200 is not increasing then, the method performs the operation 306b3.</p>
<p id="p0109" num="0109">In an embodiment of the disclosure, the proximity between the first electronic device 100 and the second electronic device 200 is determined based on the proximity threshold criteria.</p>
<p id="p0110" num="0110">In an embodiment of the disclosure, the proximity threshold criteria includes a range includes the upper limit and the lower limit dynamically determined based on one of the input data of the first electronic device 100 and the input data of the second electronic device 200.</p>
<p id="p0111" num="0111">The various actions, acts, blocks, operations, or the like in the flow diagram 306 may be performed in the order presented, in a different order or simultaneously. Further, in some embodiments of the disclosure, some of the actions, acts, blocks, operations, or<!-- EPO <DP n="21"> --> the like may be omitted, added, modified, skipped, or the like without departing from the scope of the disclosure.</p>
<p id="p0112" num="0112"><figref idref="f0006">FIG. 4</figref> illustrates an operation being managed based on devices context according to an embodiment of the disclosure.</p>
<p id="p0113" num="0113">Referring to <figref idref="f0006">FIG. 4</figref>, assume that the smart watch is used by the left hand of the user and the smart phone is used by the right hand of the user. If the Bluetooth based proximity is not detected then the smart phone can map the input to the smart watch by using the motion-based control. If the Bluetooth based proximity is detected and the smart watch and the smart phone are used by the same hand (e.g., a right hand) of the user, then only one operation (e.g., an incoming call) on the first electronic device (e.g., a smart phone) is relevant at a time by using the motion-based control.</p>
<p id="p0114" num="0114"><figref idref="f0007">FIG. 5</figref> illustrates a first electronic device sending a request to regulate a playback rate of a media file played on a second electronic device, when a first electronic device receives an incoming call, and a first electronic device and a second electronic device are used by a same hand of a user, according to an embodiment of the disclosure.</p>
<p id="p0115" num="0115">Referring to <figref idref="f0007">FIG. 5</figref>, the smart watch and the smart phone are used by different hands of the user (i.e., the smart watch is used by the left hand of the user whereas the smart phone is used by right hand of the user). The user receives the event (e.g., an incoming call over the smart phone while there is a music application running in the smart watch). If the user wishes to switch the hand to receive the call from same hand as the smart watch is worn by the user, then the controller 130 compares the motion data of the smart watch and the smart phone. If the motion data of the smart watch and the smart phone is similar or same or substantially same or the motion data of the smart watch and the smart phone is within the threshold value then, the music application running over the smart watch is paused as the user will not be able to view the application on the smart watch.</p>
<p id="p0116" num="0116"><figref idref="f0008">FIG. 6</figref> illustrates a first electronic device sending a request to regulate a playback rate of a media file played on a second electronic device, when a first electronic device receives an incoming call and a first electronic device and a second electronic device are used by different hands of a user, according to an embodiment of the disclosure.</p>
<p id="p0117" num="0117">Referring to <figref idref="f0008">FIG. 6</figref>, the smart watch and the smart phone are used by different hands of the user (i.e., the smart watch is used by the left hand of the user whereas the smart phone is used by right hand of the user). If the user receives the event (e.g., an incoming call), over the smart phone while there is the music application running in the smart watch at a same time. If the user wishes to attend the call from same hand (i.e., a right hand), then the music application running is controlled based on a mapping input defined by the user as the motion data of the smart watch and the smart phone is similar.<!-- EPO <DP n="22"> --></p>
<p id="p0118" num="0118"><figref idref="f0009">FIG. 7</figref> illustrates a first electronic device sending a request to a second electronic device to enable an input over a screen off, when a first electronic device receives an incoming call and a first electronic device and a second electronic device are used by different hands of a user, according to an embodiment of the disclosure.</p>
<p id="p0119" num="0119">Referring to <figref idref="f0009">FIG. 7</figref>, the smart watch and the smart phone are used by different hands of the user (i.e., the smart watch is used by the left hand of the user and the smart phone is used by right hand of the user), and the user receives the incoming call on the smart phone. Further, the display screen of the smart phone is OFF during the call, then the user cannot operate with the display screen of the smart phone, so that the input over smart phone can be mapped to the corresponding gesture over the smart watch if the smart watch screen is ON.</p>
<p id="p0120" num="0120">In an example, assume that the smart watch is used by the left hand of the user and the smart phone is used by the right hand of the user and the display screen of the smart watch is off. If the user receives the incoming call over the smart phone while there is the application 250 running in the smart watch, then the user can navigate through the smart watch by providing input to the smart phone using a proximity sensor during the call. Further, a navigation panel/an input mechanism may be provided on the smart phone, either at the back to be used with index finger or at a front portion on the display screen to be used with thumb.</p>
<p id="p0121" num="0121"><figref idref="f0010">FIG. 8</figref> illustrates a first electronic device sending a notification to a second electronic device, when a first electronic device is an ongoing call, and a first electronic device and a second electronic device are used by a same hand of a user, according to an embodiment of the disclosure.</p>
<p id="p0122" num="0122">Referring to <figref idref="f0010">FIG. 8</figref>, when the first electronic device 100 and the second electronic device 200 are used by the same hand of the user, then the notifications can be prioritized to the any one of the electronic devices 100 or 200, so that the user doesn't has to switch between the first electronic device 100 and the second electronic device 200 for any the event. Based on the priority, all notification will be pushed to that specific device only.</p>
<p id="p0123" num="0123">In an example, assume that the smart watch and the smart phone are used by the same hand of the user, and the user is interacting with the smart watch. If the user receives the notification related to the smart phone then the notification is displayed on the smart watch instead of the smart phone as the user is interacting with the smart watch, so that the user doesn't have to switch frequently between the smart watch and the smart phone as shown in the <figref idref="f0010">FIG. 8</figref>.</p>
<p id="p0124" num="0124"><figref idref="f0011">FIG. 9</figref> illustrates a first electronic device sending a request to a second electronic device to switch a navigation from an audio mode to a haptic feedback mode, when a first electronic device receives an incoming call, and a first electronic device and a<!-- EPO <DP n="23"> --> second electronic device are used by different hands of a user, according to an embodiment of the disclosure.</p>
<p id="p0125" num="0125">Referring to <figref idref="f0011">FIG. 9</figref>, the smart watch is used by the left hand of the user and the smart phone is used by the right hand of the user. If the user of the smart phone receives the incoming call while using the navigation application on the smart watch then, it will be difficult for the user to provide the input to the smart watch from other arm holding the smart phone for the incoming call. The input mechanism for the smart watch can be changed to the gesture mode. Based on movements of the gestures, the input can be provided to the smart watch.</p>
<p id="p0126" num="0126"><figref idref="f0012">FIG. 10</figref> illustrates a first electronic device receives a notification from a second electronic device, when a display screen of a first electronic device is in an active mode, a display screen of a second electronic device is in an inactive mode, and a first electronic device and a second electronic device are used by a same hand of a user, according to an embodiment of the disclosure.</p>
<p id="p0127" num="0127">Referring to <figref idref="f0012">FIG. 10</figref>, the user is interacting with the smart phone, and the smart watch and the smart phone are used by a same hand of the user. If the user receives the notification related to the smart watch then the notification is displayed on the smart phone as the user is interacting with the smart phone and the motion data of the smart watch and the smart phone is similar, so that the user doesn't have to switch frequently between the smart watch and the smart phone.</p>
<p id="p0128" num="0128"><figref idref="f0012">FIG. 11</figref> illustrates a first electronic device sending a request to a second electronic device to switch a navigation from an audio mode to a haptic feedback mode, when a first electronic device receives an incoming call, and a first electronic device and a second electronic device are used by a same hand of a user, according to an embodiment of the disclosure.</p>
<p id="p0129" num="0129">Referring to <figref idref="f0012">FIG. 11</figref>, consider the smart watch and the smart phone is used by a same hand of the user. If the user receives the incoming call on the smart phone while using the navigation application in an audio mode on the smart watch then the only one device (i.e., a smart watch or a smart phone) can be used at a time in this scenario, so navigation will be switched from the audio mode to a haptic feedback mode to avoid interference with the call audio as the motion data of the smart watch and the smart phone is similar.</p>
<p id="p0130" num="0130"><figref idref="f0012">FIG. 12</figref> illustrates a second electronic device displaying a notification after a hand switch event, according to an embodiment of the disclosure.</p>
<p id="p0131" num="0131">Referring to <figref idref="f0012">FIG. 12</figref>, all notification events are prioritized on the smart phone to minimize switching between the smart phone and the smart watch. If the user switches the smart phone to the other arm from the arm in which user wears the smart watch then the application corresponding to the notification will open on the smart watch<!-- EPO <DP n="24"> --> within a threshold time based on a proximity based prioritizing event technique.</p>
<p id="p0132" num="0132"><figref idref="f0013">FIG. 13</figref> illustrates a first electronic device sending a request to a second electronic device to enable an input over a screen off, when a first electronic device receives an incoming call, and a first electronic device and a second electronic device are used by different hands of a user, according to an embodiment of the disclosure.</p>
<p id="p0133" num="0133">Referring to <figref idref="f0013">FIG. 13</figref>, the call accept gesture event is detected on the smart phone. After performing the call accept gesture event, the smart phone and the smart watch initiates the motion comparison and proximity detection. Based on the motion comparison and proximity detection, the smart phone determines the different hand context. Based on the different hand context, the smart phone provides the haptic feedback on the smart watch for enabling the input over the display screen off, and the smart watch receives the alert for input mode changed. Further, if the input dispatcher is ON when the display screen of the smart phone is OFF, then the haptic feedback is provided on the smart watch for receiving the mapped input. Once the display screen of the smart phone is ON, the smart watch receives the alert for the input mode changed.</p>
<p id="p0134" num="0134"><figref idref="f0014">FIG. 14</figref> illustrates a first electronic device sending a request to provide access to a private memory at a second electronic device, when a first electronic device and a second electronic device are used by different hands of a user, according to an embodiment of the disclosure.</p>
<p id="p0135" num="0135">Referring to <figref idref="f0014">FIG. 14</figref>, the tap event is detected over an application icon in the smart phone, a time generated event is compared between the smart phone tap and the motion detected in the smart watch. If both events are similar, then the smart phone can be deduced that the tap has been performed from the smart watch hand. Hence, based on this context, if the application to be opened contains hidden contents, then those contents will be visible to the user.</p>
<p id="p0136" num="0136"><figref idref="f0014">FIG. 15</figref> illustrates a computing environment implementing method for managing an operation based on a devices context according to an embodiment of the disclosure.</p>
<p id="p0137" num="0137">Referring to <figref idref="f0014">FIG. 15</figref>, a computing environment 1502 comprises at least one processing unit 1508 that is equipped with a control unit 1504, an arithmetic logic unit (ALU) 1506, a memory unit 1510, a storage unit 1512, a plurality of networking devices 1516 and a plurality of input output (I/O) devices 1514. The processing unit 1508 is responsible for processing the instructions of the technique. The processing unit 1508 receives commands from the control unit 1504 in order to perform its processing. Further, any logical and arithmetic operations involved in the execution of the instructions are computed with the help of the ALU 1506.</p>
<p id="p0138" num="0138">The overall computing environment 1502 can be composed of multiple homogeneous or heterogeneous cores, multiple CPUs of different kinds, special media and other accelerators.<!-- EPO <DP n="25"> --> The processing unit 1508 is responsible for processing the instructions of the technique. Further, the CPUs may be located on a single chip or over multiple chips.</p>
<p id="p0139" num="0139">The technique comprising of instructions and codes required for the implementation are stored in either the memory unit 1510 or the storage unit 1512 or both. At the time of execution, the instructions may be fetched from the corresponding memory unit 1510 or storage unit 1512, and executed by the processing unit 1508.</p>
<p id="p0140" num="0140">In case of any hardware implementations various networking devices 1516 or external I/O devices 1514 may be connected to the computing environment 1502 to support the implementation through the networking unit and the I/O device unit.</p>
<p id="p0141" num="0141">The embodiments disclosed herein can be implemented through at least one software program running on at least one hardware device and performing network management functions to control the elements. The elements shown in the <figref idref="f0001 f0002 f0003 f0004 f0005 f0006 f0007 f0008 f0009 f0010 f0011 f0012 f0013 f0014">FIGS. 1A to 15</figref> include blocks, elements, actions, acts, operations, or the like which can be at least one of a hardware device, or a combination of hardware device and software module.</p>
<p id="p0142" num="0142">While the disclosure has been shown and described with reference to various embodiments thereof, it will be understood that various changes in form and details may be made therein without departing from the scope of the invention as defined by the appended claims.</p>
</description>
<claims id="claims01" lang="en"><!-- EPO <DP n="26"> -->
<claim id="c-en-01-0001" num="0001">
<claim-text>A method for performing at least one operation based on a devices context by a first electronic device (100), the method comprising:
<claim-text>detecting a first data including first motion information inputted to the first electronic device and first proximity information of a second electronic device (200);</claim-text>
<claim-text>receiving from the second electronic device (200) a second data including second motion information inputted to the second electronic device (200) and second proximity information of the first electronic device (100);</claim-text>
<claim-text>identifying a similarity between the first motion information and the second motion information, and proximity between the first electronic device (100) and the second electronic device (200) based on the first proximity information and the second proximity information;</claim-text>
<claim-text>determining a devices context based on the similarity and the proximity; and</claim-text>
<claim-text>performing the at least one operation based on the determined devices context,</claim-text>
<claim-text>wherein the determined devices context comprises one of:
<claim-text>a same hand context indicating that the first electronic device (100) and the second electronic device (200) are used by a same hand of a user, and</claim-text>
<claim-text>a different hand context indicating that the first electronic device (100) and the second electronic device (200) are used by a different hand of the user.</claim-text></claim-text></claim-text></claim>
<claim id="c-en-01-0002" num="0002">
<claim-text>The method of claim 1, further comprising:
<claim-text>identifying a hand switch event indicating that the first electronic device or the second electronic device has been switched from one hand of the user to the other hand of the user; and</claim-text>
<claim-text>updating the determined devices context based on the hand switch event.</claim-text></claim-text></claim>
<claim id="c-en-01-0003" num="0003">
<claim-text>The method of claim 1, wherein the identifying of the similarity between the first motion information and the second motion information comprises:
<claim-text>comparing the first motion information and the second motion information; and</claim-text>
<claim-text>identifying whether the first motion information and the second motion information are similar or different based on a result of the comparison.</claim-text><!-- EPO <DP n="27"> --></claim-text></claim>
<claim id="c-en-01-0004" num="0004">
<claim-text>The method of claim 3, wherein the similarity between the first motion information and the second motion information is determined based on motion threshold criteria, and<br/>
wherein the motion threshold criteria comprises a range comprising an upper limit and a lower limit determined based on one of the first motion information or the second motion information.</claim-text></claim>
<claim id="c-en-01-0005" num="0005">
<claim-text>The method of claim 1, the identifying of the proximity between the first electronic device and the second electronic device comprises:
<claim-text>comparing the first proximity information with the second proximity information; and</claim-text>
<claim-text>identifying whether a proximity between the first electronic device (100) and the second electronic device (200) is within proximity threshold criteria based on a result of the comparison.</claim-text></claim-text></claim>
<claim id="c-en-01-0006" num="0006">
<claim-text>The method of claim 1, wherein the determining of the devices context based on the similarity and the proximity comprises:<br/>
determining the devices context as one of the same hand context in response to identifying that the first motion information and the second motion information are similar and identifying that the proximity of the first electronic device and the second electronic device is within proximity threshold criteria, and the different hand context in response to identifying that the first motion information and the second motion information is different and identifying that the proximity of the first electronic device and the second electronic device is not within proximity threshold criteria.</claim-text></claim>
<claim id="c-en-01-0007" num="0007">
<claim-text>The method of claim 5, wherein the proximity threshold criteria comprises a range comprising an upper limit and a lower limit determined based on one of the first proximity information or the second proximity information.</claim-text></claim>
<claim id="c-en-01-0008" num="0008">
<claim-text>The method of claim 1, wherein the first data is detected and the second data is received when an event is detected at the first electronic device (100).</claim-text></claim>
<claim id="c-en-01-0009" num="0009">
<claim-text>The method of claim 1, wherein the at least one operation includes a motion based operation comprising at least one of:
<claim-text>transmitting a request to regulate a playback rate of a media file to the second electronic device (200);<!-- EPO <DP n="28"> --></claim-text>
<claim-text>regulating a playback rate of a media file to the first electronic device;</claim-text>
<claim-text>transmitting a request to the second electronic device to enable an input over screen off;</claim-text>
<claim-text>enabling an input dispatcher over a screen off;</claim-text>
<claim-text>receiving an input at the first electronic device and mapping the received input to the second electronic device;</claim-text>
<claim-text>transmitting a notification received at the first electronic device to the second electronic device;</claim-text>
<claim-text>transmitting a request to the second electronic device to switch a navigation from an audio mode to a haptic feedback mode;</claim-text>
<claim-text>switching a navigation from the audio mode to the haptic feedback mode;</claim-text>
<claim-text>transmitting a request to provide access to a private memory at the second electronic device; or</claim-text>
<claim-text>providing an access to a private memory.</claim-text></claim-text></claim>
<claim id="c-en-01-0010" num="0010">
<claim-text>The method of claim 1, wherein the first motion information and the second motion information are measured at a same time period.</claim-text></claim>
<claim id="c-en-01-0011" num="0011">
<claim-text>A first electronic device (100), comprising:
<claim-text>a transceiver; and</claim-text>
<claim-text>at least one processor (160) coupled to the transceiver,</claim-text>
<claim-text>wherein the at least one processor is configured to:
<claim-text>detect a first data including first motion information inputted to the first electronic device and first proximity information of a second electronic device (200),</claim-text>
<claim-text>receive a second data from the second electronic device (200) including second motion information inputted to the second electronic device (200) and second proximity information of the first electronic device (100),</claim-text>
<claim-text>identify a similarity between the first motion information and the second motion information, and proximity between the first electronic device (100) and the second electronic device (200) based on the first proximity information and the second proximity information,</claim-text>
<claim-text>determine a devices context based on the similarity and the proximity, and perform at least one operation based on the determined devices context,</claim-text>
<claim-text>wherein the determined devices context comprises one of:
<claim-text>a same hand context indicating that the first electronic device (100) and the second electronic device (200) are used by a same hand of a user, and<!-- EPO <DP n="29"> --></claim-text>
<claim-text>a different hand context indicating that the first electronic device (100) and the second electronic device (200) are used by a different hand of the user.</claim-text></claim-text></claim-text></claim-text></claim>
<claim id="c-en-01-0012" num="0012">
<claim-text>The first electronic device (100) of claim 11, wherein the at least one processor (160) is further configured to perform the method described in one of claims 2 to 10.</claim-text></claim>
</claims>
<claims id="claims02" lang="de"><!-- EPO <DP n="30"> -->
<claim id="c-de-01-0001" num="0001">
<claim-text>Verfahren zum Durchführen mindestens einer Operation auf der Basis eines Gerätekontexts durch ein erstes elektronisches Gerät (100), wobei das Verfahren Folgendes beinhaltet:
<claim-text>Erfassen erster Daten einschließlich in das erste elektronische Gerät eingegebener erster Bewegungsinformationen und erster Näheinformationen eines zweiten elektronischen Geräts (200);</claim-text>
<claim-text>Empfangen, von dem zweiten elektronischen Gerät (200), zweiter Daten einschließlich in das zweite elektronische Gerät (200) eingegebener zweiter Bewegungsinformationen und zweiter Näheinformationen des ersten elektronischen Geräts (100);</claim-text>
<claim-text>Identifizieren einer Ähnlichkeit zwischen den ersten Bewegungsinformationen und den zweiten Bewegungsinformationen und von Nähe zwischen dem ersten elektronischen Gerät (100) und dem zweiten elektronischen Gerät (200) auf der Basis der ersten Näheinformationen und der zweiten Näheinformationen;</claim-text>
<claim-text>Bestimmen eines Gerätekontexts auf der Basis der Ähnlichkeit und der Nähe; und</claim-text>
<claim-text>Durchführen der mindestens einen Operation auf der Basis des bestimmten Gerätekontexts,</claim-text>
<claim-text>wobei der bestimmte Gerätekontext eines umfasst aus:
<claim-text>einem Selbe-Hand-Kontext, der anzeigt, dass das erste elektronische Gerät (100) und das zweite elektronische Gerät (200) von derselben Hand eines Benutzers benutzt werden, und</claim-text>
<claim-text>einem Verschiedene-Hände-Kontext, der anzeigt, dass das erste elektronische Gerät (100) und das<br/>
<!-- EPO <DP n="31"> -->zweite elektronische Gerät (200) von verschiedenen Händen des Benutzers benutzt werden.</claim-text></claim-text></claim-text></claim>
<claim id="c-de-01-0002" num="0002">
<claim-text>Verfahren nach Anspruch 1, das ferner Folgendes beinhaltet:
<claim-text>Identifizieren eines Handwechselereignisses, das anzeigt, dass das erste elektronische Gerät oder das zweite elektronische Gerät von einer Hand des Benutzers auf die andere Hand des Benutzers gewechselt wurde; und</claim-text>
<claim-text>Aktualisieren des bestimmten Gerätekontexts auf der Basis des Handwechselereignisses.</claim-text></claim-text></claim>
<claim id="c-de-01-0003" num="0003">
<claim-text>Verfahren nach Anspruch 1, wobei das Identifizieren der Ähnlichkeit zwischen den ersten Bewegungsinformationen und den zweiten Bewegungsinformationen Folgendes beinhaltet:
<claim-text>Vergleichen der ersten Bewegungsinformationen und der zweiten Bewegungsinformationen; und</claim-text>
<claim-text>Identifizieren auf der Basis eines Ergebnisses des Vergleichs, ob die ersten Bewegungsinformationen und die zweiten Bewegungsinformationen ähnlich oder unterschiedlich sind.</claim-text></claim-text></claim>
<claim id="c-de-01-0004" num="0004">
<claim-text>Verfahren nach Anspruch 3, wobei die Ähnlichkeit zwischen den ersten Bewegungsinformationen und den zweiten Bewegungsinformationen auf der Basis von Bewegungsschwellenkriterien bestimmt wird, und<br/>
wobei die Bewegungsschwellenkriterien einen Bereich mit einer Obergrenze und einer Untergrenze umfassen, die auf der Basis der ersten Bewegungsinformationen oder der zweiten Bewegungsinformationen bestimmt werden.<!-- EPO <DP n="32"> --></claim-text></claim>
<claim id="c-de-01-0005" num="0005">
<claim-text>Verfahren nach Anspruch 1, wobei das Identifizieren der Nähe zwischen dem ersten elektronischen Gerät und dem zweiten elektronischen Gerät Folgendes beinhaltet:
<claim-text>Vergleichen der ersten Näheinformationen mit den zweiten Näheinformationen; und</claim-text>
<claim-text>Identifizieren auf der Basis eines Ergebnisses des Vergleichs, ob eine Nähe zwischen dem ersten elektronischen Gerät (100) und dem zweiten elektronischen Gerät (200) innerhalb von Näheschwellenkriterien liegt.</claim-text></claim-text></claim>
<claim id="c-de-01-0006" num="0006">
<claim-text>Verfahren nach Anspruch 1, wobei das Bestimmen des Gerätekontexts auf der Basis der Ähnlichkeit und der Nähe Folgendes beinhaltet:<br/>
Bestimmen des Gerätekontexts als einer von Selbe-Hand-Kontext als Reaktion auf das Identifizieren, dass die ersten Bewegungsinformationen und die zweiten Bewegungsinformationen ähnlich sind, und das Identifizieren, dass die Nähe des ersten elektronischen Geräts und des zweiten elektronischen Geräts innerhalb der Näheschwellenkriterien liegt, und Verschiedene-Hände-Kontext als Reaktion auf das Identifizieren, dass die ersten Bewegungsinformationen und die zweiten Bewegungsinformationen unterschiedlich sind, und das Identifizieren, dass die Nähe des ersten elektronischen Geräts und des zweiten elektronischen Geräts nicht innerhalb der Näheschwellenkriterien liegt.</claim-text></claim>
<claim id="c-de-01-0007" num="0007">
<claim-text>Verfahren nach Anspruch 5, wobei das Näheschwellenkriterium einen Bereich mit einer Obergrenze und einer Untergrenze umfasst, die auf der Basis der ersten Näheinformationen oder der zweiten Näheinformationen bestimmt werden.<!-- EPO <DP n="33"> --></claim-text></claim>
<claim id="c-de-01-0008" num="0008">
<claim-text>Verfahren nach Anspruch 1, wobei die ersten Daten erfasst und die zweiten Daten empfangen werden, wenn ein Ereignis am ersten elektronischen Gerät (100) erfasst wird.</claim-text></claim>
<claim id="c-de-01-0009" num="0009">
<claim-text>Verfahren nach Anspruch 1, wobei die mindestens eine Operation eine bewegungsbasierte Operation umfasst, die mindestens eines umfasst aus:
<claim-text>Übertragen einer Anforderung zum Regulieren einer Wiedergaberate einer Mediendatei zum zweiten elektronischen Gerät (200);</claim-text>
<claim-text>Regulieren einer Wiedergaberate einer Mediendatei an dem ersten elektronischen Gerät;</claim-text>
<claim-text>Übertragen einer Anforderung zum zweiten elektronischen Gerät zum Ermöglichen einer Eingabe über ausgeschalteten Bildschirm;</claim-text>
<claim-text>Aktivieren eines Eingabe-Dispatchers über einen ausgeschalteten Bildschirm;</claim-text>
<claim-text>Empfangen einer Eingabe am ersten elektronischen Gerät und Abbilden der empfangenen Eingabe auf das zweite elektronische Gerät;</claim-text>
<claim-text>Übertragen einer am ersten elektronischen Gerät empfangenen Mitteilung zum zweiten elektronischen Gerät;</claim-text>
<claim-text>Übertragen einer Aufforderung zum zweiten elektronischen Gerät zum Umschalten einer Navigation von einem Audiomodus in einem Haptisches-Feedback-Modus;</claim-text>
<claim-text>Umschalten einer Navigation vom Audiomodus in den Haptisches-Feedback-Modus;</claim-text>
<claim-text>Übertragen einer Aufforderung für Zugang zu einem privaten Speicher am zweiten elektronischen Gerät; oder</claim-text>
<claim-text>Bieten von Zugang zu einem privaten Speicher.</claim-text><!-- EPO <DP n="34"> --></claim-text></claim>
<claim id="c-de-01-0010" num="0010">
<claim-text>Verfahren nach Anspruch 1, wobei die ersten Bewegungsinformationen und die zweiten Bewegungsinformationen im selben Zeitraum gemessen werden.</claim-text></claim>
<claim id="c-de-01-0011" num="0011">
<claim-text>Erstes elektronisches Gerät (100), das Folgendes umfasst:
<claim-text>einen Transceiver; und</claim-text>
<claim-text>mindestens einen mit dem Transceiver gekoppelten Prozessor (160),</claim-text>
<claim-text>wobei der mindestens eine Prozessor konfiguriert ist zum:
<claim-text>Erfassen erster Daten einschließlich in das erste elektronische Gerät eingegebener erster Bewegungsinformationen und erster Näheinformationen eines zweiten elektronischen Geräts (200);</claim-text>
<claim-text>Empfangen, vom zweiten elektronischen Gerät (200), zweiter Daten einschließlich in das zweite elektronische Gerät (200) eingegebener zweiter Bewegungsinformationen und zweiter Näheinformationen des ersten elektronischen Geräts (100) ;</claim-text>
<claim-text>Identifizieren einer Ähnlichkeit zwischen den ersten Bewegungsinformationen und den zweiten Bewegungsinformationen und von Nähe zwischen dem ersten elektronischen Gerät (100) und dem zweiten elektronischen Gerät (200) auf der Basis der ersten Näheinformationen und der zweiten Näheinformationen;</claim-text>
<claim-text>Bestimmen eines Gerätekontexts auf der Basis der Ähnlichkeit und der Nähe; und</claim-text>
<claim-text>Durchführen mindestens einer Operation auf der Basis des bestimmten Gerätekontexts,</claim-text>
<claim-text>wobei der bestimmte Gerätekontext eines umfasst aus:
<claim-text>einem Selbe-Hand-Kontext, der anzeigt, dass das erste elektronische Gerät (100) und das zweite elektronische<!-- EPO <DP n="35"> --> Gerät (200) von derselben Hand eines Benutzers benutzt werden, und</claim-text>
<claim-text>einen Verschiedene-Hände-Kontext, der anzeigt, dass das erste elektronische Gerät (100) und das zweite elektronische Gerät (200) von verschiedenen Händen des Benutzers benutzt werden.</claim-text></claim-text></claim-text></claim-text></claim>
<claim id="c-de-01-0012" num="0012">
<claim-text>Erstes elektronisches Gerät (100) nach Anspruch 11, wobei der mindestens eine Prozessor (160) ferner zum Durchführen des in einem der Ansprüche 2 bis 10 beschriebenen Verfahrens konfiguriert ist.</claim-text></claim>
</claims>
<claims id="claims03" lang="fr"><!-- EPO <DP n="36"> -->
<claim id="c-fr-01-0001" num="0001">
<claim-text>Procédé de réalisation d'au moins une opération d'après un contexte de dispositifs par un premier dispositif électronique (100), le procédé comprenant :
<claim-text>la détection d'une première donnée incluant des premières informations de mouvement entrées dans le premier dispositif électronique et des premières informations de proximité d'un second dispositif électronique (200) ;</claim-text>
<claim-text>la réception en provenance du second dispositif électronique (200) d'une seconde donnée incluant des secondes informations de mouvement entrées dans le second dispositif électronique (200) et des secondes informations de proximité du premier dispositif électronique (100) ;</claim-text>
<claim-text>l'identification d'une similarité entre les premières informations de mouvement et les secondes informations de mouvement, et d'une proximité entre le premier dispositif électronique (100) et le second dispositif électronique (200) d'après les premières informations de proximité et les secondes informations de proximité ;</claim-text>
<claim-text>la détermination d'un contexte de dispositifs d'après la similarité et la proximité ; et</claim-text>
<claim-text>la réalisation de l'au moins une opération d'après le contexte de dispositifs déterminé,</claim-text>
<claim-text>dans lequel le contexte de dispositifs déterminé comprend l'un des contextes suivants :
<claim-text>un contexte de même main indiquant que le premier dispositif électronique (100) et le second dispositif électronique (200) sont utilisés par une même main d'un utilisateur, et</claim-text>
<claim-text>un contexte de main différente indiquant que le premier dispositif électronique (100) et le second<!-- EPO <DP n="37"> --> dispositif électronique (200) sont utilisés par une main différente de l'utilisateur.</claim-text></claim-text></claim-text></claim>
<claim id="c-fr-01-0002" num="0002">
<claim-text>Procédé selon la revendication 1, comprenant en outre :
<claim-text>l'identification d'un événement de commutation de main indiquant que le premier dispositif électronique ou le second dispositif électronique a été commuté d'une main de l'utilisateur vers l'autre main de l'utilisateur ; et</claim-text>
<claim-text>la mise à jour du contexte de dispositifs déterminé d'après l'événement de commutation de main.</claim-text></claim-text></claim>
<claim id="c-fr-01-0003" num="0003">
<claim-text>Procédé selon la revendication 1, dans lequel l'identification de la similarité entre les premières informations de mouvement et les secondes informations de mouvement comprend :
<claim-text>la comparaison des premières informations de mouvement et des secondes informations de mouvement ; et</claim-text>
<claim-text>l'identification si oui ou non les premières informations de mouvement et les secondes informations de mouvement sont similaires ou différentes d'après un résultat de la comparaison.</claim-text></claim-text></claim>
<claim id="c-fr-01-0004" num="0004">
<claim-text>Procédé selon la revendication 3, dans lequel la similarité entre les premières informations de mouvement et les secondes informations de mouvement est déterminée d'après des critères de seuil de mouvement, et<br/>
dans lequel les critères de seuil de mouvement comprennent une plage comprenant une limite supérieure et une limite inférieure déterminées d'après les premières informations de mouvement ou les secondes informations de mouvement.<!-- EPO <DP n="38"> --></claim-text></claim>
<claim id="c-fr-01-0005" num="0005">
<claim-text>Procédé selon la revendication 1, l'identification de la proximité entre le premier dispositif électronique et le second dispositif électronique comprenant :
<claim-text>la comparaison des premières informations de proximité et des secondes informations de proximité ; et</claim-text>
<claim-text>l'identification si oui ou non une proximité entre le premier dispositif électronique (100) et le second dispositif électronique (200) remplit des critères de seuil de proximité d'après un résultat de la comparaison.</claim-text></claim-text></claim>
<claim id="c-fr-01-0006" num="0006">
<claim-text>Procédé selon la revendication 1, dans lequel la détermination du contexte de dispositifs d'après la similarité et la proximité comprend :<br/>
la détermination du contexte de dispositifs comme l'un du contexte de même main en réponse à l'identification que les premières informations de mouvement et les secondes informations de mouvement sont similaires et à l'identification que la proximité du premier dispositif électronique et du second dispositif électronique remplit des critères de seuil de proximité, et du contexte de main différente en réponse à l'identification que les premières informations de mouvement et les secondes informations de mouvement sont différentes et à l'identification que la proximité du premier dispositif électronique et du second dispositif électronique ne remplit pas les critères de seuil de proximité.</claim-text></claim>
<claim id="c-fr-01-0007" num="0007">
<claim-text>Procédé selon la revendication 5, dans lequel les critères de seuil de proximité comprennent une plage comprenant une limite supérieure et une limite inférieure déterminées d'après les premières informations de proximité ou les secondes informations de proximité.<!-- EPO <DP n="39"> --></claim-text></claim>
<claim id="c-fr-01-0008" num="0008">
<claim-text>Procédé selon la revendication 1, dans lequel la première donnée est détectée et la seconde donnée est reçue lorsqu'un événement est détecté au niveau du premier dispositif électronique (100).</claim-text></claim>
<claim id="c-fr-01-0009" num="0009">
<claim-text>Procédé selon la revendication 1, dans lequel l'au moins une opération inclut une opération d'après un mouvement comprenant au moins l'une des actions suivantes :
<claim-text>la transmission d'une demande de régulation d'une vitesse de lecture d'un fichier multimédia au second dispositif électronique (200) ;</claim-text>
<claim-text>la régulation d'une vitesse de lecture d'un fichier multimédia vers le premier dispositif électronique ;</claim-text>
<claim-text>la transmission d'une demande au second dispositif électronique pour permettre une entrée sur un écran éteint ;</claim-text>
<claim-text>la permission d'un répartiteur d'entrée sur un écran éteint ;</claim-text>
<claim-text>la réception d'une entrée au niveau du premier dispositif électronique et le mappage de l'entrée reçue au second dispositif électronique ;</claim-text>
<claim-text>la transmission d'une notification reçue au niveau du premier dispositif électronique au second dispositif électronique ;</claim-text>
<claim-text>la transmission d'une demande au second dispositif électronique pour commuter une navigation d'un mode audio vers un mode de rétroaction haptique ;</claim-text>
<claim-text>la commutation d'une navigation du mode audio vers le mode de rétroaction haptique ;</claim-text>
<claim-text>la transmission d'une demande de fourniture d'accès à une mémoire privée au niveau du second dispositif électronique ; ou</claim-text>
<claim-text>la fourniture d'un accès à une mémoire privée.</claim-text><!-- EPO <DP n="40"> --></claim-text></claim>
<claim id="c-fr-01-0010" num="0010">
<claim-text>Procédé selon la revendication 1, dans lequel les premières informations de mouvement et les secondes informations de mouvement sont mesurées sur une même période.</claim-text></claim>
<claim id="c-fr-01-0011" num="0011">
<claim-text>Premier dispositif électronique (100), comprenant :
<claim-text>un émetteur-récepteur ; et</claim-text>
<claim-text>au moins un processeur (160) couplé à l'émetteur-récepteur,</claim-text>
<claim-text>dans lequel l'au moins un processeur est configuré pour :
<claim-text>détecter une première donnée incluant des premières informations de mouvement entrées dans le premier dispositif électronique et des premières informations de proximité d'un second dispositif électronique (200),</claim-text>
<claim-text>recevoir une seconde donnée du second dispositif électronique (200) incluant des secondes informations de mouvement entrées dans le second dispositif électronique (200) et des secondes informations de proximité du premier dispositif électronique (100),</claim-text>
<claim-text>identifier une similarité entre les premières informations de mouvement et les secondes informations de mouvement, et une proximité entre le premier dispositif électronique (100) et le second dispositif électronique (200) d'après les premières informations de proximité et les secondes informations de proximité,</claim-text>
<claim-text>déterminer un contexte de dispositifs d'après la similarité et la proximité, et réaliser au moins une opération d'après le contexte de dispositifs déterminé,</claim-text>
<claim-text>dans lequel le contexte de dispositifs déterminé comprend l'un des contextes suivants :<!-- EPO <DP n="41"> -->
<claim-text>un contexte de même main indiquant que le premier dispositif électronique (100) et le second dispositif électronique (200) sont utilisés par une même main d'un utilisateur, et</claim-text>
<claim-text>un contexte de main différente indiquant que le premier dispositif électronique (100) et le second dispositif électronique (200) sont utilisés par une main différente de l'utilisateur.</claim-text></claim-text></claim-text></claim-text></claim>
<claim id="c-fr-01-0012" num="0012">
<claim-text>Premier dispositif électronique (100) selon la revendication 11, dans lequel l'au moins un processeur (160) est en outre configuré pour réaliser le procédé décrit dans l'une des revendications 2 à 10.</claim-text></claim>
</claims>
<drawings id="draw" lang="en"><!-- EPO <DP n="42"> -->
<figure id="f0001" num="1A,1B"><img id="if0001" file="imgf0001.tif" wi="146" he="165" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="43"> -->
<figure id="f0002" num="2"><img id="if0002" file="imgf0002.tif" wi="123" he="144" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="44"> -->
<figure id="f0003" num="3A"><img id="if0003" file="imgf0003.tif" wi="138" he="205" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="45"> -->
<figure id="f0004" num="3B"><img id="if0004" file="imgf0004.tif" wi="130" he="119" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="46"> -->
<figure id="f0005" num="3C"><img id="if0005" file="imgf0005.tif" wi="136" he="142" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="47"> -->
<figure id="f0006" num="4"><img id="if0006" file="imgf0006.tif" wi="108" he="224" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="48"> -->
<figure id="f0007" num="5"><img id="if0007" file="imgf0007.tif" wi="141" he="53" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="49"> -->
<figure id="f0008" num="6"><img id="if0008" file="imgf0008.tif" wi="70" he="205" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="50"> -->
<figure id="f0009" num="7"><img id="if0009" file="imgf0009.tif" wi="46" he="194" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="51"> -->
<figure id="f0010" num="8"><img id="if0010" file="imgf0010.tif" wi="116" he="70" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="52"> -->
<figure id="f0011" num="9"><img id="if0011" file="imgf0011.tif" wi="60" he="227" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="53"> -->
<figure id="f0012" num="10,11,12"><img id="if0012" file="imgf0012.tif" wi="134" he="200" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="54"> -->
<figure id="f0013" num="13"><img id="if0013" file="imgf0013.tif" wi="122" he="207" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="55"> -->
<figure id="f0014" num="14,15"><img id="if0014" file="imgf0014.tif" wi="124" he="170" img-content="drawing" img-format="tif"/></figure>
</drawings>
<ep-reference-list id="ref-list">
<heading id="ref-h0001"><b>REFERENCES CITED IN THE DESCRIPTION</b></heading>
<p id="ref-p0001" num=""><i>This list of references cited by the applicant is for the reader's convenience only. It does not form part of the European patent document. Even though great care has been taken in compiling the references, errors or omissions cannot be excluded and the EPO disclaims all liability in this regard.</i></p>
<heading id="ref-h0002"><b>Patent documents cited in the description</b></heading>
<p id="ref-p0002" num="">
<ul id="ref-ul0001" list-style="bullet">
<li><patcit id="ref-pcit0001" dnum="US2016098091A1"><document-id><country>US</country><doc-number>2016098091</doc-number><kind>A1</kind></document-id></patcit><crossref idref="pcit0001">[0002]</crossref></li>
<li><patcit id="ref-pcit0002" dnum="US20150022438A1"><document-id><country>US</country><doc-number>20150022438</doc-number><kind>A1</kind></document-id></patcit><crossref idref="pcit0002">[0003]</crossref></li>
</ul></p>
</ep-reference-list>
</ep-patent-document>
